diff,label,Model 1,Model 2,Model 3,Model 4,Choice
"diff --git a/release.gradle b/release.gradle
index ab3472c..c1d8557 100644
--- a/release.gradle
+++ b/release.gradle
@@ -15,8 +15,8 @@ task commitRelease(type: Exec) {
 task createGithubRelease(type: Exec) {
     def versionName = getVersionName()
     def jsonData = JsonOutput.toJson([
-            tag_name: ""v$versionName"",
-            name    : ""v$versionName"",
+            tag_name: ""$versionName"",
+            name    : ""$versionName"",
             draft   : true])
     commandLine ""curl"", ""--data"", jsonData, ""-u"", ""amlcurran:"" + System.getenv('GITHUB_TOKEN'), ""https://api.github.com/repos/amlcurran/ShowcaseView/releases""
 }","Remove \"" v \"" from release and tag name","""Remove 'v' prefix from GitHub release tag and name""","""Remove version prefix from GitHub release name and tag""","Update tag_name and name in createGithubRelease task

The changes in the code are:

- The `tag_name` and `name` in the `jsonData` object no longer have a ""v"" prefix for the version name.

Here is the updated code for the `createGithubRelease` task:

```groovy
task createGithubRelease(type: Exec) {
    def versionName = getVersionName()
    def jsonData = JsonOutput.toJson([
        tag_name: ""$versionName"",
        name    : ""$versionName"",
        draft   : true])
    commandLine ""curl"", ""--data"", jsonData, ""-u"", ""amlcurran:"" + System.getenv('GITHUB_TOKEN'), ""https://api.github.com/repos/amlcurran/ShowcaseView/releases""
}
```

This change will affect how the version is displayed on the GitHub release page. The ""v"" prefix will no longer be automatically added, so if you want to include it, you will need to update the `getVersionName()` function to return the version name with the prefix.",Simplified tag and release name by removing 'v' prefix in createGithubRelease task within release.gradle.,Model 1
"diff --git a/distro/sql-script/upgrade/db2_engine_7.7_patch_7.7.4_to_7.7.5.sql b/distro/sql-script/upgrade/db2_engine_7.7_patch_7.7.4_to_7.7.5.sql
new file mode 100644
index 0000000000..404dd4378f
--- /dev/null
+++ b/distro/sql-script/upgrade/db2_engine_7.7_patch_7.7.4_to_7.7.5.sql
@@ -0,0 +1,14 @@
+-- insert indices for history cleanup - https://app.camunda.com/jira/browse/CAM-8184 --
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
\ No newline at end of file
diff --git a/distro/sql-script/upgrade/h2_engine_7.7_patch_7.7.4_to_7.7.5.sql b/distro/sql-script/upgrade/h2_engine_7.7_patch_7.7.4_to_7.7.5.sql
new file mode 100644
index 0000000000..404dd4378f
--- /dev/null
+++ b/distro/sql-script/upgrade/h2_engine_7.7_patch_7.7.4_to_7.7.5.sql
@@ -0,0 +1,14 @@
+-- insert indices for history cleanup - https://app.camunda.com/jira/browse/CAM-8184 --
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
\ No newline at end of file
diff --git a/distro/sql-script/upgrade/mariadb_engine_7.7_patch_7.7.4_to_7.7.5.sql b/distro/sql-script/upgrade/mariadb_engine_7.7_patch_7.7.4_to_7.7.5.sql
new file mode 100644
index 0000000000..404dd4378f
--- /dev/null
+++ b/distro/sql-script/upgrade/mariadb_engine_7.7_patch_7.7.4_to_7.7.5.sql
@@ -0,0 +1,14 @@
+-- insert indices for history cleanup - https://app.camunda.com/jira/browse/CAM-8184 --
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
\ No newline at end of file
diff --git a/distro/sql-script/upgrade/mssql_engine_7.7_patch_7.7.4_to_7.7.5.sql b/distro/sql-script/upgrade/mssql_engine_7.7_patch_7.7.4_to_7.7.5.sql
new file mode 100644
index 0000000000..404dd4378f
--- /dev/null
+++ b/distro/sql-script/upgrade/mssql_engine_7.7_patch_7.7.4_to_7.7.5.sql
@@ -0,0 +1,14 @@
+-- insert indices for history cleanup - https://app.camunda.com/jira/browse/CAM-8184 --
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
\ No newline at end of file
diff --git a/distro/sql-script/upgrade/mysql_engine_7.7_patch_7.7.4_to_7.7.5.sql b/distro/sql-script/upgrade/mysql_engine_7.7_patch_7.7.4_to_7.7.5.sql
new file mode 100644
index 0000000000..404dd4378f
--- /dev/null
+++ b/distro/sql-script/upgrade/mysql_engine_7.7_patch_7.7.4_to_7.7.5.sql
@@ -0,0 +1,14 @@
+-- insert indices for history cleanup - https://app.camunda.com/jira/browse/CAM-8184 --
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
\ No newline at end of file
diff --git a/distro/sql-script/upgrade/oracle_engine_7.7_patch_7.7.4_to_7.7.5.sql b/distro/sql-script/upgrade/oracle_engine_7.7_patch_7.7.4_to_7.7.5.sql
new file mode 100644
index 0000000000..404dd4378f
--- /dev/null
+++ b/distro/sql-script/upgrade/oracle_engine_7.7_patch_7.7.4_to_7.7.5.sql
@@ -0,0 +1,14 @@
+-- insert indices for history cleanup - https://app.camunda.com/jira/browse/CAM-8184 --
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
\ No newline at end of file
diff --git a/distro/sql-script/upgrade/postgres_engine_7.7_patch_7.7.4_to_7.7.5.sql b/distro/sql-script/upgrade/postgres_engine_7.7_patch_7.7.4_to_7.7.5.sql
new file mode 100644
index 0000000000..404dd4378f
--- /dev/null
+++ b/distro/sql-script/upgrade/postgres_engine_7.7_patch_7.7.4_to_7.7.5.sql
@@ -0,0 +1,14 @@
+-- insert indices for history cleanup - https://app.camunda.com/jira/browse/CAM-8184 --
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
\ No newline at end of file
diff --git a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.db2.create.history.sql b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.db2.create.history.sql
index d0b6cf3a6b..3fc5f04530 100644
--- a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.db2.create.history.sql
+++ b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.db2.create.history.sql
@@ -292,6 +292,8 @@ create index ACT_IDX_HI_ACT_INST_PROC_DEF_KEY on ACT_HI_ACTINST(PROC_DEF_KEY_);
 
 create index ACT_IDX_HI_TASK_INST_TENANT_ID on ACT_HI_TASKINST(TENANT_ID_);
 create index ACT_IDX_HI_TASK_INST_PROC_DEF_KEY on ACT_HI_TASKINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
 
 create index ACT_IDX_HI_DETAIL_PROC_INST on ACT_HI_DETAIL(PROC_INST_ID_);
 create index ACT_IDX_HI_DETAIL_ACT_INST on ACT_HI_DETAIL(ACT_INST_ID_);
@@ -302,33 +304,44 @@ create index ACT_IDX_HI_DETAIL_NAME on ACT_HI_DETAIL(NAME_);
 create index ACT_IDX_HI_DETAIL_TASK_ID on ACT_HI_DETAIL(TASK_ID_);
 create index ACT_IDX_HI_DETAIL_TENANT_ID on ACT_HI_DETAIL(TENANT_ID_);
 create index ACT_IDX_HI_DETAIL_PROC_DEF_KEY on ACT_HI_DETAIL(PROC_DEF_KEY_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_IDENT_LNK_USER on ACT_HI_IDENTITYLINK(USER_ID_);
 create index ACT_IDX_HI_IDENT_LNK_GROUP on ACT_HI_IDENTITYLINK(GROUP_ID_);
 create index ACT_IDX_HI_IDENT_LNK_TENANT_ID on ACT_HI_IDENTITYLINK(TENANT_ID_);
 create index ACT_IDX_HI_IDENT_LNK_PROC_DEF_KEY on ACT_HI_IDENTITYLINK(PROC_DEF_KEY_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
 
 create index ACT_IDX_HI_PROCVAR_PROC_INST on ACT_HI_VARINST(PROC_INST_ID_);
 create index ACT_IDX_HI_PROCVAR_NAME_TYPE on ACT_HI_VARINST(NAME_, VAR_TYPE_);
 create index ACT_IDX_HI_CASEVAR_CASE_INST on ACT_HI_VARINST(CASE_INST_ID_);
 create index ACT_IDX_HI_VAR_INST_TENANT_ID on ACT_HI_VARINST(TENANT_ID_);
 create index ACT_IDX_HI_VAR_INST_PROC_DEF_KEY on ACT_HI_VARINST(PROC_DEF_KEY_);
-
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_INCIDENT_TENANT_ID on ACT_HI_INCIDENT(TENANT_ID_);
 create index ACT_IDX_HI_INCIDENT_PROC_DEF_KEY on ACT_HI_INCIDENT(PROC_DEF_KEY_);
-
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
 
 create index ACT_IDX_HI_JOB_LOG_PROCINST on ACT_HI_JOB_LOG(PROCESS_INSTANCE_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROCDEF on ACT_HI_JOB_LOG(PROCESS_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_TENANT_ID on ACT_HI_JOB_LOG(TENANT_ID_);
 create index ACT_IDX_HI_JOB_LOG_JOB_DEF_ID on ACT_HI_JOB_LOG(JOB_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROC_DEF_KEY on ACT_HI_JOB_LOG(PROCESS_DEF_KEY_);
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
 
 create index ACT_HI_EXT_TASK_LOG_PROCINST on ACT_HI_EXT_TASK_LOG(PROC_INST_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROCDEF on ACT_HI_EXT_TASK_LOG(PROC_DEF_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROC_DEF_KEY on ACT_HI_EXT_TASK_LOG(PROC_DEF_KEY_);
 create index ACT_HI_EXT_TASK_LOG_TENANT_ID on ACT_HI_EXT_TASK_LOG(TENANT_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
 
 create index ACT_IDX_HI_OP_LOG_PROCINST on ACT_HI_OP_LOG(PROC_INST_ID_);
 create index ACT_IDX_HI_OP_LOG_PROCDEF on ACT_HI_OP_LOG(PROC_DEF_ID_);
+
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
\ No newline at end of file
diff --git a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.h2.create.history.sql b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.h2.create.history.sql
index 598235780e..128177edfc 100644
--- a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.h2.create.history.sql
+++ b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.h2.create.history.sql
@@ -297,35 +297,49 @@ create index ACT_IDX_HI_DETAIL_NAME on ACT_HI_DETAIL(NAME_);
 create index ACT_IDX_HI_DETAIL_TASK_ID on ACT_HI_DETAIL(TASK_ID_);
 create index ACT_IDX_HI_DETAIL_TENANT_ID on ACT_HI_DETAIL(TENANT_ID_);
 create index ACT_IDX_HI_DETAIL_PROC_DEF_KEY on ACT_HI_DETAIL(PROC_DEF_KEY_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_IDENT_LNK_USER on ACT_HI_IDENTITYLINK(USER_ID_);
 create index ACT_IDX_HI_IDENT_LNK_TENANT_ID on ACT_HI_IDENTITYLINK(TENANT_ID_);
 create index ACT_IDX_HI_IDENT_LNK_GROUP on ACT_HI_IDENTITYLINK(GROUP_ID_);
 create index ACT_IDX_HI_IDENT_LNK_PROC_DEF_KEY on ACT_HI_IDENTITYLINK(PROC_DEF_KEY_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
 
 create index ACT_IDX_HI_TASK_INST_TENANT_ID on ACT_HI_TASKINST(TENANT_ID_);
 create index ACT_IDX_HI_TASK_INST_PROC_DEF_KEY on ACT_HI_TASKINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
 
 create index ACT_IDX_HI_PROCVAR_PROC_INST on ACT_HI_VARINST(PROC_INST_ID_);
 create index ACT_IDX_HI_PROCVAR_NAME_TYPE on ACT_HI_VARINST(NAME_, VAR_TYPE_);
 create index ACT_IDX_HI_CASEVAR_CASE_INST on ACT_HI_VARINST(CASE_INST_ID_);
 create index ACT_IDX_HI_VAR_INST_TENANT_ID on ACT_HI_VARINST(TENANT_ID_);
 create index ACT_IDX_HI_VAR_INST_PROC_DEF_KEY on ACT_HI_VARINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_INCIDENT_TENANT_ID on ACT_HI_INCIDENT(TENANT_ID_);
 create index ACT_IDX_HI_INCIDENT_PROC_DEF_KEY on ACT_HI_INCIDENT(PROC_DEF_KEY_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
 
 create index ACT_IDX_HI_JOB_LOG_PROCINST on ACT_HI_JOB_LOG(PROCESS_INSTANCE_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROCDEF on ACT_HI_JOB_LOG(PROCESS_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_TENANT_ID on ACT_HI_JOB_LOG(TENANT_ID_);
 create index ACT_IDX_HI_JOB_LOG_JOB_DEF_ID on ACT_HI_JOB_LOG(JOB_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROC_DEF_KEY on ACT_HI_JOB_LOG(PROCESS_DEF_KEY_);
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
 
 create index ACT_HI_EXT_TASK_LOG_PROCINST on ACT_HI_EXT_TASK_LOG(PROC_INST_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROCDEF on ACT_HI_EXT_TASK_LOG(PROC_DEF_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROC_DEF_KEY on ACT_HI_EXT_TASK_LOG(PROC_DEF_KEY_);
 create index ACT_HI_EXT_TASK_LOG_TENANT_ID on ACT_HI_EXT_TASK_LOG(TENANT_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
 
 create index ACT_IDX_HI_OP_LOG_PROCINST on ACT_HI_OP_LOG(PROC_INST_ID_);
 create index ACT_IDX_HI_OP_LOG_PROCDEF on ACT_HI_OP_LOG(PROC_DEF_ID_);
 
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
diff --git a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mariadb.create.history.sql b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mariadb.create.history.sql
index 1a9060608e..fd806fea63 100644
--- a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mariadb.create.history.sql
+++ b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mariadb.create.history.sql
@@ -290,6 +290,8 @@ create index ACT_IDX_HI_ACT_INST_PROC_DEF_KEY on ACT_HI_ACTINST(PROC_DEF_KEY_);
 
 create index ACT_IDX_HI_TASK_INST_TENANT_ID on ACT_HI_TASKINST(TENANT_ID_);
 create index ACT_IDX_HI_TASK_INST_PROC_DEF_KEY on ACT_HI_TASKINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
 
 create index ACT_IDX_HI_DETAIL_PROC_INST on ACT_HI_DETAIL(PROC_INST_ID_);
 create index ACT_IDX_HI_DETAIL_ACT_INST on ACT_HI_DETAIL(ACT_INST_ID_);
@@ -300,31 +302,44 @@ create index ACT_IDX_HI_DETAIL_NAME on ACT_HI_DETAIL(NAME_);
 create index ACT_IDX_HI_DETAIL_TASK_ID on ACT_HI_DETAIL(TASK_ID_);
 create index ACT_IDX_HI_DETAIL_TENANT_ID on ACT_HI_DETAIL(TENANT_ID_);
 create index ACT_IDX_HI_DETAIL_PROC_DEF_KEY on ACT_HI_DETAIL(PROC_DEF_KEY_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_IDENT_LNK_USER on ACT_HI_IDENTITYLINK(USER_ID_);
 create index ACT_IDX_HI_IDENT_LNK_GROUP on ACT_HI_IDENTITYLINK(GROUP_ID_);
 create index ACT_IDX_HI_IDENT_LNK_TENANT_ID on ACT_HI_IDENTITYLINK(TENANT_ID_);
 create index ACT_IDX_HI_IDENT_LNK_PROC_DEF_KEY on ACT_HI_IDENTITYLINK(PROC_DEF_KEY_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
 
 create index ACT_IDX_HI_PROCVAR_PROC_INST on ACT_HI_VARINST(PROC_INST_ID_);
 create index ACT_IDX_HI_PROCVAR_NAME_TYPE on ACT_HI_VARINST(NAME_, VAR_TYPE_);
 create index ACT_IDX_HI_CASEVAR_CASE_INST on ACT_HI_VARINST(CASE_INST_ID_);
 create index ACT_IDX_HI_VAR_INST_TENANT_ID on ACT_HI_VARINST(TENANT_ID_);
 create index ACT_IDX_HI_VAR_INST_PROC_DEF_KEY on ACT_HI_VARINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_INCIDENT_TENANT_ID on ACT_HI_INCIDENT(TENANT_ID_);
 create index ACT_IDX_HI_INCIDENT_PROC_DEF_KEY on ACT_HI_INCIDENT(PROC_DEF_KEY_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
 
 create index ACT_IDX_HI_JOB_LOG_PROCINST on ACT_HI_JOB_LOG(PROCESS_INSTANCE_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROCDEF on ACT_HI_JOB_LOG(PROCESS_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_TENANT_ID on ACT_HI_JOB_LOG(TENANT_ID_);
 create index ACT_IDX_HI_JOB_LOG_JOB_DEF_ID on ACT_HI_JOB_LOG(JOB_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROC_DEF_KEY on ACT_HI_JOB_LOG(PROCESS_DEF_KEY_);
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
 
 create index ACT_HI_EXT_TASK_LOG_PROCINST on ACT_HI_EXT_TASK_LOG(PROC_INST_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROCDEF on ACT_HI_EXT_TASK_LOG(PROC_DEF_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROC_DEF_KEY on ACT_HI_EXT_TASK_LOG(PROC_DEF_KEY_);
 create index ACT_HI_EXT_TASK_LOG_TENANT_ID on ACT_HI_EXT_TASK_LOG(TENANT_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
 
 create index ACT_IDX_HI_OP_LOG_PROCINST on ACT_HI_OP_LOG(PROC_INST_ID_);
 create index ACT_IDX_HI_OP_LOG_PROCDEF on ACT_HI_OP_LOG(PROC_DEF_ID_);
+
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
diff --git a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mssql.create.history.sql b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mssql.create.history.sql
index 0e698d9b66..24fb9882c3 100644
--- a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mssql.create.history.sql
+++ b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mssql.create.history.sql
@@ -289,11 +289,14 @@ create index ACT_IDX_HI_ACT_INST_PROC_DEF_KEY on ACT_HI_ACTINST(PROC_DEF_KEY_);
 
 create index ACT_IDX_HI_TASK_INST_TENANT_ID on ACT_HI_TASKINST(TENANT_ID_);
 create index ACT_IDX_HI_TASK_INST_PROC_DEF_KEY on ACT_HI_TASKINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
 
 create index ACT_IDX_HI_IDENT_LNK_USER on ACT_HI_IDENTITYLINK(USER_ID_);
 create index ACT_IDX_HI_IDENT_LNK_GROUP on ACT_HI_IDENTITYLINK(GROUP_ID_);
 create index ACT_IDX_HI_IDENT_LNK_TENANT_ID on ACT_HI_IDENTITYLINK(TENANT_ID_);
 create index ACT_IDX_HI_IDENT_LNK_PROC_DEF_KEY on ACT_HI_IDENTITYLINK(PROC_DEF_KEY_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
 
 create index ACT_IDX_HI_DETAIL_PROC_INST on ACT_HI_DETAIL(PROC_INST_ID_);
 create index ACT_IDX_HI_DETAIL_ACT_INST on ACT_HI_DETAIL(ACT_INST_ID_);
@@ -304,26 +307,38 @@ create index ACT_IDX_HI_DETAIL_NAME on ACT_HI_DETAIL(NAME_);
 create index ACT_IDX_HI_DETAIL_TASK_ID on ACT_HI_DETAIL(TASK_ID_);
 create index ACT_IDX_HI_DETAIL_TENANT_ID on ACT_HI_DETAIL(TENANT_ID_);
 create index ACT_IDX_HI_DETAIL_PROC_DEF_KEY on ACT_HI_DETAIL(PROC_DEF_KEY_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_PROCVAR_PROC_INST on ACT_HI_VARINST(PROC_INST_ID_);
 create index ACT_IDX_HI_PROCVAR_NAME_TYPE on ACT_HI_VARINST(NAME_, VAR_TYPE_);
 create index ACT_IDX_HI_CASEVAR_CASE_INST on ACT_HI_VARINST(CASE_INST_ID_);
 create index ACT_IDX_HI_VAR_INST_TENANT_ID on ACT_HI_VARINST(TENANT_ID_);
 create index ACT_IDX_HI_VAR_INST_PROC_DEF_KEY on ACT_HI_VARINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_INCIDENT_TENANT_ID on ACT_HI_INCIDENT(TENANT_ID_);
 create index ACT_IDX_HI_INCIDENT_PROC_DEF_KEY on ACT_HI_INCIDENT(PROC_DEF_KEY_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
 
 create index ACT_IDX_HI_JOB_LOG_PROCINST on ACT_HI_JOB_LOG(PROCESS_INSTANCE_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROCDEF on ACT_HI_JOB_LOG(PROCESS_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_TENANT_ID on ACT_HI_JOB_LOG(TENANT_ID_);
 create index ACT_IDX_HI_JOB_LOG_JOB_DEF_ID on ACT_HI_JOB_LOG(JOB_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROC_DEF_KEY on ACT_HI_JOB_LOG(PROCESS_DEF_KEY_);
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
 
 create index ACT_HI_EXT_TASK_LOG_PROCINST on ACT_HI_EXT_TASK_LOG(PROC_INST_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROCDEF on ACT_HI_EXT_TASK_LOG(PROC_DEF_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROC_DEF_KEY on ACT_HI_EXT_TASK_LOG(PROC_DEF_KEY_);
 create index ACT_HI_EXT_TASK_LOG_TENANT_ID on ACT_HI_EXT_TASK_LOG(TENANT_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
 
 create index ACT_IDX_HI_OP_LOG_PROCINST on ACT_HI_OP_LOG(PROC_INST_ID_);
 create index ACT_IDX_HI_OP_LOG_PROCDEF on ACT_HI_OP_LOG(PROC_DEF_ID_);
+
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
diff --git a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mysql.create.history.sql b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mysql.create.history.sql
index 791a6eff3e..c48fecd387 100644
--- a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mysql.create.history.sql
+++ b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mysql.create.history.sql
@@ -292,6 +292,8 @@ create index ACT_IDX_HI_ACT_INST_PROC_DEF_KEY on ACT_HI_ACTINST(PROC_DEF_KEY_);
 
 create index ACT_IDX_HI_TASK_INST_TENANT_ID on ACT_HI_TASKINST(TENANT_ID_);
 create index ACT_IDX_HI_TASK_INST_PROC_DEF_KEY on ACT_HI_TASKINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
 
 create index ACT_IDX_HI_DETAIL_PROC_INST on ACT_HI_DETAIL(PROC_INST_ID_);
 create index ACT_IDX_HI_DETAIL_ACT_INST on ACT_HI_DETAIL(ACT_INST_ID_);
@@ -302,32 +304,44 @@ create index ACT_IDX_HI_DETAIL_NAME on ACT_HI_DETAIL(NAME_);
 create index ACT_IDX_HI_DETAIL_TASK_ID on ACT_HI_DETAIL(TASK_ID_);
 create index ACT_IDX_HI_DETAIL_TENANT_ID on ACT_HI_DETAIL(TENANT_ID_);
 create index ACT_IDX_HI_DETAIL_PROC_DEF_KEY on ACT_HI_DETAIL(PROC_DEF_KEY_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_IDENT_LNK_USER on ACT_HI_IDENTITYLINK(USER_ID_);
 create index ACT_IDX_HI_IDENT_LNK_GROUP on ACT_HI_IDENTITYLINK(GROUP_ID_);
 create index ACT_IDX_HI_IDENT_LNK_TENANT_ID on ACT_HI_IDENTITYLINK(TENANT_ID_);
 create index ACT_IDX_HI_IDENT_LNK_PROC_DEF_KEY on ACT_HI_IDENTITYLINK(PROC_DEF_KEY_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
 
 create index ACT_IDX_HI_PROCVAR_PROC_INST on ACT_HI_VARINST(PROC_INST_ID_);
 create index ACT_IDX_HI_PROCVAR_NAME_TYPE on ACT_HI_VARINST(NAME_, VAR_TYPE_);
 create index ACT_IDX_HI_CASEVAR_CASE_INST on ACT_HI_VARINST(CASE_INST_ID_);
 create index ACT_IDX_HI_VAR_INST_TENANT_ID on ACT_HI_VARINST(TENANT_ID_);
 create index ACT_IDX_HI_VAR_INST_PROC_DEF_KEY on ACT_HI_VARINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_INCIDENT_TENANT_ID on ACT_HI_INCIDENT(TENANT_ID_);
 create index ACT_IDX_HI_INCIDENT_PROC_DEF_KEY on ACT_HI_INCIDENT(PROC_DEF_KEY_);
-
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
 
 create index ACT_IDX_HI_JOB_LOG_PROCINST on ACT_HI_JOB_LOG(PROCESS_INSTANCE_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROCDEF on ACT_HI_JOB_LOG(PROCESS_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_TENANT_ID on ACT_HI_JOB_LOG(TENANT_ID_);
 create index ACT_IDX_HI_JOB_LOG_JOB_DEF_ID on ACT_HI_JOB_LOG(JOB_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROC_DEF_KEY on ACT_HI_JOB_LOG(PROCESS_DEF_KEY_);
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
 
 create index ACT_HI_EXT_TASK_LOG_PROCINST on ACT_HI_EXT_TASK_LOG(PROC_INST_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROCDEF on ACT_HI_EXT_TASK_LOG(PROC_DEF_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROC_DEF_KEY on ACT_HI_EXT_TASK_LOG(PROC_DEF_KEY_);
 create index ACT_HI_EXT_TASK_LOG_TENANT_ID on ACT_HI_EXT_TASK_LOG(TENANT_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
 
 create index ACT_IDX_HI_OP_LOG_PROCINST on ACT_HI_OP_LOG(PROC_INST_ID_);
 create index ACT_IDX_HI_OP_LOG_PROCDEF on ACT_HI_OP_LOG(PROC_DEF_ID_);
+
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
diff --git a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.oracle.create.history.sql b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.oracle.create.history.sql
index 640173763c..76169cc873 100644
--- a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.oracle.create.history.sql
+++ b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.oracle.create.history.sql
@@ -290,6 +290,8 @@ create index ACT_IDX_HI_ACT_INST_PROC_KEY on ACT_HI_ACTINST(PROC_DEF_KEY_);
 
 create index ACT_IDX_HI_TASK_INST_TENANT_ID on ACT_HI_TASKINST(TENANT_ID_, 0);
 create index ACT_IDX_HI_TASK_INST_PROC_KEY on ACT_HI_TASKINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
 
 create index ACT_IDX_HI_DETAIL_PROC_INST on ACT_HI_DETAIL(PROC_INST_ID_);
 create index ACT_IDX_HI_DETAIL_ACT_INST on ACT_HI_DETAIL(ACT_INST_ID_);
@@ -300,31 +302,44 @@ create index ACT_IDX_HI_DETAIL_NAME on ACT_HI_DETAIL(NAME_);
 create index ACT_IDX_HI_DETAIL_TASK_ID on ACT_HI_DETAIL(TASK_ID_);
 create index ACT_IDX_HI_DETAIL_TENANT_ID on ACT_HI_DETAIL(TENANT_ID_, 0);
 create index ACT_IDX_HI_DETAIL_PROC_KEY on ACT_HI_DETAIL(PROC_DEF_KEY_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_IDENT_LNK_USER on ACT_HI_IDENTITYLINK(USER_ID_);
 create index ACT_IDX_HI_IDENT_LNK_GROUP on ACT_HI_IDENTITYLINK(GROUP_ID_);
 create index ACT_IDX_HI_IDENT_LNK_TENANT_ID on ACT_HI_IDENTITYLINK(TENANT_ID_, 0);
 create index ACT_IDX_HI_IDENT_LNK_PROC_KEY on ACT_HI_IDENTITYLINK(PROC_DEF_KEY_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
 
 create index ACT_IDX_HI_PROCVAR_PROC_INST on ACT_HI_VARINST(PROC_INST_ID_);
 create index ACT_IDX_HI_PROCVAR_NAME_TYPE on ACT_HI_VARINST(NAME_, VAR_TYPE_);
 create index ACT_IDX_HI_CASEVAR_CASE_INST on ACT_HI_VARINST(CASE_INST_ID_);
 create index ACT_IDX_HI_VAR_INST_TENANT_ID on ACT_HI_VARINST(TENANT_ID_, 0);
 create index ACT_IDX_HI_VAR_INST_PROC_KEY on ACT_HI_VARINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_INCIDENT_TENANT_ID on ACT_HI_INCIDENT(TENANT_ID_, 0);
 create index ACT_IDX_HI_INCIDENT_PROC_KEY on ACT_HI_INCIDENT(PROC_DEF_KEY_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
 
 create index ACT_IDX_HI_JOB_LOG_PROCINST on ACT_HI_JOB_LOG(PROCESS_INSTANCE_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROCDEF on ACT_HI_JOB_LOG(PROCESS_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_TENANT_ID on ACT_HI_JOB_LOG(TENANT_ID_, 0);
 create index ACT_IDX_HI_JOB_LOG_JOB_DEF_ID on ACT_HI_JOB_LOG(JOB_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROC_KEY on ACT_HI_JOB_LOG(PROCESS_DEF_KEY_);
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
 
 create index ACT_HI_EXT_TASK_LOG_PROCINST on ACT_HI_EXT_TASK_LOG(PROC_INST_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROCDEF on ACT_HI_EXT_TASK_LOG(PROC_DEF_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROC_KEY on ACT_HI_EXT_TASK_LOG(PROC_DEF_KEY_);
 create index ACT_HI_EXT_TASK_LOG_TENANT_ID on ACT_HI_EXT_TASK_LOG(TENANT_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
 
 create index ACT_IDX_HI_OP_LOG_PROCINST on ACT_HI_OP_LOG(PROC_INST_ID_);
 create index ACT_IDX_HI_OP_LOG_PROCDEF on ACT_HI_OP_LOG(PROC_DEF_ID_);
+
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
diff --git a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.postgres.create.history.sql b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.postgres.create.history.sql
index 865f1cae79..ff57a31286 100644
--- a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.postgres.create.history.sql
+++ b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.postgres.create.history.sql
@@ -290,6 +290,8 @@ create index ACT_IDX_HI_ACT_INST_PROC_DEF_KEY on ACT_HI_ACTINST(PROC_DEF_KEY_);
 
 create index ACT_IDX_HI_TASK_INST_TENANT_ID on ACT_HI_TASKINST(TENANT_ID_);
 create index ACT_IDX_HI_TASK_INST_PROC_DEF_KEY on ACT_HI_TASKINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
 
 create index ACT_IDX_HI_DETAIL_PROC_INST on ACT_HI_DETAIL(PROC_INST_ID_);
 create index ACT_IDX_HI_DETAIL_ACT_INST on ACT_HI_DETAIL(ACT_INST_ID_);
@@ -300,32 +302,44 @@ create index ACT_IDX_HI_DETAIL_NAME on ACT_HI_DETAIL(NAME_);
 create index ACT_IDX_HI_DETAIL_TASK_ID on ACT_HI_DETAIL(TASK_ID_);
 create index ACT_IDX_HI_DETAIL_TENANT_ID on ACT_HI_DETAIL(TENANT_ID_);
 create index ACT_IDX_HI_DETAIL_PROC_DEF_KEY on ACT_HI_DETAIL(PROC_DEF_KEY_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_IDENT_LNK_USER on ACT_HI_IDENTITYLINK(USER_ID_);
 create index ACT_IDX_HI_IDENT_LNK_GROUP on ACT_HI_IDENTITYLINK(GROUP_ID_);
 create index ACT_IDX_HI_IDENT_LNK_TENANT_ID on ACT_HI_IDENTITYLINK(TENANT_ID_);
 create index ACT_IDX_HI_IDENT_LNK_PROC_DEF_KEY on ACT_HI_IDENTITYLINK(PROC_DEF_KEY_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
 
 create index ACT_IDX_HI_PROCVAR_PROC_INST",add indices to improve performance of history cleanup .,"""Added indices for history cleanup (CAM-8184)""","""Added missing indices for history cleanup across various database engines""","""Adding indices for history cleanup - CAM-8184""

This commit appears to add new indices to several tables in the database schema used by Camunda BPM. The indices are added to tables such as ACT\_HI\_JOB\_LOG, ACT\_HI\_VARINST, ACT\_HI\_DETAIL, ACT\_HI\_EXT\_TASK\_LOG, ACT\_HI\_COMMENT, ACT\_HI\_ATTACHMENT, ACT\_HI\_TASKINST, and ACT\_HI\_IDENTITYLINK. The indices are added to columns such as JOB\_EXCEPTION\_STACK\_ID\_, BYTEARRAY\_ID\_, ERROR\_DETAILS\_ID\_, TASK\_ID\_, PROC\_INST\_ID\_, ID\_PROCINST, CONTENT\_ID\_, and PROC\_INST\_ID\_. The purpose of these indices is to optimize the performance of history cleanup, as indicated by the commit message and the Jira ticket CAM-8184.",Added indices for history cleanup in various database scripts to enhance performance as per CAM-8184.,Model 2
"diff --git a/src/cpp/session/modules/SessionReticulate.R b/src/cpp/session/modules/SessionReticulate.R
index 3dfad2adb5..4fbd2c44d4 100644
--- a/src/cpp/session/modules/SessionReticulate.R
+++ b/src/cpp/session/modules/SessionReticulate.R
@@ -521,15 +521,14 @@ options(reticulate.repl.teardown   = .rs.reticulate.replTeardown)
 {
    inspect <- reticulate::import(""inspect"", convert = TRUE)
    
-   # if this is a class object (has an __init__ method), then
-   # get methods from that
-   init <- reticulate::py_get_attr(object, ""__init__"", silent = TRUE)
-   if (!inherits(init, ""python.builtin.NoneType"")) {
+   if (inspect$isclass(object)) {
+      # for class objects, use the arguments of the __init__ method
+      init <- reticulate::py_get_attr(object, ""__init__"", silent = TRUE)
       arguments <- tryCatch(inspect$getargspec(init)$args, error = identity)
       if (inherits(arguments, ""error""))
          return(.rs.python.emptyCompletions())
-      arguments <- setdiff(arguments, ""self"")
    } else {
+      # assume that this is a callable, and ask for the arg spec
       arguments <- tryCatch(inspect$getargspec(object)$args, error = identity)
       if (inherits(arguments, ""error""))
          return(.rs.python.emptyCompletions())",fix up argument completion,"""Improve Python object inspection in reticulate module""","""Improve handling of Python class objects and callables in SessionReticulate""","""Update completion logic for Python objects in reticulate: use inspect.isclass to check if an object is a class, and handle arguments for both class objects and callable objects.""",Update Python object inspection to differentiate class objects from callables.,Model 1
"diff --git a/requery-processor/src/main/java/io/requery/processor/AttributeMember.java b/requery-processor/src/main/java/io/requery/processor/AttributeMember.java
index fa0fd54..2c32116 100644
--- a/requery-processor/src/main/java/io/requery/processor/AttributeMember.java
+++ b/requery-processor/src/main/java/io/requery/processor/AttributeMember.java
@@ -46,7 +46,6 @@ import io.requery.meta.MapAttributeBuilder;
 import io.requery.meta.ResultAttributeBuilder;
 import io.requery.meta.SetAttributeBuilder;
 import io.requery.query.Order;
-import io.requery.sql.Keyword;
 
 import javax.annotation.processing.ProcessingEnvironment;
 import javax.lang.model.SourceVersion;
@@ -184,7 +183,7 @@ class AttributeMember extends BaseProcessableElement<Element> implements Attribu
                     isIterable = Mirrors.isInstance(types, element, Iterable.class);
                 }
                 isMap = Mirrors.isInstance(types, element, Map.class);
-                if (isMap) {
+                if (isMap && cardinality != null) {
                     builderClass = MapAttributeBuilder.class;
                 }
                 isOptional = Mirrors.isInstance(types, element, Optional.class);
diff --git a/requery-processor/src/main/java/io/requery/processor/EntityGenerator.java b/requery-processor/src/main/java/io/requery/processor/EntityGenerator.java
index b5c017a..48d9808 100644
--- a/requery-processor/src/main/java/io/requery/processor/EntityGenerator.java
+++ b/requery-processor/src/main/java/io/requery/processor/EntityGenerator.java
@@ -629,7 +629,7 @@ class EntityGenerator implements SourceGenerator {
             builder.add(""\nnew $T($S, $T.class, $T.class)\n"",
                 builderName, attribute.name(), ClassName.get(collectionElement), name);
 
-        } else if (attribute.isMap()) {
+        } else if (attribute.isMap() && attribute.cardinality() != null) {
             List<TypeMirror> parameters = Mirrors.listGenericTypeArguments(typeMirror);
             // key type
             TypeName keyName = TypeName.get(parameters.get(0));",Resolve <issue_id> Don \' t use map attribute builder for non relational map,"""Fix map attribute handling to require cardinality""","""Refine attribute processing for maps with cardinality constraints""","""Fixed attribute member generation for maps with null cardinality and updated map attribute handling in entity generator""

This commit appears to have made two changes to the code:

1. In the `AttributeMember` class, it added a check for `cardinality != null` before setting the `builderClass` to `MapAttributeBuilder.class` when `isMap` is true. This prevents a `NullPointerException` when the cardinality is null.
2. In the `EntityGenerator` class, it added a similar check for `cardinality != null` before checking if the attribute is a map. This ensures that the map attribute is only handled when the cardinality is not null.

These changes seem to be related to fixing issues with generating code for map attributes when the cardinality is null.",Ensure `isMap` considers cardinality in `AttributeMember` and `EntityGenerator`.,Model 3
"diff --git a/server/webapp/WEB-INF/applicationContext-acegi-security.xml b/server/webapp/WEB-INF/applicationContext-acegi-security.xml
index 002dae3bbf..ae3e662fbe 100644
--- a/server/webapp/WEB-INF/applicationContext-acegi-security.xml
+++ b/server/webapp/WEB-INF/applicationContext-acegi-security.xml
@@ -272,6 +272,7 @@
                 /api/admin/plugin_info/**=ROLE_SUPERVISOR, ROLE_GROUP_SUPERVISOR
                 /api/admin/agents=ROLE_SUPERVISOR
                 /api/elastic/profiles/**=ROLE_SUPERVISOR, ROLE_GROUP_SUPERVISOR
+                /admin/elastic_profiles/**=ROLE_SUPERVISOR, ROLE_GROUP_SUPERVISOR
                 /api/admin/templates/**=ROLE_SUPERVISOR
                 /api/admin/**=ROLE_SUPERVISOR
                 /api/config-repository.git/**=ROLE_SUPERVISOR
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/javascripts/lib/string-plus.js b/server/webapp/WEB-INF/rails.new/app/assets/javascripts/lib/string-plus.js
index 6e56d644ad..c6b610092d 100644
--- a/server/webapp/WEB-INF/rails.new/app/assets/javascripts/lib/string-plus.js
+++ b/server/webapp/WEB-INF/rails.new/app/assets/javascripts/lib/string-plus.js
@@ -79,6 +79,14 @@ define(['string', 'lodash', 'mithril'], function (s, _, m) {
 
       return s4() + s4() + '-' + s4() + '-' + s4() + '-' +
         s4() + '-' + s4() + s4() + s4();
+    },
+
+    terminateWithPeriod: function (str) {
+      if (s.endsWith(str, '.')) {
+        return str;
+      } else {
+        return `${str}.`;
+      }
     }
   };
 
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/helpers/form_helper.js.msx b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/helpers/form_helper.js.msx
index b6f38ad61e..542542be5a 100644
--- a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/helpers/form_helper.js.msx
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/helpers/form_helper.js.msx
@@ -57,7 +57,7 @@ define(['mithril', 'jquery', 'lodash', 'string-plus', 'models/model_mixins', 'es
 
         return (
           <div class={compactClasses(args, 'columns', 'medium-' + size, 'large-' + largeSize, end)}
-            {...args}>
+               {...args}>
             {children}
           </div>
         );
@@ -77,7 +77,7 @@ define(['mithril', 'jquery', 'lodash', 'string-plus', 'models/model_mixins', 'es
       },
 
       view: function (ctrl, args) {
-        var model = deleteKeyAndReturnValue(args, 'model'),
+        var model       = deleteKeyAndReturnValue(args, 'model'),
           attrName    = deleteKeyAndReturnValue(args, 'attrName'),
           type        = deleteKeyAndReturnValue(args, 'type', 'text'),
           placeholder = deleteKeyAndReturnValue(args, 'placeholder', ''),
@@ -367,7 +367,7 @@ define(['mithril', 'jquery', 'lodash', 'string-plus', 'models/model_mixins', 'es
 
       view: function (ctrl, args, children) {
         var tabs = (
-          <ul class={_.compact(['tabs', args.isVertical ? 'vertical': undefined]).join(' ')}>
+          <ul class={_.compact(['tabs', args.isVertical ? 'vertical' : undefined]).join(' ')}>
             {_.map(args.tabTitles, function (tabTitle, tabIndex) {
 
               var tabTitleElem;
@@ -395,7 +395,7 @@ define(['mithril', 'jquery', 'lodash', 'string-plus', 'models/model_mixins', 'es
 
         var tabsContent = (
           <div
-            class={_.compact([args.isVertical ? 'vertical': undefined, 'tabs-content', 'tabs-content-container', ctrl.prefixedClass('tabs-content-container')]).join(' ')}>
+            class={_.compact([args.isVertical ? 'vertical' : undefined, 'tabs-content', 'tabs-content-container', ctrl.prefixedClass('tabs-content-container')]).join(' ')}>
             {_.map(_.flatten(children), function (child, tabIndex) {
 
               var renderedChild;
@@ -604,33 +604,28 @@ define(['mithril', 'jquery', 'lodash', 'string-plus', 'models/model_mixins', 'es
       }
     },
 
+    callout: {
+      view: function (ctrl, args, children) {
+        var type = deleteKeyAndReturnValue(args, 'type');
+        return (<div class={'callout ' + type} {...args}>{children}</div>);
+      }
+    },
+
     alert: {
       view: function (ctrl, args, children) {
-        return (
-          <div>
-            <span class=""callout alert"">{children}</span>
-          </div>
-        );
+        return (<f.callout type=""alert"" {...args}>{children}</f.callout>);
       }
     },
 
     warning: {
       view: function (ctrl, args, children) {
-        return (
-          <div class='warning callout'>
-            <p>{children}</p>
-          </div>
-        );
+        return (<f.callout type=""warning"" {...args}>{children}</f.callout>);
       }
     },
 
     info: {
       view: function (ctrl, args, children) {
-        return (
-          <div class='info callout'>
-            <p>{children}</p>
-          </div>
-        );
+        return (<f.callout type=""info"" {...args}>{children}</f.callout>);
       }
     },
 
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/helpers/mrequest.js b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/helpers/mrequest.js
index 96713de62f..d73b73a21a 100644
--- a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/helpers/mrequest.js
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/helpers/mrequest.js
@@ -14,10 +14,14 @@
  * limitations under the License.
  */
 
-define([], function () {
+define(['jquery'], function ($) {
   var setHeaders = function (xhr, version) {
     xhr.setRequestHeader(""Content-Type"", ""application/json"");
     xhr.setRequestHeader(""Accept"", ""application/vnd.go.cd."" + version + ""+json"");
+    var csrfToken = $('meta[name=csrf-token]').attr('content');
+    if (csrfToken) {
+      xhr.setRequestHeader('X-CSRF-Token', csrfToken);
+    }
   };
 
   return {
@@ -34,6 +38,14 @@ define([], function () {
       v4: function (xhr) {
         setHeaders(xhr, 'v4');
       }
+    },
+
+    unwrapErrorExtractMessage: function (data) {
+      if (data.message) {
+        return data.message;
+      } else {
+        return ""There was an unknown error performing the operation"";
+      }
     }
   };
 });
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/elastic_profiles/elastic_profiles.js b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/elastic_profiles/elastic_profiles.js
new file mode 100644
index 0000000000..3d5294c94a
--- /dev/null
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/elastic_profiles/elastic_profiles.js
@@ -0,0 +1,135 @@
+/*
+ * Copyright 2016 ThoughtWorks, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+define([
+  'mithril', 'lodash', 'string-plus', 'models/model_mixins', 'models/shared/plugin_configurations', 'helpers/mrequest', 'js-routes', 'models/validatable_mixin'
+], function (m, _, s, Mixins, PluginConfigurations, mrequest, Routes, Validatable) {
+
+  var unwrapMessageOrProfile = function (data, xhr) {
+    if (xhr.status === 422) {
+      return new ElasticProfiles.Profile.fromJSON(data.data);
+    } else {
+      return mrequest.unwrapErrorExtractMessage(data, xhr);
+    }
+  };
+
+  var ElasticProfiles = function (data) {
+    Mixins.HasMany.call(this, {
+      factory:    ElasticProfiles.Profile.create,
+      as:         'Profile',
+      collection: data,
+      uniqueOn:   'id'
+    });
+  };
+
+  ElasticProfiles.all = function () {
+    return m.request({
+      method:        ""GET"",
+      url:           Routes.apiv1ElasticProfilesPath(),
+      config:        mrequest.xhrConfig.v1,
+      unwrapSuccess: function (data) {
+        return ElasticProfiles.fromJSON(data['_embedded']['profiles']);
+      },
+      unwrapError:   mrequest.unwrapErrorExtractMessage
+    });
+  };
+
+  ElasticProfiles.Profile = function (data) {
+    this.id         = m.prop(s.defaultToIfBlank(data.id, ''));
+    this.pluginId   = m.prop(s.defaultToIfBlank(data.pluginId, ''));
+    this.properties = s.collectionToJSON(m.prop(s.defaultToIfBlank(data.properties, new PluginConfigurations())));
+    this.parent     = Mixins.GetterSetter();
+    this.etag       = Mixins.GetterSetter();
+
+    Validatable.call(this, data);
+
+    this.validatePresenceOf('id');
+    this.validatePresenceOf('pluginId');
+
+    this.update = function () {
+      var profile = this;
+      return m.request({
+        method:      'PUT',
+        url:         Routes.apiv1ElasticProfilePath(this.id()),
+        config:      function (xhr) {
+          mrequest.xhrConfig.v1(xhr);
+          xhr.setRequestHeader('If-Match', profile.etag());
+        },
+        data:        JSON.parse(JSON.stringify(profile, s.snakeCaser)),
+        unwrapError: unwrapMessageOrProfile
+      });
+    };
+
+    this.delete = function () {
+      return m.request({
+        method:        ""DELETE"",
+        url:           Routes.apiv1ElasticProfilePath(this.id()),
+        config:        mrequest.xhrConfig.v1,
+        unwrapSuccess: function (data, xhr) {
+          if (xhr.status === 200) {
+            return data.message;
+          }
+        },
+        unwrapError:   mrequest.unwrapErrorExtractMessage
+      });
+    };
+
+    this.create = function () {
+      return m.request({
+        method:      'POST',
+        url:         Routes.apiv1ElasticProfilesPath(),
+        config:      mrequest.xhrConfig.v1,
+        data:        JSON.parse(JSON.stringify(this, s.snakeCaser)),
+        unwrapError: unwrapMessageOrProfile
+      });
+    };
+  };
+
+  ElasticProfiles.Profile.get = function (id) {
+    return m.request({
+      method:        'GET',
+      url:           Routes.apiv1ElasticProfilePath(id),
+      config:        mrequest.xhrConfig.v1,
+      unwrapSuccess: function (data, xhr) {
+        var profile = ElasticProfiles.Profile.fromJSON(data);
+        profile.etag(xhr.getResponseHeader('ETag'));
+        return profile;
+      },
+      unwrapError:   mrequest.unwrapErrorExtractMessage
+    });
+  };
+
+  ElasticProfiles.Profile.create = function (data) {
+    return new ElasticProfiles.Profile(data);
+  };
+
+  ElasticProfiles.Profile.fromJSON = function (data) {
+    return new ElasticProfiles.Profile({
+      id:         data.id,
+      pluginId:   data.plugin_id,
+      errors:     data.errors,
+      properties: PluginConfigurations.fromJSON(data.properties)
+    });
+  };
+
+  Mixins.fromJSONCollection({
+    parentType: ElasticProfiles,
+    childType:  ElasticProfiles.Profile,
+    via:        'addProfile'
+  });
+
+  return ElasticProfiles;
+});
\ No newline at end of file
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/errors.js b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/errors.js
index 7899c1715b..e5f833f219 100644
--- a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/errors.js
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/errors.js
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 
-define(['mithril', 'lodash'], function (m, _) {
+define(['mithril', 'lodash', 'string-plus'], function (m, _, s) {
   var Errors = function (errors) {
     errors = errors || {};
 
@@ -40,9 +40,7 @@ define(['mithril', 'lodash'], function (m, _) {
     };
 
     this.errorsForDisplay = function (attrName) {
-      return _.map(errors[attrName] || [], function (message) {
-        return message + ""."";
-      }).join("" "");
+      return _.map(errors[attrName] || [], s.terminateWithPeriod).join("" "");
     };
   };
 
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/pipeline_configs/plugin_infos.js b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/pipeline_configs/plugin_infos.js
index 7b0b822eb6..7788bab31b 100644
--- a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/pipeline_configs/plugin_infos.js
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/pipeline_configs/plugin_infos.js
@@ -14,17 +14,17 @@
  * limitations under the License.
  */
 
-define(['mithril', 'lodash', 'string-plus', 'helpers/mrequest', 'js-routes'], function (m, _, s, mrequest, Routes) {
+define(['mithril', 'lodash', 'string-plus', 'helpers/mrequest', 'models/shared/image', 'js-routes'], function (m, _, s, mrequest, Image, Routes) {
   var PluginInfos = m.prop([]);
 
-  PluginInfos.init = function () {
+  PluginInfos.init = function (type) {
     var unwrap = function (response) {
       return response._embedded.plugin_info;
     };
 
     return m.request({
       method:        'GET',
-      url:           Routes.apiv1AdminPluginInfoIndexPath(),
+      url:           Routes.apiv1AdminPluginInfoIndexPath({'type': type}),
       background:    true,
       config:        mrequest.xhrConfig.v1,
       unwrapSuccess: unwrap,
@@ -55,17 +55,22 @@ define(['mithril', 'lodash', 'string-plus', 'helpers/mrequest', 'js-routes'], fu
     this.version        = m.prop(data.version);
     this.type           = m.prop(data.type);
     this.configurations = data.pluggable_instance_settings ?
-                            m.prop(s.defaultToIfBlank(data.pluggable_instance_settings.configurations, {})) :
-                            m.prop({});
+      m.prop(s.defaultToIfBlank(data.pluggable_instance_settings.configurations, {})) :
+      m.prop({});
     this.viewTemplate   = m.prop(s.defaultToIfBlank(view(data.pluggable_instance_settings).template, ''));
+
+    if (data.image) {
+      this.image = m.prop(new Image(data.image.content_type, data.image.data));
+    }
   };
 
   PluginInfos.PluginInfo.byId = function (id) {
     return m.request({
-      method: 'GET',
-      url:    Routes.apiv1AdminPluginInfoPath({id: id}),
-      config: mrequest.xhrConfig.v1,
-      type:   PluginInfos.PluginInfo
+      method:      'GET',
+      url:         Routes.apiv1AdminPluginInfoPath({id: id}),
+      config:      mrequest.xhrConfig.v1,
+      type:        PluginInfos.PluginInfo,
+      unwrapError: mrequest.unwrapErrorExtractMessage
     });
   };
 
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/shared/image.js b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/shared/image.js
new file mode 100644
index 0000000000..bd5352bfeb
--- /dev/null
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/shared/image.js
@@ -0,0 +1,28 @@
+/*
+ * Copyright 2016 ThoughtWorks, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+define(['mithril'], function (m) {
+  var Image = function (contentType, data) {
+    this.contentType = m.prop(contentType);
+    this.data        = m.prop(data);
+
+    this.toDataURI = function () {
+      return ""data:"" + this.contentType() + "";base64,"" + this.data();
+    };
+  };
+
+  return Image;
+});
\ No newline at end of file
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/single_page_apps/elastic_profiles.js b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/single_page_apps/elastic_profiles.js
new file mode 100644
index 0000000000..172c5e7610
--- /dev/null
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/single_page_apps/elastic_profiles.js
@@ -0,0 +1,33 @@
+/*
+ * Copyright 2016 ThoughtWorks, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+require([
+  'jquery', 'mithril',
+  'js-routes',
+  'views/elastic_profiles/elastic_profiles_widget',
+  'models/pipeline_configs/plugin_infos',
+  'foundation.util.mediaQuery', 'foundation.dropdownMenu', 'foundation.responsiveToggle', 'foundation.dropdown'
+], function ($, m, JsRoutes,
+             ElasticProfilesWidget, PluginInfos) {
+
+  $(function () {
+    $(document).foundation();
+
+    m.sync([PluginInfos.init('elastic-agent')]).then(function () {
+      m.mount($(""#elastic-profiles"").get(0), ElasticProfilesWidget);
+    });
+  });
+});
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/agents/agents_widget.js.msx b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/agents/agents_widget.js.msx
index 59db732710..24721bde39 100644
--- a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/agents/agents_widget.js.msx
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/agents/agents_widget.js.msx
@@ -233,7 +233,7 @@ define([
 
       return (
         <div onclick={ctrl.hideDropDownsAndMessage.bind(ctrl)}>
-          <div class=""agent-header-panel"">
+          <div class=""header-panel"">
             <ButtonRowWidget isAnyAgentSelected={ ctrl.isAnyAgentSelected.bind(ctrl) }
                              dropdown={args.vm.dropdown}
                              selectedAgents={ ctrl.selectedAgents.bind(ctrl) }
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/agents/button_row_widget.js.msx b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/agents/button_row_widget.js.msx
index dcb460a581..6114d1f486 100644
--- a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/agents/button_row_widget.js.msx
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/agents/button_row_widget.js.msx
@@ -56,34 +56,30 @@ define(['mithril', 'lodash',
             </f.column>
 
             <f.column size={7}>
-              <ul class=""button-group agent-button-group"">
+              <ul class=""button-group header-panel-button-group"">
                 <li>
-                  <f.button class=""button""
-                            onclick={args.onDelete}
+                  <f.button onclick={args.onDelete}
                             disabled={!args.isAnyAgentSelected()}>
                     Delete
                   </f.button>
                 </li>
 
                 <li>
-                  <f.button class=""button""
-                            onclick={args.onDisable}
+                  <f.button onclick={args.onDisable}
                             disabled={!args.isAnyAgentSelected()}>
                     Disable
                   </f.button>
                 </li>
 
                 <li>
-                  <f.button class=""button""
-                            onclick={args.onEnable}
+                  <f.button onclick={args.onEnable}
                             disabled={!args.isAnyAgentSelected()}>
                     Enable
                   </f.button>
                 </li>
 
                 <li class={ ctrl.dropdownClass('resource') }>
-                  <f.button class=""button""
-                            onclick={ctrl.resourcesButtonClicked}
+                  <f.button onclick={ctrl.resourcesButtonClicked}
                             disabled={!args.isAnyAgentSelected()}>
                     Resources
                   </f.button>
@@ -95,8 +91,7 @@ define(['mithril', 'lodash',
                 </li>
 
                 <li class={ctrl.dropdownClass('environment')}>
-                  <f.button class=""button""
-                            onclick={ctrl.environmentsButtonClicked}
+                  <f.button onclick={ctrl.environmentsButtonClicked}
                             disabled={!args.isAnyAgentSelected()}>
                     Environments
                   </f.button>
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/elastic_profiles/elastic_profile_modal_body.js.msx b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/elastic_profiles/elastic_profile_modal_body.js.msx
new file mode 100644
index 0000000000..61f7594ef4
--- /dev/null
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/elastic_profiles/elastic_profile_modal_body.js.msx
@@ -0,0 +1,120 @@
+/*
+ * Copyright 2016 ThoughtWorks, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+define([
+  ""mithril"", 'lodash', 'jquery', 'helpers/form_helper', 'models/pipeline_configs/plugin_infos', 'models/elastic_profiles/elastic_profiles',
+  'views/shared/angular_plugin'
+], function (m, _, $, f, PluginInfos, ElasticProfiles, AngularPlugin) {
+
+  var autoComplete = function (model, attrName, selectCb) {
+    return function (elem, isInitialized) {
+      if (isInitialized) {
+        return;
+      }
+
+      var $inputElem = $($(elem).find(`input[data-prop-name='${attrName}']`));
+      var values     = _.map(PluginInfos(), function (pi) {
+        return pi.id();
+      });
+
+      $inputElem.textcomplete([
+        {
+          match:   /([^\s].*)$/,
+          index:   1, // use the second match in the regex to extract the search term
+          search:  function (term, callback) {
+            term = term.toLowerCase();
+            callback($.map(values, function (word) {
+              return",Add a page to manage elastic agent profiles,"""Added elastic profiles feature, including security configuration, JavaScript models, and views""","""Added Elastic Profiles feature and security updates""","This commit contains several changes to the JavaScript code in a web application using Mithril.js and jQuery. Here's a summary of the changes:

1. In `applicationContext-acegi-security.xml`, added a new security rule for the URL pattern `/admin/elastic_profiles/**` requiring the roles `ROLE_SUPERVISOR` and `ROLE_GROUP_SUPERVISOR`.

2. In `string-plus.js`, added a new `terminateWithPeriod` function to ensure a string ends with a period.

3. In `form_helper.js.msx`, updated the class attribute in the `<div>` element inside the `columns` function to properly use the `compact` function from lodash to join class names. Also, added a new `callout` component.

4. In `mrequest.js`, added a new function `unwrapErrorExtractMessage` to extract the error message from a response data object. Also, added code to set the 'X-CSRF-Token' header in the `setHeaders` function if a CSRF token is found in the meta tag of the HTML.

5. In `errors.js`, updated the `errorsForDisplay` function to use the new `terminateWithPeriod` function from `string-plus.js`.

6. In `plugin_infos.js`, updated the `init` function to accept a `type` parameter and pass it to the API endpoint when fetching plugin info. Also, added an `Image` property to the `PluginInfos.PluginInfo` object if an image is present in the plugin info data.

7. Added a new `image.js` file to define an `Image` model with a `toDataURI` function.

8. Added a new `elastic_profiles.js` file to handle Elastic Profiles functionality.

9. Added a new `elastic_profiles_widget.js.msx` file to define the UI for the Elastic Profiles widget.

10. In `agents_widget.js.msx`, updated the class attribute of a `<div>` element to remove the 'agent-' prefix from the 'agent-header-panel' class name.

11. In `button_row_widget.js.msx`, updated the class attribute of a `<ul>` element to remove the 'agent-' prefix from the 'agent-button-group' class name.

12. Added a new `elastic_profile_modal_body.js.msx` file to define the UI for the Elastic Profile modal body.

The commit message could be: ""Add Elastic Profiles functionality, update form helper, and various other changes and fixes.""","### Commit Message

""Add CSRF Token, Elastic Profile Management, UI Enhancements, and Error Handling Improvements""",Model 4
"diff --git a/build/qa/pmd-ruleset.xml b/build/qa/pmd-ruleset.xml
index 3947e8fe7b..edba7d484e 100644
--- a/build/qa/pmd-ruleset.xml
+++ b/build/qa/pmd-ruleset.xml
@@ -85,6 +85,12 @@ under the License.
     <rule ref=""category/java/errorprone.xml/UnnecessaryConversionTemporary"" />
     <rule ref=""category/java/errorprone.xml/UnusedNullCheckInEquals"" />
     <rule ref=""category/java/errorprone.xml/UselessOperationOnImmutable"" />
+    <rule ref=""category/java/errorprone.xml/CloseResource"" >
+        <properties>
+            <!-- When calling the store to close, PMD wants the full prefix before the call to the method to match, so let's try to use common var names for store ... -->
+            <property name=""closeTargets"" value=""releaseConnection,store.releaseConnection,closeQuietly,closeConnection,closeSafe,store.closeSafe,dataStore.closeSafe,getDataStore().closeSafe,close,closeResultSet,closeStmt,closeFinally,JDBCUtils.close""/>
+        </properties>
+    </rule>
 
     <rule ref=""category/java/multithreading.xml/AvoidThreadGroup"" />
     <rule ref=""category/java/multithreading.xml/DontCallThreadRun"" />",Adding checks for unclosed sql closeables,"""Added CloseResource rule to PMD ruleset with custom closeTargets""",Added PMD rule to enforce closing resources and improved configuration for better matching.,"""Added custom configuration for CloseResource rule in PMD ruleset XML""

Explanation: The diff shows that a new rule has been added to the PMD ruleset XML file, specifically the ""CloseResource"" rule under the ""errorprone"" category. Additionally, some properties have been set for this rule to customize its behavior, specifically the ""closeTargets"" property. Therefore, the commit message should reflect that the CloseResource rule has been added and customized in the PMD ruleset XML file.",Add CloseResource rule to detect unclosed resources and specify common close method names in PMD ruleset.,Model 1
"diff --git a/community/cypher/src/main/java/org/neo4j/cypher/javacompat/ExecutionResult.java b/community/cypher/src/main/java/org/neo4j/cypher/javacompat/ExecutionResult.java
index 9ff0e6d3eb6..e87d50727c2 100644
--- a/community/cypher/src/main/java/org/neo4j/cypher/javacompat/ExecutionResult.java
+++ b/community/cypher/src/main/java/org/neo4j/cypher/javacompat/ExecutionResult.java
@@ -54,7 +54,8 @@ public class ExecutionResult implements Iterable<Map<String,Object>>
     }
 
     /**
-     * Provides result objects from a single column of the result set.
+     * Provides result objects from a single column of the result set. This method is best used for
+     * single column results.
      *
      * @param n exact name of the column, as it appeared in the original query
      * @param <T> desired type cast for the result objects",Added javadoc,"""Added note to ExecutionResult's column method to recommend its use for single column results""","""Added documentation to ExecutionResult#column() method to clarify its usage for single column results.""","This commit adds a comment to the `columnAs` method in the `ExecutionResult` class of the `org.neo4j.cypher.javacompat` package in the Neo4j community Cypher project. The comment recommends using the method for single column results and provides a brief description of the method's functionality.

The added comment is:
```python
+     * Provides result objects from a single column of the result set. This method is best used for
+     * single column results.
```
The commit message could be: ""Added recommendation to use ExecutionResult.columnAs method for single column results and provided brief description of method functionality.""","""Updated `columnAs` method documentation to specify its optimal use for single column results.""",Model 2
"diff --git a/DaoTest/src/de/greenrobot/daotest/query/QueryThreadLocalTest.java b/DaoTest/src/de/greenrobot/daotest/query/QueryThreadLocalTest.java
index 614a42a..a44fb2d 100644
--- a/DaoTest/src/de/greenrobot/daotest/query/QueryThreadLocalTest.java
+++ b/DaoTest/src/de/greenrobot/daotest/query/QueryThreadLocalTest.java
@@ -17,12 +17,15 @@
  */
 package de.greenrobot.daotest.query;
 
+import de.greenrobot.dao.DaoException;
 import de.greenrobot.dao.Query;
+import de.greenrobot.dao.QueryBuilder;
 import de.greenrobot.daotest.TestEntity;
 import de.greenrobot.daotest.TestEntityDao.Properties;
 import de.greenrobot.daotest.entity.TestEntityTestBase;
 
 public class QueryThreadLocalTest extends TestEntityTestBase {
+    private Query<TestEntity> queryFromOtherThread;
 
     public void testGetForCurrentThread_SameInstance() {
         Query<TestEntity> query = dao.queryBuilder().build();
@@ -41,5 +44,81 @@ public class QueryThreadLocalTest extends TestEntityTestBase {
         assertEquals(value, (int) entityFor1.getSimpleInteger());
     }
 
-    // TODO more tests
+    public void testGetForCurrentThread_TwoThreads() throws InterruptedException {
+        insert(3);
+        createQueryFromOtherThread();
+        Query<TestEntity> query = queryFromOtherThread.forCurrentThread();
+        assertNotSame(queryFromOtherThread, query);
+        query.setLimit(10);
+        query.setOffset(0);
+        assertEquals(getSimpleInteger(1), (int) query.uniqueOrThrow().getSimpleInteger());
+        int expected = getSimpleInteger(2);
+        query.setParameter(0, expected);
+        assertEquals(expected, (int) query.list().get(0).getSimpleInteger());
+        assertEquals(expected, (int) query.listLazy().get(0).getSimpleInteger());
+        assertEquals(expected, (int) query.listLazyUncached().get(0).getSimpleInteger());
+        assertEquals(expected, (int) query.unique().getSimpleInteger());
+        assertEquals(expected, (int) query.uniqueOrThrow().getSimpleInteger());
+    }
+
+    public void testThrowOutsideOwnerThread() throws InterruptedException {
+        createQueryFromOtherThread();
+        try {
+            queryFromOtherThread.list();
+            fail(""Did not throw"");
+        } catch (DaoException expected) {
+        }
+        try {
+            queryFromOtherThread.listIterator();
+            fail(""Did not throw"");
+        } catch (DaoException expected) {
+        }
+        try {
+            queryFromOtherThread.listLazyUncached();
+            fail(""Did not throw"");
+        } catch (DaoException expected) {
+        }
+        try {
+            queryFromOtherThread.setLimit(2);
+            fail(""Did not throw"");
+        } catch (DaoException expected) {
+        }
+        try {
+            queryFromOtherThread.setOffset(2);
+            fail(""Did not throw"");
+        } catch (DaoException expected) {
+        }
+        try {
+            queryFromOtherThread.setParameter(0, 42);
+            fail(""Did not throw"");
+        } catch (DaoException expected) {
+        }
+        try {
+            queryFromOtherThread.unique();
+            fail(""Did not throw"");
+        } catch (DaoException expected) {
+        }
+        try {
+            queryFromOtherThread.uniqueOrThrow();
+            fail(""Did not throw"");
+        } catch (DaoException expected) {
+        }
+    }
+
+    private void createQueryFromOtherThread() throws InterruptedException {
+        Thread thread = new Thread() {
+
+            @Override
+            public void run() {
+                QueryBuilder<TestEntity> builder = dao.queryBuilder();
+                builder.where(Properties.SimpleInteger.eq(getSimpleInteger(1)));
+                builder.limit(10).offset(20);
+                queryFromOtherThread = builder.build();
+            }
+        };
+        thread.start();
+        thread.join();
+",Added second thread tests to QueryThreadLocalTest,"""Added tests for QueryThreadLocal behavior in multi-threaded environment""","""Added tests for thread safety of Query instances""","""Added more tests to QueryThreadLocalTest and imported necessary classes""

Here's a breakdown of the changes:

1. Imported new classes: `de.greenrobot.dao.DaoException` and `de.greenrobot.dao.QueryBuilder`.

2. Added a new instance variable `private Query<TestEntity> queryFromOtherThread;`.

3. Added two new test methods: `testGetForCurrentThread_TwoThreads()` and `testThrowOutsideOwnerThread()`. These methods test the behavior of the `Query` class when used with multiple threads.

4. Added a new utility method `createQueryFromOtherThread()` which is used by the new test methods to create a `Query` instance in a separate thread.

5. Added a TODO comment in the original version of the code, indicating that more tests were planned. This comment has been removed in the new version, as the planned tests have been added.","""Added tests for Query handling across threads, ensuring expected exceptions are thrown and proper query results retrieved.""",Model 4
"diff --git a/pom.xml b/pom.xml
index 02c54eecc14..667113fbce8 100644
--- a/pom.xml
+++ b/pom.xml
@@ -1183,7 +1183,7 @@
         <equinox.osgi.version>3.10.2.v20150203-1939</equinox.osgi.version>
         <equinox.osgi.services.version>3.4.0.v20140312-2051</equinox.osgi.services.version>
         <carbon.kernel.version>5.1.0</carbon.kernel.version>
-        <transport.http.version>6.0.81</transport.http.version>
+        <transport.http.version>6.0.84</transport.http.version>
         <carbon.messaging.version>2.3.7</carbon.messaging.version>
         <carbon.deployment.version>5.0.0</carbon.deployment.version>
         <carbon.config.version>2.1.2</carbon.config.version>",Bump the transport version,"""Update transport.http.version to 6.0.84""","""Updated transport.http.version to 6.0.84""","""Updating transport.http.version from 6.0.81 to 6.0.84""",Updated `transport.http.version` from 6.0.81 to 6.0.84 in pom.xml to ensure compatibility and security patches.,Model 4
"diff --git a/querydsl-hibernate-search/src/main/java/com/mysema/query/search/LuceneQuery.java b/querydsl-hibernate-search/src/main/java/com/mysema/query/search/LuceneQuery.java
index 3f319d48f..f7651a422 100644
--- a/querydsl-hibernate-search/src/main/java/com/mysema/query/search/LuceneQuery.java
+++ b/querydsl-hibernate-search/src/main/java/com/mysema/query/search/LuceneQuery.java
@@ -11,7 +11,6 @@ import com.mysema.query.QueryModifiers;
 import com.mysema.query.SimpleProjectable;
 import com.mysema.query.SimpleQuery;
 import com.mysema.query.support.QueryMixin;
-import com.mysema.query.support.SimpleQueryAdapter;
 import com.mysema.query.types.OrderSpecifier;
 import com.mysema.query.types.expr.EBoolean;
 import com.mysema.query.types.path.Path;",organized imports,"""Remove unused import of SimpleQueryAdapter in LuceneQuery.java""","""Remove unused import from LuceneQuery.java""","""Remove import of SimpleQueryAdapter in LuceneQuery.java""",Remove unnecessary import SimpleQueryAdapter from LuceneQuery.java in querydsl-hibernate-search.,Model 3
"diff --git a/src/gwt/acesupport/acemixins/token_tooltip.js b/src/gwt/acesupport/acemixins/token_tooltip.js
new file mode 100644
index 0000000000..f77a3fe9ec
--- /dev/null
+++ b/src/gwt/acesupport/acemixins/token_tooltip.js
@@ -0,0 +1,155 @@
+/* ***** BEGIN LICENSE BLOCK *****
+ * Distributed under the BSD license:
+ *
+ * Copyright (c) 2010, Ajax.org B.V.
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Ajax.org B.V. nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS"" AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL AJAX.ORG B.V. BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * ***** END LICENSE BLOCK ***** */
+
+define(""ace/token_tooltip"", [""require"", ""exports"", ""module""], function(require, exports, module) {
+
+var dom = require(""ace/lib/dom"");
+var oop = require(""ace/lib/oop"");
+var event = require(""ace/lib/event"");
+var Range = require(""ace/range"").Range;
+var Tooltip = require(""ace/tooltip"").Tooltip;
+
+function TokenTooltip (editor) {
+    if (editor.tokenTooltip)
+        return;
+    Tooltip.call(this, editor.container);
+    editor.tokenTooltip = this;
+    this.editor = editor;
+
+    this.update = this.update.bind(this);
+    this.onMouseMove = this.onMouseMove.bind(this);
+    this.onMouseOut = this.onMouseOut.bind(this);
+    event.addListener(editor.renderer.scroller, ""mousemove"", this.onMouseMove);
+    event.addListener(editor.renderer.content, ""mouseout"", this.onMouseOut);
+}
+
+oop.inherits(TokenTooltip, Tooltip);
+
+(function(){
+    this.token = {};
+    this.range = new Range();
+    
+    this.update = function() {
+        this.$timer = null;
+        
+        var r = this.editor.renderer;
+        if (this.lastT - (r.timeStamp || 0) > 1000) {
+            r.rect = null;
+            r.timeStamp = this.lastT;
+            this.maxHeight = window.innerHeight;
+            this.maxWidth = window.innerWidth;
+        }
+
+        var canvasPos = r.rect || (r.rect = r.scroller.getBoundingClientRect());
+        var offset = (this.x + r.scrollLeft - canvasPos.left - r.$padding) / r.characterWidth;
+        var row = Math.floor((this.y + r.scrollTop - canvasPos.top) / r.lineHeight);
+        var col = Math.round(offset);
+
+        var screenPos = {row: row, column: col, side: offset - col > 0 ? 1 : -1};
+        var session = this.editor.session;
+        var docPos = session.screenToDocumentPosition(screenPos.row, screenPos.column);
+        var token = session.getTokenAt(docPos.row, docPos.column);
+
+        if (!token && !session.getLine(docPos.row)) {
+            token = {
+                type: """",
+                value: """",
+                state: session.bgTokenizer.getState(0)
+            };
+        }
+        if (!token) {
+            session.removeMarker(this.marker);
+            this.hide();
+            return;
+        }
+
+        var tokenText = token.type;
+        if (token.state)
+            tokenText += ""|"" + token.state;
+        if (token.merge)
+            tokenText += ""\n  merge"";
+        if (token.stateTransitions)
+            tokenText += ""\n  "" + token.stateTransitions.join(""\n  "");
+
+        if (this.tokenText != tokenText) {
+            this.setText(tokenText);
+            this.width = this.getWidth();
+            this.height = this.getHeight();
+            this.tokenText = tokenText;
+        }
+
+        this.show(null, this.x, this.y);
+
+        this.token = token;
+        session.removeMarker(this.marker);
+        this.range = new Range(docPos.row, token.start, docPos.row, token.start + token.value.length);
+        this.marker = session.addMarker(this.range, ""ace_bracket"", ""text"");
+    };
+    
+    this.onMouseMove = function(e) {
+        this.x = e.clientX;
+        this.y = e.clientY;
+        if (this.isOpen) {
+            this.lastT = e.timeStamp;
+            this.setPosition(this.x, this.y);
+        }
+        if (!this.$timer)
+            this.$timer = setTimeout(this.update, 100);
+    };
+
+    this.onMouseOut = function(e) {
+        if (e && e.currentTarget.contains(e.relatedTarget))
+            return;
+        this.hide();
+        this.editor.session.removeMarker(this.marker);
+        this.$timer = clearTimeout(this.$timer);
+    };
+
+    this.setPosition = function(x, y) {
+        if (x + 10 + this.width > this.maxWidth)
+            x = window.innerWidth - this.width - 10;
+        if (y > window.innerHeight * 0.75 || y + 20 + this.height > this.maxHeight)
+            y = y - this.height - 30;
+
+        Tooltip.prototype.setPosition.call(this, x + 10, y + 20);
+    };
+
+    this.destroy = function() {
+        this.onMouseOut();
+        event.removeListener(this.editor.renderer.scroller, ""mousemove"", this.onMouseMove);
+        event.removeListener(this.editor.renderer.content, ""mouseout"", this.onMouseOut);
+        delete this.editor.tokenTooltip;
+    };
+
+}).call(TokenTooltip.prototype);
+
+exports.TokenTooltip = TokenTooltip;
+
+});
diff --git a/src/gwt/src/org/rstudio/studio/client/workbench/commands/Commands.cmd.xml b/src/gwt/src/org/rstudio/studio/client/workbench/commands/Commands.cmd.xml
index 0207d524cc..9b6f5e46fc 100644
--- a/src/gwt/src/org/rstudio/studio/client/workbench/commands/Commands.cmd.xml
+++ b/src/gwt/src/org/rstudio/studio/client/workbench/commands/Commands.cmd.xml
@@ -425,6 +425,8 @@ well as menu structures (for main menu and popup menus).
             <cmd refid=""updateCredentials""/>
             <cmd refid=""diagnosticsReport""/>
             <separator/>
+            <cmd refid=""toggleEditorTokenInfo""/>
+            <separator/>
             <cmd refid=""debugDumpContents""/>
             <cmd refid=""debugImportDump""/>
             <cmd refid=""raiseException""/>
@@ -2518,5 +2520,9 @@ well as menu structures (for main menu and popup menus).
         desc=""Connect or disconnect accounts""
         visible=""false""
         rebindable=""false""/>
+        
+   <cmd id=""toggleEditorTokenInfo""
+        menuLabel=""Toggle Editor Token Information""
+        rebindable=""false""/>
 
 </commands>
diff --git a/src/gwt/src/org/rstudio/studio/client/workbench/commands/Commands.java b/src/gwt/src/org/rstudio/studio/client/workbench/commands/Commands.java
index 67cb2db8b1..d0959ad5ad 100644
--- a/src/gwt/src/org/rstudio/studio/client/workbench/commands/Commands.java
+++ b/src/gwt/src/org/rstudio/studio/client/workbench/commands/Commands.java
@@ -437,6 +437,7 @@ public abstract class
    public abstract AppCommand layoutConsoleOnRight();
    public abstract AppCommand paneLayout();
    public abstract AppCommand maximizeConsole();
+   public abstract AppCommand toggleEditorTokenInfo();
    
    public static final String KEYBINDINGS_PATH =
          ""~/.R/keybindings/rstudio_commands.json"";
diff --git a/src/gwt/src/org/rstudio/studio/client/workbench/views/source/Source.java b/src/gwt/src/org/rstudio/studio/client/workbench/views/source/Source.java
index e2c54c2487..025f46f211 100644
--- a/src/gwt/src/org/rstudio/studio/client/workbench/views/source/Source.java
+++ b/src/gwt/src/org/rstudio/studio/client/workbench/views/source/Source.java
@@ -940,7 +940,6 @@ public class Source implements InsertSourceHandler,
             });
    }
    
-
    @Handler
    public void onNewSourceDoc()
    {
diff --git a/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/AceEditor.java b/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/AceEditor.java
index 96c09613b3..35a589bc9d 100644
--- a/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/AceEditor.java
+++ b/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/AceEditor.java
@@ -2799,6 +2799,20 @@ public class AceEditor implements DocDisplay,
       return snippets_.onInsertSnippet();
    }
    
+   public void toggleTokenInfo()
+   {
+      toggleTokenInfo(widget_.getEditor());
+   }
+   
+   private static final native void toggleTokenInfo(AceEditorNative editor) /*-{
+      if (editor.tokenTooltip && editor.tokenTooltip.destroy) {
+         editor.tokenTooltip.destroy();
+      } else {
+         var TokenTooltip = $wnd.require(""ace/token_tooltip"").TokenTooltip;
+         editor.tokenTooltip = new TokenTooltip(editor);
+      }
+   }-*/;
+   
    private static final int DEBUG_CONTEXT_LINES = 2;
    private final HandlerManager handlers_ = new HandlerManager(this);
    private final AceEditorWidget widget_;
diff --git a/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/DocDisplay.java b/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/DocDisplay.java
index 0d9fba5daf..13dc4a1176 100644
--- a/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/DocDisplay.java
+++ b/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/DocDisplay.java
@@ -345,4 +345,6 @@ public interface DocDisplay extends HasValueChangeHandlers<Void>,
    
    void goToLineStart();
    void goToLineEnd();
+   
+   void toggleTokenInfo();
 }
diff --git a/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/TextEditingTarget.java b/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/TextEditingTarget.java
index c509ca2afc..6b376ac6bf 100644
--- a/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/TextEditingTarget.java
+++ b/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/TextEditingTarget.java
@@ -5013,6 +5013,12 @@ public class TextEditingTarget implements
       }
    }
    
+   @Handler
+   void onToggleEditorTokenInfo()
+   {
+      docDisplay_.toggleTokenInfo();
+   }
+   
    boolean useScopeTreeFolding()
    {
       return docDisplay_.hasScopeTree();",add ( debug ) command to show toke information,"""Added token tooltip feature to AceEditor""",Added token information tooltip to Ace editor and corresponding menu item.,"""Added token tooltip functionality to AceEditor in RStudio""

This commit adds a new feature to the AceEditor in RStudio, which displays token information when the mouse hovers over a token in the editor. The feature is implemented using the `ace/token_tooltip` module, which is a dependency of AceEditor.

The `TokenTooltip` class is defined in the `token_tooltip.js` file, and it extends the `Tooltip` class from the `ace/tooltip` module. The `TokenTooltip` class listens for `mousemove` events on the editor's renderer, and updates the tooltip's position and content based on the current mouse position. It also listens for `mouseout` events to hide the tooltip when the mouse leaves the editor's content area.

The `TokenTooltip` class is used by the `AceEditor` class in the `AceEditor.java` file. The `toggleTokenInfo()` method is added to the `AceEditor` class, which toggles the token tooltip functionality on or off. When the method is called, it checks if the `tokenTooltip` property is already defined on the editor's `AceEditorNative` object. If it is, the `destroy()` method is called on the `tokenTooltip` object to remove it. If it is not, a new `TokenTooltip` object is created and assigned to the `tokenTooltip` property.

The `toggleTokenInfo()` method is also added to the `DocDisplay` interface in the `DocDisplay.java` file, which is implemented by the `AceEditor` class. This allows other classes that depend on the `DocDisplay` interface to toggle the token tooltip functionality.

Finally, the `Commands.java` and `Commands.cmd.xml` files are updated to add a new command for toggling the token tooltip functionality. The command is added to the ""Tools"" menu, and is assigned the keyboard shortcut ""Ctrl+Alt+T"".","Introduce token tooltips in Ace editor, adding toggle command and integrating with existing command structure.",Model 3
"diff --git a/src/main/java/org/tron/core/capsule/AccountCapsule.java b/src/main/java/org/tron/core/capsule/AccountCapsule.java
index 623998d0b..0348d4ed2 100644
--- a/src/main/java/org/tron/core/capsule/AccountCapsule.java
+++ b/src/main/java/org/tron/core/capsule/AccountCapsule.java
@@ -329,6 +329,14 @@ public class AccountCapsule implements ProtoCapsule<Account>, Comparable<Account
     return getInstance().getFrozenList();
   }
 
+  public int getFrozenSupplyCount() {
+    return getInstance().getFrozenSupplyCount();
+  }
+
+  public List<Frozen> getFrozenSupplyList() {
+    return getInstance().getFrozenSupplyList();
+  }
+
   public long getFrozenBalance() {
     List<Frozen> frozenList = getFrozenList();
     final long[] frozenBalance = {0};",add supply interface in AccountCapsule,"""Added methods to retrieve frozen supply count and list in AccountCapsule""","Added methods to retrieve frozen supply information

This commit message is concise and accurately describes the changes made in the commit. It mentions the addition of new methods to retrieve frozen supply information, which is in line with the changes shown in the diff.","""Added getFrozenSupplyCount and getFrozenSupplyList methods to AccountCapsule class""

This commit message describes the change made in the code snippet provided, where two new methods `getFrozenSupplyCount()` and `getFrozenSupplyList()` have been added to the `AccountCapsule` class.",Added methods to retrieve frozen supply count and list in AccountCapsule.,Model 4
"diff --git a/engine/src/main/java/org/terasology/rendering/assets/mesh/ObjMeshFormat.java b/engine/src/main/java/org/terasology/rendering/assets/mesh/ObjMeshFormat.java
index 1c35cdc89..bc33b2283 100644
--- a/engine/src/main/java/org/terasology/rendering/assets/mesh/ObjMeshFormat.java
+++ b/engine/src/main/java/org/terasology/rendering/assets/mesh/ObjMeshFormat.java
@@ -69,10 +69,10 @@ public MeshData load(ResourceUrn urn, List<AssetDataFile> inputs) throws IOExcep
             if (data.getVertices() == null) {
                 throw new IOException(""No vertices define"");
             }
-            //if (data.getNormals() == null || data.getNormals().size() != data.getVertices().size()) {
-            //    throw new IOException(""The number of normals does not match the number of vertices."");
-            //}
-            if (data.getTexCoord0() == null || data.getTexCoord0().size() / 2 != data.getVertices().size() / 3) {
+            if (!data.getNormals().isEmpty() && data.getNormals().size() != data.getVertices().size()) {
+                throw new IOException(""The number of normals does not match the number of vertices."");
+            }
+            if (!data.getTexCoord0().isEmpty() && data.getTexCoord0().size() / 2 != data.getVertices().size() / 3) {
                 throw new IOException(""The number of tex coords does not match the number of vertices."");
             }",Allow obj meshes without texture coords .,"""Relax OBJ mesh format validation to allow missing normals and tex coords""","""Fixed vertex data validation in ObjMeshFormat to check for missing normals and incorrect tex coord count.""","""Updated ObjMeshFormat to allow meshes without normals or texture coordinates""

This commit removes the requirement for normals and texture coordinates to be present in the OBJ mesh data. It also checks if the size of the normals or texture coordinates array matches the size of the vertices array only if they are not empty. This allows for the loading of OBJ meshes that do not have normals or texture coordinates defined.","""Validate normals and texture coordinates only if they are present in ObjMeshFormat.java, fixed validation logic.""",Label
"diff --git a/src/net/java/sip/communicator/impl/callhistory/CallRecordImpl.java b/src/net/java/sip/communicator/impl/callhistory/CallRecordImpl.java
index 4fb410ad3..c52728a86 100644
--- a/src/net/java/sip/communicator/impl/callhistory/CallRecordImpl.java
+++ b/src/net/java/sip/communicator/impl/callhistory/CallRecordImpl.java
@@ -53,7 +53,7 @@ public Call getSourceCall()
 
     /**
      * Set the time when the call finishes
-     * If some participant has no end Time set we set it also
+     * If some peer has no end Time set we set it also
      * @param endTime Date
      */
     public void setEndTime(Date endTime)
diff --git a/src/net/java/sip/communicator/impl/gui/main/call/CallManager.java b/src/net/java/sip/communicator/impl/gui/main/call/CallManager.java
index e4b98ba32..ccde718cc 100644
--- a/src/net/java/sip/communicator/impl/gui/main/call/CallManager.java
+++ b/src/net/java/sip/communicator/impl/gui/main/call/CallManager.java
@@ -280,7 +280,7 @@ public void run()
 
 
     /**
-     * Answers all call participants in the given call.
+     * Answers all call peers in the given call.
      */
     private static class AnswerCallThread
         extends Thread
@@ -295,22 +295,22 @@ public AnswerCallThread(Call call)
         public void run()
         {
             ProtocolProviderService pps = call.getProtocolProvider();
-            Iterator<CallPeer> participants = call.getCallPeers();
+            Iterator<CallPeer> peers = call.getCallPeers();
 
-            while (participants.hasNext())
+            while (peers.hasNext())
             {
-                CallPeer participant = participants.next();
+                CallPeer peer = peers.next();
                 OperationSetBasicTelephony telephony =
                     (OperationSetBasicTelephony) pps
                         .getOperationSet(OperationSetBasicTelephony.class);
 
                 try
                 {
-                    telephony.answerCallPeer(participant);
+                    telephony.answerCallPeer(peer);
                 }
                 catch (OperationFailedException e)
                 {
-                    logger.error(""Could not answer to : "" + participant
+                    logger.error(""Could not answer to : "" + peer
                         + "" caused by the following exception: "" + e);
                 }
             }
@@ -318,7 +318,7 @@ public void run()
     }
 
     /**
-     * Hangups all call participants in the given call.
+     * Hangups all call peers in the given call.
      */
     private static class HangupCallThread
         extends Thread
@@ -333,11 +333,11 @@ public HangupCallThread(Call call)
         public void run()
         {
             ProtocolProviderService pps = call.getProtocolProvider();
-            Iterator<CallPeer> participants = call.getCallPeers();
+            Iterator<CallPeer> peers = call.getCallPeers();
 
-            while (participants.hasNext())
+            while (peers.hasNext())
             {
-                CallPeer participant = participants.next();
+                CallPeer participant = peers.next();
                 OperationSetBasicTelephony telephony =
                     (OperationSetBasicTelephony) pps
                         .getOperationSet(OperationSetBasicTelephony.class);
diff --git a/src/net/java/sip/communicator/impl/gui/main/call/ReceivedCallDialog.java b/src/net/java/sip/communicator/impl/gui/main/call/ReceivedCallDialog.java
index b14c8cc9a..0dbb05f78 100644
--- a/src/net/java/sip/communicator/impl/gui/main/call/ReceivedCallDialog.java
+++ b/src/net/java/sip/communicator/impl/gui/main/call/ReceivedCallDialog.java
@@ -121,41 +121,40 @@ private void initComponents()
      */
     private void initCallLabel(JLabel callLabel)
     {
-        Iterator<CallPeer> participantsIter
-            = incomingCall.getCallPeers();
+        Iterator<CallPeer> peersIter = incomingCall.getCallPeers();
 
-        boolean hasMoreParticipants = false;
+        boolean hasMorePeers = false;
         String text = """";
 
         ImageIcon imageIcon =
             ImageUtils.getScaledRoundedIcon(ImageLoader
                 .getImage(ImageLoader.DEFAULT_USER_PHOTO), 40, 45);
 
-        while (participantsIter.hasNext())
+        while (peersIter.hasNext())
         {
-            CallPeer participant = participantsIter.next();
+            CallPeer peer = peersIter.next();
 
-            // More participants.
-            if (participantsIter.hasNext())
+            // More peers.
+            if (peersIter.hasNext())
             {
                 text = callLabel.getText()
-                    + participant.getDisplayName() + "", "";
+                    + peer.getDisplayName() + "", "";
 
-                hasMoreParticipants = true;
+                hasMorePeers = true;
             }
-            // Only one participant.
+            // Only one peer.
             else
             {
                 text = callLabel.getText()
-                    + participant.getDisplayName()
+                    + peer.getDisplayName()
                     + "" ""
                     + GuiActivator.getResources().getI18NString(""service.gui.IS_CALLING"");
 
-                imageIcon = getParticipantImage(participant);
+                imageIcon = getPeerImage(peer);
             }
         }
 
-        if (hasMoreParticipants)
+        if (hasMorePeers)
             text += GuiActivator.getResources()
                 .getI18NString(""service.gui.ARE_CALLING"");
 
@@ -186,21 +185,21 @@ else if (buttonName.equals(HANGUP_BUTTON))
     }
 
     /**
-     * Returns the participant image.
+     * Returns the peer image.
      *
-     * @param participant The call participant, for which we're returning an
+     * @param peer The call peer, for which we're returning an
      * image.
-     * @return the participant image.
+     * @return the peer image.
      */
-    private ImageIcon getParticipantImage(CallPeer participant)
+    private ImageIcon getPeerImage(CallPeer peer)
     {",Renames occurrences of callParticipant to callPeer so that it would better reflect our new Call architecture that also includes conferencing and ConferenceMembers,"""Replace 'participant' with 'peer' in call-related classes for consistency""","""Consistent use of 'peer' terminology in call history and call management.""","""Updated terminology from 'participant' to 'peer' in CallRecordImpl, CallManager, and ReceivedCallDialog""","""Refactor: Replaced 'participant' with 'peer' for consistency in naming throughout the call management classes.""",Model 3
"diff --git a/do-release.sh b/do-release.sh
index f276238301..d1efe7f60d 100755
--- a/do-release.sh
+++ b/do-release.sh
@@ -113,7 +113,10 @@ echo
 echo ""Updated stats in release notes:""
 echo ""$STATS""
 echo
+echo ""Please verify docs/pages/release_notes.md""
 echo
+echo ""Press enter to continue...""
+read
 
 # install bundles needed for rendering release notes
 bundle install --with=release_notes_preprocessing --path vendor/bundle",Add a verify step in do - release . sh,"""Add confirmation step before rendering release notes""","""Added verification step for release notes and added prompt to continue""","Added prompts to verify release notes and press enter to continue in do-release.sh

This commit adds two echo statements and a read statement in the do-release.sh script. The first echo statement prompts the user to verify the release notes located in docs/pages/release\_notes.md. The second echo statement asks the user to press enter to continue. The read statement pauses the script execution until the user presses enter.

Additionally, there is a comment indicating that the script installs bundles needed for rendering release notes using the command ""bundle install --with=release\_notes\_preprocessing --path vendor/bundle"". This comment was already present in the original file and was not added in this commit.",Add release notes verification and prompt before continuing the release script process.,Model 1
"diff --git a/src/main/java/hex/FrameTask.java b/src/main/java/hex/FrameTask.java
index a7b161c7e..f6e459b47 100644
--- a/src/main/java/hex/FrameTask.java
+++ b/src/main/java/hex/FrameTask.java
@@ -23,6 +23,8 @@ public abstract class FrameTask<T extends FrameTask<T>> extends MRTask2<T>{
   protected float _useFraction = 1.0f;
   protected boolean _shuffle = false;
 
+  protected boolean skipMissing() { return true; }
+
   public FrameTask(Key jobKey, DataInfo dinfo) {
     this(jobKey,dinfo,null);
   }
@@ -556,10 +558,11 @@ public abstract class FrameTask<T extends FrameTask<T>> extends MRTask2<T>{
         final long lr = r + chunks[0]._start;
         if ((_dinfo._nfolds > 0 && (lr % _dinfo._nfolds) == _dinfo._foldId)
                 || (skip_rng != null && skip_rng.nextFloat() > _useFraction))continue;
-        for(Chunk c:chunks)if(c.isNA0(r))continue OUTER; // skip rows with NAs!
+        for(Chunk c:chunks)if(skipMissing() && c.isNA0(r))continue OUTER; // skip rows with NAs!
         ++num_processed_rows;
         int i = 0, ncats = 0;
         for(; i < _dinfo._cats; ++i){
+          assert(!chunks[i].isNA0(r));
           int c = (int)chunks[i].at80(r);
           if(_dinfo._catLvls != null){ // some levels are ignored?
             c = Arrays.binarySearch(_dinfo._catLvls[i],c);
@@ -572,13 +575,14 @@ public abstract class FrameTask<T extends FrameTask<T>> extends MRTask2<T>{
         }
         final int n = chunks.length-_dinfo._responses;
         for(;i < n;++i){
-          double d = chunks[i].at0(r);
+          double d = chunks[i].at0(r); //can be NA if skipMissing() == false
           if(_dinfo._normMul != null) d = (d - _dinfo._normSub[i-_dinfo._cats])*_dinfo._normMul[i-_dinfo._cats];
           nums[i-_dinfo._cats] = d;
         }
         for(i = 0; i < _dinfo._responses; ++i) {
           response[i] = chunks[chunks.length-_dinfo._responses + i].at0(r);
           if (_dinfo._normRespMul != null) response[i] = (response[i] - _dinfo._normRespSub[i])*_dinfo._normRespMul[i];
+          if(Double.isNaN(response[i]))continue OUTER; // skip rows without a valid response (no supervised training possible)
         }
         long seed = offset + rrr*(end-start) + r;
         if (outputs != null && outputs.length > 0)
diff --git a/src/main/java/hex/deeplearning/DeepLearningTask.java b/src/main/java/hex/deeplearning/DeepLearningTask.java
index 992003d6a..230c93319 100644
--- a/src/main/java/hex/deeplearning/DeepLearningTask.java
+++ b/src/main/java/hex/deeplearning/DeepLearningTask.java
@@ -19,6 +19,8 @@ public class DeepLearningTask extends FrameTask<DeepLearningTask> {
 
   int _chunk_node_count = 1;
 
+  @Override protected boolean skipMissing() { return false; }
+
   public DeepLearningTask(hex.deeplearning.DeepLearningModel.DeepLearningModelInfo input, float fraction){this(input,fraction,null);}
   private DeepLearningTask(hex.deeplearning.DeepLearningModel.DeepLearningModelInfo input, float fraction, H2OCountedCompleter cmp){
     super(input.get_params().self(),input.data_info(),cmp);
@@ -167,8 +169,13 @@ public class DeepLearningTask extends FrameTask<DeepLearningTask> {
           if (training) {
             for (int i = 1; i < neurons.length - 1; i++)
               Arrays.fill(neurons[i]._e.raw(), 0);
-            assert ((double) (int) responses[0] == responses[0]);
-            final int target_label = (int) responses[0];
+            int target_label;
+            if (Double.isNaN(responses[0])) { //missing response
+              target_label = Neurons.missing_int_value;
+            } else {
+              assert ((double) (int) responses[0] == responses[0]); //classification -> integer labels expected
+              target_label = (int) responses[0];
+            }
             ((Neurons.Softmax) neurons[neurons.length - 1]).bprop(target_label);
           }
         } else {
@@ -176,7 +183,12 @@ public class DeepLearningTask extends FrameTask<DeepLearningTask> {
           if (training) {
             for (int i = 1; i < neurons.length - 1; i++)
               Arrays.fill(neurons[i]._e.raw(), 0);
-            final float target_value = (float) responses[0];
+            float target_value;
+            if (Double.isNaN(responses[0])) { //missing response
+              target_value = Neurons.missing_real_value;
+            } else {
+              target_value = (float) responses[0];
+            }
             ((Neurons.Linear) neurons[neurons.length - 1]).bprop(target_value);
           }
         }
diff --git a/src/main/java/hex/deeplearning/Neurons.java b/src/main/java/hex/deeplearning/Neurons.java
index 4050c6967..3eee80643 100644
--- a/src/main/java/hex/deeplearning/Neurons.java
+++ b/src/main/java/hex/deeplearning/Neurons.java
@@ -5,7 +5,6 @@ import hex.deeplearning.DeepLearning.Loss;
 import water.Iced;
 import water.MemoryManager;
 import water.api.Request.API;
-import water.util.Log;
 import water.util.Utils;
 
 import java.util.Arrays;
@@ -89,16 +88,8 @@ public abstract class Neurons {
 
   public DenseVector _avg_a;
 
-//  /**
-//   * We need a way to encode a missing value in the neural net forward/back-propagation scheme.
-//   * For simplicity and performance, we simply use the largest values to encode a missing value.
-//   * If we run into exactly one of those values with regular neural net updates, then we're very
-//   * likely also running into overflow problems, which will trigger a NaN somewhere, which will be
-//   * caught and lead to automatic job cancellation.
-//   */
-//  public static final int missing_int_value = Integer.MAX_VALUE; //encode missing label or target
-//  public static final double missing_double_value = Double.MAX_VALUE; //encode missing input
-
+  public static final int missing_int_value = Integer.MAX_VALUE; //encode missing label
+  public static final Float missing_real_value = Float.NaN; //encode missing regression target
 
   /**
    * Helper to check sanity of Neuron layers
@@ -928,7 +919,7 @@ public abstract class Neurons {
      * @param target actual class label
      */
     protected void bprop(int target) {
-//      if (target == missing_int_value) return; //ignore missing response values
+      assert (target != missing_int_value); // no correction of weights/biases for missing label
       float m = momentum();
       float r = _minfo.adaDelta() ? 0 : rate(_minfo.get_processed_total()) * (1f - m);
       float g; //partial derivative dE/dy * dy/dnet
@@ -966,7 +957,7 @@ public abstract class Neurons {
      * @param target floating-point target value
      */
     protected void bprop(float target) {
-//      if (target == missing_double_value) return;
+      assert (target != missing_real_value);
       if (params.loss != Loss.MeanSquare) throw new UnsupportedOperationException(""Regression is only implemented for MeanSquare error."");
       final int row = 0;
       // Computing partial derivative: dE/dnet = dE/dy * dy/dnet = dE/dy * 1",Add support for missing values in DL ( via mean imputation ) .,"""Handle missing values in FrameTask and DeepLearningTask""","""Added skipMissing() method to FrameTask and DeepLearningTask, and updated handling of missing values in Neurons and DeepLearningTask.""","The commit message should be:

""Added method to skip missing values in FrameTask and handling for missing responses in DeepLearningTask and Neurons. Also added assertions to check for missing values in DeepLearningTask and Neurons.""

This commit introduces a new method `skipMissing()` in the `FrameTask` class to allow subclasses to decide whether to skip rows with missing values or not. It also adds handling for missing responses in the `DeepLearningTask` and `Neurons` classes. Furthermore, assertions are added to check for missing values in these classes to ensure that the code behaves as expected.","The commit message is:

""Add handling for missing values in FrameTask and DeepLearningTask, including skip logic and missing value encodings.""",Model 4
"diff --git a/devtools/gradle/src/functionalTest/java/io/quarkus/gradle/devmode/DotEnvQuarkusDevModeConfigurationTest.java b/devtools/gradle/src/functionalTest/java/io/quarkus/gradle/devmode/DotEnvQuarkusDevModeConfigurationTest.java
new file mode 100644
index 00000000000..5a23dcb26bb
--- /dev/null
+++ b/devtools/gradle/src/functionalTest/java/io/quarkus/gradle/devmode/DotEnvQuarkusDevModeConfigurationTest.java
@@ -0,0 +1,15 @@
+package io.quarkus.gradle.devmode;
+
+import static org.assertj.core.api.Assertions.assertThat;
+
+public class DotEnvQuarkusDevModeConfigurationTest extends QuarkusDevGradleTestBase {
+    @Override
+    protected String projectDirectoryName() {
+        return ""dotenv-config-java-module"";
+    }
+
+    @Override
+    protected void testDevMode() throws Exception {
+        assertThat(getHttpResponse(""/hello"")).contains(""hey"");
+    }
+}
diff --git a/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/.env b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/.env
new file mode 100644
index 00000000000..c1f759725f0
--- /dev/null
+++ b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/.env
@@ -0,0 +1 @@
+GREETING_MESSAGE=hey
diff --git a/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/build.gradle b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/build.gradle
new file mode 100644
index 00000000000..183d880b88a
--- /dev/null
+++ b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/build.gradle
@@ -0,0 +1,33 @@
+plugins {
+    id 'java'
+    id 'io.quarkus'
+}
+
+repositories {
+     mavenLocal()
+     mavenCentral()
+}
+
+dependencies {
+    implementation enforcedPlatform(""${quarkusPlatformGroupId}:${quarkusPlatformArtifactId}:${quarkusPlatformVersion}"")
+    implementation 'io.quarkus:quarkus-resteasy'
+
+    testImplementation 'io.quarkus:quarkus-junit5'
+    testImplementation 'io.rest-assured:rest-assured'
+}
+
+group 'org.acme'
+version '1.0.0-SNAPSHOT'
+
+compileJava {
+    options.encoding = 'UTF-8'
+    options.compilerArgs << '-parameters'
+}
+
+compileTestJava {
+    options.encoding = 'UTF-8'
+}
+
+quarkusDev {
+    workingDir = System.getProperty(""java.io.tmpdir"")
+}
diff --git a/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/gradle.properties b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/gradle.properties
new file mode 100644
index 00000000000..ec2b6ef199c
--- /dev/null
+++ b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/gradle.properties
@@ -0,0 +1,2 @@
+quarkusPlatformArtifactId=quarkus-bom
+quarkusPlatformGroupId=io.quarkus
diff --git a/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/settings.gradle b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/settings.gradle
new file mode 100644
index 00000000000..554eb4c4098
--- /dev/null
+++ b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/settings.gradle
@@ -0,0 +1,11 @@
+pluginManagement {
+    repositories {
+        mavenLocal()
+        mavenCentral()
+        gradlePluginPortal()
+    }
+    plugins {
+      id 'io.quarkus' version ""${quarkusPluginVersion}""
+    }
+}
+rootProject.name='code-with-quarkus'
diff --git a/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/src/main/java/org/acme/GreetingResource.java b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/src/main/java/org/acme/GreetingResource.java
new file mode 100644
index 00000000000..6ac027d26dc
--- /dev/null
+++ b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/src/main/java/org/acme/GreetingResource.java
@@ -0,0 +1,21 @@
+package org.acme;
+
+import javax.ws.rs.GET;
+import javax.ws.rs.Path;
+import javax.ws.rs.Produces;
+import javax.ws.rs.core.MediaType;
+
+import org.eclipse.microprofile.config.inject.ConfigProperty;
+
+@Path(""/hello"")
+public class GreetingResource {
+
+    @ConfigProperty(name = ""greeting.message"")
+    String message;
+
+    @GET
+    @Produces(MediaType.TEXT_PLAIN)
+    public String hello() {
+        return message;
+    }
+}",Add test to ensure that . env works in Gradle .,"""Add functional test for Quarkus dev mode with .env configuration""","""Add test for Quarkus Dev Mode configuration with .env file""","""Add functional test for dotenv configuration in Quarkus dev mode""

This commit appears to add a new functional test class `DotEnvQuarkusDevModeConfigurationTest` for testing the dotenv configuration in Quarkus dev mode using Gradle. It also includes a new Gradle project in the `dotenv-config-java-module` directory with an `.env` file containing a single key-value pair for testing. The `build.gradle` file sets up the project with the necessary dependencies and configurations for Quarkus, and the `GreetingResource` class uses the `@ConfigProperty` annotation to inject the value from the `.env` file. The test case in `DotEnvQuarkusDevModeConfigurationTest` verifies that the injected value is correctly used by the application in dev mode.",Add dotenv configuration test for Quarkus Gradle dev mode with GreetingResource endpoint using environment variable.,Model 2
"diff --git a/frontend/server/src/test/resources/inference_open_api.json b/frontend/server/src/test/resources/inference_open_api.json
index e0b601d2..702af168 100644
--- a/frontend/server/src/test/resources/inference_open_api.json
+++ b/frontend/server/src/test/resources/inference_open_api.json
@@ -125,7 +125,7 @@
         }
       }
     },
-    ""/predictions/{model_name}"": {
+    ""/predictions/{model_name}[/{model_version}]"": {
       ""post"": {
         ""description"": ""Predictions entry point for each model. Use OPTIONS method to get detailed model API input and output description."",
         ""operationId"": ""predictions"",
diff --git a/frontend/server/src/test/resources/management_open_api.json b/frontend/server/src/test/resources/management_open_api.json
index 79ff026d..7848c2e9 100644
--- a/frontend/server/src/test/resources/management_open_api.json
+++ b/frontend/server/src/test/resources/management_open_api.json
@@ -448,9 +448,9 @@
         }
       }
     },
-    ""/models/{model_name}"": {
+    ""/models/{model_name}[/{model_version}]"": {
       ""get"": {
-        ""description"": ""Provides detailed information about the specified model."",
+        ""description"": ""Provides detailed information about the specified version of a model. If no version is specified, returns the details of default version. If \""all\"" is specified as version, returns the details about all the versions of the model."",
         ""operationId"": ""describeModel"",
         ""parameters"": [
           {
@@ -461,6 +461,15 @@
             ""schema"": {
               ""type"": ""string""
             }
+          },
+          {
+            ""in"": ""path"",
+            ""name"": ""model_version"",
+            ""description"": ""Version of model to describe."",
+            ""required"": true,
+            ""schema"": {
+              ""type"": ""string""
+            }
           }
         ],
         ""responses"": {
@@ -607,7 +616,7 @@
         }
       },
       ""put"": {
-        ""description"": ""Configure number of workers for a model, This is a asynchronous call by default. Caller need to call describeModel check if the model workers has been changed."",
+        ""description"": ""Configure number of workers for a specified version of a model. If no version is specified, this applies to the default version of the model. This is a asynchronous call by default. Caller need to call describeModel check if the model workers has been changed."",
         ""operationId"": ""setAutoScale"",
         ""parameters"": [
           {
@@ -619,6 +628,15 @@
               ""type"": ""string""
             }
           },
+          {
+            ""in"": ""path"",
+            ""name"": ""model_version"",
+            ""description"": ""Version of model to describe."",
+            ""required"": true,
+            ""schema"": {
+              ""type"": ""string""
+            }
+          },
           {
             ""in"": ""query"",
             ""name"": ""min_worker"",
@@ -818,7 +836,7 @@
         }
       },
       ""delete"": {
-        ""description"": ""Unregister a model from TorchServe. This is an asynchronous call by default. Caller can call listModels to confirm if all the works has be terminated."",
+        ""description"": ""Unregister the specified version of a model from TorchServe. If no version is specified, TorchServe tries to unregister the default version of the model and unregisters it if it is the only version available. This is an asynchronous call by default. Caller can call listModels to confirm if all the works has be terminated."",
         ""operationId"": ""unregisterModel"",
         ""parameters"": [
           {
@@ -830,6 +848,15 @@
               ""type"": ""string""
             }
           },
+          {
+            ""in"": ""path"",
+            ""name"": ""model_version"",
+            ""description"": ""Version of model to unregister."",
+            ""required"": true,
+            ""schema"": {
+              ""type"": ""string""
+            }
+          },
           {
             ""in"": ""query"",
             ""name"": ""synchronous"",
@@ -919,6 +946,35 @@
               }
             }
           },
+          ""400"": {
+            ""description"": ""Model version not found"",
+            ""content"": {
+              ""application/json"": {
+                ""schema"": {
+                  ""type"": ""object"",
+                  ""required"": [
+                    ""code"",
+                    ""type"",
+                    ""message""
+                  ],
+                  ""properties"": {
+                    ""code"": {
+                      ""type"": ""integer"",
+                      ""description"": ""Error code.""
+                    },
+                    ""type"": {
+                      ""type"": ""string"",
+                      ""description"": ""Error type.""
+                    },
+                    ""message"": {
+                      ""type"": ""string"",
+                      ""description"": ""Error message.""
+                    }
+                  }
+                }
+              }
+            }
+          },
           ""408"": {
             ""description"": ""Request Timeout Error"",
             ""content"": {
@@ -979,6 +1035,111 @@
           }
         }
       }
+    },
+    ""/models/{model_name}/{model_version}/set-default"": {
+      ""put"": {
+        ""description"": ""Set default version of a model"",
+        ""operationId"": ""setDefault"",
+        ""parameters"": [
+          {
+",updated expected output for UTs,"""Added model versioning support to OpenAPI definitions""

This commit message accurately reflects the changes made in the diff, which include adding model versioning support to various API endpoints in the OpenAPI definitions.","Added support for model versions in OpenAPI definitions

This commit message is concise and accurately describes the changes made in the commit. It mentions the key feature added, which is support for model versions in the OpenAPI definitions.","""Update OpenAPI specifications for model versioning:
- Add model version parameter to the /predictions/{model_name} endpoint in inference_open_api.json
- Add model version parameter to various endpoints in management_open_api.json
- Update descriptions and responses to reflect changes due to model versioning""

Explanation:
The changes made in this commit primarily involve adding a new parameter ""model_version"" to several endpoints in both inference_open_api.json and management_open_api.json. The descriptions and responses have also been updated to reflect the changes brought about by the introduction of model versioning. For instance, the description for the /models/{model_name} GET request has been modified to include version-specific details. Similarly, the descriptions for other endpoints like /models/{model_name} PUT and DELETE requests have been updated to reflect the changes due to model versioning. Additionally, new response codes and their descriptions have been introduced where necessary.","""Add model version handling and detailed descriptions for API endpoints in inference_open_api.json and management_open_api.json.""",Model 2
"diff --git a/README b/README
index b5db6e3c6..34a82e0b3 100644
--- a/README
+++ b/README
@@ -15,7 +15,7 @@ Atmosphere is also availaible as part of the following framework:
 * Akka, event-driven, scalable and fault-tolerant architectures for the JVM
 * Google Widget Toolkit (GWT)
 
-Browse our super easy Rest based PubSub sample and read on what is Atmosphere exactly.
+Atmosphere ship with a JQuery Plug In that can be used with any Comet or WebSocket Framework:
 
     http://is.gd/bJXhH",Improve documentation,"""Update README to mention Atmosphere's JQuery Plug In""","""Update README to mention Atmosphere's JQuery Plug In""","""Updated README: Added information about Atmosphere's JQuery Plug In""","Updated README to mention the jQuery plugin for use with Comet or WebSocket Frameworks, replacing Rest-based PubSub sample reference.",Model 3
"diff --git a/README.txt b/README.txt
index c9977efb7c7..9ff5e59e856 100644
--- a/README.txt
+++ b/README.txt
@@ -433,6 +433,9 @@ web.xml of source.war file and change them (see note1) appropriately.
   - The file 'body_include' can be created under DATA_ROOT.
     The contents of this file will be inserted above the footer of the web
     application's ""Home"" page.
+  - The file 'error_forbidden_include' can be created under DATA_ROOT.
+    The contents of this file will be displayed as the error page when
+    the user is forbidden to see a particular project with HTTP 403 code.
 
 
 5.4.3 - Path Descriptions (optional)
diff --git a/src/org/opensolaris/opengrok/configuration/Configuration.java b/src/org/opensolaris/opengrok/configuration/Configuration.java
index e2d4619b757..0ec1c4d34be 100644
--- a/src/org/opensolaris/opengrok/configuration/Configuration.java
+++ b/src/org/opensolaris/opengrok/configuration/Configuration.java
@@ -1014,6 +1014,30 @@ public final class Configuration {
         return body;
     }
 
+    /**
+     * The name of the file relative to the <var>DATA_ROOT</var>, which should
+     * be included into the error page handling access forbidden errors - HTTP
+     * code 403 Forbidden.
+     */
+    public static final String E_FORBIDDEN_INCLUDE_FILE = ""error_forbidden_include"";
+
+    private transient String eforbidden_content = null;
+
+    /**
+     * Get the contents of the page for forbidden error page (403 Forbidden)
+     * include file.
+     *
+     * @return an empty string if it could not be read successfully, the
+     * contents of the file otherwise.
+     * @see Configuration#E_FORBIDDEN_INCLUDE_FILE
+     */
+    public String getForbiddenIncludeFileContent() {
+        if (eforbidden_content == null) {
+            eforbidden_content = getFileContent(new File(getDataRoot(), E_FORBIDDEN_INCLUDE_FILE));
+        }
+        return eforbidden_content;
+    }
+
     /**
      * Get the eftar file, which contains definition tags.
      *
diff --git a/web/WEB-INF/web.xml b/web/WEB-INF/web.xml
index d5249d94005..a9f9e0f75f4 100644
--- a/web/WEB-INF/web.xml
+++ b/web/WEB-INF/web.xml
@@ -127,6 +127,15 @@
 <param-name>keepgenerated</param-name><param-value>true</param-value>
 </init-param>
   </servlet>
+  <servlet>
+      <display-name>Forbidden error handler</display-name>
+      <servlet-name>eforbidden</servlet-name>
+      <jsp-file>/eforbidden.jsp</jsp-file>
+      <init-param>
+          <param-name>keepgenerated</param-name>
+          <param-value>true</param-value>
+      </init-param>
+  </servlet>
   <servlet-mapping>
     <servlet-name>search</servlet-name>
     <url-pattern>/search</url-pattern>		<!-- SEARCH_P -->
@@ -179,6 +188,10 @@
     <servlet-name>enoent</servlet-name>
     <url-pattern>/enoent</url-pattern>		<!-- NOT_FOUND -->
   </servlet-mapping>
+  <servlet-mapping>
+      <servlet-name>eforbidden</servlet-name>
+      <url-pattern>/eforbidden</url-pattern>		<!-- FORBIDDEN -->
+  </servlet-mapping>
   <error-page>
     <error-code>404</error-code>
     <location>/enoent</location>
@@ -187,8 +200,12 @@
     <error-code>500</error-code>
     <location>/error</location>
   </error-page>
+  <error-page>
+      <error-code>403</error-code>
+      <location>/eforbidden</location>
+  </error-page>
   <jsp-config>
-    <jsp-property-group>
+      <jsp-property-group>
       <url-pattern>*.jsp</url-pattern>
       <trim-directive-whitespaces>true</trim-directive-whitespaces>
     </jsp-property-group>
diff --git a/web/eforbidden.jsp b/web/eforbidden.jsp
new file mode 100644
index 00000000000..3d4121ab9a7
--- /dev/null
+++ b/web/eforbidden.jsp
@@ -0,0 +1,30 @@
+<%--
+CDDL HEADER START
+
+The contents of this file are subject to the terms of the
+Common Development and Distribution License (the ""License"").
+You may not use this file except in compliance with the License.
+
+See LICENSE.txt included in this distribution for the specific
+language governing permissions and limitations under the License.
+
+When distributing Covered Code, include this CDDL HEADER in each
+file and include the License file at LICENSE.txt.
+If applicable, add the following below this CDDL HEADER, with the
+fields enclosed by brackets ""[]"" replaced with your own identifying
+information: Portions Copyright [yyyy] [name of copyright owner]
+
+CDDL HEADER END
+
+Copyright (c) 2017, Oracle and/or its affiliates. All rights reserved.
+--%><%@page  session=""false"" isErrorPage=""true"" import=""
+             org.opensolaris.opengrok.web.PageConfig""
+%><%
+    /* ---------------------- eforbidden.jspf start --------------------- */
+    {
+%>
+<%= PageConfig.get(request).getEnv().getConfiguration().getForbiddenIncludeFileContent()%>
+<%
+    }
+    /* ---------------------- eforbidden.jspf end --------------------- */
+%>",let the user to customize the 403 error page ( <issue_id> ) .,"""Added support for custom 403 Forbidden error page""","""Added support for custom forbidden error page with HTTP 403 code""","The commit message could be:

""Added support for custom error page for forbidden access (HTTP 403)

Changes include:
- Updated README.txt to include instructions for creating the error_forbidden_include file
- Added a new constant E_FORBIDDEN_INCLUDE_FILE and a new method getForbiddenIncludeFileContent() in Configuration.java
- Added a new servlet for handling forbidden errors in web.xml
- Created a new JSP file eforbidden.jsp to display the custom error message""",Add error handling for HTTP 403 forbidden in the web application with customizable error page include file.,Model 1
"diff --git a/README.md b/README.md
index ae0690ae3..dbb0e562d 100644
--- a/README.md
+++ b/README.md
@@ -8,6 +8,11 @@ This is the official repository of AntennaPod, a podcast manager for Android.
 </a>
 [AntennaPod on fdroid.org](http://f-droid.org/repository/browse/?fdcategory=Multimedia&fdid=de.danoeh.antennapod&fdpage=1)
 
+## Feedback
+You can use the [AntennaPod Google Group](https://groups.google.com/forum/#!forum/antennapod) for discussions about the app.
+
+Bug reports and feature requests can be submitted [here](https://github.com/danieloeh/AntennaPod/issues/new) (please read the [instructions](https://github.com/danieloeh/AntennaPod/blob/master/CONTRIBUTING.md) on how to report a bug and how to submit a feature request first!).
+
 ## License
 
 AntennaPod is licensed under the MIT License. You can find the license text in the LICENSE file.",Added feedback section,"""Add feedback section to README with links to Google Group and issue tracker""","""Added feedback section to README.md with information on discussion forum, bug reports, and feature requests.""","The commit message should be:

 Add feedback section to README.md

 This commit message describes the change made in the README.md file, which is the addition of a new section about feedback. It provides a brief summary of the changes made in the commit.","""Add feedback section with links to Google Group for discussions and GitHub issues for bug reports and feature requests.""",Model 4
"diff --git a/SwitchButton/library/src/main/java/com/kyleduo/switchbutton/SwitchButton.java b/SwitchButton/library/src/main/java/com/kyleduo/switchbutton/SwitchButton.java
index 64f589a..6f30abe 100644
--- a/SwitchButton/library/src/main/java/com/kyleduo/switchbutton/SwitchButton.java
+++ b/SwitchButton/library/src/main/java/com/kyleduo/switchbutton/SwitchButton.java
@@ -13,6 +13,9 @@ import android.graphics.RectF;
 import android.graphics.drawable.Drawable;
 import android.graphics.drawable.StateListDrawable;
 import android.support.v4.content.ContextCompat;
+import android.text.Layout;
+import android.text.StaticLayout;
+import android.text.TextPaint;
 import android.util.AttributeSet;
 import android.view.MotionEvent;
 import android.view.SoundEffectConstants;
@@ -52,7 +55,7 @@ public class SwitchButton extends CompoundButton {
 
 	private int mCurrThumbColor, mCurrBackColor, mNextBackColor;
 	private Drawable mCurrentBackDrawable, mNextBackDrawable;
-	private RectF mThumbRectF, mBackRectF, mSafeRectF;
+	private RectF mThumbRectF, mBackRectF, mSafeRectF, mTextOnRectF, mTextOffRectF;
 	private Paint mPaint;
 	// whether using Drawable for thumb or back
 	private boolean mIsThumbUseDrawable, mIsBackUseDrawable;
@@ -66,6 +69,11 @@ public class SwitchButton extends CompoundButton {
 	private int mTouchSlop;
 	private int mClickTimeout;
 	private Paint mRectPaint;
+	private String mTextOn;
+	private String mTextOff;
+	private TextPaint mTextPaint;
+	private Layout mOnLayout;
+	private Layout mOffLayout;
 
 	public SwitchButton(Context context, AttributeSet attrs, int defStyle) {
 		super(context, attrs, defStyle);
@@ -91,11 +99,15 @@ public class SwitchButton extends CompoundButton {
 		mRectPaint.setStyle(Paint.Style.STROKE);
 		mRectPaint.setStrokeWidth(getResources().getDisplayMetrics().density);
 
+		mTextPaint = getPaint();
+
 		mThumbRectF = new RectF();
 		mBackRectF = new RectF();
 		mSafeRectF = new RectF();
 		mThumbSizeF = new PointF();
 		mThumbMargin = new RectF();
+		mTextOnRectF = new RectF();
+		mTextOffRectF = new RectF();
 
 		mProcessAnimator = ObjectAnimator.ofFloat(this, ""process"", 0, 0).setDuration(DEFAULT_ANIMATION_DURATION);
 		mProcessAnimator.setInterpolator(new AccelerateDecelerateInterpolator());
@@ -122,6 +134,8 @@ public class SwitchButton extends CompoundButton {
 		int animationDuration = DEFAULT_ANIMATION_DURATION;
 		boolean fadeBack = true;
 		int tintColor = Integer.MIN_VALUE;
+		String textOn = null;
+		String textOff = null;
 
 		TypedArray ta = attrs == null ? null : getContext().obtainStyledAttributes(attrs, R.styleable.SwitchButton);
 		if (ta != null) {
@@ -142,9 +156,15 @@ public class SwitchButton extends CompoundButton {
 			animationDuration = ta.getInteger(R.styleable.SwitchButton_kswAnimationDuration, animationDuration);
 			fadeBack = ta.getBoolean(R.styleable.SwitchButton_kswFadeBack, true);
 			tintColor = ta.getColor(R.styleable.SwitchButton_kswTintColor, tintColor);
+			textOn = ta.getString(R.styleable.SwitchButton_kswTextOn);
+			textOff = ta.getString(R.styleable.SwitchButton_kswTextOff);
 			ta.recycle();
 		}
 
+		// text
+		mTextOn = textOn;
+		mTextOff = textOff;
+
 		// thumb drawable and color
 		mThumbDrawable = thumbDrawable;
 		mThumbColor = thumbColor;
@@ -195,8 +215,19 @@ public class SwitchButton extends CompoundButton {
 		}
 	}
 
+
+	private Layout makeLayout(CharSequence text) {
+		return new StaticLayout(text, mTextPaint, (int) Math.ceil(Layout.getDesiredWidth(text, mTextPaint)), Layout.Alignment.ALIGN_NORMAL, 1.f, 0, false);
+	}
+
 	@Override
 	protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) {
+		if (mOnLayout == null) {
+            mOnLayout = makeLayout(mTextOn == null ? """" : mTextOn);
+        }
+        if (mOffLayout == null) {
+            mOffLayout = makeLayout(mTextOff == null ? """" : mTextOff);
+        }
 		setMeasuredDimension(measureWidth(widthMeasureSpec), measureHeight(heightMeasureSpec));
 	}
 
@@ -279,6 +310,14 @@ public class SwitchButton extends CompoundButton {
 		if (mBackDrawable != null) {
 			mBackDrawable.setBounds((int) mBackRectF.left, (int) mBackRectF.top, (int) mBackRectF.right, (int) mBackRectF.bottom);
 		}
+
+		float marginOnX = Math.max(0, (mBackRectF.width() - mThumbRectF.width() - mOnLayout.getWidth()) / 2);
+		float marginOnY = Math.max(0, (mBackRectF.height() - mOnLayout.getHeight()) / 2);
+		mTextOnRectF.set(mBackRectF.left + marginOnX, mBackRectF.top + marginOnY, mBackRectF.right - mThumbRectF.width() - marginOnX, mBackRectF.bottom - marginOnY);
+
+		float marginOffX = Math.max(0, (mBackRectF.width() - mThumbRectF.width() - mOffLayout.getWidth()) / 2);
+		float marginOffY = Math.max(0, (mBackRectF.height() - mOffLayout.getHeight()) / 2);
+		mTextOffRectF.set(mBackRectF.left + mThumbRectF.width() + marginOffX, mBackRectF.top + marginOffY, mBackRectF.right - marginOffX, mBackRectF.bottom - marginOffY);
 	}
 
 	@Override
@@ -324,6 +363,14 @@ public class SwitchButton extends CompoundButton {
 			}
 		}
 
+		// text
+		Layout switchText = isChecked() ? mOnLayout : mOffLayout;
+		RectF textRectF = isChecked() ? mTextOnRectF : mTextOffRectF;
+		canvas.save();
+		canvas.translate(textRectF.left, textRectF.top);
+		switchText.draw(canvas);
+		canvas.restore();
+
 		// thumb
 		mPresentThumbRectF.set(mThumbRectF);
 		mPresentThumbRectF.offset(mProcess * mSafeRectF.width(), 0);
@@ -340,6 +387,8 @@ public class SwitchButton extends CompoundButton {
 			canvas.drawRect(mBackRectF, mRectPaint);
 			mRectPaint.setColor(Color.parseColor(""#0000FF""));
 			canvas.drawRect(mPresentThumbRectF, mRectPaint);
+			mRectPaint.setColor(Color.parseColor(""#00CC00""));
+			canvas.drawRect(isChecked() ? mTextOnRectF : mTextOffRectF, mRectPaint);
 		}
 	}
 
diff --git a/SwitchButton/library/src/main/res/values/attrs.xml b/SwitchButton/library/src/main/res/values/attrs.xml
index 8dcc647..b8af9b9 100644
--- a/SwitchButton/library/src/main/res/values/attrs.xml
+++ b/SwitchButton/library/src/main/res/values/attrs.xml
@@ -19,6 +19,8 @@
 		<attr name=""kswBackMeasureRatio"" format=""float""/>
 		<attr name=""kswAnimationDuration"" format=""integer""/>
 		<attr name=""kswTintColor"" format=""color|reference""/>
+		<attr name=""kswTextOn"" format=""string""/>
+		<attr name=""kswTextOff"" format=""string""/>
 	</declare-styleable>
 
 </resources>
\ No newline at end of file",Adding \' kswTextOn \' and \' kswTextOff \' attributes,"""Added support for displaying text on the switch button""","Added text on/off support to SwitchButton

This commit message is concise and accurately describes the changes made in the commit. It mentions the key feature added, which is the support for text on/off in the SwitchButton.","This commit adds text support to the SwitchButton library. It includes the following changes:

1. Added new attributes `kswTextOn` and `kswTextOff` in `attrs.xml` to set the text for the on and off states of the switch button.
2. Added new instance variables `mTextOn`, `mTextOff`, `mTextPaint`, `mOnLayout`, `mOffLayout`, `mTextOnRectF`, and `mTextOffRectF` in `SwitchButton.java` to handle the text drawing.
3. Updated the `SwitchButton` constructor to initialize the `TextPaint` object and added code to retrieve the values of `kswTextOn` and `kswTextOff` attributes.
4. Added a new method `makeLayout` in `SwitchButton.java` to create a `Layout` object for the text.
5. Updated the `onMeasure` method in `SwitchButton.java` to create the `Layout` objects for the on and off text.
6. Updated the `onDraw` method in `SwitchButton.java` to draw the text using the `Layout.draw` method.
7. Added a new `RectF` object `mTextOnRectF` and `mTextOffRectF` in `SwitchButton.java` to define the bounds for drawing the text.
8. Updated the `onSizeChanged` method in `SwitchButton.java` to set the bounds for the `mTextOnRectF` and `mTextOffRectF` objects.
9. Added some debug code in `onDraw` method to draw a rectangle around the text bounds.

Overall, this commit adds support for displaying text on the switch button, which can be customized using the `kswTextOn` and `kswTextOff` attributes.","""Add text display functionality with attributes `kswTextOn` and `kswTextOff` to `SwitchButton` component.""",Model 4
"diff --git a/searchlib/src/vespa/searchlib/transactionlog/domain.cpp b/searchlib/src/vespa/searchlib/transactionlog/domain.cpp
index 6d251a2a30e..fdee9dc1a24 100644
--- a/searchlib/src/vespa/searchlib/transactionlog/domain.cpp
+++ b/searchlib/src/vespa/searchlib/transactionlog/domain.cpp
@@ -341,7 +341,6 @@ Domain::startCommit(DoneCallback onDone) {
     vespalib::MonitorGuard guard(_currentChunkMonitor);
     if ( !_currentChunk->empty() ) {
         auto completed = grabCurrentChunk(guard);
-        assert(completed);
         completed->setCommitDoneCallback(std::move(onDone));
         CommitResult result(completed->createCommitResult());
         commitChunk(std::move(completed), guard);
@@ -355,9 +354,7 @@ Domain::commitIfFull(const vespalib::MonitorGuard &guard) {
     if (_currentChunk->sizeBytes() > _config.getChunkSizeLimit()) {
         auto completed = std::move(_currentChunk);
         _currentChunk = std::make_unique<CommitChunk>(_config.getChunkSizeLimit(), completed->stealCallbacks());
-        if (completed) {
-            commitChunk(std::move(completed), guard);
-        }
+        commitChunk(std::move(completed), guard);
     }
 }
 
@@ -369,20 +366,18 @@ Domain::grabCurrentChunk(const vespalib::MonitorGuard & guard) {
     return chunk;
 }
 
-bool
+void
 Domain::commitChunk(std::unique_ptr<CommitChunk> chunk, const vespalib::MonitorGuard & chunkOrderGuard) {
     assert(chunkOrderGuard.monitors(_currentChunkMonitor));
-    if ( ! chunk->getPacket().empty()) {
-        _singleCommitter->execute( makeLambdaTask([this, chunk = std::move(chunk)]() mutable {
-            doCommit(std::move(chunk));
-        }));
-        return true;
-    }
-    return false;
+    _singleCommitter->execute( makeLambdaTask([this, chunk = std::move(chunk)]() mutable {
+        doCommit(std::move(chunk));
+    }));
 }
 
 void
 Domain::doCommit(std::unique_ptr<CommitChunk> chunk) {
+    if (chunk->empty()) return;
+
     const Packet & packet = chunk->getPacket();
     vespalib::nbostream_longlivedbuf is(packet.getHandle().data(), packet.getHandle().size());
     Packet::Entry entry;
diff --git a/searchlib/src/vespa/searchlib/transactionlog/domain.h b/searchlib/src/vespa/searchlib/transactionlog/domain.h
index 5bd11ea2bdf..041ec27cf23 100644
--- a/searchlib/src/vespa/searchlib/transactionlog/domain.h
+++ b/searchlib/src/vespa/searchlib/transactionlog/domain.h
@@ -59,7 +59,7 @@ private:
     void commitIfFull(const vespalib::MonitorGuard & guard);
 
     std::unique_ptr<CommitChunk> grabCurrentChunk(const vespalib::MonitorGuard & guard);
-    bool commitChunk(std::unique_ptr<CommitChunk> chunk, const vespalib::MonitorGuard & chunkOrderGuard);
+    void commitChunk(std::unique_ptr<CommitChunk> chunk, const vespalib::MonitorGuard & chunkOrderGuard);
     void doCommit(std::unique_ptr<CommitChunk> chunk);
     SerialNum begin(const vespalib::LockGuard & guard) const;
     SerialNum end(const vespalib::LockGuard & guard) const;",Remove unnecessary guard and move check for emptiness inside doCommit to ensure ordering also of empty chunks .,"""Remove unnecessary checks and return values in Domain::commitChunk and related methods""","The commit message should be:

""Remove unnecessary assertions and improve code readability in Domain class""

Or, if you want to be more concise:

""Improve Domain class code readability""

However, a more descriptive commit message would be:

""Remove unnecessary assertions and simplify logic in Domain::commitChunk method""

This commit message accurately describes the changes made in the commit, which include removing unnecessary assertions and simplifying the logic in the `commitChunk` method.","""Remove unnecessary assert and return statement in Domain::commitChunk()""

Explanation:

* The assert statement in Domain::startCommit() has been removed.
* The return statement in Domain::commitChunk() has been changed from `bool` to `void`.
* The conditional statement checking if `completed` is not null before calling `commitChunk()` in Domain::commitIfFull() has been removed.
* An early return statement has been added in Domain::doCommit() if `chunk` is empty.

These changes simplify the code by removing unnecessary checks and return statements.",Refactor commitChunk to return void and remove unnecessary checks for empty chunks.,Model 4
"diff --git a/core/src/main/java/fi/iki/elonen/NanoHTTPD.java b/core/src/main/java/fi/iki/elonen/NanoHTTPD.java
index 3279a92..780c588 100644
--- a/core/src/main/java/fi/iki/elonen/NanoHTTPD.java
+++ b/core/src/main/java/fi/iki/elonen/NanoHTTPD.java
@@ -468,11 +468,15 @@ public abstract class NanoHTTPD {
         }
     }
 
-    private static final String CHARSET_REGEX = ""[ |\t]*(charset)[ |\t]*=[ |\t]*['|\""]?([^\""^'^;]*)['|\""]?"";
+    private static final String CONTENT_REGEX = ""[ |\t]*([^/^ ^;^,]+/[^ ^;^,]+)"";
+
+    private static final Pattern MIME_PATTERN = Pattern.compile(CONTENT_REGEX, Pattern.CASE_INSENSITIVE);
+
+    private static final String CHARSET_REGEX = ""[ |\t]*(charset)[ |\t]*=[ |\t]*['|\""]?([^\""^'^;^,]*)['|\""]?"";
 
     private static final Pattern CHARSET_PATTERN = Pattern.compile(CHARSET_REGEX, Pattern.CASE_INSENSITIVE);
 
-    private static final String BOUNDARY_REGEX = ""[ |\t]*(boundary)[ |\t]*=[ |\t]*['|\""]?([^\""^'^;]*)['|\""]?"";
+    private static final String BOUNDARY_REGEX = ""[ |\t]*(boundary)[ |\t]*=[ |\t]*['|\""]?([^\""^'^;^,]*)['|\""]?"";
 
     private static final Pattern BOUNDARY_PATTERN = Pattern.compile(BOUNDARY_REGEX, Pattern.CASE_INSENSITIVE);
 
@@ -625,7 +629,7 @@ public abstract class NanoHTTPD {
                     NanoHTTPD.LOG.log(Level.FINE, ""no protocol version specified, strange. Assuming HTTP/1.1."");
                 }
                 String line = in.readLine();
-                while (line != null && line.trim().length() > 0) {
+                while (line != null && !line.trim().isEmpty()) {
                     int p = line.indexOf(':');
                     if (p >= 0) {
                         headers.put(line.substring(0, p).trim().toLowerCase(Locale.US), line.substring(p + 1).trim());
@@ -1041,28 +1045,23 @@ public abstract class NanoHTTPD {
                 // in data section, too, read it:
                 if (Method.POST.equals(this.method)) {
                     String contentType = """";
+                    String encoding = ""UTF-8"";
                     String contentTypeHeader = this.headers.get(""content-type"");
-
-                    StringTokenizer st = null;
                     if (contentTypeHeader != null) {
-                        st = new StringTokenizer(contentTypeHeader, "",; "");
-                        if (st.hasMoreTokens()) {
-                            contentType = st.nextToken();
-                        }
+                        contentType = getDetailFromContentHeader(contentTypeHeader, MIME_PATTERN, """", 1);
+                        encoding = getDetailFromContentHeader(contentTypeHeader, CHARSET_PATTERN, ""US-ASCII"", 2);
                     }
-
                     if (""multipart/form-data"".equalsIgnoreCase(contentType)) {
-                        // Handle multipart/form-data
-                        if (!st.hasMoreTokens()) {
+                        String boundary = getDetailFromContentHeader(contentTypeHeader, BOUNDARY_PATTERN, null, 2);
+                        if (boundary == null) {
                             throw new ResponseException(Response.Status.BAD_REQUEST,
                                     ""BAD REQUEST: Content type is multipart/form-data but boundary missing. Usage: GET /example/file.html"");
                         }
-                        decodeMultipartFormData(getAttributeFromContentHeader(contentTypeHeader, BOUNDARY_PATTERN, null), //
-                                getAttributeFromContentHeader(contentTypeHeader, CHARSET_PATTERN, ""US-ASCII""), fbuf, this.parms, files);
+                        decodeMultipartFormData(boundary, encoding, fbuf, this.parms, files);
                     } else {
                         byte[] postBytes = new byte[fbuf.remaining()];
                         fbuf.get(postBytes);
-                        String postLine = new String(postBytes).trim();
+                        String postLine = new String(postBytes, encoding).trim();
                         // Handle application/x-www-form-urlencoded
                         if (""application/x-www-form-urlencoded"".equalsIgnoreCase(contentType)) {
                             decodeParms(postLine, this.parms);
@@ -1081,9 +1080,9 @@ public abstract class NanoHTTPD {
             }
         }
 
-        private String getAttributeFromContentHeader(String contentTypeHeader, Pattern pattern, String defaultValue) {
+        private String getDetailFromContentHeader(String contentTypeHeader, Pattern pattern, String defaultValue, int group) {
             Matcher",encoding and contenty type handling <issue_id>,"""Refactor NanoHTTPD to improve content type and boundary parsing""","""Improved HTTP header parsing and content type handling""","""Update regex patterns and add method to extract details from content header in NanoHTTPD""

Explanation:
The commit involves the following changes in the `NanoHTTPD.java` file:

1. Adding a new constant `CONTENT_REGEX` to store the regular expression pattern for content type.
2. Creating a new `Pattern` object, `MIME_PATTERN`, using the `CONTENT_REGEX` pattern.
3. Modifying the `CHARSET_REGEX` pattern to exclude semicolons and commas in the charset value.
4. Modifying the `BOUNDARY_REGEX` pattern to exclude semicolons and commas in the boundary value.
5. Replacing the usage of `StringTokenizer` with the new `getDetailFromContentHeader()` method to extract content type and charset encoding from the content type header.
6. Adding a new method `getDetailFromContentHeader()` to extract specific details (like content type, charset, and boundary) from the content type header using the provided `Pattern` and group number.

The main purpose of the commit is to improve the way content type and related details are extracted from the request headers. The changes make the code more robust and maintainable by using a more specific and flexible method to handle different content types and their associated properties.","Refactor content header parsing logic, improve charset and boundary regex, handle content-type and encoding details more robustly.",Model 1
"diff --git a/tools/src/main/java/com/orientechnologies/orient/console/OConsoleDatabaseApp.java b/tools/src/main/java/com/orientechnologies/orient/console/OConsoleDatabaseApp.java
index ed5babe4ec..6239596b40 100755
--- a/tools/src/main/java/com/orientechnologies/orient/console/OConsoleDatabaseApp.java
+++ b/tools/src/main/java/com/orientechnologies/orient/console/OConsoleDatabaseApp.java
@@ -153,6 +153,10 @@ public class OConsoleDatabaseApp extends OrientConsole implements OCommandOutput
 
     OGlobalConfiguration.STORAGE_KEEP_OPEN.setValue(false);
 
+    // DISABLE THE NETWORK AND STORAGE TIMEOUTS
+    OGlobalConfiguration.STORAGE_LOCK_TIMEOUT.setValue(0);
+    OGlobalConfiguration.NETWORK_LOCK_TIMEOUT.setValue(0);
+
     properties.put(""limit"", ""20"");
     properties.put(""debug"", ""false"");
     properties.put(""maxBinaryDisplay"", ""160"");",removed timeout against remote connections,"""Disable network and storage timeouts in OConsoleDatabaseApp""","""Disable network and storage timeouts in OConsoleDatabaseApp""","""Disable network and storage timeouts in OConsoleDatabaseApp configuration""

Explanation:
The diff shows that two lines of code have been added to the class `OConsoleDatabaseApp`. These lines set the values of `OGlobalConfiguration.STORAGE_LOCK_TIMEOUT` and `OGlobalConfiguration.NETWORK_LOCK_TIMEOUT` to 0. These configurations are used to disable network and storage timeouts respectively. Therefore, the commit message should reflect this change.",Disable network and storage timeouts in OConsoleDatabaseApp by setting STORAGE_LOCK_TIMEOUT and NETWORK_LOCK_TIMEOUT to 0.,Model 2
"diff --git a/jre_emul/Classes/java/util/HashMap.h b/jre_emul/Classes/java/util/HashMap.h
index 5feb0f775..8dae5d82a 100644
--- a/jre_emul/Classes/java/util/HashMap.h
+++ b/jre_emul/Classes/java/util/HashMap.h
@@ -7,16 +7,22 @@
 //
 
 #import <Foundation/Foundation.h>
+#import ""java/io/Serializable.h""
+#import ""java/util/AbstractMap.h""
 #import ""java/util/Map.h""
 
 @class JavaUtilHashMap_Entry;
 
-// An implementation for the java.util.Map protocol, using a
-// NSMutableDictionary delegate. Its constructors are defined by HashMap, so
-// that this class can potentially be a drop-in replacement.
-@interface JavaUtilHashMap : NSObject < JavaUtilMap, NSMutableCopying > {
- @private
-  NSMutableDictionary *dictionary_;
+// An implementation for the java.util.Map protocol, based on the java harmony
+// implementation.
+@interface JavaUtilHashMap : JavaUtilAbstractMap < JavaUtilMap, NSCopying, JavaIoSerializable > {
+ @public
+  int elementCount_;
+  JavaUtilHashMap_Entry **elementData_;
+  int elementDataLength_;
+  int modCount_;
+  float loadFactor_;
+  int threshold_;
 }
 
 - (id)initWithInt:(int)capacity;
diff --git a/jre_emul/Classes/java/util/HashMap.m b/jre_emul/Classes/java/util/HashMap.m
index 522b7ce83..47fb04254 100644
--- a/jre_emul/Classes/java/util/HashMap.m
+++ b/jre_emul/Classes/java/util/HashMap.m
@@ -2,533 +2,692 @@
 //  HashMap.m
 //  JreEmulation
 //
-//  Created by Tom Ball on 1/27/12.
+//  Created by Keith Stanger on 10/19/12.
 //  Copyright 2012 Google, Inc. All rights reserved.
 //
 
+#import ""java/lang/CloneNotSupportedException.h""
 #import ""java/lang/IllegalArgumentException.h""
 #import ""java/lang/IllegalStateException.h""
 #import ""java/lang/NullPointerException.h""
+#import ""java/util/Collection.h""
+#import ""java/util/ConcurrentModificationException.h""
 #import ""java/util/HashMap_PackagePrivate.h""
+#import ""java/util/Iterator.h""
 #import ""java/util/Map.h""
-#import ""IOSList.h""
-#import ""IOSSet.h""
-#import ""JreEmulation.h""
-#import <CoreFoundation/CFDictionary.h>
+#import ""java/util/NoSuchElementException.h""
+#import ""java/util/Set.h""
 
 @implementation JavaUtilHashMap
 
-#define JavaUtilHashMap_DEFAULT_SIZE 16
+@synthesize elementCount = elementCount_;
+@synthesize elementData = elementData_;
+@synthesize elementDataLength = elementDataLength_;
+@synthesize modCount = modCount_;
+@synthesize loadFactor = loadFactor_;
+@synthesize threshold = threshold_;
 
-@synthesize dictionary = dictionary_;
-
-// Private initializer.
-// We need this with a unique name to avoid clashing with subclasses.
-- (id)initJavaUtilHashMapWithCapacity:(int)capacity {
-  if (capacity < 0) {
-    id exception = [[JavaLangIllegalArgumentException alloc] init];
-#if ! __has_feature(objc_arc)
-    [exception autorelease];
-#endif
-    @throw exception;
-  }
-  self = [super init];
-  if (self) {
-    dictionary_ = (ARCBRIDGE_TRANSFER NSMutableDictionary *)
-    CFDictionaryCreateMutable(NULL, capacity,
-        &kCFTypeDictionaryKeyCallBacks, &kCFTypeDictionaryValueCallBacks);
-  }
-  return self;
-}
 
 - (id)init {
-  return [self initWithInt:JavaUtilHashMap_DEFAULT_SIZE];
+  return [self initJavaUtilHashMapWithInt:JavaUtilHashMap_DEFAULT_SIZE
+                                withFloat:JavaUtilHashMap_DEFAULT_LOAD_FACTOR];
 }
 
 - (id)initWithInt:(int)capacity {
-  return [self initJavaUtilHashMapWithCapacity:capacity];
+  return [self initJavaUtilHashMapWithInt:capacity withFloat:JavaUtilHashMap_DEFAULT_LOAD_FACTOR];
 }
 
-- (id)initWithInt:(int)capacity withFloat:(float)loadFactor {
-  if (loadFactor <= 0) {
-    id exception = [[JavaLangIllegalArgumentException alloc] init];
-#if ! __has_feature(objc_arc)
-    [exception autorelease];
-#endif
-    @throw exception;
++ (int)calculateCapacityWithInt:(int)x {
+  if (x >= 1 << 30) {
+    return 1 << 30;
+  }
+  if (x == 0) {
+    return 16;
   }
-  return [self initJavaUtilHashMapWithCapacity:capacity];
+  x = x - 1;
+  x |= x >> 1;
+  x |= x >> 2;
+  x |= x >> 4;
+  x |= x >> 8;
+  x |= x >> 16;
+  return x + 1;
 }
 
-- (id)initWithJavaUtilMap:(id<JavaUtilMap>)map {
-  if (!map) {
-    id exception = [[JavaLangNullPointerException alloc] init];
-#if ! __has_feature(objc_arc)
-    [exception autorelease];
-#endif
-    @throw exception;
-  }
-  int size = [map size];
-  self = [self initJavaUtilHashMapWithCapacity:size];
-  if (self) {
-    if ([map isMemberOfClass:[JavaUtilHashMap class]]) {
-      JavaUtilHashMap *other = (JavaUtilHashMap *) map;
-#if ! __has_feature(objc_arc)
-      [dictionary_ release];
-#endif
-      dictionary_ = (ARCBRIDGE_TRANSFER NSMutableDictionary *)
-          CFDictionaryCreateMutable(NULL, size,
-          &kCFTypeDictionaryKeyCallBacks, &kCFTypeDictionaryValueCallBacks);
-      for(id key in [other->dictionary_ allKeys]) {
-        CFDictionarySetValue((ARCBRIDGE CFMutableDictionaryRef) dictionary_,
-            (ARCBRIDGE void *) key,
-            (ARCBRIDGE void *) [other->dictionary_ objectForKey:key]);
-      }
-    } else {
-      [self putAllImpl:map];
+- (id)initJavaUtilHashMapWithInt:(int)capacity
+                       withFloat:(float)loadFactor {
+  if ((self = [super init])) {
+    modCount_ = 0;
+    if (capacity >= 0 && loadFactor > 0) {
+      capacity = [JavaUtilHashMap calculateCapacityWithInt:capacity];
+      elementCount_ = 0;
+      free(elementData_);
+      elementData_ = (JavaUtilHashMap_Entry **) calloc(capacity, sizeof(JavaUtilHashMap_Entry *));
+      elementDataLength_ = capacity;
+      self.loadFactor = loadFactor;
+      [self computeThreshold];
+    }
+    else {
+      @throw [[[JavaLangIllegalArgumentException alloc] init] autorelease];
     }
   }
   return self;
 }
 
-#pragma mark -
+- (id)initWithInt:(int)capacity
+        withFloat:(float)loadFactor {
+  return [self initJavaUtilHashMapWithInt:capacity withFloat:loadFactor];
+}
+
+- (id)initWithJavaUtilMap:(id<JavaUtilMap>)map {
+  if ((self = [self initJavaUtilHashMapWithInt:
+      [JavaUtilHashMap calculateCapacityWithInt:[((id<JavaUtilMap>) NIL_CHK(map)) size]]
+      withFloat:JavaUtilHashMap_DEFAULT_LOAD_FACTOR])) {
+    [self putAllImplWithJavaUtilMap:map];
+  }
+  return self;
+}
 
 - (void)clear {
-  [dictionary_ removeAllObjects];
+  if (elementCount_ > 0) {
+    elementCount_ = 0;
+    for (int i = 0; i < elementDataLength_; i++) {
+      JavaUtilHashMap_Entry *entry = elementData_[i];
+      elementData_[i] = nil;
+      while (entry != nil) {
+        JavaUtilHashMap_Entry *next = entry->next_;
+        [entry release];
+        entry = next;
+      }
+    }
+    modCount_++;
+  }
 }
 
-id nullify(id object) {
-  return object == [NSNull null] ? nil : object;
+- (void)copyAllPropertiesTo:(id)copy {
+  [super copyAllPropertiesTo:copy];
+  JavaUtilHashMap *typedCopy = (JavaUtilHashMap *) copy;
+  typedCopy.modCount = modCount_;
+  typedCopy.loadFactor = loadFactor_;
+  typedCopy.threshold = threshold_;
 }
 
-id denullify(id object) {
-  return object == nil ? [NSNull null] : object;
+- (id)clone {
+  @try {
+    JavaUtilHashMap *map = (JavaUtilHashMap *) [super clone];
+    map.elementCount = 0;
+    map.elementData =
+        (JavaUtilHashMap_Entry **) calloc(elementDataLength_, sizeof(JavaUtilHashMap_Entry *));
+    map.elementDataLength = elementDataLength_;
+    [map putAllWithJavaUtilMap:self];
+    return map;
+  }
+  @catch (JavaLangCloneNotSupportedException *e) {
+    return nil;
+  }
+}
+
+- (void)computeThreshold {
+  threshold_ = (int) (elementDataLength_ * loadFactor_);
 }
 
 - (BOOL)containsKeyWithId:(id)key {
-  return [dictionary_ objectForKey:denullify(key)] != nil;
+  JavaUtilHashMap_Entry *m = [self getEntryWithId:key];
+  return m != nil;
 }
 
 - (BOOL)containsValueWithId:(id)value {
-  NSArray *keys = [dictionary_ allKeysForObject:denullify(value)];
-  return [keys count] > 0;
+  if (value != nil) {
+    for (int i = 0; i < elementDataLength_; i++) {
+      JavaUtilHashMap_Entry *entry = elementData_[i];
+      while (entry != nil) {
+        if ([JavaUtilHashMap areEqualValuesWithId:value withId:entry->value_]) {
+          return YES;
+        }
+        entry = entry->next_;
+      }
+    }
+  }
+  else {
+    for (int i = 0; i < elementDataLength_; i++) {
+      JavaUtilHashMap_Entry *entry = elementData_[i];
+      while (entry != nil) {
+        if (entry->value_ == nil) {
+          return YES;
+        }
+        entry = entry->next_;
+      }
+    }
+  }
+  return NO;
 }
 
 - (id<JavaUtilSet>)entrySet {
-  id result = [[JavaUtilHashMap_EntrySet alloc] initWithJavaUtilHashMap:self];
-#if ! __has_feature(objc_arc)
-  [result autorelease];
-#endif
-  return result;
+  return [[[JavaUtilHashMap_HashMapEntrySet alloc] initWithJavaUtilHashMap:self] autorelease];
 }
 
 - (id)getWithId:(id)key {
-  id result = [dictionary_ objectForKey:denullify(key)];
-  return nullify(result);
+  JavaUtilHashMap_Entry *m = [self getEntryWithId:key];
+  if (m != nil) {
+    return m.value;
+  }
+  return nil;
 }
 
-- (NSUInteger)hash {
-  return [dictionary_ hash];
+- (JavaUtilHashMap_Entry *)getEntryWithId:(id)key {
+  JavaUtilHashMap_Entry *m;
+  if (key == nil) {
+    m = [self findNullKeyEntry];
+  }
+  else {
+    int hash_ = [JavaUtilHashMap computeHashCodeWithId:key];
+    int index = hash_ & (elementDataLength_ - 1);
+    m = [self findNonNullKeyEntryWithId:key withInt:index withInt:hash_];
+  }
+  return m;
 }
 
-- (BOOL)isEmpty {
-  return [dictionary_ count] == 0;
+- (JavaUtilHashMap_Entry *)findNonNullKeyEntryWithId:(id)key
+                                             withInt:(int)index
+                                             withInt:(int)keyHash {
+  JavaUtilHashMap_Entry *m = elementData_[index];
+  while (m != nil
+      && (m->origKeyHash_ != keyHash || ![JavaUtilHashMap areEqualKeysWithId:key withId:m->key_])) {
+    m = m->next_;
+  }
+  return m;
 }
 
-- (BOOL)isEqual:(id)object {
-  if ([object isKindOfClass:[JavaUtilHashMap class]]) {
-    JavaUtilHashMap *other = (JavaUtilHashMap *) object;
-    BOOL foo = [dictionary_ isEqualToDictionary:other->dictionary_];
-    return foo;
-  }
-  return NO;
+- (JavaUtilHashMap_Entry *)findNullKeyEntry {
+  JavaUtilHashMap_Entry *m = elementData_[0];
+  while (m != nil && m->key_ != nil) m = m->next_;
+  return m;
+}
+
+- (BOOL)isEmpty {
+  return elementCount_ == 0;
 }
 
 - (id<JavaUtilSet>)keySet {
-  id result = [[JavaUtilHashMap_KeySet alloc] initWithJavaUtilHashMap:self];
-#if ! __has_feature(objc_arc)
-  [result autorelease];
-#endif
-  return result;
+  if (keySet__ == nil) {
+    keySet__ = [[JavaUtilHashMap_KeySet alloc] initWithJavaUtilHashMap:self];
+  }
+  return keySet__;
 }
 
 - (id)putWithId:(id)key
          withId:(id)value {
-  key = denullify(key);
-  value = denullify(value);
-  id previous = [dictionary_ objectForKey:key];
-
-#if ! __has_feature(objc_arc)
-  [[previous retain] autorelease];
-#endif
+  return [self putImplWithId:key withId:value];
+}
+
+- (id)putImplWithId:(id)key
+             withId:(id)value {
+  JavaUtilHashMap_Entry *entry;
+  if (key == nil) {
+    entry = [self findNullKeyEntry];
+    if (entry == nil) {
+      modCount_++;
+      entry = [self createHashedEntryWithId:nil withInt:0 withInt:0];
+      if (++elementCount_ > threshold_) {
+        [self rehash];
+      }
+    }
+  }
+  else {
+    int hash_ = [JavaUtilHashMap computeHashCodeWithId:key];
+    int index = hash_ & (elementDataLength_ - 1);
+    entry = [self findNonNullKeyEntryWithId:key withInt:index withInt:hash_];
+    if (entry == nil) {
+      modCount_++;
+      entry = [self createHashedEntryWithId:key withInt:index withInt:hash_];
+      if (++elementCount_ > threshold_) {
+        [self rehash];
+      }
+    }
+  }
+  id result = [entry->value_ autorelease];
+  entry->value_ = [value retain];
+  return result;
+}
 
-  // Use a CFDictionary function so the key is retained rather than copied,
-  // as HashMap keys can't be required to be cloneable.
-  CFDictionarySetValue((ARCBRIDGE CFMutableDictionaryRef) dictionary_,
-                       (ARCBRIDGE void *) key, (ARCBRIDGE void *) value);
-  return nullify(previous);
+- (JavaUtilHashMap_Entry *)createHashedEntryWithId:(id)key
+                                           withInt:(int)index
+                                           withInt:(int)hash_ {
+  JavaUtilHashMap_Entry *entry = [[JavaUtilHashMap_Entry alloc] initWithId:key withInt:hash_];
+  entry->next_ = elementData_[index];
+  elementData_[index] = entry;
+  return entry;
 }
 
 - (void)putAllWithJavaUtilMap:(id<JavaUtilMap>)map {
-  if (![map isEmpty]) {
-    [self putAllImpl:map];
+  if (![((id<JavaUtilMap>) NIL_CHK(map)) isEmpty]) {
+    [self putAllImplWithJavaUtilMap:map];
   }
 }
 
-- (void)putAllImpl:(id<JavaUtilMap>)map {
-  id<JavaUtilSet> entrySet = [map entrySet];
-  id<JavaUtilIterator> iterator = [entrySet iterator];
-
-  // Throw NPE if null iterator, but only if there's something to iterate.
-  if (!iterator) {
-    id exception = [[JavaLangNullPointerException alloc] init];
-#if ! __has_feature(objc_arc)
-    [exception autorelease];
-#endif
-    @throw exception;
+- (void)putAllImplWithJavaUtilMap:(id<JavaUtilMap>)map {
+  int capacity = elementCount_ + [((id<JavaUtilMap>) NIL_CHK(map)) size];
+  if (capacity > threshold_) {
+    [self rehashWithInt:capacity];
   }
+  {
+    id<JavaLangIterable> array__ = (id<JavaLangIterable>) [((id<JavaUtilMap>) NIL_CHK(map)) entrySet];
+    if (!array__) {
+      @throw [[[JavaLangNullPointerException alloc] init] autorelease];
+    }
+    id<JavaUtilIterator> iter__ = [array__ iterator];
+    while ([iter__ hasNext]) {
+      id<JavaUtilMap_Entry> entry = (id<JavaUtilMap_Entry>) [iter__ next];
+      [self putImplWithId:((id) [((id<JavaUtilMap_Entry>) NIL_CHK(entry)) getKey]) withId:((id) [((id<JavaUtilMap_Entry>) NIL_CHK(entry)) getValue])];
+    }
+  }
+}
 
-  while ([iterator hasNext]) {
-    id entry = [iterator next];
-    [self putWithId:[entry getKey] withId:[entry getValue]];
+- (void)rehashWithInt:(int)capacity {
+  int length = [JavaUtilHashMap calculateCapacityWithInt:(capacity == 0 ? 1 : capacity << 1)];
+  JavaUtilHashMap_Entry **newData = calloc(length, sizeof(JavaUtilHashMap_Entry *));
+  for (int i = 0; i < elementDataLength_; i++) {
+    JavaUtilHashMap_Entry *entry = elementData_[i];
+    elementData_[i] = nil;
+    while (entry != nil) {
+      int index = entry->origKeyHash_ & (length - 1);
+      JavaUtilHashMap_Entry *next = entry->next_;
+      entry->next_ = newData[index];
+      newData[index] = entry;
+      entry = next;
+    }
   }
+  free(elementData_);
+  elementData_ = newData;
+  elementDataLength_ = length;
+  [self computeThreshold];
+}
+
+- (void)rehash {
+  [self rehashWithInt:elementDataLength_];
 }
 
 - (id)removeWithId:(id)key {
-  key = denullify(key);
-  id result = [dictionary_ objectForKey:key];
-  if (result) {
-#if ! __has_feature(objc_arc)
-    [[result retain] autorelease];
-#endif
-    [dictionary_ removeObjectForKey:key];
+  JavaUtilHashMap_Entry *entry = [self removeEntryWithId:key];
+  if (entry != nil) {
+    return entry.value;
+  }
+  return nil;
+}
+
+- (void)removeEntryWithJavaUtilHashMap_Entry:(JavaUtilHashMap_Entry *)entry {
+  int index = entry->origKeyHash_ & (elementDataLength_ - 1);
+  JavaUtilHashMap_Entry *m = elementData_[index];
+  if (m == entry) {
+    elementData_[index] = entry->next_;
+  }
+  else {
+    while (m->next_ != entry) {
+      m = m->next_;
+    }
+    m->next_ = entry->next_;
+  }
+  modCount_++;
+  elementCount_--;
+  [entry autorelease];
+}
+
+- (JavaUtilHashMap_Entry *)removeEntryWithId:(id)key {
+  int index = 0;
+  JavaUtilHashMap_Entry *entry;
+  JavaUtilHashMap_Entry *last = nil;
+  if (key != nil) {
+    int hash_ = [JavaUtilHashMap computeHashCodeWithId:key];
+    index = hash_ & (elementDataLength_ - 1);
+    entry = elementData_[index];
+    while (entry != nil
+        && !(entry->origKeyHash_ == hash_
+            && [JavaUtilHashMap areEqualKeysWithId:key withId:entry->key_])) {
+      last = entry;
+      entry = entry->next_;
+    }
   }
-  return nullify(result);
+  else {
+    entry = elementData_[0];
+    while (entry != nil && entry->key_ != nil) {
+      last = entry;
+      entry = entry->next_;
+    }
+  }
+  if (entry == nil) {
+    return nil;
+  }
+  if (last == nil) {
+    elementData_[index] = entry->next_;
+  } else {
+    last->next_ = entry->next_;
+  }
+  modCount_++;
+  elementCount_--;
+  return [entry autorelease];
 }
 
 - (int)size {
-  return [dictionary_ count];
+  return elementCount_;
 }
 
 - (id<JavaUtilCollection>)values {
-  id result = [[JavaUtilHashMap_Values alloc] initWithJavaUtilHashMap:self];
-#if ! __has_feature(objc_arc)
-  [result autorelease];
-#endif
-  return result;
+  if (valuesCollection_ == nil) {
+    valuesCollection_ = [[JavaUtilHashMap_ValuesCollection alloc] initWithJavaUtilHashMap:self];
+  }
+  return valuesCollection_;
 }
 
-- (JavaUtilHashMap_Entry *)entry:(id)key {
-  key = denullify(key);
-  id value = [dictionary_ objectForKey:key];
-  id result = [[JavaUtilHashMap_Entry alloc] initWithKey:key value:value];
-#if ! __has_feature(objc_arc)
-  [result autorelease];
-#endif
-  return result;
++ (int)computeHashCodeWithId:(id)key {
+  return [NIL_CHK(key) hash];
 }
 
-- (id)mutableCopyWithZone:(NSZone *)zone {
-  JavaUtilHashMap *copy = [[[self class] alloc] initWithJavaUtilMap:self];
-  return copy;
++ (BOOL)areEqualKeysWithId:(id)key1
+                    withId:(id)key2 {
+  return (key1 == key2) || [NIL_CHK(key1) isEqual:key2];
 }
 
-- (id)clone {
-  id result = [self mutableCopy];
-#if ! __has_feature(objc_arc)
-  [result autorelease];
-#endif
-  return result;
++ (BOOL)areEqualValuesWithId:(id)value1
+                      withId:(id)value2 {
+  return (value1 == value2) || [NIL_CHK(value1) isEqual:value2];
 }
 
 - (id)copyWithZone:(NSZone *)zone {
-  return [self mutableCopyWithZone:zone];
+  return [self clone];
 }
 
-- (NSString *)description {
-  // Handle case where a map contains itself (legal, but weird).
-  static BOOL recursing = NO;
-  if (recursing) {
-    return @""(this Map)"";
-  } else {
-    BOOL wasRecursing = recursing;
-    @try {
-      recursing = YES;
-      return [dictionary_ description];
-    }
-    @finally {
-      recursing = wasRecursing;
-    }
-  }
-}
-
-#if ! __has_feature(objc_arc)
 - (void)dealloc {
-  [dictionary_ release];
+  [self clear];
+  free(elementData_);
+  elementData_ = nil;
   [super dealloc];
 }
-#endif
-
-#pragma mark -
 
 @end
 
-@implementation JavaUtilHashMap_Entry
-
-- (id)initWithKey:(id)key value:(id)value {
-  return [super initWithId:key withId:value];
-}
 
-#pragma mark -
-#pragma mark JavaUtilMap_Entry
+@implementation JavaUtilHashMap_Entry
 
-- (id)getKey {
-  return nullify([super key]);
+- (id)initWithId:(id)theKey
+         withInt:(int)hash_ {
+  if ((self = [super initWithId:theKey withId:nil])) {
+    origKeyHash_ = hash_;
+  }
+  return self;
 }
 
-- (id)getValue {
-  return nullify([super value]);
+- (id)initWithId:(id)theKey
+          withId:(id)theValue {
+  if ((self = [super initWithId:theKey withId:theValue])) {
+    origKeyHash_ = (theKey == nil ? 0 : [JavaUtilHashMap computeHashCodeWithId:theKey]);
+  }
+  return self;
 }
 
 @end
 
-@implementation JavaUtilHashMap_KeySet
 
-@synthesize map = map_;
+@implementation JavaUtilHashMap_AbstractMapIterator
 
-- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)map {
+@synthesize position = position_;
+@synthesize expectedModCount = expectedModCount_;
+@synthesize futureEntry = futureEntry_;
+@synthesize currentEntry = currentEntry_;
+@synthesize prevEntry = prevEntry_;
+@synthesize associatedMap = associatedMap_;
+
+
+- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)hm {
   if ((self = [super init])) {
-    map_ = map;
+    position_ = 0;
+    [associatedMap_ autorelease];
+    associatedMap_ = [hm retain];
+    expectedModCount_ = ((JavaUtilHashMap *) NIL_CHK(hm)).modCount;
+    futureEntry_ = nil;
   }
   return self;
 }
 
-- (int)size {
-  return [map_ size];
+- (BOOL)hasNext {
+  if (futureEntry_ != nil) {
+    return YES;
+  }
+  while (position_ < associatedMap_.elementDataLength) {
+    if (associatedMap_.elementData[position_] == nil) {
+      position_++;
+    }
+    else {
+      return YES;
+    }
+  }
+  return NO;
 }
 
-- (void)clear {
-  [map_ clear];
+- (void)checkConcurrentMod {
+  if (expectedModCount_ != ((JavaUtilHashMap *) NIL_CHK(associatedMap_)).modCount) {
+    @throw [[[JavaUtilConcurrentModificationException alloc] init] autorelease];
+  }
 }
 
-- (BOOL)removeWithId:(id)key {
-  if ([map_ containsKeyWithId:key]) {
-    [map_ removeWithId:key];
-    return YES;
+- (void)makeNext {
+  [self checkConcurrentMod];
+  if (![self hasNext]) {
+    @throw [[[JavaUtilNoSuchElementException alloc] init] autorelease];
+  }
+  if (futureEntry_ == nil) {
+    currentEntry_ = associatedMap_.elementData[position_++];
+    futureEntry_ = currentEntry_->next_;
+    prevEntry_ = nil;
+  }
+  else {
+    if (currentEntry_ != nil) {
+      prevEntry_ = currentEntry_;
+    }
+    currentEntry_ = futureEntry_;
+    futureEntry_ = futureEntry_->next_;
   }
-  return NO;
 }
 
-- (BOOL)containsWithId:(id)key {
-  return [map_ containsKeyWithId:key];
+- (void)remove {
+  [self checkConcurrentMod];
+  if (currentEntry_ == nil) {
+    @throw [[[JavaLangIllegalStateException alloc] init] autorelease];
+  }
+  if (prevEntry_ == nil) {
+    int index = currentEntry_->origKeyHash_ & (associatedMap_.elementDataLength - 1);
+    associatedMap_.elementData[index] = associatedMap_.elementData[index]->next_;
+  }
+  else {
+    prevEntry_->next_ = currentEntry_->next_;
+  }
+  [currentEntry_ autorelease];
+  currentEntry_ = nil;
+  expectedModCount_++;
+  associatedMap_.modCount++;
+  associatedMap_.elementCount--;
 }
 
-- (id<JavaUtilIterator>)iterator {
-  NSMutableArray *keyList = [[self.map.dictionary allKeys] mutableCopy];
-#if ! __has_feature(objc_arc)
-  [keyList autorelease];
-#endif
-  IOSIterator *keyIterator = [[IOSIterator alloc] initWithList:keyList];
-#if ! __has_feature(objc_arc)
-  [keyIterator autorelease];
-#endif
-  id iterator =
-      [[JavaUtilHashMap_KeySetIterator alloc]
-       initWithJavaUtilHashMap:self.map withIterator:keyIterator];
-#if ! __has_feature(objc_arc)
-  [iterator autorelease];
-#endif
-  return iterator;
+- (void)dealloc {
+  [associatedMap_ autorelease];
+  [super dealloc];
 }
 
 @end
 
-@implementation JavaUtilHashMap_EntrySet
 
-- (BOOL)removeWithId:(id)object {
-  if ([object conformsToProtocol:@protocol(JavaUtilMap_Entry)]) {
-    id<JavaUtilMap_Entry> entry = (id<JavaUtilMap_Entry>) object;
-    return [super removeWithId:[entry getKey]];
-  }
-  return NO;
+@implementation JavaUtilHashMap_EntryIterator
+
+- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)map {
+  return [super initWithJavaUtilHashMap:map];
 }
 
-- (BOOL)containsWithId:(id)object {
-  if ([object conformsToProtocol:@protocol(JavaUtilMap_Entry)]) {
-    id<JavaUtilMap_Entry>entry = (id<JavaUtilMap_Entry>) object;
-    return [super containsWithId:[entry getKey]];
-  }
-  return NO;
+- (id<JavaUtilMap_Entry>)next {
+  [self makeNext];
+  return currentEntry_;
 }
 
-- (id<JavaUtilIterator>)iterator {
-  NSMutableArray *keyList = [[self.map.dictionary allKeys] mutableCopy];
-#if ! __has_feature(objc_arc)
-  [keyList autorelease];
-#endif
-  IOSIterator *keyIterator = [[IOSIterator alloc] initWithList:keyList];
-#if ! __has_feature(objc_arc)
-  [keyIterator autorelease];
-#endif
-  id iterator =
-      [[JavaUtilHashMap_EntrySetIterator alloc]
-       initWithJavaUtilHashMap:self.map withIterator:keyIterator];
-#if ! __has_feature(objc_arc)
-  [iterator autorelease];
-#endif
-  return iterator;
+@end
+
+
+@implementation JavaUtilHashMap_KeyIterator
+
+- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)map {
+  return [super initWithJavaUtilHashMap:map];
+}
+
+- (id)next {
+  [self makeNext];
+  return ((JavaUtilHashMap_Entry *) NIL_CHK(currentEntry_)).key;
+}
+
+@end
+
+
+@implementation JavaUtilHashMap_ValueIterator
+
+- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)map {
+  return [super initWithJavaUtilHashMap:map];
+}
+
+- (id)next {
+  [self makeNext];
+  return ((JavaUtilHashMap_Entry *) NIL_CHK(currentEntry_)).value;
 }
 
 @end
 
-@implementation JavaUtilHashMap_KeySetIterator
 
-@synthesize map = map_;
-@synthesize iterator = iterator_;
+@implementation JavaUtilHashMap_HashMapEntrySet
 
-- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)map
-                 withIterator:(IOSIterator *)iterator {
+- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)hm {
   if ((self = [super init])) {
-    map_ = map;
-    iterator_ = iterator;
-    lastKey_ = nil;
+    [associatedMap_ autorelease];
+    associatedMap_ = [hm retain];
   }
   return self;
 }
 
-- (BOOL)hasNext {
-  return [iterator_ hasNext];
+- (JavaUtilHashMap *)hashMap {
+  return associatedMap_;
 }
 
-- (id)next {
-  lastKey_ = [iterator_ next];
-  return lastKey_;
+- (int)size {
+  return ((JavaUtilHashMap *) NIL_CHK(associatedMap_)).elementCount;
 }
 
-- (void)remove {
-  if (!lastKey_) {
-    id exception = [[JavaLangIllegalStateException alloc] init];
-#if ! __has_feature(objc_arc)
-    [exception autorelease];
-#endif
-    @throw exception;
+- (void)clear {
+  [((JavaUtilHashMap *) NIL_CHK(associatedMap_)) clear];
+}
+
+- (BOOL)removeWithId:(id)object {
+  if ([object conformsToProtocol: @protocol(JavaUtilMap_Entry)]) {
+    id<JavaUtilMap_Entry> oEntry = (id<JavaUtilMap_Entry>) object;
+    JavaUtilHashMap_Entry *entry = [associatedMap_ getEntryWithId:[oEntry getKey]];
+    if ([JavaUtilHashMap_HashMapEntrySet valuesEqWithJavaUtilHashMap_Entry:entry
+                                                     withJavaUtilMap_Entry:oEntry]) {
+      [associatedMap_ removeEntryWithJavaUtilHashMap_Entry:entry];
+      return YES;
+    }
   }
-  [map_ removeWithId:lastKey_];
-  lastKey_ = nil;
+  return NO;
 }
 
-- (NSString *)description {
-  return [iterator_ description];
+- (BOOL)containsWithId:(id)object {
+  if ([object conformsToProtocol: @protocol(JavaUtilMap_Entry)]) {
+    id<JavaUtilMap_Entry> oEntry = (id<JavaUtilMap_Entry>) object;
+    JavaUtilHashMap_Entry *entry = [associatedMap_ getEntryWithId:[oEntry getKey]];
+    return [JavaUtilHashMap_HashMapEntrySet valuesEqWithJavaUtilHashMap_Entry:entry
+                                                        withJavaUtilMap_Entry:oEntry];
+  }
+  return NO;
 }
 
-@end
++ (BOOL)valuesEqWithJavaUtilHashMap_Entry:(JavaUtilHashMap_Entry *)entry
+                    withJavaUtilMap_Entry:(id<JavaUtilMap_Entry>)oEntry {
+  return (entry != nil)
+      && ((entry->value_ == nil) ? ([oEntry getValue] == nil)
+          : ([JavaUtilHashMap areEqualValuesWithId:entry->value_ withId:[oEntry getValue]]));
+}
 
-@implementation JavaUtilHashMap_EntrySetIterator
+- (id<JavaUtilIterator>)iterator {
+  return [[[JavaUtilHashMap_EntryIterator alloc] initWithJavaUtilHashMap:associatedMap_] autorelease];
+}
 
-- (id)next {
-  id key = [self.iterator next];
-  id value = [self.map getWithId:key];
-  id result = [[JavaUtilHashMap_Entry alloc] initWithKey:key value:value];
-#if ! __has_feature(objc_arc)
-  [result autorelease];
-#endif
-  return result;
+- (void)dealloc {
+  [associatedMap_ autorelease];
+  [super dealloc];
 }
 
 @end
 
-@implementation JavaUtilHashMap_Values
 
-@synthesize map = map_;
+@implementation JavaUtilHashMap_KeySet
 
-- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)map {
-  if ((self = [super init])) {
-    map_ = map;
-  }
-  return self;
+- (BOOL)containsWithId:(id)object {
+  return [outer_ containsKeyWithId:object];
 }
 
 - (int)size {
-  return [map_ size];
+  return [outer_ size];
 }
 
 - (void)clear {
-  [map_ clear];
+  [outer_ clear];
 }
 
-- (BOOL)containsWithId:(id)object {
-  return [map_ containsValueWithId:object];
+- (BOOL)removeWithId:(id)key {
+  JavaUtilHashMap_Entry *entry = [outer_ removeEntryWithId:key];
+  return entry != nil;
 }
 
 - (id<JavaUtilIterator>)iterator {
-  NSMutableArray *valueList = [[self.map.dictionary allValues] mutableCopy];
-#if ! __has_feature(objc_arc)
-  [valueList autorelease];
-#endif
-  IOSIterator *valueIterator = [[IOSIterator alloc] initWithList:valueList];
-#if ! __has_feature(objc_arc)
-  [valueIterator autorelease];
-#endif
-  id iterator = [[JavaUtilHashMap_ValuesIterator alloc]
-                 initWithJavaUtilHashMap:self.map withIterator:valueIterator];
-#if ! __has_feature(objc_arc)
-  [iterator autorelease];
-#endif
-  return iterator;
-}
-
-- (BOOL)removeWithId:(id)value {
-  if ([map_ containsValueWithId:value]) {
-    for (id key in [map_.dictionary allKeysForObject:value]) {
-      [map_ removeWithId:key];
-      return YES;
-    }
+  return [[[JavaUtilHashMap_KeyIterator alloc] initWithJavaUtilHashMap:outer_] autorelease];
+}
+
+- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)outer {
+  if ((self = [super init])) {
+    [outer_ autorelease];
+    outer_ = [outer retain];
   }
-  return NO;
+  return self;
+}
+
+- (void)dealloc {
+  [outer_ autorelease];
+  [super dealloc];
 }
 
 @end
 
-@implementation JavaUtilHashMap_ValuesIterator
 
-@synthesize map = map_;
+@implementation JavaUtilHashMap_ValuesCollection
 
-- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)map
-                 withIterator:(IOSIterator *)iterator {
-  if ((self = [super init])) {
-    map_ = map;
-    iterator_ = iterator;
-    lastValue_ = nil;
-  }
-  return self;
+- (BOOL)containsWithId:(id)object {
+  return [outer_ containsValueWithId:object];
 }
 
-- (BOOL)hasNext {
-  return [iterator_ hasNext];
+- (int)size {
+  return [outer_ size];
 }
 
-- (id)next {
-  lastValue_ = [iterator_ next];
-  return lastValue_;
+- (void)clear {
+  [outer_ clear];",Rewrite HashMap and LinkedHashMap based on translated apache harmony versions . . Change on 2012 / 11 / 08 by kstanger @ kstanger .,"""Refactor JavaUtilHashMap to use a custom implementation instead of NSMutableDictionary""","Based on the provided diff, the commit message should be:

""Update HashMap implementation to use Java Harmony implementation""

This commit message accurately reflects the changes made in the diff, which include updating the HashMap implementation to use the Java Harmony implementation instead of the previous NSMutableDictionary-based implementation.","The commit message should be:

""Refactor HashMap implementation to be based on Java Harmony""

Explanation:
The changes in the diff show a significant refactoring of the HashMap implementation in the JreEmulation project. The new implementation appears to be based on the Java Harmony project, which is an open-source implementation of the Java Class Library.

The changes include the addition of new instance variables, such as `elementCount_`, `elementData_`, `elementDataLength_`, `modCount_`, `loadFactor_`, and `threshold_`, which are used to manage the internal state of the HashMap. The implementation also appears to use a linked list data structure to handle collisions in the hash table, which is a common technique for implementing hash maps.

Overall, the changes suggest a significant refactoring of the HashMap implementation to improve its performance and compatibility with the Java standard library.","Refactored `JavaUtilHashMap` to replace `NSMutableDictionary` with custom implementation based on Java's HashMap, including entry handling and rehashing.",Label
"diff --git a/spring-boot-project/spring-boot-docs/src/main/asciidoc/appendix-application-properties.adoc b/spring-boot-project/spring-boot-docs/src/main/asciidoc/appendix-application-properties.adoc
index 4833f5652b..c43771b1f8 100644
--- a/spring-boot-project/spring-boot-docs/src/main/asciidoc/appendix-application-properties.adoc
+++ b/spring-boot-project/spring-boot-docs/src/main/asciidoc/appendix-application-properties.adoc
@@ -14,66 +14,96 @@ Also, you can define your own properties.
 
 
 
-== Core properties
-
+[[common-application-properties-core]]
+== Core properties [[core-properties]]
 include::{generated-resources-root}/config-docs/core.adoc[]
 
-== Cache properties
 
+
+[[common-application-properties-cache]]
+== Cache properties [[cache-properties]]
 include::{generated-resources-root}/config-docs/cache.adoc[]
 
-== Mail properties
 
+
+[[common-application-properties-mail]]
+== Mail properties [[mail-properties]]
 include::{generated-resources-root}/config-docs/mail.adoc[]
 
-== JSON properties
 
+
+[[common-application-properties-json]]
+== JSON properties [[json-properties]]
 include::{generated-resources-root}/config-docs/json.adoc[]
 
-== Data properties
 
+
+[[common-application-properties-data]]
+== Data properties [[data-properties]]
 include::{generated-resources-root}/config-docs/data.adoc[]
 
-== Transaction properties
 
+
+[[common-application-properties-transaction]]
+== Transaction properties [[transaction-properties]]
 include::{generated-resources-root}/config-docs/transaction.adoc[]
 
-== Data migration properties
 
+
+[[common-application-properties-data-migration]]
+== Data migration properties [[data-migration-properties]]
 include::{generated-resources-root}/config-docs/data-migration.adoc[]
 
-== Integration properties
 
+
+[[common-application-properties-integration]]
+== Integration properties [[integration-properties]]
 include::{generated-resources-root}/config-docs/integration.adoc[]
 
-== Web properties
 
+
+[[common-application-properties-web]]
+== Web properties [[web-properties]]
 include::{generated-resources-root}/config-docs/web.adoc[]
 
-== Templating properties
 
+
+[[common-application-properties-templating]]
+== Templating properties [[templating-properties]]
 include::{generated-resources-root}/config-docs/templating.adoc[]
 
-== Server properties
 
+
+[[common-application-properties-server]]
+== Server properties [[server-properties]]
 include::{generated-resources-root}/config-docs/server.adoc[]
 
-== Security properties
 
+
+[[common-application-properties-security]]
+== Security properties [[security-properties]]
 include::{generated-resources-root}/config-docs/security.adoc[]
 
-== RSocket properties
 
+
+[[common-application-properties-rsocket]]
+== RSocket properties [[rsocket-properties]]
 include::{generated-resources-root}/config-docs/rsocket.adoc[]
 
-== Actuator properties
 
+
+[[common-application-properties-actuator]]
+== Actuator properties [[actuator-properties]]
 include::{generated-resources-root}/config-docs/actuator.adoc[]
 
-== Devtools properties
 
+
+[[common-application-properties-devtools]]
+== Devtools properties [[devtools-properties]]
 include::{generated-resources-root}/config-docs/devtools.adoc[]
 
-== Testing properties
 
+
+[[common-application-properties-testing]]
+== Testing properties [[testing-properties]]
 include::{generated-resources-root}/config-docs/testing.adoc[]
diff --git a/spring-boot-project/spring-boot-docs/src/main/asciidoc/spring-boot-features.adoc b/spring-boot-project/spring-boot-docs/src/main/asciidoc/spring-boot-features.adoc
index 18988385b9..51d3b72fc2 100644
--- a/spring-boot-project/spring-boot-docs/src/main/asciidoc/spring-boot-features.adoc
+++ b/spring-boot-project/spring-boot-docs/src/main/asciidoc/spring-boot-features.adoc
@@ -2346,6 +2346,10 @@ If you have this problem, you can reorder the classpath in the IDE to place the
 By default, Spring Boot provides an `/error` mapping that handles all errors in a sensible way, and it is registered as a ""`global`"" error page in the servlet container.
 For machine clients, it produces a JSON response with details of the error, the HTTP status, and the exception message.
 For browser clients, there is a ""`whitelabel`"" error view that renders the same data in HTML format (to customize it, add a `View` that resolves to `error`).
+
+There are a number of `server.error` properties that can be set if you want to customize the default error handling behavior.
+See the <<appendix-application-properties.adoc#common-application-properties-server, ""`Server Properties`"">> section of the Appendix.  
+
 To replace the default behavior completely, you can implement `ErrorController` and register a bean definition of that type or add a bean of type `ErrorAttributes` to use the existing mechanism but replace the contents.
 
 TIP: The `BasicErrorController` can be used as a base class for a custom `ErrorController`.",Add link to appendix from error handling .,"""Added anchor links to application properties sections and referenced server properties in error handling documentation""","""Refactor application properties documentation to improve organization and readability""","""Update appendix-application-properties.adoc and spring-boot-features.adoc""

The changes made in the first file (appendix-application-properties.adoc) involve adding anchor links to the headings of different sections. The format for these anchor links is `[[common-application-properties-<section-name>]]`. For example, `[[common-application-properties-core]]` is added before the ""Core properties"" section.

In the second file (spring-boot-features.adoc), a paragraph is added at the end of a section, and a link is included in this paragraph that points to a specific section in the first file. The link is created using the format `<<appendix-application-properties.adoc#common-application-properties-<section-name>, ""`<Section-Name>`"">>`. For example, `<<appendix-application-properties.adoc#common-application-properties-server, ""`Server Properties`"">>` is used to link to the ""Server Properties"" section in the first file.",Add section links to server properties in appendix and error handling in Spring Boot docs.,Model 4
"diff --git a/assembly/pom.xml b/assembly/pom.xml
index cd81a376b9..76cd48ce81 100644
--- a/assembly/pom.xml
+++ b/assembly/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-parent</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <groupId>org.tachyonproject</groupId>
   <artifactId>tachyon-assemblies</artifactId>
diff --git a/clients/client/pom.xml b/clients/client/pom.xml
index e5edd61807..f1a3fd58ce 100644
--- a/clients/client/pom.xml
+++ b/clients/client/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-clients</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <groupId>org.tachyonproject</groupId>
   <artifactId>tachyon-client</artifactId>
diff --git a/clients/pom.xml b/clients/pom.xml
index 4b6c5e20fe..c44d36f5ef 100644
--- a/clients/pom.xml
+++ b/clients/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-parent</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-clients</artifactId>
   <packaging>pom</packaging>
diff --git a/clients/unshaded/pom.xml b/clients/unshaded/pom.xml
index d98d2b689d..7a90c025b6 100644
--- a/clients/unshaded/pom.xml
+++ b/clients/unshaded/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-clients</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-client-unshaded</artifactId>
   <packaging>jar</packaging>
diff --git a/common/pom.xml b/common/pom.xml
index 75ecfedf8f..1d2e885e2a 100644
--- a/common/pom.xml
+++ b/common/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-parent</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-common</artifactId>
   <packaging>jar</packaging>
diff --git a/examples/pom.xml b/examples/pom.xml
index ecb63530cc..c6019674d6 100644
--- a/examples/pom.xml
+++ b/examples/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-parent</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-examples</artifactId>
   <packaging>jar</packaging>
diff --git a/integration-tests/pom.xml b/integration-tests/pom.xml
index fc3440f351..0b2806b4b3 100644
--- a/integration-tests/pom.xml
+++ b/integration-tests/pom.xml
@@ -1,9 +1,11 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-parent</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-integration-tests</artifactId>
   <packaging>jar</packaging>
@@ -214,7 +216,7 @@
             <groupId>org.apache.maven.plugins</groupId>
             <artifactId>maven-compiler-plugin</artifactId>
             <configuration>
-              <testExcludes combine.self=""override"" />
+              <testExcludes combine.self=""override""/>
             </configuration>
           </plugin>
         </plugins>
diff --git a/minicluster/pom.xml b/minicluster/pom.xml
index 53825dc888..465342d8ae 100644
--- a/minicluster/pom.xml
+++ b/minicluster/pom.xml
@@ -1,8 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <parent>
     <artifactId>tachyon-parent</artifactId>
     <groupId>org.tachyonproject</groupId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <modelVersion>4.0.0</modelVersion>
 
diff --git a/pom.xml b/pom.xml
index 99f01e6a65..26309fabf6 100644
--- a/pom.xml
+++ b/pom.xml
@@ -2,7 +2,7 @@
   <modelVersion>4.0.0</modelVersion>
   <groupId>org.tachyonproject</groupId>
   <artifactId>tachyon-parent</artifactId>
-  <version>0.7.1-SNAPSHOT</version>
+  <version>0.7.0-SNAPSHOT</version>
   <packaging>pom</packaging>
   <name>Tachyon Parent</name>
   <description>Parent POM of Tachyon project: a Reliable Memory Centric Distributed Storage System</description>
diff --git a/servers/pom.xml b/servers/pom.xml
index 39d06b0c45..d875ff9ce2 100644
--- a/servers/pom.xml
+++ b/servers/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-parent</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-servers</artifactId>
   <packaging>jar</packaging>
diff --git a/shell/pom.xml b/shell/pom.xml
index 8992588abf..ae9dcd50c0 100644
--- a/shell/pom.xml
+++ b/shell/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-parent</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-shell</artifactId>
   <packaging>jar</packaging>
diff --git a/underfs/glusterfs/pom.xml b/underfs/glusterfs/pom.xml
index fd0a59e4f8..5d21326147 100644
--- a/underfs/glusterfs/pom.xml
+++ b/underfs/glusterfs/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-underfs</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-underfs-glusterfs</artifactId>
   <name>Tachyon Under File System - Gluster FS</name>
diff --git a/underfs/hdfs/pom.xml b/underfs/hdfs/pom.xml
index b8fa76e907..d3788a7709 100644
--- a/underfs/hdfs/pom.xml
+++ b/underfs/hdfs/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-underfs</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-underfs-hdfs</artifactId>
   <name>Tachyon Under File System - HDFS</name>
diff --git a/underfs/local/pom.xml b/underfs/local/pom.xml
index ac867dfd92..62d2298512 100644
--- a/underfs/local/pom.xml
+++ b/underfs/local/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-underfs</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-underfs-local</artifactId>
   <name>Tachyon Under File System - Local FS</name>
diff --git a/underfs/pom.xml b/underfs/pom.xml
index 91381959cd..795b192577 100644
--- a/underfs/pom.xml
+++ b/underfs/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-parent</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-underfs</artifactId>
   <packaging>pom</packaging>
diff --git a/underfs/s3/pom.xml b/underfs/s3/pom.xml
index 4f18103a13..08c3c03552 100644
--- a/underfs/s3/pom.xml
+++ b/underfs/s3/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-underfs</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-underfs-s3</artifactId>
   <name>Tachyon Under File System - S3</name>
diff --git a/underfs/swift/pom.xml b/underfs/swift/pom.xml
index a1834e9d08..4283f2b395 100644
--- a/underfs/swift/pom.xml
+++ b/underfs/swift/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-underfs</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-underfs-swift</artifactId>
   <name>Tachyon Under File System - Swift</name>",Revert release plugin changes .,Downgrade Tachyon version from 0.7.1-SNAPSHOT to 0.7.0-SNAPSHOT,Bump Tachyon version to 0.7.0-SNAPSHOT in various pom.xml files.,"""Downgrading Tachyon version from 0.7.1-SNAPSHOT to 0.7.0-SNAPSHOT""

This commit involves changing the version of Tachyon from 0.7.1-SNAPSHOT to 0.7.0-SNAPSHOT in multiple pom.xml files throughout the project. It seems like the project is downgrading the version of Tachyon used.","""Revert version from 0.7.1-SNAPSHOT to 0.7.0-SNAPSHOT across multiple POM files""",Model 4
"diff --git a/crepecake/build.gradle b/crepecake/build.gradle
index 6c62c19c..3b4dbb05 100644
--- a/crepecake/build.gradle
+++ b/crepecake/build.gradle
@@ -15,6 +15,7 @@ repositories {
 
 dependencies {
     compile gradleApi()
+    compile 'com.google.http-client:google-http-client:1.23.0'
     compile 'org.apache.commons:commons-compress:1.15'
     compile 'com.google.guava:guava:23.5-jre'
     compile 'com.fasterxml.jackson.core:jackson-databind:2.9.2'
diff --git a/crepecake/src/main/java/com/google/cloud/tools/crepecake/blob/InputStreamBlob.java b/crepecake/src/main/java/com/google/cloud/tools/crepecake/blob/InputStreamBlob.java
index cb9c21fd..363f7f75 100644
--- a/crepecake/src/main/java/com/google/cloud/tools/crepecake/blob/InputStreamBlob.java
+++ b/crepecake/src/main/java/com/google/cloud/tools/crepecake/blob/InputStreamBlob.java
@@ -45,6 +45,8 @@ class InputStreamBlob implements Blob {
 
   @Override
   public BlobDescriptor writeTo(OutputStream outputStream) throws IOException {
-    return writeFromInputStream(inputStream, outputStream);
+    try (InputStream inputStream = this.inputStream) {
+      return writeFromInputStream(inputStream, outputStream);
+    }
   }
 }
diff --git a/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/BlobHttpContent.java b/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/BlobHttpContent.java
new file mode 100644
index 00000000..94d0f179
--- /dev/null
+++ b/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/BlobHttpContent.java
@@ -0,0 +1,54 @@
+/*
+ * Copyright 2017 Google Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License""); you may not
+ * use this file except in compliance with the License. You may obtain a copy of
+ * the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+
+package com.google.cloud.tools.crepecake.http;
+
+import com.google.api.client.http.HttpContent;
+import com.google.cloud.tools.crepecake.blob.Blob;
+import java.io.IOException;
+import java.io.OutputStream;
+
+/** {@link Blob}-backed {@link HttpContent}. */
+class BlobHttpContent implements HttpContent {
+
+  private final Blob blob;
+
+  BlobHttpContent(Blob blob) {
+    this.blob = blob;
+  }
+
+  @Override
+  public long getLength() throws IOException {
+    // Returns negative value for unknown length.
+    return -1;
+  }
+
+  @Override
+  public String getType() {
+    // TODO: This should return the actual Content-Type.
+    return null;
+  }
+
+  @Override
+  public boolean retrySupported() {
+    return false;
+  }
+
+  @Override
+  public void writeTo(OutputStream outputStream) throws IOException {
+    blob.writeTo(outputStream);
+  }
+}
diff --git a/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Connection.java b/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Connection.java
new file mode 100644
index 00000000..a61e322a
--- /dev/null
+++ b/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Connection.java
@@ -0,0 +1,99 @@
+/*
+ * Copyright 2017 Google Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License""); you may not
+ * use this file except in compliance with the License. You may obtain a copy of
+ * the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+
+package com.google.cloud.tools.crepecake.http;
+
+import com.google.api.client.http.GenericUrl;
+import com.google.api.client.http.HttpMethods;
+import com.google.api.client.http.HttpRequestFactory;
+import com.google.api.client.http.HttpResponse;
+import com.google.api.client.http.javanet.NetHttpTransport;
+import com.google.common.annotations.VisibleForTesting;
+import java.io.Closeable;
+import java.io.IOException;
+import java.net.URL;
+
+/**
+ * Sends an HTTP {@link Request} and stores the {@link Response}.
+ *
+ * <p>Example usage:
+ *
+ * <pre>{@code
+ * try (Connection connection = new Connection(url)) {
+ *   Response response = connection.get(request);
+ *   // ... process the response
+ * }
+ * }</pre>
+ */
+public class Connection implements Closeable {
+
+  private static final HttpRequestFactory HTTP_REQUEST_FACTORY =
+      new NetHttpTransport().createRequestFactory();
+
+  private final HttpRequestFactory requestFactory;
+
+  private HttpResponse httpResponse;
+
+  /** The URL to send the request to. */
+  private GenericUrl url;
+
+  /**
+   * Make sure to wrap with a try-with-resource to ensure that the connection is closed after usage.
+   */
+  public Connection(URL url) throws IOException {
+    this(url, HTTP_REQUEST_FACTORY);
+  }
+
+  @VisibleForTesting
+  Connection(URL url, HttpRequestFactory requestFactory) {
+    this.url = new GenericUrl(url);
+    this.requestFactory = requestFactory;
+  }
+
+  @Override
+  public void close() throws IOException {
+    if (httpResponse == null) {
+      return;
+    }
+
+    httpResponse.disconnect();
+  }
+
+  /** Sends the request with method GET. */
+  public Response get(Request request) throws IOException {
+    return send(HttpMethods.GET, request);
+  }
+
+  /** Sends the request with method POST. */
+  public Response post(Request request) throws IOException {
+    return send(HttpMethods.POST, request);
+  }
+
+  /** Sends the request with method PUT. */
+  public Response put(Request request) throws IOException {
+    return send(HttpMethods.PUT, request);
+  }
+
+  /** Sends the request. */
+  private Response send(String httpMethod, Request request) throws IOException {
+    httpResponse =
+        requestFactory
+            .buildRequest(httpMethod, url, request.getHttpContent())
+            .setHeaders(request.getHeaders())
+            .execute();
+    return new Response(httpResponse);
+  }
+}
diff --git a/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Request.java b/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Request.java
new file mode 100644
index 00000000..6e17a0ec
--- /dev/null
+++ b/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Request.java
@@ -0,0 +1,51 @@
+/*
+ * Copyright 2017 Google Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License""); you may not
+ * use this file except in compliance with the License. You may obtain a copy of
+ * the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+
+package com.google.cloud.tools.crepecake.http;
+
+import com.google.api.client.http.HttpHeaders;
+import com.google.cloud.tools.crepecake.blob.Blob;
+import javax.annotation.Nullable;
+
+/** Holds an HTTP request. */
+public class Request {
+
+  /** The HTTP request headers. */
+  private final HttpHeaders headers = new HttpHeaders();
+
+  /** The HTTP request body. */
+  @Nullable private BlobHttpContent body;
+
+  public HttpHeaders getHeaders() {
+    return headers;
+  }
+
+  @Nullable
+  public BlobHttpContent getHttpContent() {
+    return body;
+  }
+
+  /** Sets the {@code Content-Type} header. */
+  public Request setContentType(String contentType) {
+    headers.setContentType(contentType);
+    return this;
+  }
+
+  public Request setBody(Blob body) {
+    this.body = new BlobHttpContent(body);
+    return this;
+  }
+}
diff --git a/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Response.java b/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Response.java
new file mode 100644
index 00000000..ecd00d87
--- /dev/null
+++ b/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Response.java
@@ -0,0 +1,48 @@
+/*
+ * Copyright 2017 Google Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License""); you may not
+ * use this file except in compliance with the License. You may obtain a copy of
+ * the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+
+package com.google.cloud.tools.crepecake.http;
+
+import com.google.api.client.http.HttpResponse;
+import com.google.cloud.tools.crepecake.blob.Blob;
+import com.google.cloud.tools.crepecake.blob.Blobs;
+import java.io.IOException;
+import java.util.List;
+
+/** Holds an HTTP response. */
+public class Response {
+
+  private final HttpResponse httpResponse;
+
+  Response(HttpResponse httpResponse) {
+    this.httpResponse = httpResponse;
+  }
+
+  /** Gets the HTTP status code of the response. */
+  public int getStatusCode() {
+    return httpResponse.getStatusCode();
+  }
+
+  /** Gets a header in the response. */
+  public List<String> getHeader(String headerName) {
+    return httpResponse.getHeaders().getHeaderStringValues(headerName);
+  }
+
+  /** Gets the HTTP response body as a {@link Blob}. */
+  public Blob getBody() throws IOException {
+    return Blobs.from(httpResponse.getContent());
+  }
+}
diff --git a/crepecake/src/test/java/com/google/cloud/tools/crepecake/blob/BlobTest.java b/crepecake/src/test/java/com/google/cloud/tools/crepecake/blob/BlobTest.java
index 359029da..90599990 100644
--- a/crepecake/src/test/java/com/google/cloud/tools/crepecake/blob/BlobTest.java
+++ b/crepecake/src/test/java/com/google/cloud/tools/crepecake/blob/BlobTest.java
@@ -38,33 +38,33 @@ public class BlobTest {
 
   @Test
   public void testEmpty() throws IOException, DigestException {
-    verifyBlobStreamWriteTo("""", Blobs.empty());
+    verifyBlobWriteTo("""", Blobs.empty());
   }
 
   @Test
   public void testFromInputStream() throws IOException, DigestException {
     String expected = ""crepecake"";
     InputStream inputStream = new ByteArrayInputStream(expected.getBytes(Charsets.UTF_8));
-    verifyBlobStreamWriteTo(expected, Blobs.from(inputStream));
+    verifyBlobWriteTo(expected, Blobs.from(inputStream));
   }
 
   @Test
   public void testFromFile() throws IOException, DigestException, URISyntaxException {
     File fileA = new File(Resources.getResource(""fileA"").toURI());
     String expected = new String(Files.readAllBytes(fileA.toPath()), Charsets.UTF_8);
-    verifyBlobStreamWriteTo(expected, Blobs.from(fileA));
+    verifyBlobWriteTo(expected, Blobs.from(fileA));
   }
 
   @Test
   public void testFromString_hashing() throws IOException, DigestException {
     String expected = ""crepecake"";
-    verifyBlobStreamWriteTo(expected, Blobs.from(expected, true));
+    verifyBlobWriteTo(expected, Blobs.from(expected, true));
   }
 
   @Test
   public void testFromString_noHashing() throws IOException, DigestException {
     String expected = ""crepecake"";
-    verifyBlobStreamWriteTo(expected, Blobs.from(expected, false));
+    verifyBlobWriteTo(expected, Blobs.from(expected, false));
   }
 
   @Test
@@ -73,12 +73,11 @@ public class BlobTest {
 
     BlobWriter writer = outputStream -> outputStream.write(expected.getBytes(Charsets.UTF_8));
 
-    verifyBlobStreamWriteTo(expected, Blobs.from(writer));
+    verifyBlobWriteTo(expected, Blobs.from(writer));
   }
 
   /** Checks that the {@link Blob} streams the expected string. */
-  private void verifyBlobStreamWriteTo(String expected, Blob blob)
-      throws IOException, DigestException {
+  private void verifyBlobWriteTo(String expected, Blob blob) throws IOException, DigestException {
     OutputStream outputStream = new ByteArrayOutputStream();
     BlobDescriptor blobDescriptor = blob.writeTo(outputStream);
 
diff --git a/crepecake/src/test/java/com/google/cloud/tools/crepecake/http/ConnectionTest.java b/crepecake/src/test/java/com/google/cloud/tools/crepecake/http/ConnectionTest.java
new file mode 100644
index 00000000..87c27042
--- /dev/null
+++ b/crepecake/src/test/java/com/google/cloud/tools/crepecake/http/ConnectionTest.java
@@ -0,0 +1,112 @@
+/*
+ * Copyright 2017 Google Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License""); you may not
+ * use this file except in compliance with the License. You may obtain a copy of
+ * the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+
+package com.google.cloud.tools.crepecake.http;
+
+import com.google.api.client.http.GenericUrl;
+import com.google.api.client.http.HttpHeaders;
+import com.google.api.client.http.HttpMethods;
+import com.google.api.client.http.HttpRequest;
+import com.google.api.client.http.HttpRequestFactory;
+import com.google.api.client.http.HttpResponse;
+import com.google.cloud.tools.crepecake.blob.Blob;
+import com.google.cloud.tools.crepecake.blob.Blobs;
+import com.google.common.base.Charsets;
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.ArgumentCaptor;
+import org.mockito.Mock;
+import org.mockito.Mockito;
+import org.mockito.junit.MockitoJUnitRunner;
+
+/** Tests for {@link Connection}. */
+@RunWith(MockitoJUnitRunner.class)
+public class ConnectionTest {
+
+  @Mock private HttpRequestFactory mockHttpRequestFactory;
+  @Mock private HttpRequest mockHttpRequest;
+  @Mock private HttpResponse mockHttpResponse;
+
+  private final ArgumentCaptor<HttpHeaders> httpHeadersArgumentCaptor =
+      ArgumentCaptor.forClass(HttpHeaders.class);
+  private final ArgumentCaptor<BlobHttpContent> blobHttpContentArgumentCaptor =
+      ArgumentCaptor.forClass(BlobHttpContent.class);
+
+  private final GenericUrl fakeUrl = new GenericUrl(""http://crepecake/fake/url"");
+  private final Request fakeRequest = new Request();
+
+  @Before
+  public void setUpMocksAndFakes() throws IOException {
+    Blob fakeBlob = Blobs.from(""crepecake"", false);
+    fakeRequest.setBody(fakeBlob);
+    fakeRequest.setContentType(""fake.content.type"");
+
+    Mockito.when(
+            mockHttpRequestFactory.buildRequest(
+                Mockito.any(String.class), Mockito.eq(fakeUrl), Mockito.any(BlobHttpContent.class)))
+        .thenReturn(mockHttpRequest);
+
+    Mockito.when(mockHttpRequest.setHeaders(Mockito.any(HttpHeaders.class)))
+        .thenReturn(mockHttpRequest);
+    Mockito.when(mockHttpRequest.execute()).thenReturn(mockHttpResponse);
+  }
+
+  @Test
+  public void testGet() throws IOException {
+    testSend(HttpMethods.GET, Connection::get);
+  }
+
+  @Test
+  public void testPost() throws IOException {
+    testSend(HttpMethods.POST, Connection::post);
+  }
+
+  @Test
+  public void testPut() throws IOException {
+    testSend(HttpMethods.PUT, Connection::put);
+  }
+
+  @FunctionalInterface
+  private interface SendFunction {
+
+    Response send(Connection connection, Request request) throws IOException;
+  }
+
+  private void testSend(String httpMethod, SendFunction sendFunction) throws IOException {
+    try (Connection connection = new Connection(fakeUrl.toURL(), mockHttpRequestFactory)) {
+      sendFunction.send(connection, fakeRequest);
+    }
+
+    Mockito.verify(mockHttpRequest).setHeaders(httpHeadersArgumentCaptor.capture());
+    Mockito.verify(mockHttpResponse).disconnect();
+
+    Assert.assertEquals(""fake.content.type"", httpHeadersArgumentCaptor.getValue().getContentType());
+
+    Mockito.verify(mockHttpRequestFactory)
+        .buildRequest(
+            Mockito.eq(httpMethod), Mockito.eq(fakeUrl), blobHttpContentArgumentCaptor.capture());
+
+    ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();
+    blobHttpContentArgumentCaptor.getValue().writeTo(byteArrayOutputStream);
+
+    Assert.assertEquals(
+        ""crepecake"", new String(byteArrayOutputStream.toByteArray(), Charsets.UTF_8));
+  }
+}
diff --git a/crepecake/src/test/java/com/google/cloud/tools/crepecake/http/ResponseTest.java b/crepecake/src/test/java/com/google/cloud/tools/crepecake/http/ResponseTest.java
new file mode 100644
index 00000000..d7fd0782
--- /dev/null
+++ b/crepecake/src/test/java/com/google/cloud/tools/crepecake/http/ResponseTest.java
@@ -0,0 +1,55 @@
+/*
+ * Copyright 2017 Google Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License""); you may not
+ * use this file except in compliance with the License. You may obtain a copy of
+ * the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+
+package com.google.cloud.tools.crepecake.http;
+
+import com.google.api.client.http.HttpResponse;
+import com.google.cloud.tools.crepecake.blob.Blob;
+import com.google.common.base.Charsets;
+import java.io.ByteArrayInputStream;
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import org.junit.Assert;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mock;
+import org.mockito.Mockito;
+import org.mockito.junit.MockitoJUnitRunner;
+
+/** Tests for {@link Response}. */
+@RunWith(MockitoJUnitRunner.class)
+public class ResponseTest {
+
+  @Mock private HttpResponse httpResponseMock;
+
+  @Test
+  public void testGetContent() throws IOException {
+    String expectedResponse = ""crepecake\nis\ngood!"";
+    ByteArrayInputStream responseInputStream =
+        new ByteArrayInputStream(expectedResponse.getBytes(Charsets.UTF_8));
+
+    Mockito.when(httpResponseMock.getContent()).thenReturn(responseInputStream);
+
+    Response response = new Response(httpResponseMock);
+    Blob responseStream = response.getBody();
+
+    ByteArrayOutputStream responseOutputStream = new ByteArrayOutputStream();
+    responseStream.writeTo(responseOutputStream);
+
+    Assert.assertEquals(
+        expectedResponse, new String(responseOutputStream.toByteArray(), Charsets.UTF_8));
+  }
+}
diff --git a/crepecake/src/test/resources/mockito-extensions/org.mockito.plugins.MockMaker b/crepecake/src/test/resources/mockito-extensions/org.mockito.plugins.MockMaker
new file mode 100644
index 00000000..1f0955d4
--- /dev/null
+++ b/crepecake/src/test/resources/mockito-extensions/org.mockito.plugins.MockMaker
@@ -0,0 +1 @@
+mock-maker-inline",Adds HTTP request utilities .,"""Added HTTP client functionality and tests""","Added HTTP client functionality to crepecake

This commit message is concise and accurately describes the changes made in the commit. It mentions the addition of HTTP client functionality, which is the main focus of the changes.","""Added Google HTTP client library and related code changes""

The commit adds the Google HTTP client library as a dependency in the build.gradle file and includes several new Java classes related to HTTP requests and responses in the crepecake/src/main/java/com/google/cloud/tools/crepecake/http/ directory. There is also a change to the InputStreamBlob class to properly close the input stream after use.","Added HTTP request handling using google-http-client, included new BlobHttpContent, Connection, Request, and Response classes, and corresponding unit tests.",Model 4
"diff --git a/components/camel-http/src/main/java/org/apache/camel/component/http/HttpComponent.java b/components/camel-http/src/main/java/org/apache/camel/component/http/HttpComponent.java
index d1de0457021..b8b2b028d11 100644
--- a/components/camel-http/src/main/java/org/apache/camel/component/http/HttpComponent.java
+++ b/components/camel-http/src/main/java/org/apache/camel/component/http/HttpComponent.java
@@ -397,7 +397,7 @@ public class HttpComponent extends HttpCommonComponent implements RestProducerFa
         if (localConnectionsPerRoute > 0) {
             answer.setDefaultMaxPerRoute(localConnectionsPerRoute);
         }
-        LOG.info(""Created ClientConnectionManager {}"", answer);
+        LOG.debug(""Created ClientConnectionManager {}"", answer);
 
         return answer;
     }",create connection manager method logs in debug mode .,"""Downgrade log level for ClientConnectionManager creation from INFO to DEBUG""","""Log level for ClientConnectionManager creation changed to DEBUG""","""Change log level from INFO to DEBUG for creating ClientConnectionManager in HttpComponent.java""",Changed log level from info to debug for ClientConnectionManager creation in HttpComponent.,Model 4
"diff --git a/management/src/main/java/io/micronaut/management/endpoint/info/InfoAggregator.java b/management/src/main/java/io/micronaut/management/endpoint/info/InfoAggregator.java
index ab2dc2d822..b2ec2cf328 100644
--- a/management/src/main/java/io/micronaut/management/endpoint/info/InfoAggregator.java
+++ b/management/src/main/java/io/micronaut/management/endpoint/info/InfoAggregator.java
@@ -15,9 +15,6 @@
  */
 package io.micronaut.management.endpoint.info;
 
-import io.micronaut.context.env.Environment;
-import io.micronaut.context.env.PropertySource;
-import io.micronaut.management.endpoint.Endpoint;
 import org.reactivestreams.Publisher;
 
 /**
@@ -27,7 +24,6 @@ import org.reactivestreams.Publisher;
  * @author Zachary Klein
  * @since 1.0
  */
-@Endpoint(""info"")
 public interface InfoAggregator<T> {
 
     /**
diff --git a/management/src/main/java/io/micronaut/management/endpoint/info/InfoEndpoint.java b/management/src/main/java/io/micronaut/management/endpoint/info/InfoEndpoint.java
index 74a6cdb599..f8af9fede9 100644
--- a/management/src/main/java/io/micronaut/management/endpoint/info/InfoEndpoint.java
+++ b/management/src/main/java/io/micronaut/management/endpoint/info/InfoEndpoint.java
@@ -27,10 +27,9 @@ import org.reactivestreams.Publisher;
  * @author Zachary Klein
  * @since 1.0
  */
-@Endpoint(""info"")
+@Endpoint(InfoEndpoint.NAME)
 public class InfoEndpoint {
 
-
     public static final String NAME = ""info"";
     public static final String PREFIX = EndpointConfiguration.PREFIX + ""."" + NAME;",Remove endpoint annotation added where it shouldnt be,"""Remove duplicate @Endpoint annotation from InfoAggregator and standardize endpoint name in InfoEndpoint""","The commit message should be: 

""Remove unnecessary imports and annotations from InfoAggregator and InfoEndpoint""","""Remove @Endpoint annotation from InfoAggregator and add it to InfoEndpoint with constant name""

Explanation:
The diff shows that the `@Endpoint(""info"")` annotation has been removed from the `InfoAggregator` interface and added to the `InfoEndpoint` class with the constant name `InfoEndpoint.NAME`. Additionally, an unused import statement `import io.micronaut.management.endpoint.Endpoint;` has been removed from the `InfoAggregator` interface.",Refactor: Specify `InfoEndpoint.NAME` in `@Endpoint` annotation and clean up imports and `@Endpoint` annotation from `InfoAggregator`.,Model 3
"diff --git a/modules/core/src/main/java/org/apache/ignite/internal/processors/cache/transactions/TxDeadlockDetection.java b/modules/core/src/main/java/org/apache/ignite/internal/processors/cache/transactions/TxDeadlockDetection.java
index a904e5b6fe..576dec74d7 100644
--- a/modules/core/src/main/java/org/apache/ignite/internal/processors/cache/transactions/TxDeadlockDetection.java
+++ b/modules/core/src/main/java/org/apache/ignite/internal/processors/cache/transactions/TxDeadlockDetection.java
@@ -52,7 +52,7 @@ import static org.apache.ignite.internal.processors.cache.transactions.IgniteTxM
  */
 public class TxDeadlockDetection {
     /** Deadlock detection maximum iterations. */
-    private static final int DEADLOCK_TIMEOUT = getInteger(IGNITE_TX_DEADLOCK_DETECTION_TIMEOUT, 60000);
+    private static int deadLockTimeout = getInteger(IGNITE_TX_DEADLOCK_DETECTION_TIMEOUT, 60000);
 
     /** Sequence. */
     private static final AtomicLong SEQ = new AtomicLong();
@@ -229,7 +229,7 @@ public class TxDeadlockDetection {
             this.topVer = topVer;
             this.keys = keys;
 
-            if (DEADLOCK_TIMEOUT > 0) {
+            if (deadLockTimeout > 0) {
                 timeoutObj = new DeadlockTimeoutObject();
 
                 cctx.time().addTimeoutObject(timeoutObj);
@@ -555,7 +555,7 @@ public class TxDeadlockDetection {
              * Default constructor.
              */
             DeadlockTimeoutObject() {
-                super(DEADLOCK_TIMEOUT);
+                super(deadLockTimeout);
             }
 
             /** {@inheritDoc} */
@@ -564,7 +564,7 @@ public class TxDeadlockDetection {
 
                 IgniteLogger log = cctx.kernalContext().log(this.getClass());
 
-                U.warn(log, ""Deadlock detection was timed out [timeout="" + DEADLOCK_TIMEOUT + "", fut="" + this + ']');
+                U.warn(log, ""Deadlock detection was timed out [timeout="" + deadLockTimeout + "", fut="" + this + ']');
 
                 onDone();
             }
diff --git a/modules/core/src/test/java/org/apache/ignite/internal/processors/cache/transactions/TxDeadlockDetectionNoHangsTest.java b/modules/core/src/test/java/org/apache/ignite/internal/processors/cache/transactions/TxDeadlockDetectionNoHangsTest.java
index 27a07993d5..7a7651b6b5 100644
--- a/modules/core/src/test/java/org/apache/ignite/internal/processors/cache/transactions/TxDeadlockDetectionNoHangsTest.java
+++ b/modules/core/src/test/java/org/apache/ignite/internal/processors/cache/transactions/TxDeadlockDetectionNoHangsTest.java
@@ -89,12 +89,12 @@ public class TxDeadlockDetectionNoHangsTest extends GridCommonAbstractTest {
     @Override protected void beforeTestsStarted() throws Exception {
         super.beforeTestsStarted();
 
-        GridTestUtils.setFieldValue(null, TxDeadlockDetection.class, ""DEADLOCK_TIMEOUT"", (int)(getTestTimeout() * 2));
+        GridTestUtils.setFieldValue(TxDeadlockDetection.class, ""deadLockTimeout"", (int)(getTestTimeout() * 2));
     }
 
     /** {@inheritDoc} */
     @Override protected void afterTestsStopped() throws Exception {
-        GridTestUtils.setFieldValue(null, TxDeadlockDetection.class, ""DEADLOCK_TIMEOUT"",
+        GridTestUtils.setFieldValue(TxDeadlockDetection.class, ""deadLockTimeout"",
             getInteger(IGNITE_TX_DEADLOCK_DETECTION_TIMEOUT, 60000));
     }
 
@@ -113,14 +113,14 @@ public class TxDeadlockDetectionNoHangsTest extends GridCommonAbstractTest {
         doTest(PESSIMISTIC);
 
         try {
-            GridTestUtils.setFieldValue(null, IgniteTxManager.class, ""DEADLOCK_MAX_ITERS"", 0);
+            GridTestUtils.setFieldValue(IgniteTxManager.class, ""DEADLOCK_MAX_ITERS"", 0);
 
             assertFalse(grid(0).context().cache().context().tm().deadlockDetectionEnabled());
 
             doTest(PESSIMISTIC);
         }
         finally {
-            GridTestUtils.setFieldValue(null, IgniteTxManager.class, ""DEADLOCK_MAX_ITERS"",
+            GridTestUtils.setFieldValue(IgniteTxManager.class, ""DEADLOCK_MAX_ITERS"",
                 IgniteSystemProperties.getInteger(IGNITE_TX_DEADLOCK_DETECTION_MAX_ITERS, 1000));
         }
     }
@@ -135,14 +135,14 @@ public class TxDeadlockDetectionNoHangsTest extends GridCommonAbstractTest {
         doTest(OPTIMISTIC);
 
         try {
-            GridTestUtils.setFieldValue(null, IgniteTxManager.class, ""DEADLOCK_MAX_ITERS"", 0);
+            GridTestUtils.setFieldValue(IgniteTxManager.class, ""DEADLOCK_MAX_ITERS"", 0);
 
             assertFalse(grid(0).context().cache().context().tm().deadlockDetectionEnabled());
 
             doTest(OPTIMISTIC);
         }
         finally {
-            GridTestUtils.setFieldValue(null, IgniteTxManager.class, ""DEADLOCK_MAX_ITERS"",
+            GridTestUtils.setFieldValue(IgniteTxManager.class, ""DEADLOCK_MAX_ITERS"",
                 IgniteSystemProperties.getInteger(IGNITE_TX_DEADLOCK_DETECTION_MAX_ITERS, 1000));
         }
     }
diff --git a/modules/core/src/test/java/org/apache/ignite/testframework/GridTestUtils.java b/modules/core/src/test/java/org/apache/ignite/testframework/GridTestUtils.java
index f7993226b6..608c52aa4c 100644
--- a/modules/core/src/test/java/org/apache/ignite/testframework/GridTestUtils.java
+++ b/modules/core/src/test/java/org/apache/ignite/testframework/GridTestUtils.java
@@ -34,10 +34,8 @@ import java.net.InetAddress;
 import java.net.MulticastSocket;
 import java.net.ServerSocket;
 import java.nio.file.attribute.PosixFilePermission;
-import java.security.AccessController;
 import java.security.GeneralSecurityException;
 import java.security.KeyStore;
-import java.security.PrivilegedAction;
 import java.sql.Connection;
 import java.sql.DriverManager;
 import java.sql.SQLException;
@@ -1621,27 +1619,6 @@ public final class GridTestUtils {
         return field.get(obj);
     }
 
-    /**
-     * Change static final fields.
-     * @param field Need to be changed.
-     * @param newVal New value.
-     * @throws Exception If failed.
-     */
-    public static void setFieldValue(Field field, Object newVal) throws Exception {
-        field.setAccessible(true);
-        Field modifiersField = Field.class.getDeclaredField(""modifiers"");
-
-        AccessController.doPrivileged(new PrivilegedAction() {
-            @Override public Object run() {
-                modifiersField.setAccessible(true);
-                return null;
-            }
-        });
-
-        modifiersField.setInt(field, field.getModifiers() & ~Modifier.FINAL);
-        field.set(null, newVal);
-    }
-
     /**
      * Get inner class by its name from the enclosing class.
      *
@@ -1674,6 +1651,18 @@ public final class GridTestUtils {
 
             Field field = cls.getDeclaredField(fieldName);
 
+            boolean isFinal = (field.getModifiers() & Modifier.FINAL) != 0;
+
+            boolean isStatic = (field.getModifiers() & Modifier.STATIC) != 0;
+
+            /**
+             * http://java.sun.com/docs/books/jls/third_edition/html/memory.html#17.5.3
+             * If a final field is initialized to a compile-time constant in the field declaration,
+             *   changes to the final field may not be observed.
+             */
+            if (isFinal && isStatic)
+                throw new IgniteException(""Modification of static final field through reflection."");
+
             boolean accessible = field.isAccessible();
 
             if (!accessible)
@@ -1708,6 +1697,16 @@ public final class GridTestUtils {
 
             boolean isFinal = (field.getModifiers() & Modifier.FINAL) != 0;
 
+            boolean isStatic = (field.getModifiers() & Modifier.STATIC) != 0;
+
+            /**
+             * http://java.sun.com/docs/books/jls/third_edition/html/memory.html#17.5.3
+             * If a final field is initialized to a compile-time constant in the field declaration,
+             *   changes to the final field may not be observed.
+             */
+            if (isFinal && isStatic)
+                throw new IgniteException(""Modification of static final field through reflection."");
+
             if (isFinal) {
                 Field modifiersField = Field.class.getDeclaredField(""modifiers"");
 
diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/twostep/AbstractReducer.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/twostep/AbstractReducer.java
index dfb23d736a..3b08fe1d0b 100644
--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/twostep/AbstractReducer.java
+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/twostep/AbstractReducer.java
@@ -54,16 +54,16 @@ public abstract class AbstractReducer implements Reducer {
     static final int MAX_FETCH_SIZE = getInteger(IGNITE_SQL_MERGE_TABLE_MAX_SIZE, 10_000);
 
     /** */
-    static final int PREFETCH_SIZE = getInteger(IGNITE_SQL_MERGE_TABLE_PREFETCH_SIZE, 1024);
+    static int prefetchSize = getInteger(IGNITE_SQL_MERGE_TABLE_PREFETCH_SIZE, 1024);
 
     static {
-        if (!U.isPow2(PREFETCH_SIZE)) {
-            throw new IllegalArgumentException(IGNITE_SQL_MERGE_TABLE_PREFETCH_SIZE + "" ("" + PREFETCH_SIZE +
+        if (!U.isPow2(prefetchSize)) {
+            throw new IllegalArgumentException(IGNITE_SQL_MERGE_TABLE_PREFETCH_SIZE + "" ("" + prefetchSize +
                 "") must be positive and a power of 2."");
         }
 
-        if (PREFETCH_SIZE >= MAX_FETCH_SIZE) {
-            throw new IllegalArgumentException(IGNITE_SQL_MERGE_TABLE_PREFETCH_SIZE + "" ("" + PREFETCH_SIZE +
+        if (prefetchSize >= MAX_FETCH_SIZE) {
+            throw new IllegalArgumentException(IGNITE_SQL_MERGE_TABLE_PREFETCH_SIZE + "" ("" + prefetchSize +
                 "") must be less than "" + IGNITE_SQL_MERGE_TABLE_MAX_SIZE + "" ("" + MAX_FETCH_SIZE + "")."");
         }
     }
@@ -102,7 +102,7 @@ public abstract class AbstractReducer implements Reducer {
     AbstractReducer(GridKernalContext ctx) {
         this.ctx = ctx;
 
-        fetched = new ReduceBlockList<>(PREFETCH_SIZE);
+        fetched = new ReduceBlockList<>(prefetchSize);
     }
 
     /** {@inheritDoc} */
@@ -191,7 +191,7 @@ public abstract class AbstractReducer implements Reducer {
      * @param evictedBlock Evicted block.
      */
     protected void onBlockEvict(@NotNull List<Row> evictedBlock) {
-        assert evictedBlock.size() == PREFETCH_SIZE;
+        assert evictedBlock.size() == prefetchSize;
 
         // Remember the last row (it will be max row) from the evicted block.
         lastEvictedRow = requireNonNull(last(evictedBlock));
diff --git a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/IgniteSqlSplitterSelfTest.java b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/IgniteSqlSplitterSelfTest.java
index 92e0739a06..15dd2e1323 100644
--- a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/IgniteSqlSplitterSelfTest.java
+++ b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/IgniteSqlSplitterSelfTest.java
@@ -567,7 +567,7 @@ public class IgniteSqlSplitterSelfTest extends AbstractIndexingCommonTest {
             Integer.class, Value.class));
 
         try {
-            GridTestUtils.setFieldValue(null, AbstractReducer.class, ""PREFETCH_SIZE"", 8);
+            GridTestUtils.setFieldValue(AbstractReducer.class, ""prefetchSize"", 8);
 
             Random rnd = new GridRandom();
 
@@ -617,7 +617,7 @@ public class IgniteSqlSplitterSelfTest extends AbstractIndexingCommonTest {
             }
         }
         finally {
-            GridTestUtils.setFieldValue(null, AbstractReducer.class, ""PREFETCH_SIZE"", 1024);
+            GridTestUtils.setFieldValue(AbstractReducer.class, ""prefetchSize"", 1024);
 
             c.destroy();
         }
diff --git a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/h2/twostep/RetryCauseMessageSelfTest.java b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/h2/twostep/RetryCauseMessageSelfTest.java
index 62f5f32d57..a1f670e57f 100644
--- a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/h2/twostep/RetryCauseMessageSelfTest.java
+++ b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/h2/twostep/RetryCauseMessageSelfTest.java
@@ -96,7 +96,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
     public void testSynthCacheWasNotFoundMessage() {
         GridMapQueryExecutor mapQryExec = GridTestUtils.getFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"");
 
-        GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"",
+        GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"",
             new MockGridMapQueryExecutor() {
                 @Override public void onQueryRequest(ClusterNode node, GridH2QueryRequest qryReq)
                     throws IgniteCheckedException {
@@ -121,7 +121,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
             return;
         }
         finally {
-            GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"", mapQryExec);
+            GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"", mapQryExec);
         }
         fail();
     }
@@ -135,7 +135,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
 
         final ConcurrentMap<PartitionReservationKey, GridReservable> reservations = reservations(h2Idx);
 
-        GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"",
+        GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"",
             new MockGridMapQueryExecutor() {
                 @Override public void onQueryRequest(ClusterNode node, GridH2QueryRequest qryReq)
                     throws IgniteCheckedException {
@@ -166,7 +166,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
             return;
         }
         finally {
-            GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"", mapQryExec);
+            GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"", mapQryExec);
         }
         fail();
     }
@@ -181,7 +181,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
 
         final GridKernalContext ctx = GridTestUtils.getFieldValue(mapQryExec, GridMapQueryExecutor.class, ""ctx"");
 
-        GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"",
+        GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"",
             new MockGridMapQueryExecutor() {
                 @Override public void onQueryRequest(ClusterNode node, GridH2QueryRequest qryReq) throws IgniteCheckedException {
                     GridCacheContext<?, ?> cctx = ctx.cache().context().cacheContext(qryReq.caches().get(0));
@@ -211,7 +211,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
             return;
         }
         finally {
-            GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"", mapQryExec);
+            GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"", mapQryExec);
         }
         fail();
     }
@@ -225,7 +225,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
 
         final GridKernalContext ctx = GridTestUtils.getFieldValue(mapQryExec, GridMapQueryExecutor.class, ""ctx"");
 
-        GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"",
+        GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"",
             new MockGridMapQueryExecutor() {
                 @Override public void onQueryRequest(ClusterNode node, GridH2QueryRequest qryReq)
                     throws IgniteCheckedException {
@@ -256,7 +256,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
             return;
         }
         finally {
-            GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"", mapQryExec);
+            GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"", mapQryExec);
         }
         fail();
     }
@@ -270,7 +270,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
 
         final ConcurrentMap<PartitionReservationKey, GridReservable> reservations = reservations(h2Idx);
 
-        GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"",
+        GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"",
             new MockGridMapQueryExecutor() {
                 @Override public void onQueryRequest(ClusterNode node, GridH2QueryRequest qryReq)
                     throws IgniteCheckedException {
@@ -300,7 +300,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
             return;
         }
         finally {
-            GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"", mapQryExec);
+            GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"", mapQryExec);
         }
         fail();
     }
@@ -316,7 +316,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
         final IgniteLogger logger = GridTestUtils.getFieldValue(rdcQryExec, GridReduceQueryExecutor.class, ""log"");
         final GridKernalContext ctx = GridTestUtils.getFieldValue(rdcQryExec, GridReduceQueryExecutor.class, ""ctx"");
 
-        GridTestUtils.setFieldValue(rdcQryExec, GridReduceQueryExecutor.class, ""mapper"",
+        GridTestUtils.setFieldValue(rdcQryExec, ""mapper"",
             new ReducePartitionMapper(ctx, logger) {
                 @Override public ReducePartitionMapResult nodesForPartitions(List<Integer> cacheIds,",IGNITE - 13039 Get rid of possibility to change final static fields - Fixes <issue_id> . . Signed - off - by : Alexey Goncharuk < alexey . goncharuk @ gmail . com >,"""Fixed issues with modifying static final fields through reflection and updated related test cases""","The commit message should be:

""Refactor static final fields to be non-final and mutable.""","This commit changes the way the `DEADLOCK_TIMEOUT` and `deadLockTimeout` variables are accessed and modified in the `TxDeadlockDetection` class.

Previously, `DEADLOCK_TIMEOUT` was a static final field that was accessed and modified directly. Now, `deadLockTimeout` is a static non-final field that is accessed and modified using getter and setter methods.

Additionally, the `DeadlockTimeoutObject` constructor has been updated to use the new `deadLockTimeout` field instead of `DEADLOCK_TIMEOUT`.

The `TxDeadlockDetectionNoHangsTest` class has also been updated to use the new getter and setter methods for `deadLockTimeout`.

Finally, the `GridTestUtils` class has been updated to throw an exception when attempting to modify a static final field through reflection. This is due to the fact that changes to static final fields may not be observed if they are initialized to a compile-time constant in the field declaration.","Refactor code to remove static final fields, replace direct static field access with instance methods, and simplify reflection utility in GridTestUtils.",Model 3
"diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/Partitioning.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/Partitioning.java
index d7b6854725..681f94dd6b 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/Partitioning.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/Partitioning.java
@@ -16,6 +16,8 @@ package com.facebook.presto.sql.planner;
 import com.facebook.presto.Session;
 import com.facebook.presto.metadata.Metadata;
 import com.facebook.presto.spi.predicate.NullableValue;
+import com.facebook.presto.sql.tree.Expression;
+import com.facebook.presto.sql.tree.SymbolReference;
 import com.fasterxml.jackson.annotation.JsonCreator;
 import com.fasterxml.jackson.annotation.JsonProperty;
 import com.google.common.collect.ImmutableList;
@@ -32,6 +34,7 @@ import java.util.function.Function;
 
 import static com.google.common.base.MoreObjects.toStringHelper;
 import static com.google.common.base.Preconditions.checkArgument;
+import static com.google.common.base.Verify.verify;
 import static com.google.common.collect.ImmutableList.toImmutableList;
 import static com.google.common.collect.ImmutableSet.toImmutableSet;
 import static java.util.Objects.requireNonNull;
@@ -51,7 +54,15 @@ public final class Partitioning
     public static Partitioning create(PartitioningHandle handle, List<Symbol> columns)
     {
         return new Partitioning(handle, columns.stream()
-                .map(ArgumentBinding::columnBinding)
+                .map(Symbol::toSymbolReference)
+                .map(ArgumentBinding::expressionBinding)
+                .collect(toImmutableList()));
+    }
+
+    public static Partitioning createWithExpressions(PartitioningHandle handle, List<Expression> expressions)
+    {
+        return new Partitioning(handle, expressions.stream()
+                .map(ArgumentBinding::expressionBinding)
                 .collect(toImmutableList()));
     }
 
@@ -160,13 +171,20 @@ public final class Partitioning
 
     public boolean isPartitionedOn(Collection<Symbol> columns, Set<Symbol> knownConstants)
     {
-        // partitioned on (k_1, k_2, ..., k_n) => partitioned on (k_1, k_2, ..., k_n, k_n+1, ...)
-        // can safely ignore all constant columns when comparing partition properties
-        return arguments.stream()
-                .filter(ArgumentBinding::isVariable)
-                .map(ArgumentBinding::getColumn)
-                .filter(symbol -> !knownConstants.contains(symbol))
-                .allMatch(columns::contains);
+        for (ArgumentBinding argument : arguments) {
+            // partitioned on (k_1, k_2, ..., k_n) => partitioned on (k_1, k_2, ..., k_n, k_n+1, ...)
+            // can safely ignore all constant columns when comparing partition properties
+            if (argument.isConstant()) {
+                continue;
+            }
+            if (!argument.isVariable()) {
+                return false;
+            }
+            if (!knownConstants.contains(argument.getColumn()) && !columns.contains(argument.getColumn())) {
+                return false;
+            }
+        }
+        return true;
     }
 
     public boolean isEffectivelySinglePartition(Set<Symbol> knownConstants)
@@ -194,11 +212,11 @@ public final class Partitioning
                 .collect(toImmutableList()));
     }
 
-    public Optional<Partitioning> translate(Function<Symbol, Optional<Symbol>> translator, Function<Symbol, Optional<NullableValue>> constants)
+    public Optional<Partitioning> translate(Translator translator)
     {
         ImmutableList.Builder<ArgumentBinding> newArguments = ImmutableList.builder();
         for (ArgumentBinding argument : arguments) {
-            Optional<ArgumentBinding> newArgument = argument.translate(translator, constants);
+            Optional<ArgumentBinding> newArgument = argument.translate(translator);
             if (!newArgument.isPresent()) {
                 return Optional.empty();
             }
@@ -242,25 +260,43 @@ public final class Partitioning
                 .toString();
     }
 
+    @Immutable
+    public static final class Translator
+    {
+        private final Function<Symbol, Optional<Symbol>> columnTranslator;
+        private final Function<Symbol, Optional<NullableValue>> constantTranslator;
+        private final Function<Expression, Optional<Symbol>> expressionTranslator;
+
+        public Translator(
+                Function<Symbol, Optional<Symbol>> columnTranslator,
+                Function<Symbol, Optional<NullableValue>> constantTranslator,
+                Function<Expression, Optional<Symbol>> expressionTranslator)
+        {
+            this.columnTranslator = requireNonNull(columnTranslator, ""columnTranslator is null"");
+            this.constantTranslator = requireNonNull(constantTranslator, ""constantTranslator is null"");
+            this.expressionTranslator = requireNonNull(expressionTranslator, ""expressionTranslator is null"");
+        }
+    }
+
     @Immutable
     public static final class ArgumentBinding
     {
-        private final Symbol column;
+        private final Expression expression;
         private final NullableValue constant;
 
         @JsonCreator
         public ArgumentBinding(
-                @JsonProperty(""column"") Symbol column,
+                @JsonProperty(""expression"") Expression expression,
                 @JsonProperty(""constant"") NullableValue constant)
         {
-            this.column = column;
+            this.expression = expression;
             this.constant = constant;
-            checkArgument((column == null) != (constant == null), ""Either column or constant must be set"");
+            checkArgument((expression == null) != (constant == null), ""Either expression or constant must be set"");
         }
 
-        public static ArgumentBinding columnBinding(Symbol column)
+        public static ArgumentBinding expressionBinding(Expression expression)
         {
-            return new ArgumentBinding(requireNonNull(column, ""column is null""), null);
+            return new ArgumentBinding(requireNonNull(expression, ""expression is null""), null);
         }
 
         public static ArgumentBinding constantBinding(NullableValue constant)
@@ -275,13 +311,19 @@ public final class Partitioning
 
         public boolean isVariable()
         {
-            return column != null;
+            return expression instanceof SymbolReference;
         }
 
-        @JsonProperty
         public Symbol getColumn()
         {
-            return column;
+            verify(expression instanceof SymbolReference, ""Expect the expression to be a SymbolReference"");
+            return Symbol.from(expression);
+        }
+
+        @JsonProperty
+        public Expression getExpression()
+        {
+            return expression;
         }
 
         @JsonProperty
@@ -295,25 +337,31 @@ public final class Partitioning
             if (isConstant()) {
                 return this;
             }
-            return columnBinding(translator.apply(column));
+            return expressionBinding(translator.apply(Symbol.from(expression)).toSymbolReference());
         }
 
-        public Optional<ArgumentBinding> translate(Function<Symbol, Optional<Symbol>> translator, Function<Symbol, Optional<NullableValue>> constants)
+        public Optional<ArgumentBinding> translate(Translator translator)
         {
             if (isConstant()) {
                 return Optional.of(this);
             }
 
-            Optional<ArgumentBinding> newColumn = translator.apply(column)
-                    .map(ArgumentBinding::columnBinding);
+            if (!isVariable()) {
+                return translator.expressionTranslator.apply(expression)
+                        .map(Symbol::toSymbolReference)
+                        .map(ArgumentBinding::expressionBinding);
+            }
+
+            Optional<ArgumentBinding> newColumn = translator.columnTranslator.apply(Symbol.from(expression))
+                    .map(Symbol::toSymbolReference)
+                    .map(ArgumentBinding::expressionBinding);
             if (newColumn.isPresent()) {
                 return newColumn;
             }
-
             // As a last resort, check for a constant mapping for the symbol
             // Note: this MUST be last because we want to favor the symbol representation
             // as it makes further optimizations possible.
-            return constants.apply(column)
+            return translator.constantTranslator.apply(Symbol.from(expression))
                     .map(ArgumentBinding::constantBinding);
         }
 
@@ -323,7 +371,8 @@ public final class Partitioning
             if (constant != null) {
                 return constant.toString();
             }
-            return ""\"""" + column + ""\"""";
+
+            return expression.toString();
         }
 
         @Override
@@ -336,14 +385,14 @@ public final class Partitioning
                 return false;
             }
             ArgumentBinding that = (ArgumentBinding) o;
-            return Objects.equals(column, that.column) &&
+            return Objects.equals(expression, that.expression) &&
                     Objects.equals(constant, that.constant);
         }
 
         @Override
         public int hashCode()
         {
-            return Objects.hash(column, constant);
+            return Objects.hash(expression, constant);
         }
     }
 }
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/ActualProperties.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/ActualProperties.java
index 762d8c6868..7747914b71 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/ActualProperties.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/ActualProperties.java
@@ -21,6 +21,7 @@ import com.facebook.presto.spi.predicate.NullableValue;
 import com.facebook.presto.sql.planner.Partitioning;
 import com.facebook.presto.sql.planner.PartitioningHandle;
 import com.facebook.presto.sql.planner.Symbol;
+import com.facebook.presto.sql.tree.Expression;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.ImmutableSet;
@@ -153,17 +154,21 @@ public class ActualProperties
 
     public ActualProperties translate(Function<Symbol, Optional<Symbol>> translator)
     {
-        Map<Symbol, NullableValue> translatedConstants = new HashMap<>();
-        for (Map.Entry<Symbol, NullableValue> entry : constants.entrySet()) {
-            Optional<Symbol> translatedKey = translator.apply(entry.getKey());
-            if (translatedKey.isPresent()) {
-                translatedConstants.put(translatedKey.get(), entry.getValue());
-            }
-        }
         return builder()
-                .global(global.translate(translator, symbol -> Optional.ofNullable(constants.get(symbol))))
+                .global(global.translate(new Partitioning.Translator(translator, symbol -> Optional.ofNullable(constants.get(symbol)), expression -> Optional.empty())))
                 .local(LocalProperties.translate(localProperties, translator))
-                .constants(translatedConstants)
+                .constants(translateConstants(translator))
+                .build();
+    }
+
+    public ActualProperties translate(
+            Function<Symbol, Optional<Symbol>> translator,
+            Function<Expression, Optional<Symbol>> expressionTranslator)
+    {
+        return builder()
+                .global(global.translate(new Partitioning.Translator(translator, symbol -> Optional.ofNullable(constants.get(symbol)), expressionTranslator)))
+                .local(LocalProperties.translate(localProperties, translator))
+                .constants(translateConstants(translator))
                 .build();
     }
 
@@ -199,6 +204,18 @@ public class ActualProperties
         return new Builder(properties.global, properties.localProperties, properties.constants);
     }
 
+    private Map<Symbol, NullableValue> translateConstants(Function<Symbol, Optional<Symbol>> translator)
+    {
+        Map<Symbol, NullableValue> translatedConstants = new HashMap<>();
+        for (Map.Entry<Symbol, NullableValue> entry : constants.entrySet()) {
+            Optional<Symbol> translatedKey = translator.apply(entry.getKey());
+            if (translatedKey.isPresent()) {
+                translatedConstants.put(translatedKey.get(), entry.getValue());
+            }
+        }
+        return translatedConstants;
+    }
+
     public static class Builder
     {
         private Global global;
@@ -448,11 +465,11 @@ public class ActualProperties
             return (!streamPartitioning.isPresent() || streamPartitioning.get().isRepartitionEffective(keys, constants)) && !nullsAndAnyReplicated;
         }
 
-        private Global translate(Function<Symbol, Optional<Symbol>> translator, Function<Symbol, Optional<NullableValue>> constants)
+        private Global translate(Partitioning.Translator translator)
         {
             return new Global(
-                    nodePartitioning.flatMap(partitioning -> partitioning.translate(translator, constants)),
-                    streamPartitioning.flatMap(partitioning -> partitioning.translate(translator, constants)),
+                    nodePartitioning.flatMap(partitioning -> partitioning.translate(translator)),
+                    streamPartitioning.flatMap(partitioning -> partitioning.translate(translator)),
                     nullsAndAnyReplicated);
         }
 
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PreferredProperties.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PreferredProperties.java
index 7089a11370..d89aa005c9 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PreferredProperties.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PreferredProperties.java
@@ -391,7 +391,7 @@ class PreferredProperties
                 return Optional.of(new PartitioningProperties(newPartitioningColumns, Optional.empty(), nullsAndAnyReplicated));
             }
 
-            Optional<Partitioning> newPartitioning = partitioning.get().translate(translator, symbol -> Optional.empty());
+            Optional<Partitioning> newPartitioning = partitioning.get().translate(new Partitioning.Translator(translator, symbol -> Optional.empty(), coalesceSymbols -> Optional.empty()));
             if (!newPartitioning.isPresent()) {
                 return Optional.empty();
             }
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PropertyDerivations.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PropertyDerivations.java
index 66fc8bf9da..23964ab9c5 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PropertyDerivations.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PropertyDerivations.java
@@ -31,6 +31,7 @@ import com.facebook.presto.sql.planner.DomainTranslator;
 import com.facebook.presto.sql.planner.ExpressionInterpreter;
 import com.facebook.presto.sql.planner.NoOpSymbolResolver;
 import com.facebook.presto.sql.planner.OrderingScheme;
+import com.facebook.presto.sql.planner.Partitioning;
 import com.facebook.presto.sql.planner.Symbol;
 import com.facebook.presto.sql.planner.TypeProvider;
 import com.facebook.presto.sql.planner.optimizations.ActualProperties.Global;
@@ -67,6 +68,7 @@ import com.facebook.presto.sql.planner.plan.TopNRowNumberNode;
 import com.facebook.presto.sql.planner.plan.UnnestNode;
 import com.facebook.presto.sql.planner.plan.ValuesNode;
 import com.facebook.presto.sql.planner.plan.WindowNode;
+import com.facebook.presto.sql.tree.CoalesceExpression;
 import com.facebook.presto.sql.tree.Expression;
 import com.facebook.presto.sql.tree.NodeRef;
 import com.facebook.presto.sql.tree.SymbolReference;
@@ -422,8 +424,22 @@ public class PropertyDerivations
                             .unordered(unordered)
                             .build();
                 case FULL:
-                    // We can't say anything about the partitioning scheme because any partition of
-                    // a hash-partitioned join can produce nulls in case of a lack of matches
+                    if (probeProperties.getNodePartitioning().isPresent()) {
+                        Partitioning nodePartitioning = probeProperties.getNodePartitioning().get();
+                        ImmutableList.Builder<Expression> coalesceExpressions = ImmutableList.builder();
+                        for (Symbol column : nodePartitioning.getColumns()) {
+                            for (JoinNode.EquiJoinClause equality : node.getCriteria()) {
+                                if (equality.getLeft().equals(column) || equality.getRight().equals(column)) {
+                                    coalesceExpressions.add(new CoalesceExpression(ImmutableList.of(equality.getLeft().toSymbolReference(), equality.getRight().toSymbolReference())));
+                                }
+                            }
+                        }
+
+                        return ActualProperties.builder()
+                                .global(partitionedOn(Partitioning.createWithExpressions(nodePartitioning.getHandle(), coalesceExpressions.build()), Optional.empty()))
+                                .unordered(unordered)
+                                .build();
+                    }
                     return ActualProperties.builder()
                             .global(probeProperties.isSingleNode() ? singleStreamPartition() : arbitraryPartition())
                             .unordered(unordered)
@@ -606,7 +622,7 @@ public class PropertyDerivations
 
             Map<Symbol, Symbol> identities = computeIdentityTranslations(node.getAssignments().getMap());
 
-            ActualProperties translatedProperties = properties.translate(column -> Optional.ofNullable(identities.get(column)));
+            ActualProperties translatedProperties = properties.translate(column -> Optional.ofNullable(identities.get(column)), expression -> rewriteExpression(node.getAssignments().getMap(), expression));
 
             // Extract additional constants
             Map<Symbol, NullableValue> constants = new HashMap<>();
@@ -824,4 +840,28 @@ public class PropertyDerivations
 
         return Optional.empty();
     }
+
+    public static Optional<Symbol> rewriteExpression(Map<Symbol, Expression> assignments, Expression expression)
+    {
+        checkArgument(expression instanceof CoalesceExpression, ""The rewrite can only handle CoalesceExpression"");
+        // We are using the property that the result of coalesce from full outer join keys would not be null despite of the order
+        // of the arguments. Thus we extract and compare the symbols of the CoalesceExpression as a set rather than compare the
+        // CoalesceExpression directly.
+        for (Map.Entry<Symbol, Expression> entry : assignments.entrySet()) {
+            if (entry.getValue() instanceof CoalesceExpression) {
+                Set<Symbol> symbolsInAssignment = ((CoalesceExpression) entry.getValue()).getOperands().stream()
+                        .filter(SymbolReference.class::isInstance)
+                        .map(Symbol::from)
+                        .collect(toImmutableSet());
+                Set<Symbol> symbolInExpression = ((CoalesceExpression) expression).getOperands().stream()
+                        .filter(SymbolReference.class::isInstance)
+                        .map(Symbol::from)
+                        .collect(toImmutableSet());
+                if (symbolsInAssignment.containsAll(symbolInExpression)) {
+                    return Optional.of(entry.getKey());
+                }
+            }
+        }
+        return Optional.empty();
+    }
 }
diff --git a/presto-main/src/main/java/com/facebook/presto/util/GraphvizPrinter.java b/presto-main/src/main/java/com/facebook/presto/util/GraphvizPrinter.java
index e18789afeb..f9135dcff2 100644
--- a/presto-main/src/main/java/com/facebook/presto/util/GraphvizPrinter.java
+++ b/presto-main/src/main/java/com/facebook/presto/util/GraphvizPrinter.java
@@ -309,7 +309,8 @@ public final class GraphvizPrinter
         public Void visitExchange(ExchangeNode node, Void context)
         {
             List<ArgumentBinding> symbols = node.getOutputSymbols().stream()
-",Propagate partition properties for full outer join .,"""Refactor Partitioning to use Expressions instead of Symbols""","According to the diff, the commit message should be:

""Refactor Partitioning to use Expression instead of Symbol and add Translator for translating Partitioning""","The commit message could be: ""Refactor Partitioning to support expressions and update ActualProperties, PreferredProperties, and PropertyDerivations accordingly.""

This commit refactors the Partitioning class to support expressions, not just symbols. It also updates the ActualProperties, PreferredProperties, and PropertyDerivations classes to work with this new Partitioning class. The changes include new methods for translating expressions and constants, and updating the partitioning schemes to handle expressions. Additionally, it adds a new class, Partitioning.Translator, to encapsulate the translation of symbols, constants, and expressions.","""Refactored Partitioning to support expressions, added comprehensive translation capabilities, and enhanced join handling.""",Model 4
"diff --git a/configserver/src/main/java/com/yahoo/vespa/config/server/ApplicationRepository.java b/configserver/src/main/java/com/yahoo/vespa/config/server/ApplicationRepository.java
index a8b4844ca43..585a1a67f4d 100644
--- a/configserver/src/main/java/com/yahoo/vespa/config/server/ApplicationRepository.java
+++ b/configserver/src/main/java/com/yahoo/vespa/config/server/ApplicationRepository.java
@@ -36,6 +36,7 @@ import com.yahoo.vespa.config.server.configchange.RestartActions;
 import com.yahoo.vespa.config.server.deploy.DeployHandlerLogger;
 import com.yahoo.vespa.config.server.deploy.Deployment;
 import com.yahoo.vespa.config.server.http.CompressedApplicationInputStream;
+import com.yahoo.vespa.config.server.http.LogRetriever;
 import com.yahoo.vespa.config.server.http.SimpleHttpFetcher;
 import com.yahoo.vespa.config.server.http.v2.PrepareResult;
 import com.yahoo.vespa.config.server.provision.HostProvisionerProvider;
@@ -50,6 +51,7 @@ import com.yahoo.vespa.config.server.session.SilentDeployLogger;
 import com.yahoo.vespa.config.server.tenant.Rotations;
 import com.yahoo.vespa.config.server.tenant.Tenant;
 import com.yahoo.vespa.config.server.tenant.TenantRepository;
+import com.yahoo.vespa.model.VespaModel;
 
 import java.io.File;
 import java.io.IOException;
@@ -477,6 +479,13 @@ public class ApplicationRepository implements com.yahoo.config.provision.Deploye
         return convergeChecker.servicesToCheck(getApplication(applicationId), uri, timeout);
     }
 
+    // ---------------- Logs ----------------------------------------------------------------
+
+    public HttpResponse getLogs(ApplicationId applicationId) {
+        String logServerHostName = getLogServerHostname(applicationId);
+        return LogRetriever.getLogs(logServerHostName);
+    }
+
     // ---------------- Session operations ----------------------------------------------------------------
 
     /**
@@ -690,6 +699,13 @@ public class ApplicationRepository implements com.yahoo.config.provision.Deploye
         }
     }
 
+    private String getLogServerHostname(ApplicationId applicationId) {
+        Application application = getApplication(applicationId);
+        VespaModel model = (VespaModel) application.getModel();
+        String logServerHostname = model.getAdmin().getLogserver().getHostName();
+        return logServerHostname;
+    }
+
     /** Returns version to use when deploying application in given environment */
     static Version decideVersion(ApplicationId application, Environment environment, Version targetVersion, boolean bootstrap) {
         if (environment.isManuallyDeployed() &&
diff --git a/configserver/src/main/java/com/yahoo/vespa/config/server/http/LogRetriever.java b/configserver/src/main/java/com/yahoo/vespa/config/server/http/LogRetriever.java
new file mode 100644
index 00000000000..f4952b5b9fc
--- /dev/null
+++ b/configserver/src/main/java/com/yahoo/vespa/config/server/http/LogRetriever.java
@@ -0,0 +1,41 @@
+package com.yahoo.vespa.config.server.http;
+
+import com.yahoo.container.jdisc.HttpResponse;
+import org.apache.http.client.methods.HttpGet;
+import org.apache.http.impl.client.CloseableHttpClient;
+import org.apache.http.impl.client.HttpClientBuilder;
+import org.apache.http.util.EntityUtils;
+
+import java.io.IOException;
+import java.io.OutputStream;
+import java.util.logging.Level;
+import java.util.logging.Logger;
+
+
+public class LogRetriever {
+
+    private final static Logger log = Logger.getLogger(LogRetriever.class.getName());
+
+    public static HttpResponse getLogs(String logServerHostname) {
+        HttpGet get = new HttpGet(logServerHostname);
+        try (CloseableHttpClient httpClient = HttpClientBuilder.create().build()) {
+            org.apache.http.HttpResponse response = httpClient.execute(get);
+            String responseBody = EntityUtils.toString(response.getEntity(), ""UTF-8"");
+            return new HttpResponse(response.getStatusLine().getStatusCode()) {
+                @Override
+                public void render(OutputStream outputStream) throws IOException {
+                    if (response.getEntity() != null ) outputStream.write(responseBody.getBytes());
+                }
+            };
+        } catch (IOException e) {
+            log.log(Level.WARNING, ""Failed to retrieve logs from log server"", e);
+            return new HttpResponse(404) {
+                @Override
+                public void render(OutputStream outputStream) throws IOException {
+                    outputStream.write(e.toString().getBytes());
+                }
+            };
+        }
+
+    }
+}
diff --git a/configserver/src/main/java/com/yahoo/vespa/config/server/http/v2/ApplicationHandler.java b/configserver/src/main/java/com/yahoo/vespa/config/server/http/v2/ApplicationHandler.java
index 2004ab95144..b65cb370f93 100644
--- a/configserver/src/main/java/com/yahoo/vespa/config/server/http/v2/ApplicationHandler.java
+++ b/configserver/src/main/java/com/yahoo/vespa/config/server/http/v2/ApplicationHandler.java
@@ -96,6 +96,10 @@ public class ApplicationHandler extends HttpHandler {
             return applicationRepository.filedistributionStatus(applicationId, timeout);
         }
 
+        if (isLogRequest(request)) {
+            return applicationRepository.getLogs(applicationId);
+        }
+
         return new GetApplicationResponse(Response.Status.OK, applicationRepository.getApplicationGeneration(applicationId));
     }
 
@@ -140,7 +144,13 @@ public class ApplicationHandler extends HttpHandler {
                 ""http://*/application/v2/tenant/*/application/*/environment/*/region/*/instance/*/serviceconverge/*"",
                 ""http://*/application/v2/tenant/*/application/*/environment/*/region/*/instance/*/clustercontroller/*/status/*"",
                 ""http://*/application/v2/tenant/*/application/*/environment/*/region/*/instance/*"",
-                ""http://*/application/v2/tenant/*/application/*"");
+                ""http://*/application/v2/tenant/*/application/*"",
+                ""http://*/application/v2/tenant/*/application/*/logs"");
+    }
+
+    private static boolean isLogRequest(HttpRequest request) {
+        return getBindingMatch(request).groupCount() == 4 &&
+                request.getUri().getPath().endsWith(""/logs"");
     }
 
     private static boolean isServiceConvergeListRequest(HttpRequest request) {
diff --git a/configserver/src/main/resources/configserver-app/services.xml b/configserver/src/main/resources/configserver-app/services.xml
index 8a99869e69a..60dd7b0cea2 100644
--- a/configserver/src/main/resources/configserver-app/services.xml
+++ b/configserver/src/main/resources/configserver-app/services.xml
@@ -147,6 +147,8 @@
       <binding>https://*/application/v2/tenant/*/application/*/environment/*/region/*/instance/*</binding>
       <binding>http://*/application/v2/tenant/*/application/*</binding>
       <binding>https://*/application/v2/tenant/*/application/*</binding>
+      <binding>http://*/application/v2/tenant/*/application/*/logs</binding>
+      <binding>https://*/application/v2/tenant/*/application/*/logs</binding>
     </handler>
     <handler id='com.yahoo.vespa.config.server.http.v2.HttpGetConfigHandler' bundle='configserver'>
       <binding>http://*/config/v2/tenant/*/application/*/*</binding>
diff --git a/configserver/src/test/java/com/yahoo/vespa/config/server/http/LogRetrieverTest.java b/configserver/src/test/java/com/yahoo/vespa/config/server/http/LogRetrieverTest.java
new file mode 100644
index 00000000000..2c3622e3dac
--- /dev/null
+++ b/configserver/src/test/java/com/yahoo/vespa/config/server/http/LogRetrieverTest.java
@@ -0,0 +1,46 @@
+package com.yahoo.vespa.config.server.http;
+
+import com.github.tomakehurst.wiremock.junit.WireMockRule;
+import com.yahoo.container.jdisc.HttpResponse;
+import org.junit.Rule;
+import org.junit.Test;
+
+
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+
+import static com.github.tomakehurst.wiremock.client.WireMock.aResponse;
+import static com.github.tomakehurst.wiremock.client.WireMock.get;
+import static com.github.tomakehurst.wiremock.client.WireMock.okJson;
+import static com.github.tomakehurst.wiremock.client.WireMock.stubFor;
+import static com.github.tomakehurst.wiremock.client.WireMock.urlEqualTo;
+import static com.github.tomakehurst.wiremock.core.WireMockConfiguration.options;
+import static org.junit.Assert.assertEquals;
+
+public class LogRetrieverTest {
+
+    private String logServerHostName = ""http://localhost:8080/"";
+    @Rule
+    public final WireMockRule wireMock = new WireMockRule(options().port(8080), true);
+
+    @Test
+    public void testThatLogHandlerPropagatesResponseBody() throws IOException {
+        String expectedBody = ""{logs-json}"";
+        stubFor(get(urlEqualTo(""/"")).willReturn(okJson(expectedBody)));
+        HttpResponse response = LogRetriever.getLogs(logServerHostName);
+        ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();
+        response.render(byteArrayOutputStream);
+        assertEquals(expectedBody, byteArrayOutputStream.toString());
+        assertEquals(200, response.getStatus());
+    }
+
+    @Test
+    public void testThatNotFoundLogServerReturns404() throws IOException {
+        stubFor(get(urlEqualTo(""/"")).willReturn(aResponse().withStatus(200)));
+        HttpResponse response = LogRetriever.getLogs(""http://wrong-host:8080/"");
+        assertEquals(404, response.getStatus());
+    }
+
+
+
+}
\ No newline at end of file
diff --git a/container-core/src/main/java/com/yahoo/container/handler/LogHandler.java b/container-core/src/main/java/com/yahoo/container/handler/LogHandler.java
new file mode 100644
index 00000000000..474d7d7321a
--- /dev/null
+++ b/container-core/src/main/java/com/yahoo/container/handler/LogHandler.java
@@ -0,0 +1,31 @@
+package com.yahoo.container.handler;
+
+import com.fasterxml.jackson.core.JsonFactory;
+import com.google.inject.Inject;
+import com.yahoo.container.jdisc.HttpRequest;
+import com.yahoo.container.jdisc.HttpResponse;
+import com.yahoo.container.jdisc.ThreadedHttpRequestHandler;
+import java.io.IOException;
+import java.io.OutputStream;
+import java.util.concurrent.Executor;
+
+public class LogHandler extends ThreadedHttpRequestHandler {
+
+    private static final String LOG_DIRECTORY = ""/home/y/logs/vespa/"";
+
+    @Inject
+    public LogHandler(Executor executor) {
+        super(executor);
+    }
+
+    @Override
+    public HttpResponse handle(HttpRequest request) {
+
+        return new HttpResponse(200) {
+            @Override
+            public void render(OutputStream outputStream) throws IOException {
+                LogReader.writeToOutputStream(LOG_DIRECTORY, outputStream);
+            }
+        };
+    }
+}
diff --git a/container-core/src/main/java/com/yahoo/container/handler/LogReader.java b/container-core/src/main/java/com/yahoo/container/handler/LogReader.java
new file mode 100644
index 00000000000..e35ea748c0e
--- /dev/null
+++ b/container-core/src/main/java/com/yahoo/container/handler/LogReader.java
@@ -0,0 +1,44 @@
+package com.yahoo.container.handler;
+
+import com.fasterxml.jackson.core.JsonFactory;
+import com.fasterxml.jackson.core.JsonGenerator;
+import org.apache.commons.codec.binary.Base64;
+import org.json.JSONException;
+import org.json.JSONObject;
+
+import javax.xml.bind.DatatypeConverter;
+import java.io.ByteArrayOutputStream;
+import java.io.File;
+import java.io.IOException;
+import java.io.OutputStream;
+import java.io.OutputStreamWriter;
+import java.nio.file.Files;
+
+public class LogReader {
+
+    protected static void writeToOutputStream(String logDirectory, OutputStream outputStream) throws IOException {
+        OutputStreamWriter outputStreamWriter = new OutputStreamWriter(outputStream);
+        JSONObject json = new JSONObject();
+        File root = new File(logDirectory);
+        try {
+            traverse_folder(root, json);
+        } catch (JSONException e) {
+            outputStreamWriter.write(""Failed to create log JSON"");
+        }
+        outputStreamWriter.write(json.toString());
+        outputStreamWriter.close();
+    }
+
+    private static void traverse_folder(File root, JSONObject json) throws IOException, JSONException {
+        for(File child : root.listFiles()) {
+            JSONObject childJson = new JSONObject();
+            if(child.isFile()) {
+                json.put(child.getName(), DatatypeConverter.printBase64Binary(Files.readAllBytes(child.toPath())));
+            }
+            else {
+                json.put(child.getName(), childJson);
+                traverse_folder(child, childJson);
+            }
+        }
+    }
+}
diff --git a/container-core/src/test/java/com/yahoo/container/handler/LogReaderTest.java b/container-core/src/test/java/com/yahoo/container/handler/LogReaderTest.java
new file mode 100644
index 00000000000..ff6ea74a411
--- /dev/null
+++ b/container-core/src/test/java/com/yahoo/container/handler/LogReaderTest.java
@@ -0,0 +1,36 @@
+package com.yahoo.container.handler;
+
+import org.junit.Before;
+import org.junit.Test;
+
+import java.io.ByteArrayOutputStream;
+
+import static org.junit.Assert.*;
+
+public class LogReaderTest {
+
+    ByteArrayOutputStream outputStream;
+
+    @Before
+    public void setup() {
+        outputStream = new ByteArrayOutputStream();
+    }
+
+    @Test
+    public void testThatFilesAreWrittenCorrectlyToOutputStream() throws Exception{
+        String logDirectory = ""src/test/resources/logfolder/"";
+        LogReader.writeToOutputStream(logDirectory, outputStream);
+        String expected = ""{\""subfolder\"":{\""log2.log\"":\""VGhpcyBpcyBhbm90aGVyIGxvZyBmaWxl\""},\""log1.log\"":\""VGhpcyBpcyBvbmUgbG9nIGZpbGU=\""}"";
+        String actual = new String(outputStream.toByteArray());
+        assertEquals(expected, actual);
+    }
+
+    @Test
+    public void testNothingISWrittenToOutputStreamWithEmptyLogFolder() throws Exception {
+        String logDirectory = ""src/test/resources/emptylogfolder/"";
+        LogReader.writeToOutputStream(logDirectory, outputStream);
+        String expected = ""{}"";
+        String actual = new String(outputStream.toByteArray());
+        assertEquals(expected, actual);
+    }
+}
\ No newline at end of file
diff --git a/container-core/src/test/resources/logfolder/log1.log b/container-core/src/test/resources/logfolder/log1.log
new file mode 100644
index 00000000000..bb85d5a4950
--- /dev/null
+++ b/container-core/src/test/resources/logfolder/log1.log
@@ -0,0 +1 @@
+This is one log file
\ No newline at end of file
diff --git a/container-core/src/test/resources/logfolder/subfolder/log2.log b/container-core/src/test/resources/logfolder/subfolder/log2.log
new file mode 100644
index 00000000000..aee6eaca2e8
--- /dev/null
+++ b/container-core/src/test/resources/logfolder/subfolder/log2.log
@@ -0,0 +1 @@
+This is another log file
\ No newline at end of file
diff --git a/controller-api/src/main/java/com/yahoo/vespa/hosted/controller/api/integration/configserver/ConfigServer.java b/controller-api/src/main/java/com/yahoo/vespa/hosted/controller/api/integration/configserver/ConfigServer.java
index 54e057e4187..eb10c78f891 100644
--- a/controller-api/src/main/java/com/yahoo/vespa/hosted/controller/api/integration/configserver/ConfigServer.java
+++ b/controller-api/src/main/java/com/yahoo/vespa/hosted/controller/api/integration/configserver/ConfigServer.java
@@ -1,6 +1,7 @@
 // Copyright 2018 Yahoo Holdings. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root.
 package com.yahoo.vespa.hosted.controller.api.integration.configserver;
 
+import com.yahoo.container.jdisc.HttpResponse;
 import com.yahoo.vespa.hosted.controller.api.application.v4.model.DeployOptions;
 import com.yahoo.vespa.hosted.controller.api.application.v4.model.EndpointStatus;
 import com.yahoo.vespa.hosted.controller.api.identifiers.DeploymentId;
@@ -41,6 +42,7 @@ public interface ConfigServer {
 
     Map<?,?> getServiceApiResponse(String tenantName, String applicationName, String instanceName, String environment, String region, String serviceName, String restPath);
 
+    HttpResponse getLogs(DeploymentId deployment);
     /**
      * Set new status on en endpoint in one zone.
      *
diff --git a/controller-server/src/main/java/com/yahoo/vespa/hosted/controller/restapi/application/ApplicationApiHandler.java b/controller-server/src/main/java/com/yahoo/vespa/hosted/controller/restapi/application/ApplicationApiHandler.java
index 22809ac18bf..556d019d440 100644
--- a/controller-server/src/main/java/com/yahoo/vespa/hosted/controller/restapi/application/ApplicationApiHandler.java
+++ b/controller-server/src/main/java/com/yahoo/vespa/hosted/controller/restapi/application/ApplicationApiHandler.java
@@ -169,6 +169,7 @@ public class ApplicationApiHandler extends LoggingRequestHandler {
         if (path.matches(""/application/v4/tenant/{tenant}"")) return tenant(path.get(""tenant""), request);
         if (path.matches(""/application/v4/tenant/{tenant}/application"")) return applications(path.get(""tenant""), request);
         if (path.matches(""/application/v4/tenant/{tenant}/application/{application}"")) return application(path.get(""tenant""), path.get(""application""), request);
+        if (path.matches(""/application/v4/tenant/{tenant}/application/{application}/environment/{environment}/region/{region}/instance/{instance}/logs"")) return logs(path.get(""tenant""), path.get(""application""), path.get(""instance""), path.get(""environment""), path.get(""region""));
         if (path.matches(""/application/v4/tenant/{tenant}/application/{application}/instance/{instance}/job"")) return JobControllerApiHandlerHelper.jobTypeResponse(controller, appIdFromPath(path), request.getUri());
         if (path.matches(""/application/v4/tenant/{tenant}/application/{application}/instance/{instance}/job/{jobtype}"")) return JobControllerApiHandlerHelper.runResponse(controller.jobController().runs(appIdFromPath(path), jobTypeFromPath(path)), request.getUri());
         if (path.matches(""/application/v4/tenant/{tenant}/application/{application}/instance/{instance}/job/{jobtype}/run/{number}"")) return JobControllerApiHandlerHelper.runDetailsResponse(controller.jobController(), runIdFromPath(path), request.getProperty(""after""));
@@ -346,6 +347,14 @@ public class ApplicationApiHandler extends LoggingRequestHandler {
         return new SlimeJsonResponse(slime);
     }
 
+    private HttpResponse logs(String tenantName, String applicationName, String instanceName, String environment, String region) {
+        ApplicationId application = ApplicationId.from(tenantName, applicationName, instanceName);
+        ZoneId zone = ZoneId.from(environment, region);
+        DeploymentId deployment = new DeploymentId(application, zone);
+        return controller.configServer().getLogs(deployment);
+    }
+
+
     private void toSlime(Cursor object, Application application, HttpRequest request) {
         object.setString(""application"", application.id().application().value());
         object.setString(""instance"", application.id().instance().value());
diff --git a/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/integration/ConfigServerMock.java b/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/integration/ConfigServerMock.java
index 458ba49f3e3..bd65465633e 100644
--- a/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/integration/ConfigServerMock.java
+++ b/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/integration/ConfigServerMock.java
@@ -7,6 +7,7 @@ import com.yahoo.component.Version;
 import com.yahoo.config.provision.ApplicationId;
 import com.yahoo.config.provision.HostName;
 import com.yahoo.config.provision.NodeType;
+import com.yahoo.container.jdisc.HttpResponse;
 import com.yahoo.vespa.hosted.controller.api.application.v4.model.DeployOptions;
 import com.yahoo.vespa.hosted.controller.api.application.v4.model.EndpointStatus;
 import com.yahoo.vespa.hosted.controller.api.application.v4.model.configserverbindings.ConfigChangeActions;
@@ -25,7 +26,11 @@ import com.yahoo.vespa.hosted.controller.application.SystemApplication;
 import com.yahoo.vespa.serviceview.bindings.ApplicationView;
 import com.yahoo.vespa.serviceview.bindings.ClusterView;
 import com.yahoo.vespa.serviceview.bindings.ServiceView;
+import org.json.JSONException;
+import org.json.JSONObject;
 
+import java.io.IOException;
+import java.io.OutputStream;
 import java.net.URI;
 import java.util.ArrayList;
 import java.util.Arrays;
@@ -292,6 +297,17 @@ public class ConfigServerMock extends AbstractComponent implements ConfigServer
         return endpoints.getOrDefault(endpoint, result);
     }
 
+    @Override
+    public HttpResponse getLogs(DeploymentId deployment) {
+        return new HttpResponse(200) {
+            @Override
+            public void render(OutputStream outputStream) throws IOException {
+                outputStream.write(""{\""subfolder\"":{\""log2.log\"":\""VGhpcyBpcyBhbm90aGVyIGxvZyBmaWxl\""},\""log1.log\"":\""VGhpcyBpcyBvbmUgbG9nIGZpbGU=\""}"".getBytes());
+            }
+        };
+
+    }
+
     public static class Application {
 
         private final ApplicationId id;
diff --git a/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/restapi/application/ApplicationApiTest.java b/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/restapi/application/ApplicationApiTest.java
index 13092451d4b..03877cca30e 100644
--- a/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/restapi/application/ApplicationApiTest.java
+++ b/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/restapi/application/ApplicationApiTest.java
@@ -330,6 +330,9 @@ public class ApplicationApiTest extends ControllerContainerTest {
                                       .recursive(""true""),
                               new File(""application1-recursive.json""));
 
+        // GET logs
+        tester.assertResponse(request(""/application/v4/tenant/tenant2/application//application1/environment/prod/region/corp-us-east-1/instance/default/logs"", GET).userIdentity(USER_ID), new File(""logs.json""));
+
         // DELETE (cancel) ongoing change
         tester.assertResponse(request(""/application/v4/tenant/tenant1/application/application1/deploying"", DELETE)
                                       .userIdentity(HOSTED_VESPA_OPERATOR),
diff --git a/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/restapi/application/responses/logs.json b/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/restapi/application/responses/logs.json
new file mode 100644
index 00000000000..398a62758ee
--- /dev/null
+++ b/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/restapi/application/responses/logs.json
@@ -0,0 +1,5 @@
+{
+  ""subfolder"": {
+    ""log2.log"":""VGhpcyBpcyBhbm90aGVyIGxvZyBmaWxl""},
+  ""log1.log"":""VGhpcyBpcyBvbmUgbG9nIGZpbGU=""
+}
\ No newline at end of file",Add functionality for retrieving logs,"""Added support for retrieving logs from the log server""","Added support for retrieving logs from a Vespa application.

This commit introduces a new `LogRetriever` class that retrieves logs from a Vespa application by making an HTTP request to the log server. The `ApplicationRepository` class has been updated to include a new method `getLogs` that uses `LogRetriever` to retrieve logs for a given application. The `ApplicationHandler` class has been updated to handle log requests and the `ConfigServer` interface has been updated to include a new method `getLogs` that returns the logs for a given deployment. 

Additionally, a new `LogHandler` class has been added to the container-core module to handle log requests and a new `LogReader` class has been added to read log files and convert them into a JSON format. 

The commit also includes test cases for the new log retrieval functionality.","""Add log retrieval functionality to Vespa Config Server""

This commit adds the following changes:

1. A new `LogRetriever` class is added to the `com.yahoo.vespa.config.server.http` package. This class provides a static method `getLogs` that takes a log server hostname and returns an `HttpResponse` object containing the logs.
2. A new `getLogs` method is added to the `ApplicationRepository` class. This method takes an `ApplicationId` object and returns an `HttpResponse` object containing the logs for that application. It uses the `LogRetriever` class to retrieve the logs.
3. A new `getLogServerHostname` method is added to the `ApplicationRepository` class. This method takes an `ApplicationId` object and returns the log server hostname for that application.
4. The `ApplicationHandler` class is modified to handle log requests. If the request URL matches the pattern `http://*/application/v2/tenant/*/application/*/logs`, the `getLogs` method of the `ApplicationRepository` class is called to retrieve the logs.
5. The `services.xml` file is modified to add bindings for log requests. The bindings are added for both HTTP and HTTPS schemes.
6. A new `LogRetrieverTest` class is added to the test directory. This class contains two tests:
	* `testThatLogHandlerPropagatesResponseBody`: This test verifies that the `LogRetriever` class correctly propagates the response body from the log server. It uses a mock log server to return a test response, and then checks that the `LogRetriever` returns the same response.
	* `testThatNotFoundLogServerReturns404`: This test verifies that the `LogRetriever` returns a 404 status code if the log server cannot be found. It uses a mock log server that returns a 200 status code, but with a different hostname than the one used by the `LogRetriever`. The test checks that the `LogRetriever` returns a 404 status code in this case.

Overall, this commit adds functionality to the Vespa Config Server to retrieve logs for a given application. It uses a new `LogRetriever` class to retrieve the logs from a log server, and adds a new endpoint to the `ApplicationHandler` class to handle log requests. It also includes tests to verify the correct behavior of the `LogRetriever` class.","```
Add log retrieval functionality to ApplicationHandler, including new LogRetriever class and endpoints to fetch logs from deployment environments.
```",Model 3
"diff --git a/jaxp/.hgtags b/jaxp/.hgtags
index b8bde0dc729..7e7e54dfed2 100644
--- a/jaxp/.hgtags
+++ b/jaxp/.hgtags
@@ -187,3 +187,4 @@ af9e8b0f1900b631a8a0fcccff9f1514fe58c808 jdk8-b59
 192d8a244bc36427757866e9fb3a08938c0e674c jdk8-b63
 27ab79568c34abf80958d5fa8c04fd1740d243da jdk8-b64
 5cf3c69a93d6d088a1cdfa28031d4f0f9438c0de jdk8-b65
+e6af1ad464e3d9b1154b9f9ed9a5373b97d129fc jdk8-b66",Added tag jdk8 - b66 for changeset bc221bce9150,"""Added tag for jdk8-b66""","""Update .hgtags to include JDK 8 b66""","Based on the diff you provided, it seems like you are looking for the commit message associated with the commit hash `e6af1ad464e3d9b1154b9f9ed9a5373b97d129fc` for the tag `jdk8-b66`.

However, the diff you provided does not contain any commit messages. It only shows the change in the `.hgtags` file in the JAXP repository, where a new entry for the commit hash `e6af1ad464e3d9b1154b9f9ed9a5373b97d129fc` with the tag `jdk8-b66` was added.

To get the commit message for this commit, you would need to run the following command in the JAXP repository:
```css
git show e6af1ad464e3d9b1154b9f9ed9a5373b97d129fc
```
This command will show you the commit details, including the commit message, author, date, and the changes made in that commit.",Added tag for jdk8-b66 in .hgtags file.,Model 1
"diff --git a/src/site/xdoc/manual/configuration.xml.vm b/src/site/xdoc/manual/configuration.xml.vm
index ca0bceb6b1..d1f485c4e4 100644
--- a/src/site/xdoc/manual/configuration.xml.vm
+++ b/src/site/xdoc/manual/configuration.xml.vm
@@ -424,6 +424,7 @@ public class Bar {
                 <td>Enables diagnostic information while loading plugins.</td>
               </tr>
             </table>
+          <a name=""XML""/>
           <p>
             Log4j can be configured using two XML flavors; concise and strict. The",Add XML anchor to fix documentation link .,"""Added anchor for XML configuration section in manual""","""Added documentation for Log4j XML configuration options""",Added an XML anchor tag in the configuration.xml.vm file.,Added an anchor for XML configuration section in the Log4j configuration documentation.,Model 1
"diff --git a/src/WorldEdit.java b/src/WorldEdit.java
index 0fabd0353..63fb109d8 100644
--- a/src/WorldEdit.java
+++ b/src/WorldEdit.java
@@ -94,6 +94,8 @@ public WorldEdit() {
         commands.put(""/editexpand"", ""<Dir> [Num] - Expands the selection"");
         commands.put(""/editcontract"", ""<Dir> [Num] - Contracts the selection"");
         commands.put(""/unstuck"", ""Go up to the first free spot"");
+        commands.put(""/ascend"", ""Go up one level"");
+        commands.put(""/descend"", ""Go dowm one level"");
     }
 
     /**
@@ -202,6 +204,26 @@ public boolean performCommand(WorldEditPlayer player,
             player.findFreePosition();
             return true;
 
+        // Ascend a level
+        } else if(split[0].equalsIgnoreCase(""/ascend"")) {
+            checkArgs(split, 0, 0, split[0]);
+            if (player.ascendLevel()) {
+                player.print(""Ascended a level."");
+            } else {
+                player.printError(""No free spot above you found."");
+            }
+            return true;
+
+        // Descend a level
+        } else if(split[0].equalsIgnoreCase(""/descend"")) {
+            checkArgs(split, 0, 0, split[0]);
+            if (player.descendLevel()) {
+                player.print(""Descended a level."");
+            } else {
+                player.printError(""No free spot below you found."");
+            }
+            return true;
+
         // Set edit position #1
         } else if (split[0].equalsIgnoreCase(""/editpos1"")) {
             checkArgs(split, 0, 0, split[0]);
diff --git a/src/WorldEditPlayer.java b/src/WorldEditPlayer.java
index 45141d54b..11ffa6b81 100644
--- a/src/WorldEditPlayer.java
+++ b/src/WorldEditPlayer.java
@@ -133,7 +133,7 @@ public void printError(String msg) {
 
     /**
      * Move the player.
-     * 
+     *
      * @param pos
      * @param pitch
      * @param yaw
@@ -148,6 +148,21 @@ public void setPosition(Vector pos, float pitch, float yaw) {
         player.teleportTo(loc);
     }
 
+    /**
+     * Move the player.
+     *
+     * @param pos
+     */
+    public void setPosition(Vector pos) {
+        Location loc = new Location();
+        loc.x = pos.getX();
+        loc.y = pos.getY();
+        loc.z = pos.getZ();
+        loc.rotX = (float)getYaw();
+        loc.rotY = (float)getPitch();
+        player.teleportTo(loc);
+    }
+
     /**
      * Find a position for the player to stand that is not inside a block.
      * Blocks above the player will be iteratively tested until there is
@@ -186,6 +201,73 @@ public void findFreePosition() {
         }
     }
 
+    /**
+     * Go up one level to the next free space above.
+     *
+     * @return true if a spot was found
+     */
+    public boolean ascendLevel() {
+        int x = (int)Math.floor(player.getX());
+        int y = (int)Math.floor(player.getY());
+        int z = (int)Math.floor(player.getZ());
+
+        byte free = 0;
+        byte spots = 0;
+        boolean inFree = false;
+
+        while (y <= 129) {
+            if (etc.getServer().getBlockIdAt(x, y, z) == 0) {
+                free++;
+            } else {
+                free = 0;
+                inFree = false;
+            }
+
+            if (free == 2 && inFree == false) {
+                inFree = true;
+                spots++;
+                if (y >= 129 || spots == 2) {
+                    setPosition(new Vector(x + 0.5, y - 1, z + 0.5));
+                    return true;
+                }
+            }
+
+            y++;
+        }
+
+        return false;
+    }
+
+    /**
+     * Go up one level to the next free space above.
+     *
+     * @return true if a spot was found
+     */
+    public boolean descendLevel() {
+        int x = (int)Math.floor(player.getX());
+        int y = (int)Math.floor(player.getY()) - 1;
+        int z =",Added / ascend and / descend .,"""Added /ascend and /descend commands to move player up or down one level to the next free space""","Added commands ""/ascend"" and ""/descend"" to move up and down one level, and implemented corresponding methods in WorldEditPlayer.","""Added /ascend and /descend commands for WorldEdit""

This commit adds two new commands to the WorldEdit plugin: ""/ascend"" and ""/descend"". These commands allow the player to move up or down one level, respectively, by finding the next free spot above or below them. The ""/ascend"" command moves the player up to the first free spot above them, while the ""/descend"" command moves the player down to the first free spot below them. If no free spot is found, the player is notified with an error message. The code for these commands is added to the WorldEdit.java file, and a new method ""setPosition(Vector pos)"" is added to the WorldEditPlayer.java file to allow the player's position to be changed using a Vector object.",Add ascend and descend level commands for player movement in WorldEdit.,Model 2
"diff --git a/server/src/main/java/org/elasticsearch/search/DefaultSearchContext.java b/server/src/main/java/org/elasticsearch/search/DefaultSearchContext.java
index ebb964bb648..6184b18048b 100644
--- a/server/src/main/java/org/elasticsearch/search/DefaultSearchContext.java
+++ b/server/src/main/java/org/elasticsearch/search/DefaultSearchContext.java
@@ -28,11 +28,9 @@ import org.apache.lucene.search.MatchNoDocsQuery;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.action.search.SearchShardTask;
 import org.elasticsearch.action.search.SearchType;
-import org.elasticsearch.cluster.service.ClusterService;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.IndexSettings;
 import org.elasticsearch.index.cache.bitset.BitsetFilterCache;
@@ -83,9 +81,7 @@ final class DefaultSearchContext extends SearchContext {
     private final SearchShardTarget shardTarget;
     private final LongSupplier relativeTimeSupplier;
     private SearchType searchType;
-    private final BigArrays bigArrays;
     private final IndexShard indexShard;
-    private final ClusterService clusterService;
     private final IndexService indexService;
     private final ContextIndexSearcher searcher;
     private final DfsSearchResult dfsResult;
@@ -146,8 +142,6 @@ final class DefaultSearchContext extends SearchContext {
     DefaultSearchContext(ReaderContext readerContext,
                          ShardSearchRequest request,
                          SearchShardTarget shardTarget,
-                         ClusterService clusterService,
-                         BigArrays bigArrays,
                          LongSupplier relativeTimeSupplier,
                          TimeValue timeout,
                          FetchPhase fetchPhase,
@@ -157,14 +151,11 @@ final class DefaultSearchContext extends SearchContext {
         this.fetchPhase = fetchPhase;
         this.searchType = request.searchType();
         this.shardTarget = shardTarget;
-        // SearchContexts use a BigArrays that can circuit break
-        this.bigArrays = bigArrays.withCircuitBreaking();
         this.dfsResult = new DfsSearchResult(readerContext.id(), shardTarget, request);
         this.queryResult = new QuerySearchResult(readerContext.id(), shardTarget, request);
         this.fetchResult = new FetchSearchResult(readerContext.id(), shardTarget);
         this.indexService = readerContext.indexService();
         this.indexShard = readerContext.indexShard();
-        this.clusterService = clusterService;
 
         Engine.Searcher engineSearcher = readerContext.acquireSearcher(""search"");
         this.searcher = new ContextIndexSearcher(engineSearcher.getIndexReader(), engineSearcher.getSimilarity(),
@@ -457,11 +448,6 @@ final class DefaultSearchContext extends SearchContext {
         return this.indexShard;
     }
 
-    @Override
-    public BigArrays bigArrays() {
-        return bigArrays;
-    }
-
     @Override
     public BitsetFilterCache bitsetFilterCache() {
         return indexService.cache().bitsetFilterCache();
diff --git a/server/src/main/java/org/elasticsearch/search/SearchService.java b/server/src/main/java/org/elasticsearch/search/SearchService.java
index 57f0da88afd..8c416d9b091 100644
--- a/server/src/main/java/org/elasticsearch/search/SearchService.java
+++ b/server/src/main/java/org/elasticsearch/search/SearchService.java
@@ -768,8 +768,8 @@ public class SearchService extends AbstractLifecycleComponent implements IndexEv
         try {
             SearchShardTarget shardTarget = new SearchShardTarget(clusterService.localNode().getId(),
                 reader.indexShard().shardId(), request.getClusterAlias(), OriginalIndices.NONE);
-            searchContext = new DefaultSearchContext(reader, request, shardTarget, clusterService,
-                bigArrays, threadPool::relativeTimeInMillis, timeout, fetchPhase, lowLevelCancellation);
+            searchContext = new DefaultSearchContext(reader, request, shardTarget,
+                threadPool::relativeTimeInMillis, timeout, fetchPhase, lowLevelCancellation);
             // we clone the query shard context here just for rewriting otherwise we
             // might end up with incorrect state since we are using now() or script services
             // during rewrite and normalized / evaluate templates etc.
diff --git a/server/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregationBuilder.java b/server/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregationBuilder.java
index fe516114332..df13bb1d19c 100644
--- a/server/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregationBuilder.java
+++ b/server/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregationBuilder.java
@@ -25,7 +25,6 @@ import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;
 import org.elasticsearch.common.xcontent.ObjectParser;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.query.QueryRewriteContext;
 import org.elasticsearch.search.aggregations.AggregationBuilder;
 import org.elasticsearch.search.aggregations.Aggregator.SubAggCollectionMode;
 import org.elasticsearch.search.aggregations.AggregatorFactories;
@@ -401,11 +400,6 @@ public class TermsAggregationBuilder extends ValuesSourceAggregationBuilder<Term
         return NAME;
     }
 
-    @Override
-    protected AggregationBuilder doRewrite(QueryRewriteContext queryShardContext) throws IOException {
-        return super.doRewrite(queryShardContext);
-    }
-
     @Override
     protected ValuesSourceRegistry.RegistryKey<?> getRegistryKey() {
         return REGISTRY_KEY;
diff --git a/server/src/main/java/org/elasticsearch/search/aggregations/support/AggregationContext.java b/server/src/main/java/org/elasticsearch/search/aggregations/support/AggregationContext.java
index b5008f1e4ad..cc664811315 100644
--- a/server/src/main/java/org/elasticsearch/search/aggregations/support/AggregationContext.java
+++ b/server/src/main/java/org/elasticsearch/search/aggregations/support/AggregationContext.java
@@ -230,6 +230,12 @@ public abstract class AggregationContext {
      */
     public abstract Analyzer getIndexAnalyzer(Function<String, NamedAnalyzer> unindexedFieldAnalyzer);
 
+    /**
+     * Is this request cacheable? Requests that have
+     * non-deterministic queries or scripts aren't cachable.
+     */
+    public abstract boolean isCacheable();
+
     /**
      * Implementation of {@linkplain AggregationContext} for production usage
      * that wraps our ubiquitous {@link QueryShardContext} and anything else
@@ -239,6 +245,7 @@ public abstract class AggregationContext {
      */
     public static class ProductionAggregationContext extends AggregationContext {
         private final QueryShardContext context;
+        private final BigArrays bigArrays;
         private final Query topLevelQuery;
         private final AggregationProfiler profiler;
         private final MultiBucketConsumer multiBucketConsumer;
@@ -277,6 +284,7 @@ public abstract class AggregationContext {
             Supplier<Boolean> isCancelled
         ) {
             this.context = context;
+            this.bigArrays = context.bigArrays().withCircuitBreaking();  // We can break in searches.
             this.topLevelQuery = topLevelQuery;
             this.profiler = profiler;
             this.multiBucketConsumer = multiBucketConsumer;
@@ -343,7 +351,7 @@ public abstract class AggregationContext {
 
         @Override
         public BigArrays bigArrays() {
-            return context.bigArrays();
+            return bigArrays;
         }
 
         @Override
@@ -425,5 +433,10 @@ public abstract class AggregationContext {
         public Analyzer getIndexAnalyzer(Function<String, NamedAnalyzer> unindexedFieldAnalyzer) {
             return context.getIndexAnalyzer(unindexedFieldAnalyzer);
         }
+
+        @Override
+        public boolean isCacheable() {
+            return context.isCacheable();
+        }
     }
 }
diff --git a/server/src/main/java/org/elasticsearch/search/internal/FilteredSearchContext.java b/server/src/main/java/org/elasticsearch/search/internal/FilteredSearchContext.java
index f3c6bcebc92..b4ae043bdb2 100644
--- a/server/src/main/java/org/elasticsearch/search/internal/FilteredSearchContext.java
+++ b/server/src/main/java/org/elasticsearch/search/internal/FilteredSearchContext.java
@@ -25,7 +25,6 @@ import org.apache.lucene.search.Query;
 import org.elasticsearch.action.search.SearchShardTask;
 import org.elasticsearch.action.search.SearchType;
 import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.cache.bitset.BitsetFilterCache;
 import org.elasticsearch.index.query.ParsedQuery;
 import org.elasticsearch.index.query.QueryShardContext;
@@ -200,11 +199,6 @@ public abstract class FilteredSearchContext extends SearchContext {
         return in.indexShard();
     }
 
-    @Override
-    public BigArrays bigArrays() {
-        return in.bigArrays();
-    }
-
     @Override
     public BitsetFilterCache bitsetFilterCache() {
         return in.bitsetFilterCache();
diff --git a/server/src/main/java/org/elasticsearch/search/internal/SearchContext.java b/server/src/main/java/org/elasticsearch/search/internal/SearchContext.java
index 5a299ddfc22..59e9aabb648 100644
--- a/server/src/main/java/org/elasticsearch/search/internal/SearchContext.java
+++ b/server/src/main/java/org/elasticsearch/search/internal/SearchContext.java
@@ -28,7 +28,6 @@ import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.lease.Releasable;
 import org.elasticsearch.common.lease.Releasables;
 import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.cache.bitset.BitsetFilterCache;
 import org.elasticsearch.index.query.ParsedQuery;
 import org.elasticsearch.index.query.QueryShardContext;
@@ -210,8 +209,6 @@ public abstract class SearchContext implements Releasable {
 
     public abstract IndexShard indexShard();
 
-    public abstract BigArrays bigArrays();  // TODO this is only used in aggs land and should be contained
-
     public abstract BitsetFilterCache bitsetFilterCache();
 
     public abstract TimeValue timeout();
diff --git a/server/src/test/java/org/elasticsearch/index/SearchSlowLogTests.java b/server/src/test/java/org/elasticsearch/index/SearchSlowLogTests.java
index f587f867dc5..1378161bf26 100644
--- a/server/src/test/java/org/elasticsearch/index/SearchSlowLogTests.java
+++ b/server/src/test/java/org/elasticsearch/index/SearchSlowLogTests.java
@@ -32,7 +32,6 @@ import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.common.logging.MockAppender;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.search.builder.SearchSourceBuilder;
@@ -82,10 +81,9 @@ public class SearchSlowLogTests extends ESSingleNodeTestCase {
     }
 
     protected SearchContext createSearchContext(IndexService indexService, String... groupStats) {
-        BigArrays bigArrays = indexService.getBigArrays();
         final ShardSearchRequest request =
             new ShardSearchRequest(new ShardId(indexService.index(), 0), 0L, null);
-        return new TestSearchContext(bigArrays, indexService) {
+        return new TestSearchContext(indexService) {
             @Override
             public List<String> groupStats() {
                 return Arrays.asList(groupStats);
diff --git a/server/src/test/java/org/elasticsearch/index/shard/SearchOperationListenerTests.java b/server/src/test/java/org/elasticsearch/index/shard/SearchOperationListenerTests.java
index 38292f61cca..2d3c1c7b36c 100644
--- a/server/src/test/java/org/elasticsearch/index/shard/SearchOperationListenerTests.java
+++ b/server/src/test/java/org/elasticsearch/index/shard/SearchOperationListenerTests.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.index.shard;
 
+import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.search.internal.ReaderContext;
 import org.elasticsearch.search.internal.SearchContext;
 import org.elasticsearch.test.ESTestCase;
@@ -139,7 +140,7 @@ public class SearchOperationListenerTests extends ESTestCase {
         Collections.shuffle(indexingOperationListeners, random());
         SearchOperationListener.CompositeListener compositeListener =
             new SearchOperationListener.CompositeListener(indexingOperationListeners, logger);
-        SearchContext ctx = new TestSearchContext(null);
+        SearchContext ctx = new TestSearchContext((QueryShardContext) null);
         compositeListener.onQueryPhase(ctx, timeInNanos.get());
         assertEquals(0, preFetch.get());
         assertEquals(0, preQuery.get());
diff --git a/server/src/test/java/org/elasticsearch/search/DefaultSearchContextTests.java b/server/src/test/java/org/elasticsearch/search/DefaultSearchContextTests.java
index 2f406a50bab..e4384bd344a 100644
--- a/server/src/test/java/org/elasticsearch/search/DefaultSearchContextTests.java
+++ b/server/src/test/java/org/elasticsearch/search/DefaultSearchContextTests.java
@@ -34,9 +34,6 @@ import org.elasticsearch.cluster.metadata.IndexMetadata;
 import org.elasticsearch.common.UUIDs;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.common.util.BigArrays;
-import org.elasticsearch.common.util.MockBigArrays;
-import org.elasticsearch.common.util.MockPageCacheRecycler;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.IndexSettings;
 import org.elasticsearch.index.cache.IndexCache;
@@ -49,7 +46,6 @@ import org.elasticsearch.index.query.ParsedQuery;
 import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;
 import org.elasticsearch.search.internal.AliasFilter;
 import org.elasticsearch.search.internal.LegacyReaderContext;
 import org.elasticsearch.search.internal.ReaderContext;
@@ -122,8 +118,6 @@ public class DefaultSearchContextTests extends ESTestCase {
         when(indexService.getIndexSettings()).thenReturn(indexSettings);
         when(mapperService.getIndexSettings()).thenReturn(indexSettings);
 
-        BigArrays bigArrays = new MockBigArrays(new MockPageCacheRecycler(Settings.EMPTY), new NoneCircuitBreakerService());
-
         try (Directory dir = newDirectory();
              RandomIndexWriter w = new RandomIndexWriter(random(), dir)) {
 
@@ -150,7 +144,7 @@ public class DefaultSearchContextTests extends ESTestCase {
             ReaderContext readerWithoutScroll = new ReaderContext(
                 newContextId(), indexService, indexShard, searcherSupplier.get(), randomNonNegativeLong(), false);
             DefaultSearchContext contextWithoutScroll = new DefaultSearchContext(readerWithoutScroll, shardSearchRequest, target, null,
-                bigArrays, null, timeout, null, false);
+                timeout, null, false);
             contextWithoutScroll.from(300);
             contextWithoutScroll.close();
 
@@ -166,7 +160,7 @@ public class DefaultSearchContextTests extends ESTestCase {
             ReaderContext readerContext = new LegacyReaderContext(
                 newContextId(), indexService, indexShard, searcherSupplier.get(), shardSearchRequest, randomNonNegativeLong());
             DefaultSearchContext context1 = new DefaultSearchContext(readerContext, shardSearchRequest, target, null,
-                bigArrays, null, timeout, null, false);
+                timeout, null, false);
             context1.from(300);
             exception = expectThrows(IllegalArgumentException.class, () -> context1.preProcess(false));
             assertThat(exception.getMessage(), equalTo(""Batch size is too large, size must be less than or equal to: [""
@@ -200,7 +194,7 @@ public class DefaultSearchContextTests extends ESTestCase {
                 newContextId(), indexService, indexShard, searcherSupplier.get(), randomNonNegativeLong(), false);
             // rescore is null but sliceBuilder is not null
             DefaultSearchContext context2 = new DefaultSearchContext(readerContext, shardSearchRequest, target,
-                null, bigArrays, null, timeout, null, false);
+                null, timeout, null, false);
 
             SliceBuilder sliceBuilder = mock(SliceBuilder.class);
             int numSlices = maxSlicesPerScroll + randomIntBetween(1, 100);
@@ -217,7 +211,7 @@ public class DefaultSearchContextTests extends ESTestCase {
             when(shardSearchRequest.indexBoost()).thenReturn(AbstractQueryBuilder.DEFAULT_BOOST);
 
             DefaultSearchContext context3 = new DefaultSearchContext(readerContext, shardSearchRequest, target, null,
-                bigArrays, null, timeout, null, false);
+                timeout, null, false);
             ParsedQuery parsedQuery = ParsedQuery.parsedMatchAllQuery();
             context3.sliceBuilder(null).parsedQuery(parsedQuery).preProcess(false);
             assertEquals(context3.query(), context3.buildFilteredQuery(parsedQuery.query()));
@@ -229,7 +223,7 @@ public class DefaultSearchContextTests extends ESTestCase {
             readerContext = new ReaderContext(newContextId(), indexService, indexShard,
                 searcherSupplier.get(), randomNonNegativeLong(), false);
             DefaultSearchContext context4 =
-                new DefaultSearchContext(readerContext, shardSearchRequest, target, null, bigArrays, null, timeout, null, false);
+                new DefaultSearchContext(readerContext, shardSearchRequest, target, null, timeout, null, false);
             context4.sliceBuilder(new SliceBuilder(1,2)).parsedQuery(parsedQuery).preProcess(false);
             Query query1 = context4.query();
             context4.sliceBuilder(new SliceBuilder(0,2)).parsedQuery(parsedQuery).preProcess(false);
@@ -256,8 +250,6 @@ public class DefaultSearchContextTests extends ESTestCase {
 
         IndexService indexService = mock(IndexService.class);
 
-        BigArrays bigArrays = new MockBigArrays(new MockPageCacheRecycler(Settings.EMPTY), new NoneCircuitBreakerService());
-
         try (Directory dir = newDirectory();
              RandomIndexWriter w = new RandomIndexWriter(random(), dir)) {
 
@@ -282,7 +274,7 @@ public class DefaultSearchContextTests extends ESTestCase {
             ReaderContext readerContext = new ReaderContext(
                 newContextId(), indexService, indexShard, searcherSupplier, randomNonNegativeLong(), false);
             DefaultSearchContext context = new DefaultSearchContext(readerContext, shardSearchRequest, target, null,
-                bigArrays, null, timeout, null, false);
+                timeout, null, false);
 
             assertThat(context.searcher().hasCancellations(), is(false));
             context.searcher().addQueryCancellation(() -> {});
diff --git a/server/src/test/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregatorTests.java b/server/src/test/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregatorTests.java
index 0cea28e5f4d..f6e01830700 100644
--- a/server/src/test/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregatorTests.java
+++ b/server/src/test/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregatorTests.java
@@ -32,14 +32,10 @@ import org.elasticsearch.search.aggregations.AggregatorFactories;
 import org.elasticsearch.search.aggregations.AggregatorTestCase;
 import org.elasticsearch.search.aggregations.InternalAggregation;
 import org.elasticsearch.search.aggregations.LeafBucketCollector;
-import org.elasticsearch.search.aggregations.MultiBucketConsumerService.MultiBucketConsumer;
-import org.elasticsearch.search.aggregations.support.AggregationContext.ProductionAggregationContext;
-import org.elasticsearch.search.internal.SearchContext;
+import org.elasticsearch.search.aggregations.support.AggregationContext;
 
 import java.io.IOException;
 
-import static org.mockito.Mockito.mock;
-
 public class BucketsAggregatorTests extends AggregatorTestCase{
 
     public BucketsAggregator buildMergeAggregator() throws IOException{
@@ -53,12 +49,11 @@ public class BucketsAggregatorTests extends AggregatorTestCase{
             try (IndexReader indexReader = DirectoryReader.open(directory)) {
                 IndexSearcher indexSearcher = new IndexSearcher(indexReader);
 
-                SearchContext searchContext = createSearchContext(
+                AggregationContext context = createAggregationContext(
                     indexSearcher,
                     null,
                     new NumberFieldMapper.NumberFieldType(""test"", NumberFieldMapper.NumberType.INTEGER)
                 );
-                ProductionAggregationContext context = new ProductionAggregationContext(searchContext, mock(MultiBucketConsumer.class));
 
                 return new BucketsAggregator(""test"", AggregatorFactories.EMPTY, context, null, null, null) {
                     @Override
diff --git a/server/src/test/java/org/elasticsearch/search/aggregations/bucket/adjacency/AdjacencyMatrixAggregationBuilderTests.java b/server/src/test/java/org/elasticsearch/search/aggregations/bucket/adjacency/AdjacencyMatrixAggregationBuilderTests.java
index 9af7f6cc0c7..304e19636f1 100644
--- a/server/src/test/java/org/elasticsearch/search/aggregations/bucket/adjacency/AdjacencyMatrixAggregationBuilderTests.java
+++ b/server/src/test/java/org/elasticsearch/search/aggregations/bucket/adjacency/AdjacencyMatrixAggregationBuilderTests.java
@@ -22,6 +22,7 @@ package org.elasticsearch.search.aggregations.bucket.adjacency;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.metadata.IndexMetadata;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.IndexSettings;
 import org.elasticsearch.index.query.QueryBuilder;
@@ -62,6 +63,7 @@ public class AdjacencyMatrixAggregationBuilderTests extends ESTestCase {
         IndexSettings indexSettings = new IndexSettings(indexMetadata, Settings.EMPTY);
         when(indexShard.indexSettings()).thenReturn(indexSettings);
         when(queryShardContext.getIndexSettings()).thenReturn(indexSettings);
+        when(queryShardContext.bigArrays()).thenReturn(BigArrays.NON_RECYCLING_INSTANCE);
         when(indexShard.shardId()).thenReturn(new ShardId(new Index(""test"", ""test""), 1));
         SearchContext context = new TestSearchContext(queryShardContext, indexShard);
 
diff --git a/server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java b/server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java
index 740b3271fe9..0dc026ecd42 100644
--- a/server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java
+++ b/server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java
@@ -38,8 +38,8 @@ import org.elasticsearch.search.aggregations.Aggregator;
 import org.elasticsearch.search.aggregations.BucketOrder;
 import org.elasticsearch.search.aggregations.bucket.terms.StringTerms;
 import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;
+import org.elasticsearch.search.aggregations.support.AggregationContext;
 import org.elasticsearch.search.aggregations.support.AggregationInspectionHelper;
-import org.elasticsearch.search.internal.SearchContext;
 import org.hamcrest.Matcher;
 
 import java.io.IOException;
@@ -1210,7 +1210,7 @@ public class DateHistogramAggregatorTests extends DateHistogramAggregatorTestCas
                 );
             }
             try (IndexReader reader = indexWriter.getReader()) {
-                SearchContext context = createSearchContext(new IndexSearcher(reader), new MatchAllDocsQuery(), ft);
+                AggregationContext context = createAggregationContext(new IndexSearcher(reader), new MatchAllDocsQuery(), ft);
                 Aggregator agg = createAggregator(builder, context);
                 Matcher<Aggregator> matcher = instanceOf(DateHistogramAggregator.FromDateRange.class);
                 if (usesFromRange == false) {
diff --git a/server/src/test/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregatorTests.java b/server/src/test/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregatorTests.java
index f5697e0153f..c119cc1e484 100644
--- a/server/src/test/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregatorTests.java
+++ b/server/src/test/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregatorTests.java
@@ -88,11 +88,11 @@ import org.elasticsearch.search.aggregations.metrics.InternalTopHits;
 import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;
 import org.elasticsearch.search.aggregations.pipeline.BucketScriptPipelineAggregationBuilder;
 import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator.PipelineTree;
+import org.elasticsearch.search.aggregations.support.AggregationContext;
 import org.elasticsearch.search.aggregations.support.AggregationInspectionHelper;
 import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;
 import org.elasticsearch.search.aggregations.support.ValueType;
 import org.elasticsearch.search.aggregations.support.ValuesSourceType;
-import org.elasticsearch.search.internal.SearchContext;
 import org.elasticsearch.search.sort.FieldSortBuilder;
 import org.elasticsearch.search.sort.ScoreSortBuilder;
 import org.elasticsearch.test.geo.RandomGeoGenerator;
@@ -142,7 +142,8 @@ public class TermsAggregatorTests extends AggregatorTestCase {
         return new ScriptService(Settings.EMPTY, engines, ScriptModule.CORE_CONTEXTS);
     }
 
-    protected <A extends Aggregator> A createAggregator(AggregationBuilder aggregationBuilder, SearchContext context) throws IOException {
+    protected <A extends Aggregator> A createAggregator(AggregationBuilder aggregationBuilder, AggregationContext context)
+        throws IOException {
         try {
             if (randomizeAggregatorImpl) {
                 TermsAggregatorFactory.COLLECT_SEGMENT_ORDS = randomBoolean();
@@ -253,7 +254,7 @@ public class TermsAggregatorTests extends AggregatorTestCase {
                             .order(BucketOrder.key(true));
                         MappedFieldType fieldType = new KeywordFieldMapper.KeywordFieldType(""string"");
 
-                        SearchContext context = createSearchContext(indexSearcher, null, fieldType);
+                        AggregationContext context = createAggregationContext(indexSearcher, null, fieldType);
                         TermsAggregator aggregator = createAggregator(aggregationBuilder, context);
                         aggregator.preCollection();
                         indexSearcher.search(new MatchAllDocsQuery(), aggregator);
@@ -322,7 +323,7 @@ public class TermsAggregatorTests extends AggregatorTestCase {
                         .size(12)
                         .order(BucketOrder.key(true));
 
-                    SearchContext context = createSearchContext(indexSearcher, null, fieldType);
+                    AggregationContext context = createAggregationContext(indexSearcher, null, fieldType);
                     TermsAggregator aggregator = createAggregator(aggregationBuilder, context);
                     aggregator.preCollection();
                     indexSearcher.search(new MatchAllDocsQuery(), aggregator);
@@ -357,7 +358,7 @@ public class TermsAggregatorTests extends AggregatorTestCase {
                         .field(""sv_field"")
                         .order(BucketOrder.key(true));
 
-                    context = createSearchContext(indexSearcher, null, fieldType2);
+                    context = createAggregationContext(indexSearcher, null, fieldType2);
                     aggregator = createAggregator(aggregationBuilder, context);
                     aggregator.preCollection();
                     indexSearcher.search(new MatchAllDocsQuery(), aggregator);
@@ -381,7 +382,7 @@ public class TermsAggregatorTests extends AggregatorTestCase {
                         .field(""mv_field"")
                         .order(BucketOrder.key(true));
 
-                    context = createSearchContext(indexSearcher, null, fieldType);
+                    context = createAggregationContext(indexSearcher, null, fieldType);
                     aggregator = createAggregator(aggregationBuilder, context);
                     aggregator.preCollection();
                     indexSearcher.search(new MatchAllDocsQuery(), aggregator);
@@ -410,7 +411,7 @@ public class TermsAggregatorTests extends AggregatorTestCase {
                         .includeExclude(new IncludeExclude(null, ""val00.+""))
                         .field(""mv_field"")
                         .order(BucketOrder.key(true));
-                    context = createSearchContext(indexSearcher, null, fieldType);
+                    context = createAggregationContext(indexSearcher, null, fieldType);
                     aggregator = createAggregator(aggregationBuilder, context);
                     aggregator.preCollection();
                     indexSearcher.search(new MatchAllDocsQuery(), aggregator);
@@ -427,7",Remove BigArrays from SearchContext ( <issue_id> ) .,Remove BigArrays from SearchContext and related classes.,"Remove unused BigArrays instances and circuit breaking from SearchContext

This commit message accurately reflects the changes made in the code. The diff shows that several instances of `BigArrays` were removed, and the circuit breaking functionality was removed from `SearchContext`.","""Remove BigArrays from SearchContext and related changes""

This commit removes the BigArrays field from the SearchContext class and updates related classes accordingly. The changes include:

* Removing the BigArrays field from the DefaultSearchContext and FilteredSearchContext classes.
* Updating the ProductionAggregationContext class to use its own BigArrays instance instead of getting it from the SearchContext.
* Updating the SearchService class to create a new DefaultSearchContext without passing in a BigArrays instance.
* Removing the bigArrays() method from the SearchContext interface.
* Removing the BigArrays field from the TestSearchContext class in the SearchSlowLogTests test class.
* Updating the createSearchContext() method in the SearchSlowLogTests test class to create a new TestSearchContext without passing in a BigArrays instance.
* Updating the createSearchContext() method in the SearchOperationListenerTests test class to create a new TestSearchContext without passing in a BigArrays instance.

The commit also adds a new isCacheable() method to the AggregationContext interface, which is implemented in the ProductionAggregationContext class to return the value of the isCacheable() method from the QueryShardContext instance.","""Remove BigArrays dependency from DefaultSearchContext and improve AggregationContext by adding isCacheable method.""",Model 4
"diff --git a/src/com/google/javascript/jscomp/LintPassConfig.java b/src/com/google/javascript/jscomp/LintPassConfig.java
index a2939a56f..d718bcd10 100644
--- a/src/com/google/javascript/jscomp/LintPassConfig.java
+++ b/src/com/google/javascript/jscomp/LintPassConfig.java
@@ -17,7 +17,6 @@ package com.google.javascript.jscomp;
 
 import com.google.common.collect.ImmutableList;
 import com.google.javascript.jscomp.NodeTraversal.Callback;
-import com.google.javascript.jscomp.lint.CheckArguments;
 import com.google.javascript.jscomp.lint.CheckEmptyStatements;
 import com.google.javascript.jscomp.lint.CheckEnums;
 import com.google.javascript.jscomp.lint.CheckInterfaces;
@@ -79,7 +78,6 @@ class LintPassConfig extends PassConfig.PassConfigDelegate {
           return new CombinedCompilerPass(
               compiler,
               ImmutableList.<Callback>of(
-                  new CheckArguments(compiler),
                   new CheckEmptyStatements(compiler),
                   new CheckEnums(compiler),
                   new CheckInterfaces(compiler),","Remove the ` arguments ` check from the linter for now , until it \' s better documented and gives clearer advice to the user . . - - - - - - - - - - - - - .","""Remove CheckArguments from LintPassConfig""","""Remove unused CheckArguments lint check from LintPassConfig.""","""Remove CheckArguments from LintPassConfig in JavaScript Compiler""",Remove CheckArguments lint rule from LintPassConfig.,Model 4
"diff --git a/curator-framework/src/test/java/org/apache/curator/framework/imps/TestFrameworkBackground.java b/curator-framework/src/test/java/org/apache/curator/framework/imps/TestFrameworkBackground.java
index 8527a148..5aa13537 100644
--- a/curator-framework/src/test/java/org/apache/curator/framework/imps/TestFrameworkBackground.java
+++ b/curator-framework/src/test/java/org/apache/curator/framework/imps/TestFrameworkBackground.java
@@ -34,7 +34,6 @@ import org.testng.annotations.Test;
 import java.util.Arrays;
 import java.util.List;
 import java.util.concurrent.CountDownLatch;
-import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicLong;
 
 public class TestFrameworkBackground extends BaseClassForTests
@@ -127,11 +126,12 @@ public class TestFrameworkBackground extends BaseClassForTests
     @Test
     public void testCuratorCallbackOnError() throws Exception
     {
-
+        Timing timing = new Timing();
         CuratorFramework client = CuratorFrameworkFactory.builder()
             .connectString(server.getConnectString())
-            .sessionTimeoutMs(60000)
-            .retryPolicy(new RetryNTimes(1, 1000)).build();
+            .sessionTimeoutMs(timing.session())
+            .connectionTimeoutMs(timing.connection())
+            .retryPolicy(new RetryOneTime(1000)).build();
         final CountDownLatch latch = new CountDownLatch(1);
         try
         {
@@ -154,7 +154,7 @@ public class TestFrameworkBackground extends BaseClassForTests
             // Attempt to retrieve children list
             client.getChildren().inBackground(curatorCallback).forPath(""/"");
             // Check if the callback has been called with a correct return code
-            Assert.assertTrue(latch.await(10, TimeUnit.SECONDS), ""Callback has not been called by curator !"");
+            Assert.assertTrue(timing.awaitLatch(latch), ""Callback has not been called by curator !"");
         }
         finally
         {",Add timing for better test reliability,"""Refactor TestFrameworkBackground to use Timing class for session and connection timeouts, and retry policy""","""Refactor testCuratorCallbackOnError to use Timing class for timeout settings and latch waiting.""","""Update TestFrameworkBackground to use Timing class and adjust timeouts""

Explanation:

* The import statement for java.util.concurrent.TimeUnit has been removed.
* A new Timing object is created at the beginning of the testCuratorCallbackOnError() method.
* The sessionTimeoutMs and connectionTimeoutMs parameters in the CuratorFrameworkFactory.builder() call have been updated to use the session() and connection() methods of the Timing object, respectively.
* The RetryPolicy used in the CuratorFrameworkFactory.builder() call has been changed from RetryNTimes to RetryOneTime with a sleep time of 1000 ms.
* The latch.await() call has been replaced with timing.awaitLatch() call.

These changes suggest that the Timing class has been introduced to manage time-related settings in the test, and the timeouts have been adjusted accordingly. The RetryPolicy has also been simplified to retry only once with a fixed sleep time.","""Refactored test with Timing utility for session and connection timeouts and improved latch await mechanism.""",Model 1
"diff --git a/README.md b/README.md
index 2941e99..1d3d53b 100644
--- a/README.md
+++ b/README.md
@@ -55,6 +55,9 @@ Elasticsearch-SQL
 **5.6.4** [![5.6.4 Build Status](https://travis-ci.org/NLPchina/elasticsearch-sql.svg?branch=elastic5.6.4)](https://travis-ci.org/NLPchina/elasticsearch-sql)
 **5.6.5** [![5.6.5 Build Status](https://travis-ci.org/NLPchina/elasticsearch-sql.svg?branch=elastic5.6.5)](https://travis-ci.org/NLPchina/elasticsearch-sql)
 **6.0.0** [![6.0.0 Build Status](https://travis-ci.org/NLPchina/elasticsearch-sql.svg?branch=elastic6.0.0)](https://travis-ci.org/NLPchina/elasticsearch-sql)
+**6.0.1** [![6.0.1 Build Status](https://travis-ci.org/NLPchina/elasticsearch-sql.svg?branch=elastic6.0.1)](https://travis-ci.org/NLPchina/elasticsearch-sql)
+**6.1.0** [![6.1.0 Build Status](https://travis-ci.org/NLPchina/elasticsearch-sql.svg?branch=elastic6.1.0)](https://travis-ci.org/NLPchina/elasticsearch-sql)
+**6.1.1** [![6.1.1 Build Status](https://travis-ci.org/NLPchina/elasticsearch-sql.svg?branch=elastic6.1.1)](https://travis-ci.org/NLPchina/elasticsearch-sql)
 
 Query elasticsearch using familiar SQL syntax.
 You can also use ES functions in SQL.
@@ -123,6 +126,9 @@ Versions
 | 5.6.4                 | 5.6.4.0        | delete commands not supported  | elastic5.6.4 |
 | 5.6.5                 | 5.6.5.0        | delete commands not supported  | elastic5.6.5 |
 | 6.0.0                 | 6.0.0.0        |                                | elastic6.0.0 |
+| 6.0.1                 | 6.0.1.0        |                                | elastic6.0.1 |
+| 6.1.0                 | 6.1.0.0        |                                | elastic6.1.0 |
+| 6.1.1                 | 6.1.1.0        |                                | elastic6.1.1 |
 
 ### Elasticsearch 1.x
 ````
@@ -332,6 +338,21 @@ Versions
 ./bin/elasticsearch-plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/6.0.0.0/elasticsearch-sql-6.0.0.0.zip
 ````
 
+### Elasticsearch 6.0.1
+````
+./bin/elasticsearch-plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/6.0.1.0/elasticsearch-sql-6.0.1.0.zip
+````
+
+### Elasticsearch 6.1.0
+````
+./bin/elasticsearch-plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/6.1.0.0/elasticsearch-sql-6.1.0.0.zip
+````
+
+### Elasticsearch 6.1.1
+````
+./bin/elasticsearch-plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/6.1.1.0/elasticsearch-sql-6.1.1.0.zip
+````
+
 After doing this, you need to restart the Elasticsearch server. Otherwise you may get errors like `Invalid index name [sql], must not start with '']; "",""status"":400}`.
 
 ## Basic Usage",update README . md,"""Add support for Elasticsearch 6.0.1, 6.1.0, and 6.1.1 versions""","""Added support for Elasticsearch 6.0.1, 6.1.0, and 6.1.1, including plugin installation instructions and documentation updates.""","Updated README.md to include Elasticsearch-SQL versions for 6.0.1, 6.1.0, and 6.1.1.

The README.md file has been updated to include the Elasticsearch-SQL versions for 6.0.1, 6.1.0, and 6.1.1. The new versions have been added to the list of supported versions, and installation instructions have been provided for each version. The changes are as follows:

* Added Elasticsearch-SQL version 6.0.1 with the corresponding Travis CI build status badge and installation command.
* Added Elasticsearch-SQL version 6.1.0 with the corresponding Travis CI build status badge and installation command.
* Added Elasticsearch-SQL version 6.1.1 with the corresponding Travis CI build status badge and installation command.

These changes will allow users to easily install and use the appropriate version of Elasticsearch-SQL for their Elasticsearch server.","Added support and installation instructions for Elasticsearch versions 6.0.1, 6.1.0, and 6.1.1 in README.md.",Model 3
"diff --git a/languagetool-core/pom.xml b/languagetool-core/pom.xml
index e56a7dac85..63ba77cfc4 100644
--- a/languagetool-core/pom.xml
+++ b/languagetool-core/pom.xml
@@ -82,7 +82,6 @@
             <version>${morfologik.version}</version>
         </dependency>
         <dependency>
-            <!-- Note: if you update morfologik here, remember to also update morfologik-tools in languagetool-standalone -->
             <groupId>org.carrot2</groupId>
             <artifactId>morfologik-speller</artifactId>
             <version>${morfologik.version}</version>",remove outdated comment,"""Remove morfologik-speller dependency from languagetool-core""",Remove morfologik-speller dependency from languagetool-core.,"""Removed comment about updating morfologik-tools in languagetool-standalone from pom.xml""",Removed note about updating morfologik-tools in languagetool-standalone from languagetool-core/pom.xml.,Model 1
"diff --git a/maven-core/src/main/java/org/apache/maven/lifecycle/internal/LifecyclePluginResolver.java b/maven-core/src/main/java/org/apache/maven/lifecycle/internal/LifecyclePluginResolver.java
index 956e71723..f02552aec 100644
--- a/maven-core/src/main/java/org/apache/maven/lifecycle/internal/LifecyclePluginResolver.java
+++ b/maven-core/src/main/java/org/apache/maven/lifecycle/internal/LifecyclePluginResolver.java
@@ -19,6 +19,9 @@
  * under the License.
  */
 
+import java.util.HashMap;
+import java.util.Map;
+
 import org.apache.maven.execution.MavenSession;
 import org.apache.maven.model.Plugin;
 import org.apache.maven.model.PluginManagement;
@@ -30,9 +33,6 @@
 import org.codehaus.plexus.component.annotations.Component;
 import org.codehaus.plexus.component.annotations.Requirement;
 
-import java.util.HashMap;
-import java.util.Map;
-
 /**
  * @since 3.0
  * @author Benjamin Bentmann
@@ -46,7 +46,6 @@ public class LifecyclePluginResolver
     @Requirement
     private PluginVersionResolver pluginVersionResolver;
 
-
     public LifecyclePluginResolver( PluginVersionResolver pluginVersionResolver )
     {
         this.pluginVersionResolver = pluginVersionResolver;
@@ -65,9 +64,8 @@ public void resolveMissingPluginVersions( MavenProject project, MavenSession ses
         {
             if ( plugin.getVersion() == null )
             {
-                PluginVersionRequest request =
-                    new DefaultPluginVersionRequest( plugin, session.getRepositorySession(),
-                                                     project.getRemotePluginRepositories() );
+                PluginVersionRequest request = new DefaultPluginVersionRequest( plugin, session.getRepositorySession(),
+                                                                                project.getRemotePluginRepositories() );
                 plugin.setVersion( pluginVersionResolver.resolve( request ).getVersion() );
             }
             versions.put( plugin.getKey(), plugin.getVersion() );
diff --git a/maven-core/src/main/java/org/apache/maven/plugin/version/internal/DefaultPluginVersionResolver.java b/maven-core/src/main/java/org/apache/maven/plugin/version/internal/DefaultPluginVersionResolver.java
index f11ee956a..82e32fb31 100644
--- a/maven-core/src/main/java/org/apache/maven/plugin/version/internal/DefaultPluginVersionResolver.java
+++ b/maven-core/src/main/java/org/apache/maven/plugin/version/internal/DefaultPluginVersionResolver.java
@@ -87,8 +87,6 @@ public class DefaultPluginVersionResolver
     public PluginVersionResult resolve( PluginVersionRequest request )
         throws PluginVersionResolutionException
     {
-        logger.debug( ""Resolving plugin version for "" + request.getGroupId() + "":"" + request.getArtifactId() );
-
         PluginVersionResult result = resolveFromProject( request );
 
         if ( result == null )
@@ -103,8 +101,8 @@ public PluginVersionResult resolve( PluginVersionRequest request )
         }
         else if ( logger.isDebugEnabled() )
         {
-            logger.debug( ""Resolved plugin version for "" + request.getGroupId() + "":"" + request.getArtifactId()
-                + "" to "" + result.getVersion() + "" from POM "" + request.getPom() );
+            logger.debug( ""Resolved plugin version for "" + request.getGroupId() + "":"" + request.getArtifactId() + "" to ""
+                + result.getVersion() + "" from POM "" + request.getPom() );
         }
 
         return result;
diff --git a/maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java b/maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java
index 1d3a0f668..cea2a743e 100644
--- a/maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java
+++ b/maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java
@@ -83,17 +83,18 @@ public void validateRawModel( Model m, ModelBuildingRequest request, ModelProble
             validateStringNotEmpty( ""parent.groupId"", problems, Severity.FATAL, Version.BASE, parent.getGroupId(),
                                     parent );
 
-            validateStringNotEmpty( ""parent.artifactId"", problems, Severity.FATAL, Version.BASE,
-                                    parent.getArtifactId(), parent );
+            validateStringNotEmpty( ""parent.artifactId"", problems, Severity.FATAL, Version.BASE, parent.getArtifactId(),
+                                    parent );
 
             validateStringNotEmpty( ""parent.version"", problems, Severity.FATAL, Version.BASE, parent.getVersion(),
                                     parent );
 
-            if ( equals( parent.getGroupId(), m.getGroupId() )
-                && equals( parent.getArtifactId(), m.getArtifactId() ) )
+            if ( equals( parent.getGroupId(), m.getGroupId() ) && equals( parent.getArtifactId(), m.getArtifactId() ) )
             {
-                addViolation( problems, Severity.FATAL, Version.BASE, ""parent.artifactId"", null, ""must be changed""
-                    + "", the parent element cannot have the same groupId:artifactId as the project."", parent );
+                addViolation( problems, Severity.FATAL, Version.BASE, ""parent.artifactId"", null,
+                              ""must be changed""
+                                  + "", the parent element cannot have the same groupId:artifactId as the project."",
+                              parent );
             }
         }
 
@@ -101,6 +102,14 @@ && equals( parent.getArtifactId(), m.getArtifactId() ) )
         {
             Severity errOn30 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0 );
 
+            // [MNG-6074] Maven should produce an error if no model version has been set in a POM file used to build an
+            // effective model.
+            //
+            // As of 3.4, the model version is mandatory even in raw models. The XML element still is optional in the
+            // XML schema and this will not change anytime soon. We do not want to build effective models based on
+            // models without a version starting with 3.4.
+            validateStringNotEmpty( ""modelVersion"", problems, Severity.ERROR, Version.V20, m.getModelVersion(), m );
+
             validateEnum( ""modelVersion"", problems, Severity.ERROR, Version.V20, m.getModelVersion(), null, m,
                           ""4.0.0"" );
 
@@ -157,23 +166,23 @@ && equals( parent.getArtifactId(), m.getArtifactId() ) )
                                   ""must be unique but found duplicate profile with id "" + profile.getId(), profile );
                 }
 
-                validate30RawProfileActivation( problems, profile.getActivation(), profile.getId(), prefix
-                    + "".activation"", request );
+                validate30RawProfileActivation( problems, profile.getActivation(), profile.getId(),
+                                                prefix + "".activation"", request );
 
                 validate20RawDependencies( problems, profile.getDependencies(), prefix + "".dependencies.dependency"",
-                                         request );
+                                           request );
 
                 if ( profile.getDependencyManagement() != null )
                 {
-                    validate20RawDependencies( problems, profile.getDependencyManagement().getDependencies(), prefix
-                        + "".dependencyManagement.dependencies.dependency"", request );
+                    validate20RawDependencies( problems, profile.getDependencyManagement().getDependencies(),
+                                               prefix + "".dependencyManagement.dependencies.dependency"", request );
                 }
 
                 validateRawRepositories( problems, profile.getRepositories(), prefix + "".repositories.repository"",
-                                      request );
+                                         request );
 
-                validateRawRepositories( problems, profile.getPluginRepositories(), prefix
-                    + "".pluginRepositories.pluginRepository"", request );
+                validateRawRepositories( problems, profile.getPluginRepositories(),
+                                         prefix + "".pluginRepositories.pluginRepository"", request );
 
                 BuildBase buildBase = profile.getBuild();
                 if ( buildBase != null )
@@ -184,7 +193,7 @@ && equals( parent.getArtifactId(), m.getArtifactId() ) )
                     if ( mngt != null )
                     {
                         validate20RawPlugins( problems, mngt.getPlugins(), prefix + "".pluginManagement.plugins.plugin"",
-                                            request );
+                                              request );
                     }
                 }
             }
@@ -223,11 +232,8 @@ else if ( StringUtils.isNotEmpty( file.getMissing() ) )
 
             if ( path.contains( ""${project.basedir}"" ) )
             {
-                addViolation( problems,
-                              Severity.WARNING,
-                              Version.V30,
-                              prefix + ( missing ? "".file.missing"" : "".file.exists"" ),
-                              null,
+                addViolation( problems, Severity.WARNING, Version.V30,
+                              prefix + ( missing ? "".file.missing"" : "".file.exists"" ), null,
                               ""Failed to interpolate file location "" + path + "" for profile "" + sourceHint
                                   + "": ${project.basedir} expression not supported during profile activation, ""
                                   + ""use ${basedir} instead"",
@@ -235,15 +241,9 @@ else if ( StringUtils.isNotEmpty( file.getMissing() ) )
             }
             else if ( hasProjectExpression( path ) )
             {
-                addViolation( problems,
-                              Severity.WARNING,
-                              Version.V30,
-                              prefix + ( missing ? "".file.missing"" : "".file.exists"" ),
-                              null,
-                              ""Failed to interpolate file location ""
-                                  + path
-                                  + "" for profile ""
-                                  + sourceHint
+                addViolation( problems, Severity.WARNING, Version.V30,
+                              prefix + ( missing ? "".file.missing"" : "".file.exists"" ), null,
+                              ""Failed to interpolate file location "" + path + "" for profile "" + sourceHint
                                   + "": ${project.*} expressions are not supported during profile activation"",
                               file.getLocation( missing ? ""missing"" : ""exists"" ) );
             }
@@ -251,7 +251,7 @@ else if ( hasProjectExpression( path ) )
     }
 
     private void validate20RawPlugins( ModelProblemCollector problems, List<Plugin> plugins, String prefix,
-                                     ModelBuildingRequest request )
+                                       ModelBuildingRequest request )
     {
         Severity errOn31 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_1 );
 
@@ -259,6 +259,27 @@ private void validate20RawPlugins( ModelProblemCollector problems, List<Plugin>
 
         for ( Plugin plugin : plugins )
         {
+            if ( plugin.getGroupId() == null
+                || ( plugin.getGroupId() != null && plugin.getGroupId().trim().isEmpty() ) )
+            {
+                addViolation( problems, Severity.FATAL, Version.V20, prefix + "".(groupId:artifactId)"", null,
+                              ""groupId of a plugin must be defined. "", plugin );
+            }
+
+            if ( plugin.getArtifactId() == null
+                || ( plugin.getArtifactId() != null && plugin.getArtifactId().trim().isEmpty() ) )
+            {
+                addViolation( problems, Severity.FATAL, Version.V20, prefix + "".(groupId:artifactId)"", null,
+                              ""artifactId of a plugin must be defined. "", plugin );
+            }
+
+            // This will catch cases like <version></version> or <version/>
+            if ( plugin.getVersion() != null && plugin.getVersion().trim().isEmpty() )
+            {
+                addViolation( problems, Severity.FATAL, Version.V20, prefix + "".(groupId:artifactId)"", null,
+                              ""version of a plugin must be defined. "", plugin );
+            }
+
             String key = plugin.getKey();
 
             Plugin existing = index.get( key );
@@ -279,9 +300,9 @@ private void validate20RawPlugins( ModelProblemCollector problems, List<Plugin>
             {
                 if ( !executionIds.add( exec.getId() ) )
                 {
-                    addViolation( problems, Severity.ERROR, Version.V20, prefix + ""["" + plugin.getKey()
-                        + ""].executions.execution.id"", null, ""must be unique but found duplicate execution with id ""
-                        + exec.getId(), exec );
+                    addViolation( problems, Severity.ERROR, Version.V20,
+                                  prefix + ""["" + plugin.getKey() + ""].executions.execution.id"", null,
+                                  ""must be unique but found duplicate execution with id "" + exec.getId(), exec );
                 }
             }
         }
@@ -302,9 +323,8 @@ public void validateEffectiveModel( Model m, ModelBuildingRequest request, Model
         {
             if ( !""pom"".equals( m.getPackaging() ) )
             {
-                addViolation( problems, Severity.ERROR, Version.BASE, ""packaging"", null,
-                              ""with value '"" + m.getPackaging() + ""' is invalid. Aggregator projects ""
-                                  + ""require 'pom' as packaging."", m );
+                addViolation( problems, Severity.ERROR, Version.BASE, ""packaging"", null, ""with value '""
+                    + m.getPackaging() + ""' is invalid. Aggregator projects "" + ""require 'pom' as packaging."", m );
             }
 
             for ( int i = 0, n = m.getModules().size(); i < n; i++ )
@@ -364,8 +384,8 @@ public void validateEffectiveModel( Model m, ModelBuildingRequest request, Model
                     validate20PluginVersion( ""build.plugins.plugin.version"", problems, p.getVersion(), p.getKey(), p,
                                              request );
 
-",Confusing error message in case of missing / empty .,"Here's a possible commit message based on the provided diff:

""Improve plugin version resolution and validation in Maven core and model builder""

This commit message is short and to the point, summarizing the main changes made in the commit. It doesn't go into too much detail, but it gives a general idea of what the commit is about.","The commit message should be:

""Fix plugin version resolution and model validation issues""

This commit message is concise and accurately reflects the changes made in the commit. It mentions the two main areas of change: plugin version resolution and model validation, which are the two main files affected by the changes.","Refactored import statements and formatted logger messages in LifecyclePluginResolver, DefaultPluginVersionResolver, and DefaultModelValidator classes. Added new validation for modelVersion in DefaultModelValidator.","""Refactor code for better readability and add validation checks for plugin definitions and model versions.""",Model 4
"diff --git a/netty/src/main/java/io/grpc/netty/GrpcSslContexts.java b/netty/src/main/java/io/grpc/netty/GrpcSslContexts.java
index a39925619..d87615fb3 100644
--- a/netty/src/main/java/io/grpc/netty/GrpcSslContexts.java
+++ b/netty/src/main/java/io/grpc/netty/GrpcSslContexts.java
@@ -33,6 +33,7 @@ package io.grpc.netty;
 
 import static com.google.common.base.Preconditions.checkArgument;
 
+import com.google.errorprone.annotations.CanIgnoreReturnValue;
 import io.grpc.ExperimentalApi;
 import io.netty.handler.codec.http2.Http2SecurityUtil;
 import io.netty.handler.ssl.ApplicationProtocolConfig;
@@ -133,6 +134,7 @@ public class GrpcSslContexts {
    * Set ciphers and APN appropriate for gRPC. Precisely what is set is permitted to change, so if
    * an application requires particular settings it should override the options set here.
    */
+  @CanIgnoreReturnValue
   public static SslContextBuilder configure(SslContextBuilder builder) {
     return configure(builder, defaultSslProvider());
   }
@@ -142,6 +144,7 @@ public class GrpcSslContexts {
    * an application requires particular settings it should override the options set here.
    */
   @ExperimentalApi(""https://github.com/grpc/grpc-java/issues/1784"")
+  @CanIgnoreReturnValue
   public static SslContextBuilder configure(SslContextBuilder builder, SslProvider provider) {
     return builder.sslProvider(provider)
                   .ciphers(Http2SecurityUtil.CIPHERS, SupportedCipherSuiteFilter.INSTANCE)
diff --git a/netty/src/main/java/io/grpc/netty/NettyChannelBuilder.java b/netty/src/main/java/io/grpc/netty/NettyChannelBuilder.java
index aec7b0f7e..a0fb0733d 100644
--- a/netty/src/main/java/io/grpc/netty/NettyChannelBuilder.java
+++ b/netty/src/main/java/io/grpc/netty/NettyChannelBuilder.java
@@ -39,6 +39,7 @@ import static io.grpc.internal.GrpcUtil.DEFAULT_KEEPALIVE_TIMEOUT_NANOS;
 
 import com.google.common.annotations.VisibleForTesting;
 import com.google.common.base.Preconditions;
+import com.google.errorprone.annotations.CanIgnoreReturnValue;
 import io.grpc.Attributes;
 import io.grpc.ExperimentalApi;
 import io.grpc.NameResolver;
@@ -57,6 +58,7 @@ import java.net.SocketAddress;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.concurrent.TimeUnit;
+import javax.annotation.CheckReturnValue;
 import javax.annotation.Nullable;
 import javax.net.ssl.SSLException;
 
@@ -64,6 +66,7 @@ import javax.net.ssl.SSLException;
  * A builder to help simplify construction of channels using the Netty transport.
  */
 @ExperimentalApi(""https://github.com/grpc/grpc-java/issues/1784"")
+@CanIgnoreReturnValue
 public final class NettyChannelBuilder
     extends AbstractManagedChannelImplBuilder<NettyChannelBuilder> {
   public static final int DEFAULT_FLOW_CONTROL_WINDOW = 1048576; // 1MiB
@@ -91,6 +94,7 @@ public final class NettyChannelBuilder
    * generally be preferred over this method, since that API permits delaying DNS lookups and
    * noticing changes to DNS.
    */
+  @CheckReturnValue
   public static NettyChannelBuilder forAddress(SocketAddress serverAddress) {
     return new NettyChannelBuilder(serverAddress);
   }
@@ -98,6 +102,7 @@ public final class NettyChannelBuilder
   /**
    * Creates a new builder with the given host and port.
    */
+  @CheckReturnValue
   public static NettyChannelBuilder forAddress(String host, int port) {
     return new NettyChannelBuilder(host, port);
   }
@@ -106,22 +111,27 @@ public final class NettyChannelBuilder
    * Creates a new builder with the given target string that will be resolved by
    * {@link io.grpc.NameResolver}.
    */
+  @CheckReturnValue
   public static NettyChannelBuilder forTarget(String target) {
     return new NettyChannelBuilder(target);
   }
 
+  @CheckReturnValue
   NettyChannelBuilder(String host, int port) {
     this(GrpcUtil.authorityFromHostAndPort(host, port));
   }
 
+  @CheckReturnValue
   NettyChannelBuilder(String target) {
     super(target);
   }
 
+  @CheckReturnValue
   NettyChannelBuilder(SocketAddress address) {
     super(address, getAuthorityFromAddress(address));
   }
 
+  @CheckReturnValue
   private static String getAuthorityFromAddress(SocketAddress address) {
     if (address instanceof InetSocketAddress) {
       InetSocketAddress inetAddress = (InetSocketAddress) address;
@@ -258,6 +268,7 @@ public final class NettyChannelBuilder
   }
 
   @Override
+  @CheckReturnValue
   protected ClientTransportFactory buildTransportFactory() {
     return new NettyTransportFactory(dynamicParamsFactory, channelType, channelOptions,
         negotiationType, sslContext, eventLoopGroup, flowControlWindow, maxInboundMessageSize(),
@@ -265,6 +276,7 @@ public final class NettyChannelBuilder
   }
 
   @Override
+  @CheckReturnValue
   protected Attributes getNameResolverParams() {
     int defaultPort;
     switch (negotiationType) {
@@ -287,6 +299,7 @@ public final class NettyChannelBuilder
   }
 
   @VisibleForTesting
+  @CheckReturnValue
   static ProtocolNegotiator createProtocolNegotiator(
       String authority,
       NegotiationType negotiationType,
@@ -306,6 +319,7 @@ public final class NettyChannelBuilder
     return negotiator;
   }
 
+  @CheckReturnValue
   private static ProtocolNegotiator createProtocolNegotiatorByType(
       String authority,
       NegotiationType negotiationType,
@@ -329,11 +343,13 @@ public final class NettyChannelBuilder
     }
   }
 
+  @CheckReturnValue
   interface OverrideAuthorityChecker {
     String checkAuthority(String authority);
   }
 
   @Override
+  @CheckReturnValue
   protected String checkAuthority(String authority) {
     if (authorityChecker != null) {
       return authorityChecker.checkAuthority(authority);
@@ -346,10 +362,12 @@ public final class NettyChannelBuilder
   }
 
   interface TransportCreationParamsFilterFactory {
+    @CheckReturnValue
     TransportCreationParamsFilter create(
         SocketAddress targetServerAddress, String authority, @Nullable String userAgent);
   }
 
+  @CheckReturnValue
   interface TransportCreationParamsFilter {
     SocketAddress getTargetServerAddress();
 
@@ -363,6 +381,7 @@ public final class NettyChannelBuilder
   /**
    * Creates Netty transports. Exposed for internal use, as it should be private.
    */
+  @CheckReturnValue
   private static final class NettyTransportFactory implements ClientTransportFactory {
     private final TransportCreationParamsFilterFactory transportCreationParamsFilterFactory;
     private final Class<? extends Channel> channelType;
@@ -446,6 +465,7 @@ public final class NettyChannelBuilder
       }
     }
 
+    @CheckReturnValue
     private final class DynamicNettyTransportParams implements TransportCreationParamsFilter {
 
       private final SocketAddress targetServerAddress;
diff --git a/netty/src/main/java/io/grpc/netty/NettyServerBuilder.java b/netty/src/main/java/io/grpc/netty/NettyServerBuilder.java
index 3b8739fb1..fae56650d 100644
--- a/netty/src/main/java/io/grpc/netty/NettyServerBuilder.java
+++ b/netty/src/main/java/io/grpc/netty/NettyServerBuilder.java
@@ -35,6 +35,7 @@ import static com.google.common.base.Preconditions.checkArgument;
 import static io.grpc.internal.GrpcUtil.DEFAULT_MAX_MESSAGE_SIZE;
 
 import com.google.common.base.Preconditions;
+import com.google.errorprone.annotations.CanIgnoreReturnValue;
 import io.grpc.ExperimentalApi;
 import io.grpc.Internal;
 import io.grpc.internal.AbstractServerImplBuilder;
@@ -46,6 +47,7 @@ import io.netty.handler.ssl.SslContext;
 import java.io.File;
 import java.net.InetSocketAddress;
 import java.net.SocketAddress;
+import javax.annotation.CheckReturnValue;
 import javax.annotation.Nullable;
 import javax.net.ssl.SSLException;
 
@@ -53,6 +55,7 @@ import javax.net.ssl.SSLException;
  * A builder to help simplify the construction of a Netty-based GRPC server.
  */
 @ExperimentalApi(""https://github.com/grpc/grpc-java/issues/1784"")
+@CanIgnoreReturnValue
 public final class NettyServerBuilder extends AbstractServerImplBuilder<NettyServerBuilder> {
   public static final int DEFAULT_FLOW_CONTROL_WINDOW = 1048576; // 1MiB
 
@@ -75,6 +78,7 @@ public final class NettyServerBuilder extends AbstractServerImplBuilder<NettySer
    * @param port the port on which the server is to be bound.
    * @return the server builder.
    */
+  @CheckReturnValue
   public static NettyServerBuilder forPort(int port) {
     return new NettyServerBuilder(port);
   }
@@ -85,14 +89,17 @@ public final class NettyServerBuilder extends AbstractServerImplBuilder<NettySer
    * @param address the socket address on which the server is to be bound.
    * @return the server builder
    */
+  @CheckReturnValue
   public static NettyServerBuilder forAddress(SocketAddress address) {
     return new NettyServerBuilder(address);
   }
 
+  @CheckReturnValue
   private NettyServerBuilder(int port) {
     this.address = new InetSocketAddress(port);
   }
 
+  @CheckReturnValue
   private NettyServerBuilder(SocketAddress address) {
     this.address = address;
   }
@@ -221,6 +228,7 @@ public final class NettyServerBuilder extends AbstractServerImplBuilder<NettySer
   }
 
   @Override
+  @CheckReturnValue
   protected NettyServer buildTransportServer() {
     ProtocolNegotiator negotiator = protocolNegotiator;
     if (negotiator == null) {
diff --git a/netty/src/main/java/io/grpc/netty/WriteQueue.java b/netty/src/main/java/io/grpc/netty/WriteQueue.java
index f909feb83..2b3f77e6c 100644
--- a/netty/src/main/java/io/grpc/netty/WriteQueue.java
+++ b/netty/src/main/java/io/grpc/netty/WriteQueue.java
@@ -33,6 +33,7 @@ package io.grpc.netty;
 
 import com.google.common.annotations.VisibleForTesting;
 import com.google.common.base.Preconditions;
+import com.google.errorprone.annotations.CanIgnoreReturnValue;
 import io.netty.channel.Channel;
 import io.netty.channel.ChannelFuture;
 import io.netty.channel.ChannelPromise;
@@ -87,6 +88,7 @@ class WriteQueue {
    * @param flush true if a flush of the write should be schedule, false if a later call to
    *              enqueue will schedule the flush.
    */
+  @CanIgnoreReturnValue
   ChannelFuture enqueue(QueuedCommand command, boolean flush) {
     return enqueue(command, channel.newPromise(), flush);
   }
@@ -99,6 +101,7 @@ class WriteQueue {
    * @param flush true if a flush of the write should be schedule, false if a later call to
    *              enqueue will schedule the flush.
    */
+  @CanIgnoreReturnValue
   ChannelFuture enqueue(QueuedCommand command, ChannelPromise promise, boolean flush) {
     // Detect erroneous code that tries to reuse command objects.
     Preconditions.checkArgument(command.promise() == null, ""promise must not be set on command"");
diff --git a/netty/src/main/java/io/grpc/netty/package-info.java b/netty/src/main/java/io/grpc/netty/package-info.java
index da4e374c1..cc7805e07 100644
--- a/netty/src/main/java/io/grpc/netty/package-info.java
+++ b/netty/src/main/java/io/grpc/netty/package-info.java
@@ -33,4 +33,5 @@
  * The main transport implementation based on <a target=""_blank"" href=""http://netty.io"">Netty</a>,
  * for both the client and the server.
  */
+@javax.annotation.CheckReturnValue
 package io.grpc.netty;
diff --git a/netty/src/test/java/io/grpc/netty/NettyClientHandlerTest.java b/netty/src/test/java/io/grpc/netty/NettyClientHandlerTest.java
index df6260e59..5ccdd90ce 100644
--- a/netty/src/test/java/io/grpc/netty/NettyClientHandlerTest.java
+++ b/netty/src/test/java/io/grpc/netty/NettyClientHandlerTest.java
@@ -60,6 +60,7 @@ import com.google.common.base.Ticker;
 import com.google.common.collect.ImmutableList;
 import com.google.common.io.ByteStreams;
 import com.google.common.util.concurrent.MoreExecutors;
+import com.google.errorprone.annotations.CanIgnoreReturnValue;
 import io.grpc.Metadata;
 import io.grpc.Status;
 import io.grpc.StatusException;
@@ -536,6 +537,7 @@ public class NettyClientHandlerTest extends NettyHandlerTestBase<NettyClientHand
     createStream();
   }
 
+  @CanIgnoreReturnValue
   private ChannelFuture sendPing(PingCallback callback) {
     return enqueue(new SendPingCommand(callback, MoreExecutors.directExecutor()));
   }
@@ -545,11 +547,13 @@ public class NettyClientHandlerTest extends NettyHandlerTestBase<NettyClientHand
     channelRead(serializedSettings);
   }
 
+  @CanIgnoreReturnValue
   private ChannelFuture createStream() throws Exception {
     ChannelFuture future = enqueue(new CreateStreamCommand(grpcHeaders, streamTransportState));
     return future;
   }
 
+  @CanIgnoreReturnValue
   private ChannelFuture cancelStream(Status status) throws Exception {
     return enqueue(new CancelClientStreamCommand(streamTransportState, status));
   }
diff --git a/netty/src/test/java/io/grpc/netty/NettyClientTransportTest.java b/netty/src/test/java/io/grpc/netty/NettyClientTransportTest.java
index e99fa859d..f2b4fc4d8 100644
--- a/netty/src/test/java/io/grpc/netty/NettyClientTransportTest.java
+++ b/netty/src/test/java/io/grpc/netty/NettyClientTransportTest.java
@@ -145,7 +145,7 @@ public class NettyClientTransportTest {
   public void addDefaultUserAgent() throws Exception {
     startServer();
     NettyClientTransport transport = newTransport(newNegotiator());
-    transport.start(clientTransportListener);
+    callMeMaybe(transport.start(clientTransportListener));
 
     // Send a single RPC and wait for the response.
     new Rpc(transport).halfClose().waitForResponse();
@@ -169,7 +169,7 @@ public class NettyClientTransportTest {
         DEFAULT_WINDOW_SIZE, DEFAULT_MAX_MESSAGE_SIZE, GrpcUtil.DEFAULT_MAX_HEADER_LIST_SIZE,
         authority, null /* user agent */);
     transports.add(transport);
-    transport.start(clientTransportListener);
+    callMeMaybe(transport.start(clientTransportListener));
 
     // verify SO_LINGER has been set
     ChannelConfig config = transport.channel().config();
@@ -182,7 +182,7 @@ public class NettyClientTransportTest {
     startServer();
     NettyClientTransport transport = newTransport(newNegotiator(),
         DEFAULT_MAX_MESSAGE_SIZE, GrpcUtil.DEFAULT_MAX_HEADER_LIST_SIZE, ""testUserAgent"");
-    transport.start(clientTransportListener);
+    callMeMaybe(transport.start(clientTransportListener));
 
     new Rpc(transport, new Metadata()).halfClose().waitForResponse();
 
@@ -199,7 +199,7 @@ public class NettyClientTransportTest {
     // Allow the response payloads of up to 1 byte.
     NettyClientTransport transport = newTransport(newNegotiator(),
         1, GrpcUtil.DEFAULT_MAX_HEADER_LIST_SIZE, null);
-    transport.start(clientTransportListener);
+    callMeMaybe(transport.start(clientTransportListener));
 
     try {
       // Send a single RPC and wait for the response.
@@ -224,7 +224,7 @@ public class NettyClientTransportTest {
     ProtocolNegotiator negotiator = newNegotiator();
     for (int index = 0; index < 2; ++index) {
       NettyClientTransport transport = newTransport(negotiator);
-      transport.start(clientTransportListener);
+      callMeMaybe(transport.start(clientTransportListener));
     }
 
     // Send a single RPC on each transport.
@@ -245,7 +245,7 @@ public class NettyClientTransportTest {
     startServer(1, GrpcUtil.DEFAULT_MAX_HEADER_LIST_SIZE);
 
     NettyClientTransport transport = newTransport(newNegotiator());
-    transport.start(clientTransportListener);
+    callMeMaybe(transport.start(clientTransportListener));
 
     // Send a dummy RPC in order to ensure that the updated SETTINGS_MAX_CONCURRENT_STREAMS
     // has been received by the remote endpoint.
@@ -281,7 +281,7 @@ public class NettyClientTransportTest {
 
     NettyClientTransport transport =
         newTransport(newNegotiator(), DEFAULT_MAX_MESSAGE_SIZE, 1, null);
-    transport.start(clientTransportListener);
+    callMeMaybe(transport.start(clientTransportListener));
 
     try {
       // Send a single RPC and wait for the response.
@@ -300,7 +300,7 @@ public class NettyClientTransportTest {
     startServer(100, 1);
 
     NettyClientTransport transport = newTransport(newNegotiator());
-    transport.start(clientTransportListener);
+    callMeMaybe(transport.start(clientTransportListener));
 
     try {
       // Send a single RPC and wait for the response.
@@ -338,7 +338,7 @@ public class NettyClientTransportTest {
   public void clientStreamGetsAttributes() throws Exception {
     startServer();
     NettyClientTransport transport = newTransport(newNegotiator());
-    transport.start(clientTransportListener);
+    callMeMaybe(transport.start(clientTransportListener));
     Rpc rpc = new Rpc(transport).halfClose();
     rpc.waitForResponse();
 
@@ -392,6 +392,12 @@ public class NettyClientTransportTest {
     authority = GrpcUtil.authorityFromHostAndPort(address.getHostString(), address.getPort());
   }
 
+  private void callMeMaybe(Runnable r) {
+    if (r != null) {
+      r.run();
+    }
+  }
+
   private static class Rpc {
     static final String MESSAGE = ""hello"";
     static final MethodDescriptor<String, String> METHOD =
diff --git a/netty/src/test/java/io/grpc/netty/NettyHandlerTestBase.java b/netty/src/test/java/io/grpc/netty/NettyHandlerTestBase.java
index 8a82c38b0..a16db1413 100644
--- a/netty/src/test/java/io/grpc/netty/NettyHandlerTestBase.java
+++ b/netty/src/test/java/io/grpc/netty/NettyHandlerTestBase.java
@@ -39,6 +39,7 @@ import static org.mockito.Mockito.spy;
 import static org.mockito.Mockito.verify;
 import static org.mockito.Mockito.when;
 
+import com.google.errorprone.annotations.CanIgnoreReturnValue;
 import io.grpc.internal.MessageFramer;
 import io.grpc.internal.StatsTraceContext;
 import io.grpc.internal.WritableBuffer;
@@ -221,6 +222,7 @@ public abstract class NettyHandlerTestBase<T extends Http2ConnectionHandler> {
     return handler().connection();
   }
 
+  @CanIgnoreReturnValue
   protected final ChannelFuture enqueue(WriteQueue.QueuedCommand command) {
     ChannelFuture future = writeQueue.enqueue(command, newPromise(), true);
     channel.runPendingTasks();",add return value errorprone annotations,"""Added @CanIgnoreReturnValue and @CheckReturnValue annotations to methods in Netty transport classes""","The commit message should be:

""Add @CheckReturnValue and @CanIgnoreReturnValue annotations""

This commit message accurately reflects the changes made in the diff, which is the addition of these two annotations to various methods in the codebase.","The commit message could be: ""Add @CanIgnoreReturnValue annotation to appropriate methods in GrpcSslContexts, NettyChannelBuilder, NettyServerBuilder, WriteQueue, NettyClientHandlerTest, and NettyHandlerTestBase."" This annotation is used to indicate that it's safe to ignore the result of a method, which can help static analysis tools like Error Prone detect potential issues in the code.",Added `@CanIgnoreReturnValue` and `@CheckReturnValue` annotations for improved return value handling in gRPC Netty transport classes.,Label
"diff --git a/language-server/modules/langserver-compiler/src/test/resources/testng.xml b/language-server/modules/langserver-compiler/src/test/resources/testng.xml
index b673d226d12..e6d67a90c3a 100644
--- a/language-server/modules/langserver-compiler/src/test/resources/testng.xml
+++ b/language-server/modules/langserver-compiler/src/test/resources/testng.xml
@@ -27,7 +27,7 @@ under the License.
             </run>
         </groups>
         <packages>
-            <package name=""org.ballerinalang.langserver.compiler.*""/>
+            <!--<package name=""org.ballerinalang.langserver.compiler.*""/>-->
         </packages>
     </test>
 </suite>
diff --git a/language-server/modules/langserver-core/pom.xml b/language-server/modules/langserver-core/pom.xml
index f68a8c1f8bb..8e3d9514eb6 100644
--- a/language-server/modules/langserver-core/pom.xml
+++ b/language-server/modules/langserver-core/pom.xml
@@ -114,6 +114,14 @@
             <type>zip</type>
             <classifier>ballerina-binary-repo</classifier>
         </dependency>
+        <dependency>
+            <groupId>com.fasterxml.jackson.core</groupId>
+            <artifactId>jackson-databind</artifactId>
+        </dependency>
+        <dependency>
+            <groupId>com.fasterxml.jackson.dataformat</groupId>
+            <artifactId>jackson-dataformat-yaml</artifactId>
+        </dependency>
     </dependencies>
 
     <build>
diff --git a/language-server/modules/langserver-core/spotbugs-exclude.xml b/language-server/modules/langserver-core/spotbugs-exclude.xml
index 89d0595ddda..3ecf338c9c0 100644
--- a/language-server/modules/langserver-core/spotbugs-exclude.xml
+++ b/language-server/modules/langserver-core/spotbugs-exclude.xml
@@ -76,4 +76,10 @@
             <Bug pattern=""RV_RETURN_VALUE_IGNORED_BAD_PRACTICE"" />
         </OR>
     </Match>
+    <Match>
+        <Class name=""org.ballerinalang.langserver.extensions.ballerina.document.BallerinaDocumentServiceImpl"" />
+    </Match>
+    <Match>
+        <Class name=""org.ballerinalang.langserver.extensions.ballerina.document.BallerinaServiceListResponse"" />
+    </Match>
 </FindBugsFilter>
\ No newline at end of file
diff --git a/language-server/modules/langserver-core/src/test/resources/testng.xml b/language-server/modules/langserver-core/src/test/resources/testng.xml
index 34999820466..e6630d827f2 100644
--- a/language-server/modules/langserver-core/src/test/resources/testng.xml
+++ b/language-server/modules/langserver-core/src/test/resources/testng.xml
@@ -27,7 +27,7 @@ under the License.
             </run>
         </groups>
         <packages>
-            <package name=""org.ballerinalang.langserver.*""/>
+            <!--<package name=""org.ballerinalang.langserver.*""/>-->
         </packages>
     </test>
 </suite>",Disable language server tests temporarily,"""Update test configurations and add Jackson dependencies""

This commit message is short and to the point, indicating that the commit involves changes to test configurations (as seen in the testng.xml files) and the addition of Jackson dependencies (as seen in the pom.xml file).","Based on the provided diff, a suitable commit message could be:

""Update dependencies and exclude classes from spotbugs analysis""

This commit message accurately reflects the changes made in the commit, which include adding new dependencies and excluding certain classes from spotbugs analysis.","""Update language-server dependencies and exclude classes from SpotBugs filter""

Explanation:

* In `language-server/modules/langserver-compiler/src/test/resources/testng.xml`, the package `org.ballerinalang.langserver.compiler.*` has been commented out from the testng.xml file.
* In `language-server/modules/langserver-core/pom.xml`, two new dependencies have been added: `com.fasterxml.jackson.core:jackson-databind` and `com.fasterxml.jackson.dataformat:jackson-dataformat-yaml`.
* In `language-server/modules/langserver-core/spotbugs-exclude.xml`, two new classes have been added to the SpotBugs filter: `org.ballerinalang.langserver.extensions.ballerina.document.BallerinaDocumentServiceImpl` and `org.ballerinalang.langserver.extensions.ballerina.document.BallerinaServiceListResponse`.
* In `language-server/modules/langserver-core/src/test/resources/testng.xml`, the package `org.ballerinalang.langserver.*` has been commented out from the testng.xml file.",Updated dependencies and excluded packages from testing and SpotBugs analysis in language-server modules.,Model 4
"diff --git a/bvm/ballerina-core/src/main/java/org/ballerinalang/model/values/BValueArray.java b/bvm/ballerina-core/src/main/java/org/ballerinalang/model/values/BValueArray.java
index 58eb9fe6be7..f3428239ddc 100644
--- a/bvm/ballerina-core/src/main/java/org/ballerinalang/model/values/BValueArray.java
+++ b/bvm/ballerina-core/src/main/java/org/ballerinalang/model/values/BValueArray.java
@@ -167,6 +167,9 @@ public class BValueArray extends BNewArray implements Serializable {
         } else if (type.getTag() == TypeTags.STRING_TAG) {
             stringValues = (String[]) newArrayInstance(String.class);
             Arrays.fill(stringValues, BLangConstants.STRING_EMPTY_VALUE);
+        } else {
+            refValues = (BRefType[]) newArrayInstance(BRefType.class);
+            Arrays.fill(refValues, type.getZeroValue());
         }
 
         super.arrayType = new BArrayType(type, size);",Handle refvalue in else block,"""Added support for initializing arrays of reference types with zero values""","""Added support for initializing array with default values for non-primitive types""","""Added initialization for reference type arrays in BValueArray""

This commit adds a new branch to the if-else statement in the constructor of the `BValueArray` class. If the type of the elements in the array is a reference type (i.e., `type.getTag()` does not match `TypeTags.BOOLEAN_TAG`, `TypeTags.INT_TAG`, `TypeTags.FLOAT_TAG`, or `TypeTags.STRING_TAG`), then it creates a new array of `BRefType` objects and fills it with the zero value for the element type. This ensures that reference type arrays are properly initialized.","Initialize `refValues` in `BValueArray` for types other than integer and string, and fill with zero values.",Model 2
"diff --git a/xdocs/changes.xml b/xdocs/changes.xml
index a47baf5e71..8975cae401 100644
--- a/xdocs/changes.xml
+++ b/xdocs/changes.xml
@@ -81,6 +81,8 @@ citizen in JMeter, you can now test your expressions very easily</h4>
 <figure width=""573"" height=""444"" image=""changes/2.10/06_http_request_delete_method.png""></figure>
 </p>
 
+<h4>* Best-practices section has been improved, ensure you read it to get the most out of JMeter</h4>
+
 <h3><u>GUI and ergonomy Improvements:</u></h3>",Add section .,"""Update changes.xml to include best-practices section improvements""",Improved changes.xml with new best-practices section and GUI improvements,"The commit message should be:

 ""Added a new section to best-practices in JMeter documentation and improved the existing one to ensure users get the most out of JMeter""","""Improved best-practices section in JMeter documentation for optimized usage.""",Model 2
"diff --git a/presto-main/src/main/java/com/facebook/presto/execution/QueryManagerConfig.java b/presto-main/src/main/java/com/facebook/presto/execution/QueryManagerConfig.java
index 493ceffa29..1192b3b75f 100644
--- a/presto-main/src/main/java/com/facebook/presto/execution/QueryManagerConfig.java
+++ b/presto-main/src/main/java/com/facebook/presto/execution/QueryManagerConfig.java
@@ -46,6 +46,20 @@ public class QueryManagerConfig
     private int remoteTaskMaxConsecutiveErrorCount = 10;
     private Duration remoteTaskMinErrorDuration = new Duration(2, TimeUnit.MINUTES);
 
+    private boolean taskCpuTimerEnabled = true;
+
+    public boolean isTaskCpuTimerEnabled()
+    {
+        return taskCpuTimerEnabled;
+    }
+
+    @Config(""task.cpu-timer-enabled"")
+    public QueryManagerConfig setTaskCpuTimerEnabled(boolean taskCpuTimerEnabled)
+    {
+        this.taskCpuTimerEnabled = taskCpuTimerEnabled;
+        return this;
+    }
+
     public boolean isCoordinator()
     {
         return coordinator;
diff --git a/presto-main/src/main/java/com/facebook/presto/execution/SqlTaskExecution.java b/presto-main/src/main/java/com/facebook/presto/execution/SqlTaskExecution.java
index de1800365f..8474ea1a13 100644
--- a/presto-main/src/main/java/com/facebook/presto/execution/SqlTaskExecution.java
+++ b/presto-main/src/main/java/com/facebook/presto/execution/SqlTaskExecution.java
@@ -118,7 +118,8 @@ public class SqlTaskExecution
             ExecutorService notificationExecutor,
             DataSize maxTaskMemoryUsage,
             DataSize operatorPreAllocatedMemory,
-            QueryMonitor queryMonitor)
+            QueryMonitor queryMonitor,
+            boolean cpuTimerEnabled)
     {
         SqlTaskExecution task = new SqlTaskExecution(session,
                 taskId,
@@ -130,7 +131,8 @@ public class SqlTaskExecution
                 maxTaskMemoryUsage,
                 operatorPreAllocatedMemory,
                 queryMonitor,
-                notificationExecutor
+                notificationExecutor,
+                cpuTimerEnabled
         );
 
         try (SetThreadName setThreadName = new SetThreadName(""Task-%s"", taskId)) {
@@ -149,7 +151,8 @@ public class SqlTaskExecution
             DataSize maxTaskMemoryUsage,
             DataSize operatorPreAllocatedMemory,
             QueryMonitor queryMonitor,
-            Executor notificationExecutor)
+            Executor notificationExecutor,
+            boolean cpuTimerEnabled)
     {
         try (SetThreadName setThreadName = new SetThreadName(""Task-%s"", taskId)) {
             this.taskId = checkNotNull(taskId, ""taskId is null"");
@@ -173,7 +176,7 @@ public class SqlTaskExecution
                     session,
                     checkNotNull(maxTaskMemoryUsage, ""maxTaskMemoryUsage is null""),
                     checkNotNull(operatorPreAllocatedMemory, ""operatorPreAllocatedMemory is null""),
-                    true);
+                    cpuTimerEnabled);
 
             this.sharedBuffer = new SharedBuffer(checkNotNull(maxBufferSize, ""maxBufferSize is null""));
 
diff --git a/presto-main/src/main/java/com/facebook/presto/execution/SqlTaskManager.java b/presto-main/src/main/java/com/facebook/presto/execution/SqlTaskManager.java
index 763c912387..7f8ee8b240 100644
--- a/presto-main/src/main/java/com/facebook/presto/execution/SqlTaskManager.java
+++ b/presto-main/src/main/java/com/facebook/presto/execution/SqlTaskManager.java
@@ -80,6 +80,7 @@ public class SqlTaskManager
     private final DataSize operatorPreAllocatedMemory;
     private final Duration infoCacheTime;
     private final Duration clientTimeout;
+    private final boolean cpuTimerEnabled;
 
     private final ConcurrentMap<TaskId, TaskInfo> taskInfos = new ConcurrentHashMap<>();
     private final ConcurrentMap<TaskId, TaskExecution> tasks = new ConcurrentHashMap<>();
@@ -115,6 +116,7 @@ public class SqlTaskManager
         this.operatorPreAllocatedMemory = config.getOperatorPreAllocatedMemory();
         this.infoCacheTime = config.getInfoMaxAge();
         this.clientTimeout = config.getClientTimeout();
+        this.cpuTimerEnabled = config.isTaskCpuTimerEnabled();
 
         taskNotificationExecutor = Executors.newCachedThreadPool(threadsNamed(""task-notification-%d""));
         taskNotificationExecutorMBean = new ThreadPoolExecutorMBean((ThreadPoolExecutor) taskNotificationExecutor);
@@ -304,7 +306,8 @@ public class SqlTaskManager
                         taskNotificationExecutor,
                         maxTaskMemoryUsage,
                         operatorPreAllocatedMemory,
-                        queryMonitor
+                        queryMonitor,
+                        cpuTimerEnabled
                 );
                 tasks.put(taskId, taskExecution);
             }
@@ -389,7 +392,7 @@ public class SqlTaskManager",Make cpu time tracking in OperatorStats configurable with .,"""Add configuration option to enable/disable CPU timer for tasks""","""Added task CPU timer configuration and enabled it by default""

This commit message accurately summarizes the changes made in the commit, which include adding a new configuration option for task CPU timer and enabling it by default.",This commit adds a new configuration option `task.cpu-timer-enabled` to the `QueryManagerConfig` class in Presto. The option controls whether the CPU timer is enabled for tasks. The default value is `true`. The `SqlTaskExecution` and `SqlTaskManager` classes have been updated to accept and use this new configuration option.,Add a configuration option to enable/disable the CPU timer in SQL task execution.,Model 1
"diff --git a/src/main/java/com/xtremelabs/robolectric/shadows/ShadowHandler.java b/src/main/java/com/xtremelabs/robolectric/shadows/ShadowHandler.java
index edc74343d..4c00d9727 100644
--- a/src/main/java/com/xtremelabs/robolectric/shadows/ShadowHandler.java
+++ b/src/main/java/com/xtremelabs/robolectric/shadows/ShadowHandler.java
@@ -18,7 +18,8 @@ import static com.xtremelabs.robolectric.Robolectric.shadowOf;
 @SuppressWarnings({""UnusedDeclaration""})
 @Implements(Handler.class)
 public class ShadowHandler {
-    @RealObject private Handler realHandler;
+    @RealObject
+    private Handler realHandler;
 
     private Looper looper = Looper.myLooper();
 
@@ -67,6 +68,16 @@ public class ShadowHandler {
         return sendMessage(msg);
     }
 
+    @Implementation
+    public final Looper getLooper() {
+        return looper;
+    }
+
+    @Implementation
+    public final void removeCallbacks(java.lang.Runnable r) {
+        shadowOf(looper).getScheduler().remove(r);
+    }
+
     /**
      * @deprecated use {@link #idleMainLooper()} instead
      */
diff --git a/src/main/java/com/xtremelabs/robolectric/util/Scheduler.java b/src/main/java/com/xtremelabs/robolectric/util/Scheduler.java
index 81c3dd902..548ce6ede 100644
--- a/src/main/java/com/xtremelabs/robolectric/util/Scheduler.java
+++ b/src/main/java/com/xtremelabs/robolectric/util/Scheduler.java
@@ -3,6 +3,7 @@ package com.xtremelabs.robolectric.util;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
+import java.util.ListIterator;
 
 public class Scheduler {
     private List<PostedRunnable> postedRunnables = new ArrayList<PostedRunnable>();
@@ -36,6 +37,16 @@ public class Scheduler {
         postDelayed(runnable, 0);
     }
 
+    public void remove(Runnable runnable) {
+        ListIterator<PostedRunnable> iterator = postedRunnables.listIterator();
+        while (iterator.hasNext()) {
+            PostedRunnable next = iterator.next();
+            if (next.runnable == runnable) {
+                iterator.remove();
+            }
+        }
+    }
+
     public boolean advanceToLastPostedRunnable() {
         if (enqueuedTaskCount() < 1) {
             return false;
diff --git a/src/test/java/com/xtremelabs/robolectric/shadows/HandlerTest.java b/src/test/java/com/xtremelabs/robolectric/shadows/HandlerTest.java
index abfaa309c..31161c040 100644
--- a/src/test/java/com/xtremelabs/robolectric/shadows/HandlerTest.java
+++ b/src/test/java/com/xtremelabs/robolectric/shadows/HandlerTest.java
@@ -95,6 +95,19 @@ public class HandlerTest {
         assertThat(scratchRunnable.wasRun, equalTo(true));
     }
 
+    @Test
+    public void testRemoveCallbacks() throws Exception {
+        Handler handler = new Handler();
+        ShadowLooper shadowLooper = shadowOf(handler.getLooper());
+        shadowLooper.pause();
+        handler.post(scratchRunnable);
+        handler.removeCallbacks(scratchRunnable);
+
+        shadowLooper.unPause();
+
+        assertThat(scratchRunnable.wasRun, equalTo(false));
+    }
+
     @Test
     public void testPostDelayedThenRunMainLooperToNextTask_shouldRunOneTask() throws Exception {
         new Handler().postDelayed(scratchRunnable, 1);
@@ -146,9 +159,9 @@ public class HandlerTest {
 
     @Test
     public void sendEmptyMessageHandler() {
-        
+
         final Handler handler = new Handler(new Handler.Callback() {
-            
+
             @Override
             public boolean handleMessage(Message message) {
                 throw new UnsupportedOperationException(""Method not implemented"");
diff --git a/src/test/java/com/xtremelabs/robolectric/shadows/LooperTest.java b/src/test/java/com/xtremelabs/robolectric/shadows/LooperTest.java
index 4de9e526e..25664afb0 100644
--- a/src/test/java/com/xtremelabs/robolectric/shadows/LooperTest.java
+++ b/src/test/java/com/xtremelabs/robolectric/shadows/LooperTest.java
@@ -2,7 +2,6 @@ package com.xtremelabs.robolectric.shadows;
 
 import android.os.Handler;
 import android.os.Looper;
-import com.xtremelabs.robolectric.Robolectric;
 import com.xtremelabs.robolectric.WithTestDefaultsRunner;
 import org.junit.Test;
 import org.junit.runner.RunWith;
@@ -21,7 +20,7 @@ public class LooperTest {
 
     @Test
     public void idleMainLooper_executesScheduledTasks() {
-        final boolean[] wasRun = new boolean[] {false};
+        final boolean[] wasRun = new boolean[]{false};
         new Handler().postDelayed(new Runnable() {
             @Override
             public void run() {
diff --git a/src/test/java/com/xtremelabs/robolectric/util/SchedulerTest.java b/src/test/java/com/xtremelabs/robolectric/util/SchedulerTest.java
index 89675ccb0..2ecda5ef5 100644
--- a/src/test/java/com/xtremelabs/robolectric/util/SchedulerTest.java
+++ b/src/test/java/com/xtremelabs/robolectric/util/SchedulerTest.java
@@ -81,6 +81,19 @@ public class SchedulerTest {
         transcript.assertEventsSoFar(""three"");
     }
 
+    @Test
+    public void removeShouldRemoveAllInstancesOfRunnableFromQueue() throws Exception {
+        scheduler.post(new TestRunnable());
+        TestRunnable runnable = new TestRunnable();
+        scheduler.post(runnable);
+        scheduler.post(runnable);
+        assertThat(scheduler.enqueuedTaskCount(), equalTo(3));
+        scheduler.remove(runnable);
+        assertThat(scheduler.enqueuedTaskCount(), equalTo(1));
+        scheduler.advanceToLastPostedRunnable();
+        assertThat(runnable.wasRun, equalTo(false));
+    }
+
     @Test
     public void resetShouldUnPause() throws Exception {
         scheduler.pause();",Implement Handler # removeCallbacks,"""Implement removeCallbacks and getLooper methods in ShadowHandler""","""Implement Looper and Handler removeCallbacks functionality and add test cases for it""","""Added getLooper and removeCallbacks methods to ShadowHandler, updated Scheduler to handle removal of Runnables, and added corresponding tests""

Explanation:

* In ShadowHandler.java, two new methods (getLooper and removeCallbacks) have been added.
* In Scheduler.java, a new method (remove) has been added to handle the removal of Runnables from the postedRunnables list.
* In HandlerTest.java, a new test (testRemoveCallbacks) has been added to test the new removeCallbacks method in ShadowHandler.
* Some minor formatting changes have been made in HandlerTest.java and LooperTest.java.
* In SchedulerTest.java, a new test (removeShouldRemoveAllInstancesOfRunnableFromQueue) has been added to test the new remove method in Scheduler.","""Implemented removeCallbacks in ShadowHandler and added corresponding test cases; enhanced Scheduler to support removal of runnables.""",Model 2
"diff --git a/core/src/processing/core/PConstants.java b/core/src/processing/core/PConstants.java
index 46f5682a7..5d19fbec4 100644
--- a/core/src/processing/core/PConstants.java
+++ b/core/src/processing/core/PConstants.java
@@ -531,9 +531,9 @@ public interface PConstants {
   // hints - hint values are positive for the alternate version,
   // negative of the same value returns to the normal/default state
 
-  static final int DISABLE_OPENGL_2X_SMOOTH    =  1;
-  static final int ENABLE_OPENGL_2X_SMOOTH     = -1;
-  static final int ENABLE_OPENGL_4X_SMOOTH     =  2;
+//  static final int DISABLE_OPENGL_2X_SMOOTH    =  1;
+//  static final int ENABLE_OPENGL_2X_SMOOTH     = -1;
+//  static final int ENABLE_OPENGL_4X_SMOOTH     =  2;
 
   static final int ENABLE_NATIVE_FONTS         =  3;
   static final int DISABLE_NATIVE_FONTS         = -3;",removed opengl multi - sampling constants,"""Remove unused OpenGL smooth hint constants""","""Removed OpenGL 2X and 4X smooth rendering hints""","""Removed constants for disabling and enabling OpenGL 2x and 4x smooth in PConstants.java""",Commented out constants related to OpenGL smoothing in PConstants.java to disable 2X and 4X smoothing options.,Model 3
"diff --git a/htroot/Triple_p.html b/htroot/Triple_p.html
index f00d2cfa4..0765ebd0f 100644
--- a/htroot/Triple_p.html
+++ b/htroot/Triple_p.html
@@ -63,6 +63,15 @@
 	<h2>Query</h2>
 	<form action=""Triple_p.html"" method=""post"" enctype=""multipart/form-data"">
     
+    <textarea name=""query"" cols=""100"" rows=""10"">
+    #[query]#
+    </textarea>
+
+	<input type=""submit"" value=""Query"" />
+	
+	</form>
+	<form action=""Triple_p.csv"" method=""post"" enctype=""multipart/form-data"">
+    
     <textarea name=""query"" cols=""100"" rows=""10"">
     #[query]#
     </textarea>
diff --git a/htroot/Triple_p.java b/htroot/Triple_p.java
index 2662cbf28..c50df2067 100644
--- a/htroot/Triple_p.java
+++ b/htroot/Triple_p.java
@@ -40,13 +40,13 @@ public class Triple_p {
 		prop.put(""display"", 1); // Fixed to 1
 		prop.putHTML(""mode_output"", ""no query performed"");
 		
-		String q = ""PREFIX lln: <http://virtual.liebel-lab.org/n#>\n""+
+		String q = ""PREFIX lln: <http://virtual.x/>\n""+
 ""PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n""+
 ""PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n""+
 ""SELECT ?resource ?pa\n""+
 ""WHERE {\n""+
-	""?resource lln:percentageofarea ?pa .\n""+
-""FILTER (xsd:float (?pa) > 3.000)\n""+
+	""?resource lln:hasvalue ?pa .\n""+
+""FILTER (xsd:float (?pa) > 21.000)\n""+
 ""}"";
 
 		if (post != null) {
@@ -106,17 +106,29 @@ public class Triple_p {
 
 					prop.putHTML(""mode_rdfdump"", sos.toString());
 					
-
+					int scount = 0;
+					while (resultSet.hasNext()) {
+						QuerySolution s = resultSet.next();
+						prop.put(""entries_""+scount+""_s"", s.getResource(null).getURI());
+						prop.put(""entries_""+scount+""_p"", s.getResource(null).getURI());
+						prop.put(""entries_""+scount+""_o"", s.getResource(null).getURI());
+						scount ++;
+					}
 					
+					prop.putHTML(""entries"", """"+scount);
 					
 					for (String s: resultSet.getResultVars()) {
 						
 						prop.putHTML(""mode_output_""+count+""_caption"", s);
 						count ++;
 					}
+								
+					
 					 } catch (Exception e) {
 						 prop.putHTML(""mode_rdfdump"", ""error"");
 					 }
+					 
+					 
 									
 					prop.putHTML(""mode_output"", """"+count);
 
diff --git a/htroot/interaction/OverlayInteraction.html b/htroot/interaction/OverlayInteraction.html
index da7dee359..d3fea7278 100644
--- a/htroot/interaction/OverlayInteraction.html
+++ b/htroot/interaction/OverlayInteraction.html
@@ -52,9 +52,32 @@ border-bottom: 1px solid #ffffff;
 
 </div>
 
-<div id=""sidebar-document"" class=""sci_panel"" style=""top: 110px;"">
+<!-- <div id=""sidebar-document"" class=""sci_panel"" style=""top: 110px;"">
 
-<p>document</p> <img src=""/currentyacypeer/env/grafics/bad.png"" onclick=""contribution (document.location.href, 'like document', '#[username]#'); return false"">
+document <img src=""/currentyacypeer/env/grafics/bad.png"" width=""16px"" height=""16px"" onclick=""contribution (document.location.href, 'like document', '#[username]#'); return false"">
+
+</div> -->
+
+<div id=""sidebar-element"" class=""sci_panel"" style=""top: 110px;"">
+
+<input id=""SliderSingle"" type=""slider"" name=""price"" value=""20"" />
+
+<script type=""text/javascript"" charset=""utf-8"">
+	$(""#SliderSingle"").slider(
+		{
+			from: 0,
+			to: 100,
+			step: 2.5,
+			round: 1,
+			format: { format: '##.0', locale: 'de'},
+			dimension: '&nbsp;',
+			skin: 'round',
+			onstatechange: function(value) {
+				triple ('#[link]#', '#[link]#', 'http://virtual.x/hasvalue', value, '#[username]#');
+				}
+		}
+	);
+</script>
 
 </div>
 
diff --git a/htroot/yacysearchitem.html b/htroot/yacysearchitem.html
index de0086832..82e425ed1 100644
--- a/htroot/yacysearchitem.html
+++ b/htroot/yacysearchitem.html
@@ -2,7 +2,7 @@
   <div class=""searchresults"">
   <h4 class=""linktitle"">
   <img width=""16"" height=""16"" src=""ViewImage.png?width=16&amp;height=16&amp;code=#[faviconCode]#"" id=""f#[urlhash]#"" class=""favicon"" style=""width:16px; height:16px;"" alt="""" />
-  <a href=""#[link]#"" target=""#[target]#"">#[title]#</a></h4>
+  <a href=""#[link]#"" target=""#[target]#"">#[title]#</a> #[value]#</h4>
   <div class=""urlactions"">
     #(heuristic)#::
     <img width=""16"" height=""9"" src=""/env/grafics/heuristic_redundant.gif"" title=""heuristic:#[name]# (redundant)"" style=""width:16px; height:9px;"" alt=""heuristic:#[name]# (redundant)""/>::
diff --git a/htroot/yacysearchitem.java b/htroot/yacysearchitem.java
index 9604d2a5e..3c0f4d665 100644
--- a/htroot/yacysearchitem.java
+++ b/htroot/yacysearchitem.java
@@ -34,6 +34,7 @@ import net.yacy.cora.document.Classification.ContentDomain;
 import net.yacy.cora.protocol.HeaderFramework;
 import net.yacy.cora.protocol.RequestHeader;
 import net.yacy.cora.protocol.RequestHeader.FileType;
+import net.yacy.interaction.Interaction;
 import net.yacy.kelondro.data.meta.DigestURI;
 import net.yacy.kelondro.logging.Log;
 import net.yacy.kelondro.util.Formatter;
@@ -141,8 +142,44 @@ public class yacysearchitem {
             prop.putHTML(""content_title"", result.title());
             prop.putXML(""content_title-xml"", result.title());
             prop.putJSON(""content_title-json"", result.title());
-            prop.putHTML(""content_link"", resultUrlstring);
             prop.putHTML(""content_showPictures_link"", resultUrlstring);
+            //prop.putHTML(""content_link"", resultUrlstring);
+
+// START interaction
+            String modifyURL = resultUrlstring;
+			if (sb.getConfigBool(""proxyURL.useforresults"", false)) {
+				// check if url is allowed to view
+				if (sb.getConfig(""proxyURL.rewriteURLs"", ""all"").equals(""all"")) {
+					modifyURL = ""./proxy.html?url=""+modifyURL;
+				}
+
+				// check if url is allowed to view
+				if (sb.getConfig(""proxyURL.rewriteURLs"", ""all"").equals(""domainlist"")) {
+					try {
+						if (sb.crawlStacker.urlInAcceptedDomain(new DigestURI (modifyURL)) == null) {
+							modifyURL = ""./proxy.html?url=""+modifyURL;
+						}
+					} catch (MalformedURLException e) {
+						// TODO Auto-generated catch block
+						e.printStackTrace();
+					}
+				}
+
+				if (sb.getConfig(""proxyURL.rewriteURLs"", ""all"").equals(""yacy"")) {
+					try {
+						if ((new DigestURI (modifyURL).getHost().endsWith("".yacy""))) {
+							modifyURL = ""./proxy.html?url=""+modifyURL;
+						}
+					} catch (MalformedURLException e) {
+						// TODO Auto-generated catch block
+						e.printStackTrace();
+					}
+				}
+			}
+            prop.putHTML(""content_link"", modifyURL);
+            prop.putHTML(""content_value"", Interaction.getTriple(result.urlstring(), ""http://virtual.x/hasvalue""));
+// END interaction
+
             prop.putHTML(""content_target"", target);
             if (faviconURL != null && fileType == FileType.HTML) sb.loader.loadIfNotExistBackground(faviconURL, 1024 * 1024 * 10);
             prop.putHTML(""content_faviconCode"", sb.licensedURLs.aquireLicense(faviconURL)); // acquire license for favicon url loading
diff --git a/source/net/yacy/interaction/Interaction.java b/source/net/yacy/interaction/Interaction.java
index 285537b50..6bdf0b117 100644
--- a/source/net/yacy/interaction/Interaction.java
+++ b/source/net/yacy/interaction/Interaction.java
@@ -463,6 +463,23 @@ public static String Triple(String url, String s, String p, String o, String fro
 	return """";    
 }
 
+public static String getTriple(String s, String p) {
+
+	final Switchboard sb = Switchboard.getSwitchboard();
+
+	Resource r = TripleStore.model.getResource(s);
+	Property pr = TripleStore.model.getProperty(p);
+	
+	StmtIterator iter = TripleStore.model.listStatements(r, pr, (Resource) null);
+	
+	while (iter.hasNext()) {
+		return (iter.nextStatement().getObject().toString());
+	}
+	
+	return """";
+ 
+}
+
 public static String GetContribution(String url) {
 	
 	final Switchboard sb = Switchboard.getSwitchboard();",include value from interaction in search results .,"""Added interaction features and modified query functionality in Triple_p.html and yacysearchitem.html""","""Added query functionality and interaction elements to Triple_p.html, yacysearchitem.html, and OverlayInteraction.html, and implemented interaction logic in Interaction.java and yacysearchitem.java""","""Add form for query submission and update query prefix in Triple_p.html and Triple_p.java. Update interaction/OverlayInteraction.html to include slider input and yacysearchitem.html and yacysearchitem.java to display search result value. Add getTriple method in Interaction.java.""

Explanation:

* In Triple_p.html, a form for query submission has been added and the query prefix has been updated from ""<http://virtual.liebel-lab.org/n#>"" to ""<http://virtual.x/>"".
* In Triple_p.java, the query prefix has also been updated and a new method ""getTriple"" has been added to the ""Interaction"" class in source/net/yacy/interaction/Interaction.java.
* In interaction/OverlayInteraction.html, a slider input has been added for user interaction.
* In yacysearchitem.html and yacysearchitem.java, changes have been made to display the value of a search result.
* The commit message should summarize all these changes.","""Enhanced triple handling with custom queries, slider interaction, URL modification, and dynamic value display in search results.""",Model 3
"diff --git a/servers/src/main/java/tachyon/worker/block/BlockLockManager.java b/servers/src/main/java/tachyon/worker/block/BlockLockManager.java
index 5f68466571..88f4e7123c 100644
--- a/servers/src/main/java/tachyon/worker/block/BlockLockManager.java
+++ b/servers/src/main/java/tachyon/worker/block/BlockLockManager.java
@@ -4,9 +4,9 @@
  * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
  * ""License""); you may not use this file except in compliance with the License. You may obtain a
  * copy of the License at
- * 
+ *
  * http://www.apache.org/licenses/LICENSE-2.0
- * 
+ *
  * Unless required by applicable law or agreed to in writing, software distributed under the License
  * is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
  * or implied. See the License for the specific language governing permissions and limitations under
diff --git a/servers/src/main/java/tachyon/worker/block/BlockServiceHandler.java b/servers/src/main/java/tachyon/worker/block/BlockServiceHandler.java
index de28f47c74..b30f7fdfdc 100644
--- a/servers/src/main/java/tachyon/worker/block/BlockServiceHandler.java
+++ b/servers/src/main/java/tachyon/worker/block/BlockServiceHandler.java
@@ -22,6 +22,7 @@ import org.apache.thrift.TException;
 
 import tachyon.Users;
 import tachyon.thrift.FileAlreadyExistException;
+import tachyon.thrift.FileDoesNotExistException;
 import tachyon.thrift.OutOfSpaceException;
 import tachyon.thrift.TachyonException;
 import tachyon.thrift.WorkerService;
@@ -233,7 +234,7 @@ public class BlockServiceHandler implements WorkerService.Iface {
       long lockId = mWorker.lockBlock(userId, blockId);
       return mWorker.readBlock(userId, blockId, lockId);
     } catch (IOException ioe) {
-      throw new TException(ioe);
+      throw new FileDoesNotExistException(""Block "" + blockId + "" does not exist on this worker."");
     }
   }
 
@@ -273,7 +274,7 @@ public class BlockServiceHandler implements WorkerService.Iface {
       // TODO: Maybe add a constant for anyTier?
       return mWorker.createBlock(userId, blockId, 1, initialBytes);
     } catch (IOException ioe) {
-      throw new TException(ioe);
+      throw new OutOfSpaceException(""Failed to allocate "" + initialBytes + "" for user "" + userId);
     }
   }
 
@@ -291,7 +292,7 @@ public class BlockServiceHandler implements WorkerService.Iface {
       mWorker.requestSpace(userId, blockId, requestBytes);
       return true;
     } catch (IOException ioe) {
-      throw new TException(ioe);
+      return false;
     }
   }
 
diff --git a/servers/src/main/java/tachyon/worker/block/meta/StorageDir.java b/servers/src/main/java/tachyon/worker/block/meta/StorageDir.java
index 0bc0c67f70..b829aab743 100644
--- a/servers/src/main/java/tachyon/worker/block/meta/StorageDir.java
+++ b/servers/src/main/java/tachyon/worker/block/meta/StorageDir.java
@@ -4,9 +4,9 @@
  * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
  * ""License""); you may not use this file except in compliance with the License. You may obtain a
  * copy of the License at
- * 
+ *
  * http://www.apache.org/licenses/LICENSE-2.0
- * 
+ *
  * Unless required by applicable law or agreed to in writing, software distributed under the License
  * is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
  * or implied. See the License for the specific language governing permissions and limitations under
@@ -257,6 +257,7 @@ public class StorageDir {
           mUserIdToTempBlockIdsMap.remove(userId);
         }
         reclaimSpace(tempBlockMeta.getBlockSize());
+        return;
       }
     }
     throw new IOException(""Failed to remove TempBlockMeta: No owner userId associated"");",Fix some exceptions in block service handler .,"""Improve error handling in BlockServiceHandler and StorageDir""

This commit message is short and to the point, indicating that the changes made were related to improving error handling in the specified classes.","""Improved error handling in BlockServiceHandler and StorageDir classes""","""Update copyright headers and add file does not exist exception in BlockServiceHandler""

This commit updates the copyright headers in two Java files, BlockLockManager.java and BlockServiceHandler.java, by adding the missing Apache License, Version 2.0 disclaimer.

In addition, it modifies the BlockServiceHandler class to throw a FileDoesNotExistException instead of a generic TException when a requested block is not found on the worker. It also updates the method that creates a new block to throw an OutOfSpaceException instead of a TException when there is not enough space to allocate the requested bytes for the user. Finally, it updates the method that requests additional space for a block to return a boolean value indicating whether the request was successful or not, instead of throwing a TException.

Overall, this commit improves error handling and provides more specific error messages to clients.",Fixed exception handling in BlockServiceHandler and corrected license URL formatting in Java files.,Model 4
"diff --git a/core/src/main/java/bisq/core/dao/monitoring/DaoStateMonitoringService.java b/core/src/main/java/bisq/core/dao/monitoring/DaoStateMonitoringService.java
index f99d7ea355..5abf862979 100644
--- a/core/src/main/java/bisq/core/dao/monitoring/DaoStateMonitoringService.java
+++ b/core/src/main/java/bisq/core/dao/monitoring/DaoStateMonitoringService.java
@@ -20,6 +20,7 @@ package bisq.core.dao.monitoring;
 import bisq.core.dao.DaoSetupService;
 import bisq.core.dao.monitoring.model.DaoStateBlock;
 import bisq.core.dao.monitoring.model.DaoStateHash;
+import bisq.core.dao.monitoring.model.UtxoMismatch;
 import bisq.core.dao.monitoring.network.DaoStateNetworkService;
 import bisq.core.dao.monitoring.network.messages.GetDaoStateHashesRequest;
 import bisq.core.dao.monitoring.network.messages.NewDaoStateHashMessage;
@@ -40,6 +41,9 @@ import javax.inject.Inject;
 
 import org.apache.commons.lang3.ArrayUtils;
 
+import javafx.collections.FXCollections;
+import javafx.collections.ObservableList;
+
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Optional;
@@ -88,6 +92,8 @@ public class DaoStateMonitoringService implements DaoSetupService, DaoStateListe
     private boolean parseBlockChainComplete;
     @Getter
     private boolean isInConflict;
+    @Getter
+    private ObservableList<UtxoMismatch> utxoMismatches = FXCollections.observableArrayList();
 
 
     ///////////////////////////////////////////////////////////////////////////////////////////
@@ -142,13 +148,13 @@ public class DaoStateMonitoringService implements DaoSetupService, DaoStateListe
         long totalBurntFee = daoStateService.getTotalBurntFee();
         long compensationIssuance = daoStateService.getTotalIssuedAmount(IssuanceType.COMPENSATION);
         long reimbursementIssuance = daoStateService.getTotalIssuedAmount(IssuanceType.REIMBURSEMENT);
-        long totalConfiscatedAmount = daoStateService.getTotalAmountOfConfiscatedTxOutputs();
+        long totalInvalidAmount = daoStateService.getBurnedBsqOfAllInvalidTxs();
         // confiscated funds are still in the utxo set
         long sumUtxo = daoStateService.getUnspentTxOutputMap().values().stream().mapToLong(BaseTxOutput::getValue).sum();
-        long sumBsq = genesisTotalSupply + compensationIssuance + reimbursementIssuance - totalBurntFee;
+        long sumBsq = genesisTotalSupply + compensationIssuance + reimbursementIssuance - totalBurntFee - totalInvalidAmount;
 
         if (sumBsq != sumUtxo) {
-            throw new RuntimeException(""There is a mismatch between the UTXO set and the DAO state. Please contact the Bisq devlopers."");
+            utxoMismatches.add(new UtxoMismatch(block.getHeight(), sumUtxo, sumBsq));
         }
     }
 
diff --git a/core/src/main/java/bisq/core/dao/monitoring/model/UtxoMismatch.java b/core/src/main/java/bisq/core/dao/monitoring/model/UtxoMismatch.java
new file mode 100644
index 0000000000..1509023c92
--- /dev/null
+++ b/core/src/main/java/bisq/core/dao/monitoring/model/UtxoMismatch.java
@@ -0,0 +1,33 @@
+/*
+ * This file is part of Bisq.
+ *
+ * Bisq is free software: you can redistribute it and/or modify it
+ * under the terms of the GNU Affero General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or (at
+ * your option) any later version.
+ *
+ * Bisq is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE. See the GNU Affero General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with Bisq. If not, see <http://www.gnu.org/licenses/>.
+ */
+
+package bisq.core.dao.monitoring.model;
+
+import lombok.Value;
+
+@Value
+public class UtxoMismatch {
+    private final int height;
+    private final long sumUtxo;
+    private final long sumBsq;
+
+    public UtxoMismatch(int height, long sumUtxo, long sumBsq) {
+        this.height = height;
+        this.sumUtxo = sumUtxo;
+        this.sumBsq = sumBsq;
+    }
+}
diff --git a/desktop/src/main/java/bisq/desktop/main/dao/monitor/daostate/DaoStateMonitorView.java b/desktop/src/main/java/bisq/desktop/main/dao/monitor/daostate/DaoStateMonitorView.java
index e5b9cb79d1..722a44684f 100644
--- a/desktop/src/main/java/bisq/desktop/main/dao/monitor/daostate/DaoStateMonitorView.java
+++ b/desktop/src/main/java/bisq/desktop/main/dao/monitor/daostate/DaoStateMonitorView.java
@@ -19,6 +19,7 @@ package bisq.desktop.main.dao.monitor.daostate;
 
 import bisq.desktop.common.view.FxmlView;
 import bisq.desktop.main.dao.monitor.StateMonitorView;
+import bisq.desktop.main.overlays.Overlay;
 import bisq.desktop.main.overlays.popups.Popup;
 import bisq.desktop.util.FormBuilder;
 
@@ -28,11 +29,16 @@ import bisq.core.dao.governance.period.PeriodService;
 import bisq.core.dao.monitoring.DaoStateMonitoringService;
 import bisq.core.dao.monitoring.model.DaoStateBlock;
 import bisq.core.dao.monitoring.model.DaoStateHash;
+import bisq.core.dao.monitoring.model.UtxoMismatch;
 import bisq.core.dao.state.DaoStateService;
 import bisq.core.locale.Res;
 
+import bisq.common.util.Utilities;
+
 import javax.inject.Inject;
 
+import javafx.collections.ListChangeListener;
+
 import java.util.Map;
 import java.util.stream.Collectors;
 
@@ -40,6 +46,9 @@ import java.util.stream.Collectors;
 public class DaoStateMonitorView extends StateMonitorView<DaoStateHash, DaoStateBlock, DaoStateBlockListItem, DaoStateInConflictListItem>
         implements DaoStateMonitoringService.Listener {
     private final DaoStateMonitoringService daoStateMonitoringService;
+    private ListChangeListener<UtxoMismatch> utxoMismatchListChangeListener;
+    private Overlay warningPopup;
+
 
     ///////////////////////////////////////////////////////////////////////////////////////////
     // Constructor, lifecycle
@@ -59,6 +68,8 @@ public class DaoStateMonitorView extends StateMonitorView<DaoStateHash, DaoState
 
     @Override
     public void initialize() {
+        utxoMismatchListChangeListener = c -> updateUtxoMismatches();
+
         FormBuilder.addTitledGroupBg(root, gridRow, 3, Res.get(""dao.monitor.daoState.headline""));
 
         statusTextField = FormBuilder.addTopLabelTextField(root, ++gridRow,
@@ -71,7 +82,11 @@ public class DaoStateMonitorView extends StateMonitorView<DaoStateHash, DaoState
     @Override
     protected void activate() {
         super.activate();
+
         daoStateMonitoringService.addListener(this);
+        daoStateMonitoringService.getUtxoMismatches().addListener(utxoMismatchListChangeListener);
+
+        updateUtxoMismatches();
 
         resyncButton.setOnAction(e -> daoFacade.resyncDao(() ->
                 new Popup<>().attention(Res.get(""setting.preferences.dao.resync.popup""))
@@ -84,7 +99,9 @@ public class DaoStateMonitorView extends StateMonitorView<DaoStateHash, DaoState
     @Override
     protected void deactivate() {
         super.deactivate();
+
         daoStateMonitoringService.removeListener(this);
+        daoStateMonitoringService.getUtxoMismatches().removeListener(utxoMismatchListChangeListener);
     }
 
 
@@ -185,4 +202,28 @@ public class DaoStateMonitorView extends StateMonitorView<DaoStateHash, DaoState
     protected void requestHashesFromGenesisBlockHeight(String peerAddress) {
         daoStateMonitoringService.requestHashesFromGenesisBlockHeight(peerAddress);
     }
+
+
+    ///////////////////////////////////////////////////////////////////////////////////////////
+    // Private
+    ///////////////////////////////////////////////////////////////////////////////////////////
+
+    private void updateUtxoMismatches() {
+        if (!daoStateMonitoringService.getUtxoMismatches().isEmpty()) {
+            StringBuilder sb = new StringBuilder();
+            daoStateMonitoringService.getUtxoMismatches().forEach(e -> {
+                sb.append(""\n"").append(Res.get(""dao.monitor.daoState.utxoConflicts.blockHeight"", e.getHeight())).append(""\n"")
+                        .append(Res.get(""dao.monitor.daoState.utxoConflicts.sumUtxo"", e.getSumUtxo() / 100)).append(""\n"")
+                        .append(Res.get(""dao.monitor.daoState.utxoConflicts.sumBsq"", e.getSumBsq() / 100));
+            });
+
+            if (warningPopup == null) {
+                warningPopup = new Popup<>().headLine(Res.get(""dao.monitor.daoState.utxoConflicts""))
+                        .warning(Utilities.toTruncatedString(sb.toString(), 500, false)).onClose(() -> {
+                            warningPopup = null;
+                        });
+                warningPopup.show();
+            }
+        }
+    }
 }",Add popup in case the utxo balance does not match the bsq balance,"""Add UTXO mismatch detection and display in DAO state monitor""","""Added UTXO mismatch detection and display in DaoStateMonitorView""","""Add UTXO mismatch tracking and display in DaoStateMonitoringService and DaoStateMonitorView""

Explanation:

* The commit adds a new class `UtxoMismatch` in `bisq/core/dao/monitoring/model/UtxoMismatch.java` to represent UTXO mismatches.
* It adds a new `ObservableList<UtxoMismatch>` field `utxoMismatches` in `DaoStateMonitoringService` and updates it when there is a mismatch between the UTXO set and the DAO state.
* It adds a new `ListChangeListener<UtxoMismatch>` field `utxoMismatchListChangeListener` in `DaoStateMonitorView` and updates the UI when there are UTXO mismatches.
* It adds a new method `updateUtxoMismatches()` in `DaoStateMonitorView` to create and display a popup warning when there are UTXO mismatches.
* It adds code in `DaoStateMonitorView.activate()` to listen for changes in `utxoMismatches` and in `DaoStateMonitorView.deactivate()` to stop listening for changes.

Overall, the commit adds functionality to track and display UTXO mismatches in the Bisq DAO state monitoring service and view.",Add UTXO mismatch detection and display in DAO state monitor view for better conflict visibility.,Model 1
"diff --git a/pom.xml b/pom.xml
index 772d7ef6578..d28060f8cd7 100644
--- a/pom.xml
+++ b/pom.xml
@@ -47,6 +47,7 @@
         <tests.heap.size>512m</tests.heap.size>
         <tests.heapdump.path>${basedir}/logs/</tests.heapdump.path>
         <tests.topn>5</tests.topn>
+        <jvm.executable>${java.home}${file.separator}bin${file.separator}java</jvm.executable>
         <execution.hint.file>.local-${project.version}-execution-hints.log</execution.hint.file>
 
         <!-- Properties used for building RPM & DEB packages (see common/packaging.properties) -->
@@ -444,7 +445,7 @@
               </execution>
             </executions>
             <configuration>
-              <executable>java</executable>
+              <executable>${jvm.executable></executable>
               <arguments>
                 <argument>-classpath</argument>
                 <classpath/>
@@ -516,6 +517,7 @@
                             <goal>junit4</goal>
                         </goals>",Execute tests with $ JAVA_HOME .,"""Specify JVM executable path for test execution""","The commit message should be:

""Added JVM executable path configuration for tests""

This message accurately reflects the changes made in the commit, which involve adding a new configuration option for the JVM executable path in the `pom.xml` file.","""Added jvm.executable property and updated Maven Surefire Plugin configuration to use it""

This commit adds a new property `jvm.executable` in the pom.xml file, which specifies the path to the Java executable. The value of this property is then used to update the configuration of the Maven Surefire Plugin, which is used to run the JUnit tests. Specifically, the `<executable>` element in the plugin configuration is updated to use the value of the `jvm.executable` property. This change ensures that the correct Java executable is used to run the tests, which can be useful when there are multiple JDKs installed on the system.",Update POM to use configurable JVM executable path to ensure proper Java location during builds and executions.,Model 4
"diff --git a/.github/issue_template.md b/.github/issue_template.md
index 23d1c7d33b..55dca93962 100644
--- a/.github/issue_template.md
+++ b/.github/issue_template.md
@@ -1,13 +1,3 @@
-###### Research
-*Enter an [ x ] character to confirm the points below:*
-
-[  ] I have read the [support page](https://ankidroid.org/docs/help.html) and am reporting a bug or enhancement request specific to AnkiDroid
-
-[  ] I have checked the [manual](https://ankidroid.org/docs/manual.html) and the [FAQ](https://github.com/ankidroid/Anki-Android/wiki/FAQ) and could not find a solution to my issue
-
-[  ] I have searched for similar existing issues here and on the user forum
-
-
 ###### Reproduction Steps
 
 1. 
@@ -26,4 +16,12 @@
 ###### Debug info
 Refer to the [support page](https://ankidroid.org/docs/help.html) if you are unsure where to get the ""debug info"".
 
+###### Research
+*Enter an [ x ] character to confirm the points below:*
+
+[  ] I have read the [support page](https://ankidroid.org/docs/help.html) and am reporting a bug or enhancement request specific to AnkiDroid
+
+[  ] I have checked the [manual](https://ankidroid.org/docs/manual.html) and the [FAQ](https://github.com/ankidroid/Anki-Android/wiki/FAQ) and could not find a solution to my issue
+
+[  ] I have searched for similar existing issues here and on the user forum
 
diff --git a/.github/pull_request_template.md b/.github/pull_request_template.md
index f1d7d7a8cf..8c621e16d7 100644
--- a/.github/pull_request_template.md
+++ b/.github/pull_request_template.md
@@ -1,13 +1,5 @@
 ## Pull Request template
 
-Please, go through these checks before you submit a PR.
-
-- [ ] You have not changed whitespace unnecessarily (it makes diffs hard to read)
-- [ ] You have a descriptive commit message with a short title (first line, max 50 chars).
-- [ ] Your code follows the style of the project (e.g. never omit braces in `if` statements) 
-- [ ] You have commented your code, particularly in hard-to-understand areas
-- [ ] You have performed a self-review of your own code
-
 ## Purpose / Description
 _Describe the problem or feature and motivation_
 
@@ -25,3 +17,12 @@ Please describe the tests that you ran to verify your changes. Provide instructi
 _Describe the research stage_
 
 _Links to blog posts, patterns, libraries or addons used to solve this problem_
+
+## Checklist
+_Please, go through these checks before submitting the PR._
+
+- [ ] You have not changed whitespace unnecessarily (it makes diffs hard to read)
+- [ ] You have a descriptive commit message with a short title (first line, max 50 chars).
+- [ ] Your code follows the style of the project (e.g. never omit braces in `if` statements) 
+- [ ] You have commented your code, particularly in hard-to-understand areas
+- [ ] You have performed a self-review of your own code",Move the checklists in the templates to the bottom .,"""Reorder and reformat issue and pull request templates for consistency""","""Restored pull request and issue templates to their original state.""","It appears that you have made changes to two files in your Git repository:

1. `.github/issue_template.md`
2. `.github/pull_request_template.md`

In the first file, you have removed a section related to research steps and moved it to the end of the file. In the second file, you have removed a checklist section and added it back at the end of the file.

Based on the changes made, a suitable commit message could be:

`Refactor issue and pull request templates for improved structure`

This commit message summarizes the changes made to the two files and provides a clear description of the purpose of the changes.","The commit message should be:

""Reorganize issue and pull request templates to improve clarity and ensure completion checks are performed at the end""",Model 1
"diff --git a/presto-main/src/test/java/com/facebook/presto/operator/scalar/TestRegexpFunctions.java b/presto-main/src/test/java/com/facebook/presto/operator/scalar/TestRegexpFunctions.java
index 52deae518b..a1d24f34a6 100644
--- a/presto-main/src/test/java/com/facebook/presto/operator/scalar/TestRegexpFunctions.java
+++ b/presto-main/src/test/java/com/facebook/presto/operator/scalar/TestRegexpFunctions.java
@@ -30,6 +30,7 @@ import java.util.List;
 
 import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;
 import static com.facebook.presto.spi.type.BooleanType.BOOLEAN;
+import static com.facebook.presto.spi.type.VarcharType.createUnboundedVarcharType;
 import static com.facebook.presto.spi.type.VarcharType.createVarcharType;
 import static com.facebook.presto.sql.analyzer.RegexLibrary.JONI;
 import static com.facebook.presto.sql.analyzer.RegexLibrary.RE2J;
@@ -133,6 +134,8 @@ public class TestRegexpFunctions
         assertInvalidFunction(""REGEXP_REPLACE('xxx', '(?<name>x)', '${}')"", INVALID_FUNCTION_ARGUMENT);
         assertInvalidFunction(""REGEXP_REPLACE('xxx', '(?<name>x)', '${0}')"", INVALID_FUNCTION_ARGUMENT);
         assertInvalidFunction(""REGEXP_REPLACE('xxx', '(?<name>x)', '${nam}')"", INVALID_FUNCTION_ARGUMENT);
+
+        assertFunction(""REGEXP_REPLACE(VARCHAR 'x', '.*', 'xxxxx')"", createUnboundedVarcharType(), ""xxxxxxxxxx"");
     }
 
     @Test",Migrate product verification failing test to unit test case,"""Add test for REGEXP_REPLACE with unbounded varchar type""","According to the diff, the commit message should be:

""Add support for unbounded VARCHAR type in REGEXP_REPLACE function""

This message accurately reflects the changes made in the commit, which include adding the `createUnboundedVarcharType` import and a new test case for the `REGEXP_REPLACE` function with an unbounded VARCHAR type.","It looks like you're working with a code change in a Git repository and you're looking for a commit message. A suitable commit message for this change could be:

```
Add test case for REGEXP_REPLACE with unbounded VarcharType

This commit adds a new test case for the REGEXP_REPLACE function with an unbounded VarcharType input and output.
```

This commit message follows the convention of a short summary (50 characters or less), followed by a blank line and a more detailed explanation. The detailed explanation helps others understand the motivation for the change and can be particularly useful for larger or more complex changes.",Add a test for REGEXP_REPLACE with unbounded VARCHAR in TestRegexpFunctions.,Model 4
"diff --git a/docs/source/about/release-notes.rst b/docs/source/about/release-notes.rst
index 8a5a7dfe0..b3c053287 100644
--- a/docs/source/about/release-notes.rst
+++ b/docs/source/about/release-notes.rst
@@ -31,6 +31,7 @@ v0.3.0-SNAPSHOT
   require applications to open a single port.
 * Added ``http.adminUsername`` and ``http.adminPassword`` to allow for Basic HTTP Authentication
   for the admin servlet.
+* Upgraded to Metrics 2.1.0.
 
 .. _rel-0.2.1:",Updated relnotes .,"""Update release notes for v0.3.0-SNAPSHOT""","""Upgrade to Metrics 2.1.0 and add admin authentication""","It seems like you're working with a version control system, possibly Git, and you're looking at a diff of a file related to release notes for a software project. The change you've made is adding a line indicating that the project has been upgraded to Metrics 2.1.0.

As for the commit message, it's typically a brief summary of the changes made. Given the changes you've shown, a suitable commit message might be: ""Upgraded to Metrics 2.1.0 and added Basic HTTP Authentication for admin servlet"". However, without more context, it's hard to provide a more specific suggestion.","""Added support for Basic HTTP Authentication with admin credentials and upgraded Metrics to version 2.1.0.""",Model 4
"diff --git a/res/layout/addfeed.xml b/res/layout/addfeed.xml
index 7036bcbf9..016bc621f 100644
--- a/res/layout/addfeed.xml
+++ b/res/layout/addfeed.xml
@@ -1,32 +1,47 @@
 <?xml version=""1.0"" encoding=""utf-8""?>
-<LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
-	android:layout_width=""fill_parent""
-	android:layout_height=""fill_parent""
-	android:orientation=""vertical"" >
-	<TextView
-		android:id=""@+id/txtvFeedurl""
-		android:text=""@string/feedurl_label""
-		android:layout_width=""fill_parent""
-		android:layout_height=""wrap_content""
-		/>
-	<EditText android:id=""@+id/etxtFeedurl""
-		android:layout_width=""fill_parent""
+<RelativeLayout xmlns:android=""http://schemas.android.com/apk/res/android""
+    android:layout_width=""fill_parent""
+    android:layout_height=""fill_parent""
+    android:orientation=""vertical"" >
+
+    <TextView
+        android:id=""@+id/txtvFeedurl""
+        android:layout_width=""fill_parent""
         android:layout_height=""wrap_content""
-        android:autoText=""false""
-        android:capitalize=""none""/>
-	<LinearLayout
-		android:layout_width=""match_parent""
-		android:layout_height=""wrap_content""
-		android:orientation=""horizontal"">
-		<Button android:id=""@+id/butConfirm""
-			android:text=""@string/confirm_label""
-			android:layout_width=""0px""
-			android:layout_height=""wrap_content""
-			android:layout_weight=""1""/>
-		<Button android:id=""@+id/butCancel""
-			android:layout_width=""0px""
-			android:layout_height=""wrap_content""
-			android:layout_weight=""1""
-			android:text=""@string/cancel_label""/>
-	</LinearLayout>
-</LinearLayout>
+        android:layout_alignParentTop=""true""
+        android:layout_margin=""8dp""
+        android:text=""@string/txtvfeedurl_label"" />
+
+    <EditText
+        android:id=""@+id/etxtFeedurl""
+        android:layout_width=""fill_parent""
+        android:layout_height=""wrap_content""
+        android:layout_below=""@id/txtvFeedurl""
+        android:layout_margin=""8dp""
+        android:hint=""@string/feedurl_label""
+        android:inputType=""textUri"" />
+
+    <LinearLayout
+        android:id=""@+id/footer""
+        style=""@android:style/ButtonBar""
+        android:layout_width=""fill_parent""
+        android:layout_height=""wrap_content""
+        android:layout_alignParentBottom=""true""
+        android:orientation=""horizontal"" >
+
+        <Button
+            android:id=""@+id/butConfirm""
+            android:layout_width=""0px""
+            android:layout_height=""wrap_content""
+            android:layout_weight=""1""
+            android:text=""@string/confirm_label"" />
+
+        <Button
+            android:id=""@+id/butCancel""
+            android:layout_width=""0px""
+            android:layout_height=""wrap_content""
+            android:layout_weight=""1""
+            android:text=""@string/cancel_label"" />
+    </LinearLayout>
+
+</RelativeLayout>
\ No newline at end of file
diff --git a/res/values/strings.xml b/res/values/strings.xml
index 138ca38d6..1c8f382a1 100644
--- a/res/values/strings.xml
+++ b/res/values/strings.xml
@@ -67,5 +67,6 @@
     <string name=""error_label"">Error</string>
     <string name=""error_msg_prefix"">An error occured:</string>
     <string name=""download_error_connection_error"">Connection error</string>
+    <string name=""txtvfeedurl_label"">Type in the URL of the Feed here:</string>
 
 </resources>
\ No newline at end of file",Improved layout of Addfeedactivity,"""Refactor add feed layout to use RelativeLayout and improve UI""

This commit message is short and to the point, indicating that the layout of the add feed feature has been refactored to use a RelativeLayout, which likely improves the user interface.","""Refactor add feed layout to use RelativeLayout and improve UI""

Alternatively, you could also use:

* ""Migrate add feed layout to RelativeLayout""
* ""Improve add feed layout UI with RelativeLayout""
* ""Enhance add feed layout with RelativeLayout and string resource updates""

These commit messages are concise and accurately describe the changes made in the commit.","""Updated addfeed.xml layout and added new string resource for feed URL label""

Explanation:
The changes made in this commit are as follows:

1. The layout for the `addfeed.xml` file has been updated from a `LinearLayout` to a `RelativeLayout`. Some properties and elements have been modified, added, or removed to improve the layout design.
2. A new string resource has been added to the `strings.xml` file with the name ""txtvfeedurl_label"".

Based on these changes, a suitable commit message would be: ""Updated addfeed.xml layout and added new string resource for feed URL label"". This message summarizes the changes made in this commit.","""Changed layout to RelativeLayout, updated string resources, and aligned UI elements properly in addfeed.xml.""",Model 3
"diff --git a/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocument.java b/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocument.java
index 492910291a..2fdb99ba99 100755
--- a/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocument.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocument.java
@@ -335,6 +335,11 @@ public interface ODatabaseDocument extends ODatabase<ORecord> {
 
   OElement newElement(final String className);
 
+  OElement newEmbeddedElement();
+
+  OElement newEmbeddedElement(final String className);
+
+
   /**
    * Creates a new Edge of type E
    *
diff --git a/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocumentAbstract.java b/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocumentAbstract.java
index 4ac4f5892e..2d59eee968 100755
--- a/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocumentAbstract.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocumentAbstract.java
@@ -1420,6 +1420,16 @@ public abstract class ODatabaseDocumentAbstract extends OListenerManger<ODatabas
     return new ODocument(this, iClassName);
   }
 
+  @Override
+  public OElement newEmbeddedElement() {
+    return new ODocumentEmbedded(this);
+  }
+
+  @Override
+  public OElement newEmbeddedElement(String className) {
+    return new ODocumentEmbedded(className, this);
+  }
+
   @Override
   public OElement newElement() {
     return newInstance();
diff --git a/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocumentTx.java b/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocumentTx.java
index 2483bb49b0..18916e2b06 100755
--- a/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocumentTx.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocumentTx.java
@@ -528,6 +528,18 @@ public class ODatabaseDocumentTx implements ODatabaseDocumentInternal {
     return internal.newElement(className);
   }
 
+  @Override
+  public OElement newEmbeddedElement() {
+    checkOpenness();
+    return internal.newEmbeddedElement();
+  }
+
+  @Override
+  public OElement newEmbeddedElement(String className) {
+    checkOpenness();
+    return internal.newEmbeddedElement(className);
+  }
+
   public boolean isUseLightweightEdges() {
     return internal.isUseLightweightEdges();
   }
diff --git a/core/src/main/java/com/orientechnologies/orient/core/record/impl/ODocumentEmbedded.java b/core/src/main/java/com/orientechnologies/orient/core/record/impl/ODocumentEmbedded.java
new file mode 100644
index 0000000000..ec501c55eb
--- /dev/null
+++ b/core/src/main/java/com/orientechnologies/orient/core/record/impl/ODocumentEmbedded.java
@@ -0,0 +1,27 @@
+package com.orientechnologies.orient.core.record.impl;
+
+import com.orientechnologies.orient.core.db.ODatabaseSession;
+
+public class ODocumentEmbedded extends ODocument {
+
+  public ODocumentEmbedded() {
+    super();
+  }
+
+  public ODocumentEmbedded(String clazz) {
+    super(clazz);
+  }
+
+  public ODocumentEmbedded(String clazz, ODatabaseSession session) {
+    super(clazz, session);
+  }
+
+  public ODocumentEmbedded(ODatabaseSession session) {
+    super(session);
+  }
+
+  @Override
+  public boolean isEmbedded() {
+    return true;
+  }
+}
diff --git a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV0.java b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV0.java
index 137e72e683..aeed61a7c6 100755
--- a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV0.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV0.java
@@ -35,6 +35,7 @@ import com.orientechnologies.orient.core.metadata.schema.*;
 import com.orientechnologies.orient.core.metadata.security.OPropertyEncryption;
 import com.orientechnologies.orient.core.record.ORecordInternal;
 import com.orientechnologies.orient.core.record.impl.ODocument;
+import com.orientechnologies.orient.core.record.impl.ODocumentEmbedded;
 import com.orientechnologies.orient.core.record.impl.ODocumentEntry;
 import com.orientechnologies.orient.core.record.impl.ODocumentInternal;
 import com.orientechnologies.orient.core.serialization.ODocumentSerializable;
@@ -399,7 +400,7 @@ public class ORecordSerializerBinaryV0 implements ODocumentSerializer {
   }
 
   protected Object deserializeEmbeddedAsDocument(final BytesContainer bytes, final ORecordElement owner) {
-    Object value = new ODocument();
+    Object value = new ODocumentEmbedded();
     deserializeWithClassName((ODocument) value, bytes);
     if (((ODocument) value).containsField(ODocumentSerializable.CLASS_NAME)) {
       String className = ((ODocument) value).field(ODocumentSerializable.CLASS_NAME);
diff --git a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV1.java b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV1.java
index b615e0f21e..7e4dd53b32 100755
--- a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV1.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV1.java
@@ -15,6 +15,7 @@ import com.orientechnologies.orient.core.metadata.schema.*;
 import com.orientechnologies.orient.core.metadata.security.OPropertyEncryption;
 import com.orientechnologies.orient.core.record.ORecordInternal;
 import com.orientechnologies.orient.core.record.impl.ODocument;
+import com.orientechnologies.orient.core.record.impl.ODocumentEmbedded;
 import com.orientechnologies.orient.core.record.impl.ODocumentEntry;
 import com.orientechnologies.orient.core.record.impl.ODocumentInternal;
 import com.orientechnologies.orient.core.serialization.ODocumentSerializable;
@@ -1014,7 +1015,7 @@ public class ORecordSerializerBinaryV1 implements ODocumentSerializer {
   }
 
   protected Object deserializeEmbeddedAsDocument(final BytesContainer bytes, final ORecordElement owner) {
-    Object value = new ODocument();
+    Object value = new ODocumentEmbedded();
     deserializeWithClassName((ODocument) value, bytes);
     if (((ODocument) value).containsField(ODocumentSerializable.CLASS_NAME)) {
       String className = ((ODocument) value).field(ODocumentSerializable.CLASS_NAME);
diff --git a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerNetworkV0.java b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerNetworkV0.java
index 91405dc875..830cd10bc8 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerNetworkV0.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerNetworkV0.java
@@ -38,6 +38,7 @@ import com.orientechnologies.orient.core.metadata.security.OPropertyEncryption;
 import com.orientechnologies.orient.core.record.ORecord;
 import com.orientechnologies.orient.core.record.ORecordInternal;
 import com.orientechnologies.orient.core.record.impl.ODocument;
+import com.orientechnologies.orient.core.record.impl.ODocumentEmbedded;
 import com.orientechnologies.orient.core.record.impl.ODocumentEntry;
 import com.orientechnologies.orient.core.record.impl.ODocumentInternal;
 import com.orientechnologies.orient.core.serialization.ODocumentSerializable;
@@ -315,7 +316,7 @@ public class ORecordSerializerNetworkV0 implements ODocumentSerializer {
       value = new Date(savedTime);
       break;
     case EMBEDDED:
-      value = new ODocument();
+      value = new ODocumentEmbedded();
       deserialize((ODocument) value, bytes);
       if (((ODocument) value).containsField(ODocumentSerializable.CLASS_NAME)) {
         String className = ((ODocument) value).field(ODocumentSerializable.CLASS_NAME);
diff --git a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerNetworkV37.java b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerNetworkV37.java
index 01f997caaf..500bac9316 100755
--- a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerNetworkV37.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerNetworkV37.java
@@ -251,7 +251,7 @@ public class ORecordSerializerNetworkV37 implements ORecordSerializer {
       value = new Date(savedTime);
       break;
     case EMBEDDED:
-      value = new ODocument();
+      value = new ODocumentEmbedded();
       deserialize((ODocument) value, bytes);
       if (((ODocument) value).containsField(ODocumentSerializable.CLASS_NAME)) {
         String className = ((ODocument) value).field(ODocumentSerializable.CLASS_NAME);
diff --git a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/string/ORecordSerializerJSON.java b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/string/ORecordSerializerJSON.java
index 75746792de..ee3b3a79bf 100755
--- a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/string/ORecordSerializerJSON.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/string/ORecordSerializerJSON.java
@@ -43,10 +43,7 @@ import com.orientechnologies.orient.core.metadata.schema.OType;
 import com.orientechnologies.orient.core.record.ORecord;
 import com.orientechnologies.orient.core.record.ORecordInternal;
 import com.orientechnologies.orient.core.record.ORecordStringable;
-import com.orientechnologies.orient.core.record.impl.OBlob;
-import com.orientechnologies.orient.core.record.impl.ODocument;
-import com.orientechnologies.orient.core.record.impl.ODocumentHelper;
-import com.orientechnologies.orient.core.record.impl.ODocumentInternal;
+import com.orientechnologies.orient.core.record.impl.*;
 import com.orientechnologies.orient.core.serialization.serializer.OJSONWriter;
 import com.orientechnologies.orient.core.serialization.serializer.OStringSerializerHelper;
 import com.orientechnologies.orient.core.util.ODateHelper;
@@ -497,7 +494,7 @@ public class ORecordSerializerJSON extends ORecordSerializerStringAbstract {
         }
 
       case EMBEDDED:
-        return fromString(iFieldValueAsString);
+        return fromString(iFieldValueAsString, new ODocumentEmbedded(), null);
 
       case DATE:
         if (iFieldValueAsString == null || iFieldValueAsString.equals(""""))
diff --git a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/string/OStringSerializerEmbedded.java b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/string/OStringSerializerEmbedded.java
index 9ba9c4db03..587299d1df 100755
--- a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/string/OStringSerializerEmbedded.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/string/OStringSerializerEmbedded.java
@@ -23,6 +23,7 @@ import com.orientechnologies.common.exception.OException;
 import com.orientechnologies.common.log.OLogManager;
 import com.orientechnologies.orient.core.exception.OSerializationException;
 import com.orientechnologies.orient.core.record.impl.ODocument;
+import com.orientechnologies.orient.core.record.impl.ODocumentEmbedded;
 import com.orientechnologies.orient.core.serialization.ODocumentSerializable;
 import com.orientechnologies.orient.core.serialization.OSerializableStream;
 import com.orientechnologies.orient.core.serialization.serializer.record.string.ORecordSerializerSchemaAware2CSV;
@@ -43,7 +44,7 @@ public class OStringSerializerEmbedded implements OStringSerializer {
       // NULL VALUE
       return null;
 
-    final ODocument instance = new ODocument();
+    final ODocument instance = new ODocumentEmbedded();
     try {
       ORecordSerializerSchemaAware2CSV.INSTANCE.fromStream(iStream.getBytes(""UTF-8""), instance, null);
     } catch (UnsupportedEncodingException e) {
@@ -67,7 +68,7 @@ public class OStringSerializerEmbedded implements OStringSerializer {
     if (ODocumentSerializable.class.isAssignableFrom(clazz)) {
       try {
         final ODocumentSerializable documentSerializable = (ODocumentSerializable) clazz.newInstance();
-        final ODocument docClone = new ODocument();
+        final ODocument docClone = new ODocumentEmbedded();
         instance.copyTo(docClone);
         docClone.removeField(ODocumentSerializable.CLASS_NAME);
         documentSerializable.fromDocument(docClone);
diff --git a/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLSelectTest.java b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLSelectTest.java
index dfc132be71..3cb32d4d6a 100755
--- a/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLSelectTest.java
+++ b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLSelectTest.java
@@ -254,7 +254,7 @@ public class SQLSelectTest extends AbstractSelectTest {
 
     List<ODocument> resultset = executeQuery(""select coll[name='Jay'] as value from Profile where coll is not null"", database);
     Assert.assertEquals(resultset.size(), 1);
-    Assert.assertEquals(resultset.get(0).field(""value"").getClass(), ODocument.class);
+    Assert.assertTrue(resultset.get(0).field(""value"") instanceof ODocument);
     Assert.assertEquals(((ODocument) resultset.get(0).field(""value"")).field(""name""), ""Jay"");
 
     doc.delete();
@@ -273,7 +273,7 @@ public class SQLSelectTest extends AbstractSelectTest {
 
     List<ODocument> resultset = executeQuery(""select coll[name='Jay'] as value from Profile where coll is not null"", database);
     Assert.assertEquals(resultset.size(), 1);
-    Assert.assertEquals(resultset.get(0).field(""value"").getClass(), ODocument.class);
+    Assert.assertTrue(resultset.get(0).field(""value"") instanceof ODocument);
     Assert.assertEquals(((ODocument) resultset.get(0).field(""value"")).field(""name""), ""Jay"");
 
     doc.delete();",add concept of embedded document and integrated in record deserializations,"""Introduce ODocumentEmbedded class and update serialization to use it for embedded documents""","""Added support for embedded documents in OrientDB""","Add newEmbeddedElement methods to ODatabaseDocument

This commit adds two new methods to the ODatabaseDocument interface: newEmbeddedElement() and newEmbeddedElement(String className). These methods allow for the creation of new embedded elements in a document database.

The first method, newEmbeddedElement(), creates a new embedded element with the default class name. The second method, newEmbeddedElement(String className), allows for the creation of a new embedded element with a specified class name.

These methods have been implemented in the ODatabaseDocumentAbstract and ODatabaseDocumentTx classes, and the appropriate tests have been added to the SQLSelectTest class.

Additionally, a new class ODocumentEmbedded has been created to represent embedded documents, and changes have been made to the ORecordSerializerBinaryV0 and ORecordSerializerBinaryV1 classes to properly serialize and deserialize embedded documents.",Added support for embedded elements with new ODocumentEmbedded class and corresponding methods in ODatabaseDocument interfaces.,Model 3
"diff --git a/sonar-plugin-api/src/main/java/org/sonar/api/resources/ProjectUtils.java b/sonar-plugin-api/src/main/java/org/sonar/api/resources/ProjectUtils.java
index f2f9b0511e4..bf89e3f8d6a 100644
--- a/sonar-plugin-api/src/main/java/org/sonar/api/resources/ProjectUtils.java
+++ b/sonar-plugin-api/src/main/java/org/sonar/api/resources/ProjectUtils.java
@@ -19,6 +19,11 @@
  */
 package org.sonar.api.resources;
 
+import com.google.common.collect.Lists;
+
+import java.util.Collection;
+import java.util.List;
+
 /**
  * @TODO Actually this class incorrectly named, because provides information not about project, but about Java project.
  *       And seems that only core plugins use this class.
@@ -52,4 +57,15 @@ public final class ProjectUtils {
     }
     return null;
   }
+
+  /**
+   * @since 2.7
+   */
+  public static List<java.io.File> toIoFiles(Collection<InputFile> inputFiles) {
+    List<java.io.File> files = Lists.newArrayList();
+    for (InputFile inputFile : inputFiles) {
+      files.add(inputFile.getFile());
+    }
+    return files;
+  }
 }",add the method ProjectUtils . toIoFiles ( . . ),"""Add method to convert InputFile collection to List of java.io.File in ProjectUtils""","""Added toIoFiles method to ProjectUtils class for converting InputFile collection to a list of java.io.File objects""","""Added new static method to ProjectUtils class to convert a collection of InputFile to java.io.File in Sonar Plugin API""","""Added method to convert collection of InputFiles to list of java.io.Files in ProjectUtils class.""",Model 4
"diff --git a/elasticsearch/src/main/java/org/elasticsearch/xpack/watcher/support/SearchRequestEquivalence.java b/elasticsearch/src/main/java/org/elasticsearch/xpack/watcher/support/SearchRequestEquivalence.java
deleted file mode 100644
index cc063d56920..00000000000
--- a/elasticsearch/src/main/java/org/elasticsearch/xpack/watcher/support/SearchRequestEquivalence.java
+++ /dev/null
@@ -1,49 +0,0 @@
-/*
- * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
- * or more contributor license agreements. Licensed under the Elastic License;
- * you may not use this file except in compliance with the Elastic License.
- */
-package org.elasticsearch.xpack.watcher.support;
-
-import org.elasticsearch.action.search.SearchRequest;
-import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.bytes.BytesArray;
-import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.io.stream.BytesStreamOutput;
-
-import java.util.Arrays;
-
-import static org.elasticsearch.xpack.watcher.support.Exceptions.illegalState;
-
-
-/**
- * The only true way today to compare search request object (outside of core) is to
- * serialize it and compare the serialized output. this is heavy obviously, but luckily we
- * don't compare search requests in normal runtime... we only do it in the tests. The is here basically
- * due to the lack of equals/hashcode support in SearchRequest in core.
- */
-public final class SearchRequestEquivalence {
-
-    public static final SearchRequestEquivalence INSTANCE = new SearchRequestEquivalence();
-
-    private SearchRequestEquivalence() {
-    }
-
-    public boolean equivalent(@Nullable SearchRequest a, @Nullable SearchRequest b) {
-        return a == b ? true : (a != null && b != null ? this.doEquivalent(a, b) : false);
-    }
-
-    protected boolean doEquivalent(SearchRequest r1, SearchRequest r2) {
-        try {
-            BytesStreamOutput output1 = new BytesStreamOutput();
-            r1.writeTo(output1);
-            byte[] bytes1 = BytesReference.toBytes(output1.bytes());
-            output1.reset();
-            r2.writeTo(output1);
-            byte[] bytes2 = BytesReference.toBytes(output1.bytes());
-            return Arrays.equals(bytes1, bytes2);
-        } catch (Exception e) {
-            throw illegalState(""could not compare search requests"", e);
-        }
-    }
-}",Remove unused class .,"""Remove SearchRequestEquivalence class""","The commit message should be:

""Remove SearchRequestEquivalence class due to serialization comparison being unnecessary""

This message accurately reflects the changes made in the commit, which is the removal of the `SearchRequestEquivalence` class.","""Remove SearchRequestEquivalence class""

This class was used to compare SearchRequest objects by serializing them and comparing the serialized output. However, it was only used for testing and was heavy due to the serialization process. It seems to have been removed due to the lack of equals/hashcode support in SearchRequest in the core.",Removed `SearchRequestEquivalence` class for comparing `SearchRequest` objects through serialization in Elasticsearch Watcher support classes.,Model 1
"diff --git a/flags/src/main/java/com/yahoo/vespa/flags/Flags.java b/flags/src/main/java/com/yahoo/vespa/flags/Flags.java
index 815fcda6ee7..57228dfe49d 100644
--- a/flags/src/main/java/com/yahoo/vespa/flags/Flags.java
+++ b/flags/src/main/java/com/yahoo/vespa/flags/Flags.java
@@ -193,11 +193,6 @@ public class Flags {
             ""Takes effect on next node agent tick (but does not clear existing failure reports)"",
             HOSTNAME);
   
-    public static final UnboundBooleanFlag DISABLE_CM3 = defineFeatureFlag(
-            ""disable-cm3"", false,
-            ""Whether to disable CM3."", ""Takes effect on next host admin tick"",
-            HOSTNAME);
-
     public static final UnboundBooleanFlag GENERATE_L4_ROUTING_CONFIG = defineFeatureFlag(
             ""generate-l4-routing-config"", false,
             ""Whether routing nodes should generate",Remove unused flag .,"""Remove DISABLE_CM3 feature flag""","""Removed DISABLE_CM3 flag and added GENERATE_L4_ROUTING_CONFIG flag""","""Remove DISABLE_CM3 flag""

This commit removes the `DISABLE_CM3` flag from the Flags class in the Vespa project. This flag was used to disable CM3, but it has been removed without any replacement or alternative. The commit message should reflect this change to make it clear what has been done.","""Remove outdated DISABLE_CM3 flag for cleanup and maintainability.""",Model 4
"diff --git a/jetty-websocket/websocket-core/src/main/java/org/eclipse/jetty/websocket/driver/WebSocketEventDriver.java b/jetty-websocket/websocket-core/src/main/java/org/eclipse/jetty/websocket/driver/WebSocketEventDriver.java
index 8eedb92f16..03afd9846b 100644
--- a/jetty-websocket/websocket-core/src/main/java/org/eclipse/jetty/websocket/driver/WebSocketEventDriver.java
+++ b/jetty-websocket/websocket-core/src/main/java/org/eclipse/jetty/websocket/driver/WebSocketEventDriver.java
@@ -129,17 +129,24 @@ public class WebSocketEventDriver implements Parser.Listener
             {
                 case CLOSE:
                 {
-                    if (events.onClose != null)
+                    if (events.onClose == null)
                     {
-                        byte payload[] = frame.getPayloadData();
-                        int statusCode = CloseUtil.getStatusCode(payload);
-                        String reason = CloseUtil.getReason(payload);
-                        events.onClose.call(websocket,connection,statusCode,reason);
+                        // not interested in close events
+                        return;
                     }
+                    byte payload[] = frame.getPayloadData();
+                    int statusCode = CloseUtil.getStatusCode(payload);
+                    String reason = CloseUtil.getReason(payload);
+                    events.onClose.call(websocket,connection,statusCode,reason);
                     return;
                 }
                 case BINARY:
                 {
+                    if (events.onBinary == null)
+                    {
+                        // not interested in binary events
+                        return;
+                    }
                     if (events.onBinary.isStreaming())
                     {
                         boolean needsNotification = false;
@@ -205,6 +212,11 @@ public class WebSocketEventDriver implements Parser.Listener
                 }
                 case TEXT:
                 {
+                    if (events.onText == null)
+                    {
+                        // not interested in text events
+                        return;
+                    }
                     if (events.onText.isStreaming())",Fixing more tests,"""Optimize WebSocketEventDriver by skipping unregistered event handlers""","""Add support for ignoring specific WebSocket events""","""Added null checks for onClose, onBinary, and onText in WebSocketEventDriver""

This commit adds null checks for the `onClose`, `onBinary`, and `onText` event handlers in the `WebSocketEventDriver` class. If any of these handlers are null, the method will return early, skipping the processing of the corresponding event. This change ensures that the application does not throw a `NullPointerException` when it does not provide an event handler for a specific event type.","Add null checks for onClose, onBinary, and onText event handlers in WebSocketEventDriver before handling respective events.",Label
"diff --git a/src/com/android/launcher3/BubbleTextView.java b/src/com/android/launcher3/BubbleTextView.java
index 3d91306f8..33b3ad347 100644
--- a/src/com/android/launcher3/BubbleTextView.java
+++ b/src/com/android/launcher3/BubbleTextView.java
@@ -56,11 +56,12 @@ public class BubbleTextView extends TextView
 
     private static SparseArray<Theme> sPreloaderThemes = new SparseArray<Theme>(2);
 
-    private static final float SHADOW_LARGE_RADIUS = 4.0f;
-    private static final float SHADOW_SMALL_RADIUS = 1.75f;
-    private static final float SHADOW_Y_OFFSET = 2.0f;
-    private static final int SHADOW_LARGE_COLOUR = 0xDD000000;
-    private static final int SHADOW_SMALL_COLOUR = 0xCC000000;
+    // Dimensions in DP
+    private static final float AMBIENT_SHADOW_RADIUS = 2.5f;
+    private static final float KEY_SHADOW_RADIUS = 1f;
+    private static final float KEY_SHADOW_OFFSET = 0.5f;
+    private static final int AMBIENT_SHADOW_COLOR = 0x33000000;
+    private static final int KEY_SHADOW_COLOR = 0x66000000;
 
     private static final int DISPLAY_WORKSPACE = 0;
     private static final int DISPLAY_ALL_APPS = 1;
@@ -136,6 +137,10 @@ public class BubbleTextView extends TextView
             // Draw the background itself as the parent is drawn twice.
             mBackground = getBackground();
             setBackground(null);
+
+            // Set shadow layer as the larger shadow to that the textView does not clip the shadow.
+            float density = getResources().getDisplayMetrics().density;
+            setShadowLayer(density * AMBIENT_SHADOW_RADIUS, 0, 0, AMBIENT_SHADOW_COLOR);
         } else {
             mBackground = null;
         }
@@ -144,10 +149,6 @@ public class BubbleTextView extends TextView
         mStylusEventHelper = new StylusEventHelper(new SimpleOnStylusPressListener(this), this);
 
         mOutlineHelper = HolographicOutlineHelper.obtain(getContext());
-        if (mCustomShadowsEnabled) {
-            setShadowLayer(SHADOW_LARGE_RADIUS, 0.0f, SHADOW_Y_OFFSET, SHADOW_LARGE_COLOUR);
-        }
-
         setAccessibilityDelegate(mLauncher.getAccessibilityDelegate());
     }
 
@@ -408,13 +409,15 @@ public class BubbleTextView extends TextView
         }
 
         // We enhance the shadow by drawing the shadow twice
-        getPaint().setShadowLayer(SHADOW_LARGE_RADIUS, 0.0f, SHADOW_Y_OFFSET, SHADOW_LARGE_COLOUR);
+        float density = getResources().getDisplayMetrics().density;
+        getPaint().setShadowLayer(density * AMBIENT_SHADOW_RADIUS, 0, 0, AMBIENT_SHADOW_COLOR);
         super.draw(canvas);
         canvas.save(Canvas.CLIP_SAVE_FLAG);
         canvas.clipRect(getScrollX(), getScrollY() + getExtendedPaddingTop(),
                 getScrollX() + getWidth(),
                 getScrollY() + getHeight(), Region.Op.INTERSECT);
-        getPaint().setShadowLayer(SHADOW_SMALL_RADIUS, 0.0f, 0.0f, SHADOW_SMALL_COLOUR);
+        getPaint().setShadowLayer(
+                density * KEY_SHADOW_RADIUS, 0.0f, density * KEY_SHADOW_OFFSET, KEY_SHADOW_COLOR);
         super.draw(canvas);
         canvas.restore();
     }
diff --git a/src/com/android/launcher3/allapps/AllAppsContainerView.java b/src/com/android/launcher3/allapps/AllAppsContainerView.java
index 8b1f95087..428f78401 100644
--- a/src/com/android/launcher3/allapps/AllAppsContainerView.java
+++ b/src/com/android/launcher3/allapps/AllAppsContainerView.java
@@ -210,6 +210,7 @@ public class AllAppsContainerView extends BaseContainerView implements DragSourc
      */
     public void addApps(List<AppInfo> apps) {
         mApps.addApps(apps);
+        mSearchBarController.refreshSearchResult();
     }
 
     /**
@@ -217,6 +218,7 @@ public class AllAppsContainerView extends BaseContainerView implements DragSourc
      */
     public void updateApps(List<AppInfo> apps) {
         mApps.updateApps(apps);
+        mSearchBarController.refreshSearchResult();
     }
 
     /**
@@ -224,6 +226,7 @@ public class AllAppsContainerView extends BaseContainerView implements DragSourc
      */
     public void removeApps(List<AppInfo> apps) {
         mApps.removeApps(apps);
+        mSearchBarController.refreshSearchResult();
     }
 
     public void setSearchBarVisible(boolean visible) {
diff --git a/src/com/android/launcher3/allapps/AllAppsSearchBarController.java b/src/com/android/launcher3/allapps/AllAppsSearchBarController.java
index ac3593238..e75210b93 100644
--- a/src/com/android/launcher3/allapps/AllAppsSearchBarController.java
+++ b/src/com/android/launcher3/allapps/AllAppsSearchBarController.java
@@ -45,6 +45,7 @@ public abstract class AllAppsSearchBarController
     protected AlphabeticalAppsList mApps;
     protected Callbacks mCb;
     protected ExtendedEditText mInput;
+    private String mQuery;
 
     protected DefaultAppSearchAlgorithm mSearchAlgorithm;
     protected InputMethodManager mInputMethodManager;
@@ -90,14 +91,23 @@ public abstract class AllAppsSearchBarController
 
     @Override
     public void afterTextChanged(final Editable s) {
-        String query = s.toString();
-        if (query.isEmpty()) {
+        mQuery = s.toString();
+        if (mQuery.isEmpty()) {
             mSearchAlgorithm.cancel(true);
             mCb.clearSearchResult();
         } else {
             mSearchAlgorithm.cancel(false);
-            mSearchAlgorithm.doSearch(query, mCb);
+            mSearchAlgorithm.doSearch(mQuery, mCb);
+        }
+    }
+
+    protected void refreshSearchResult() {
+        if (mQuery == null) {
+            return;
         }
+        // If play store continues auto updating an app, we want to show partial result.
+",Added custom actions for showing the shortcuts menu and adding a quick action on the home screen .,"""Update BubbleTextView shadow styles and refresh search results in AllAppsContainerView""

This commit message accurately reflects the changes made in the code. The BubbleTextView class has been updated to use new shadow styles, and the AllAppsContainerView class has been updated to refresh search results after adding, updating, or removing apps.","According to the diff, the commit message should be:

""Update shadow layer dimensions and add search result refresh functionality""

However, this commit message is a bit generic and doesn't fully capture the changes made in the commit. A more descriptive commit message would be:

""Update shadow layer dimensions to use density-independent pixels and add search result refresh functionality to AllAppsContainerView and AllAppsSearchBarController""

This commit message is more specific and accurately describes the changes made in the commit.","This commit makes several changes to the BubbleTextView and AllAppsContainerView classes in the Android Launcher3 application.

In the BubbleTextView class, the commit changes the shadow radius, offset, and color values for the text view. The new values are defined as constants in DP (density-independent pixels) and are then converted to pixels using the device's display metrics. The commit also modifies the draw() method to use these new shadow values when drawing the text.

In the AllAppsContainerView class, the commit adds a new method called refreshSearchResult() to the SearchBarController interface. This method is then called in the addApps(), updateApps(), and removeApps() methods to refresh the search results whenever the list of apps is modified.

The commit message for this change could be something like: ""Updated shadow values for BubbleTextView and added refreshSearchResult() method to SearchBarController in AllAppsContainerView.""","""Refactor shadow handling in BubbleTextView and refresh search results on app list changes in AllAppsContainerView.""",Model 1
"diff --git a/core/cas-server-core-authentication-mfa-api/src/main/java/org/apereo/cas/authentication/trigger/PredicatedPrincipalAttributeMultifactorAuthenticationTrigger.java b/core/cas-server-core-authentication-mfa-api/src/main/java/org/apereo/cas/authentication/trigger/PredicatedPrincipalAttributeMultifactorAuthenticationTrigger.java
index 6b2a94c2c0..4f5e383e5b 100644
--- a/core/cas-server-core-authentication-mfa-api/src/main/java/org/apereo/cas/authentication/trigger/PredicatedPrincipalAttributeMultifactorAuthenticationTrigger.java
+++ b/core/cas-server-core-authentication-mfa-api/src/main/java/org/apereo/cas/authentication/trigger/PredicatedPrincipalAttributeMultifactorAuthenticationTrigger.java
@@ -19,6 +19,7 @@ import org.springframework.context.ApplicationContext;
 import org.springframework.core.Ordered;
 
 import javax.servlet.http.HttpServletRequest;
+
 import java.util.Comparator;
 import java.util.Optional;
 import java.util.function.Predicate;
@@ -37,6 +38,7 @@ public class PredicatedPrincipalAttributeMultifactorAuthenticationTrigger implem
     private static final Class[] PREDICATE_CTOR_PARAMETERS = {Object.class, Object.class, Object.class, Object.class};
 
     private final CasConfigurationProperties casProperties;
+
     private final ApplicationContext applicationContext;
 
     private int order = Ordered.LOWEST_PRECEDENCE;
diff --git a/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/MultifactorAuthenticationTestsSuite.java b/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/MultifactorAuthenticationTestsSuite.java
index 308895c191..c2c6454f9f 100644
--- a/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/MultifactorAuthenticationTestsSuite.java
+++ b/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/MultifactorAuthenticationTestsSuite.java
@@ -12,6 +12,7 @@ import org.apereo.cas.authentication.mfa.trigger.AuthenticationAttributeMultifac
 import org.apereo.cas.authentication.mfa.trigger.GlobalMultifactorAuthenticationTriggerTests;
 import org.apereo.cas.authentication.mfa.trigger.GroovyScriptMultifactorAuthenticationTriggerTests;
 import org.apereo.cas.authentication.mfa.trigger.HttpRequestMultifactorAuthenticationTriggerTests;
+import org.apereo.cas.authentication.mfa.trigger.PredicatedPrincipalAttributeMultifactorAuthenticationTriggerTests;
 import org.apereo.cas.authentication.mfa.trigger.PrincipalAttributeMultifactorAuthenticationTriggerTests;
 import org.apereo.cas.authentication.mfa.trigger.RegisteredServiceMultifactorAuthenticationTriggerTests;
 import org.apereo.cas.authentication.mfa.trigger.RegisteredServicePrincipalAttributeMultifactorAuthenticationTriggerTests;
@@ -38,6 +39,7 @@ import org.junit.runner.RunWith;
     AdaptiveMultifactorAuthenticationTriggerTests.class,
     GlobalMultifactorAuthenticationTriggerTests.class,
     MultifactorAuthenticationUtilsTests.class,
+    PredicatedPrincipalAttributeMultifactorAuthenticationTriggerTests.class,
     ScriptedRegisteredServiceMultifactorAuthenticationTriggerTests.class,
     RegisteredServiceMultifactorAuthenticationTriggerTests.class,
     RegisteredServicePrincipalAttributeMultifactorAuthenticationTriggerTests.class,
diff --git a/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/mfa/trigger/GroovyScriptMultifactorAuthenticationTriggerTests.java b/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/mfa/trigger/GroovyScriptMultifactorAuthenticationTriggerTests.java
index 1de953fb7d..3464387306 100644
--- a/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/mfa/trigger/GroovyScriptMultifactorAuthenticationTriggerTests.java
+++ b/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/mfa/trigger/GroovyScriptMultifactorAuthenticationTriggerTests.java
@@ -28,4 +28,35 @@ public class GroovyScriptMultifactorAuthenticationTriggerTests extends BaseMulti
         val result = trigger.isActivated(authentication, registeredService, this.httpRequest, mock(Service.class));
         assertTrue(result.isPresent());
     }
+
+    @Test
+    public void verifyScriptDoesNotExist() {
+        val props = new CasConfigurationProperties();
+        var trigger = new GroovyScriptMultifactorAuthenticationTrigger(props, applicationContext);
+        var result = trigger.isActivated(authentication, registeredService, this.httpRequest, mock(Service.class));
+        assertFalse(result.isPresent());
+        
+        props.getAuthn().getMfa().setGroovyScript(new ClassPathResource(""DoesNotExist.groovy""));
+        trigger = new GroovyScriptMultifactorAuthenticationTrigger(props, applicationContext);
+        result = trigger.isActivated(authentication, registeredService, this.httpRequest, mock(Service.class));
+        assertFalse(result.isPresent());
+    }
+
+    @Test
+    public void verifyBadInputParameters() {
+        val props = new CasConfigurationProperties();
+        props.getAuthn().getMfa().setGroovyScript(new ClassPathResource(""GroovyMfaTrigger.groovy""));
+
+        var trigger = new GroovyScriptMultifactorAuthenticationTrigger(props, applicationContext);
+        var result = trigger.isActivated(null, registeredService, this.httpRequest, mock(Service.class));
+        assertFalse(result.isPresent());
+
+        result = trigger.isActivated(authentication, null, this.httpRequest, mock(Service.class));
+        assertFalse(result.isPresent());
+
+        result = trigger.isActivated(authentication, registeredService, this.httpRequest, null);
+        assertFalse(result.isPresent());
+
+        trigger.destroy();
+    }
 }
diff --git a/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/mfa/trigger/PredicatedPrincipalAttributeMultifactorAuthenticationTriggerTests.java b/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/mfa/trigger/PredicatedPrincipalAttributeMultifactorAuthenticationTriggerTests.java
new file mode 100644
index 0000000000..52491d71ff
--- /dev/null
+++ b/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/mfa/trigger/PredicatedPrincipalAttributeMultifactorAuthenticationTriggerTests.java
@@ -0,0 +1,31 @@
+package org.apereo.cas.authentication.mfa.trigger;
+
+import org.apereo.cas.authentication.principal.Service;
+import org.apereo.cas.authentication.trigger.PredicatedPrincipalAttributeMultifactorAuthenticationTrigger;
+import org.apereo.cas.configuration.CasConfigurationProperties;
+
+import lombok.val;
+import org.junit.jupiter.api.Tag;
+import org.junit.jupiter.api.Test;
+import org.springframework.core.io.ClassPathResource;
+
+import static org.junit.jupiter.api.Assertions.*;
+import static org.mockito.Mockito.*;
+
+/**
+ * This is {@link PredicatedPrincipalAttributeMultifactorAuthenticationTriggerTests}.
+ *
+ * @author Misagh Moayyed
+ * @since 6.2.0
+ */
+@Tag(""MFA"")
+public class PredicatedPrincipalAttributeMultifactorAuthenticationTriggerTests extends BaseMultifactorAuthenticationTriggerTests {
+    @Test
+    public void verifyOperationByHeader() {
+        val props = new CasConfigurationProperties();
+        props.getAuthn().getMfa().setGlobalPrincipalAttributePredicate(new ClassPathResource(""GroovyPredicate.groovy""));
+        val trigger = new PredicatedPrincipalAttributeMultifactorAuthenticationTrigger(props, this.applicationContext);
+        val result = trigger.isActivated(authentication, registeredService, this.httpRequest, mock(Service.class));
+        assertTrue(result.isPresent());
+    }
+}
diff --git a/core/cas-server-core-authentication-mfa-api/src/test/resources/GroovyPredicate.groovy b/core/cas-server-core-authentication-mfa-api/src/test/resources/GroovyPredicate.groovy
new file mode 100644
index 0000000000..d71d049a13
--- /dev/null
+++ b/core/cas-server-core-authentication-mfa-api/src/test/resources/GroovyPredicate.groovy
@@ -0,0 +1,18 @@
+import groovy.transform.TupleConstructor
+import org.apereo.cas.authentication.principal.Principal
+import org.apereo.cas.authentication.principal.Service
+
+import java.util.function.Predicate
+
+@TupleConstructor
+class GroovyPredicate implements Predicate {
+    Object service;
+    Object principal;
+    Object providers
+    Object logger;
+
+    @Override
+    boolean test(final Object o) {
+        return true
+    }
+}
diff --git a/core/cas-server-core-util-api/src/main/java/org/apereo/cas/util/crypto/GlibcCryptPasswordEncoder.java b/core/cas-server-core-util-api/src/main/java/org/apereo/cas/util/crypto/GlibcCryptPasswordEncoder.java
index 9fb0506815..62b251c478 100644
--- a/core/cas-server-core-util-api/src/main/java/org/apereo/cas/util/crypto/GlibcCryptPasswordEncoder.java
+++ b/core/cas-server-core-util-api/src/main/java/org/apereo/cas/util/crypto/GlibcCryptPasswordEncoder.java
@@ -22,7 +22,9 @@ public class GlibcCryptPasswordEncoder implements PasswordEncoder {
     private static final int SALT_LENGTH = 8;
 
     private final String encodingAlgorithm;
+
     private final int strength;
+
     private String secret;
 
     @Override
diff --git a/core/cas-server-core-util-api/src/main/java/org/apereo/cas/util/scripting/ScriptingUtils.java b/core/cas-server-core-util-api/src/main/java/org/apereo/cas/util/scripting/ScriptingUtils.java
index a4a7c0903a..94957ace83 100644
--- a/core/cas-server-core-util-api/src/main/java/org/apereo/cas/util/scripting/ScriptingUtils.java
+++ b/core/cas-server-core-util-api/src/main/java/org/apereo/cas/util/scripting/ScriptingUtils.java
@@ -522,7 +522,7 @@ public class ScriptingUtils {
                 return classLoader.parseClass(script);
             });
 
-            LOGGER.debug(""Preparing constructor arguments [{}] for resource [{}]"", args, resource);
+            LOGGER.trace(""Preparing constructor arguments [{}] for resource [{}]"", args, resource);
             val ctor = clazz.getDeclaredConstructor(constructorArgs);
             val result = ctor.newInstance(args);
 
diff --git a/core/cas-server-core-util-api/src/test/java/org/apereo/cas/util/crypto/GlibcCryptPasswordEncoderTests.java b/core/cas-server-core-util-api/src/test/java/org/apereo/cas/util/crypto/GlibcCryptPasswordEncoderTests.java
index f37d162b92..51bf91c159 100644
--- a/core/cas-server-core-util-api/src/test/java/org/apereo/cas/util/crypto/GlibcCryptPasswordEncoderTests.java
+++ b/core/cas-server-core-util-api/src/test/java/org/apereo/cas/util/crypto/GlibcCryptPasswordEncoderTests.java
@@ -17,6 +17,25 @@ public class GlibcCryptPasswordEncoderTests {
 
     private static final String PASSWORD_CLEAR = ""12345abcDEF!$"";
 
+    private static boolean testEncodingRoundtrip(final String algorithm) {
+        val encoder = new GlibcCryptPasswordEncoder(algorithm, 0, null);
+
+        val passwordHash = encoder.encode(PASSWORD_CLEAR);
+        LOGGER.debug(""Password [{}] was encoded by algorithm [{}] to hash [{}]"", PASSWORD_CLEAR, algorithm, passwordHash);
+
+        val match = encoder.matches(PASSWORD_CLEAR, passwordHash);
+        LOGGER.debug(""Does password [{}] match original password [{}]: [{}]"", passwordHash, PASSWORD_CLEAR, match);
+
+        return match;
+    }
+
+    private static boolean testMatchWithDifferentSalt(final String algorithm, final String encodedPassword) {
+        val encoder = new GlibcCryptPasswordEncoder(algorithm, 0, null);
+        val match = encoder.matches(PASSWORD_CLEAR, encodedPassword);
+        LOGGER.debug(""Does password [{}] match original password [{}]: [{}]"", encodedPassword, PASSWORD_CLEAR, match);
+        return match;
+    }
+
     @Test
     public void sha512EncodingTest() {
         assertTrue(testEncodingRoundtrip(""SHA-512""));
@@ -45,23 +64,4 @@ public class GlibcCryptPasswordEncoderTests {
         assertTrue(testMatchWithDifferentSalt(""aB"", ""aB4fMcNOggJoQ""));
     }
 
-    private static boolean testEncodingRoundtrip(final String algorithm) {
-        val encoder = new GlibcCryptPasswordEncoder(algorithm, 0, null);
-
-        val passwordHash = encoder.encode(PASSWORD_CLEAR);
-        LOGGER.debug(""Password [{}] was encoded by algorithm [{}] to hash [{}]"", PASSWORD_CLEAR, algorithm, passwordHash);
-
-        val match = encoder.matches(PASSWORD_CLEAR, passwordHash);
-        LOGGER.debug(""Does password [{}] match original password [{}]: [{}]"", passwordHash, PASSWORD_CLEAR, match);
-
-        return match;
-    }
-
-    private static boolean testMatchWithDifferentSalt(final String algorithm, final String encodedPassword) {
-        val encoder = new GlibcCryptPasswordEncoder(algorithm, 0, null);
-        val match = encoder.matches(PASSWORD_CLEAR, encodedPassword);
-        LOGGER.debug(""Does password [{}] match original password [{}]: [{}]"", encodedPassword, PASSWORD_CLEAR, match);
-        return match;
-    }
-
 }
diff --git a/gradle.properties b/gradle.properties
index 43ec97ec74..1f78ecdedb 100644
--- a/gradle.properties
+++ b/gradle.properties
@@ -56,7 +56,7 @@ istackVersion=3.0.10
 spotbugsVersion=4.0.0
 spotbugsContribVersion=7.4.7
 findbugsSecVersion=1.10.1
-checkstyleVersion=8.29
+checkstyleVersion=8.30
 gradleRetryVersion=1.1.1
 gradleGitVersion=2.2.2
 gradleLombokVersion=3.3.0
diff --git a/support/cas-server-support-aup-jdbc/src/test/java/org/apereo/cas/aup/BaseJdbcAcceptableUsagePolicyRepositoryTests.java b/support/cas-server-support-aup-jdbc/src/test/java/org/apereo/cas/aup/BaseJdbcAcceptableUsagePolicyRepositoryTests.java
index 78d13579f3..e9022de979 100644
--- a/support/cas-server-support-aup-jdbc/src/test/java/org/apereo/cas/aup/BaseJdbcAcceptableUsagePolicyRepositoryTests.java
+++ b/support/cas-server-support-aup-jdbc/src/test/java/org/apereo/cas/aup/BaseJdbcAcceptableUsagePolicyRepositoryTests.java
@@ -95,11 +95,6 @@ public abstract class BaseJdbcAcceptableUsagePolicyRepositoryTests extends BaseA
     @Autowired
     protected CasConfigurationProperties casProperties;
 
-    @Override
-    public boolean hasLiveUpdates() {
-        return false;
-    }
-
     protected String determinePrincipalId(final String actualPrincipalId, final Map<String, List<Object>> profileAttributes) {
         val aupProperties = casProperties.getAcceptableUsagePolicy();
         val jdbcAupRepository = new JdbcAcceptableUsagePolicyRepository(ticketRegistrySupport.getObject(),
@@ -120,4 +115,9 @@ public abstract class BaseJdbcAcceptableUsagePolicyRepositoryTests extends BaseA
     public AcceptableUsagePolicyRepository getAcceptableUsagePolicyRepository() {
         return acceptableUsagePolicyRepository.getObject();
     }
+
+    @Override
+    public boolean hasLiveUpdates() {
+        return false;
+    }
 }
diff --git a/support/cas-server-support-aup-jdbc/src/test/java/org/apereo/cas/aup/JdbcAcceptableUsagePolicyRepositoryAdvancedTests.java b/support/cas-server-support-aup-jdbc/src/test/java/org/apereo/cas/aup/JdbcAcceptableUsagePolicyRepositoryAdvancedTests.java
index 300a30709e..0646c6f5ed 100644
--- a/support/cas-server-support-aup-jdbc/src/test/java/org/apereo/cas/aup/JdbcAcceptableUsagePolicyRepositoryAdvancedTests.java
+++ b/support/cas-server-support-aup-jdbc/src/test/java/org/apereo/cas/aup/JdbcAcceptableUsagePolicyRepositoryAdvancedTests.java
@@ -49,7 +49,7 @@ public class JdbcAcceptableUsagePolicyRepositoryAdvancedTests extends BaseJdbcAc
             }
         }
     }
-    
+
     @AfterEach
     public void cleanup() throws SQLException {
         try (val c = this.acceptableUsagePolicyDataSource.getObject().getConnection()) {
@@ -65,14 +65,14 @@ public class JdbcAcceptableUsagePolicyRepositoryAdvancedTests extends BaseJdbcAc
         verifyRepositoryAction(""casuser"",
             CollectionUtils.wrap(""aupAccepted"", List.of(""false""), ""email"", List.of(""CASuser@example.org"")));
     }
-    
+
     @Test
     public void determinePrincipalIdWithAdvancedConfig() {
         val principalId = determinePrincipalId(""casuser"",
             CollectionUtils.wrap(""aupAccepted"", List.of(""false""), ""email"", List.of(""CASuser@example.org"")));
         assertEquals(""CASuser@example.org"", principalId);
     }
-    
+
     @Test
     public void raiseMissingPrincipalAttributeError() {
         val exception = assertThrows(IllegalStateException.class,
@@ -80,29 +80,29 @@ public class JdbcAcceptableUsagePolicyRepositoryAdvancedTests extends BaseJdbcAc
                 List.of(""CASuser@example.org""))));
         assertTrue(exception.getMessage().contains(""cannot be found""));
     }
-    
+
     @Test
     public void raiseEmptyPrincipalAttributeError() {
         val exception = assertThrows(IllegalStateException.class,
             () -> raiseException(CollectionUtils.wrap(""aupAccepted"", List.of(""false""), ""email"", new ArrayList<>())));
         assertTrue(exception.getMessage().contains(""empty or multi-valued with an empty element""));
     }
-    
+
     private void raiseException(final Map<String, List<Object>> profileAttributes) {
         val aupProperties = casProperties.getAcceptableUsagePolicy();
         val jdbcAupRepository = new JdbcAcceptableUsagePolicyRepository(ticketRegistrySupport.getObject(),
-                aupProperties.getAupAttributeName(),
+            aupProperties.getAupAttributeName(),
             acceptableUsagePolicyDataSource.getObject(), aupProperties);
-        
+
         val context = new MockRequestContext();
         val request = new MockHttpServletRequest();
         context.setExternalContext(new ServletExternalContext(new MockServletContext(), request, new MockHttpServletResponse()));
-        
+
         val c = CoreAuthenticationTestUtils.getCredentialsWithSameUsernameAndPassword(""casuser"");
         val principal = CoreAuthenticationTestUtils.getPrincipal(c.getId(), profileAttributes);
         val auth = CoreAuthenticationTestUtils.getAuthentication(principal);
         WebUtils.putAuthentication(auth, context);
-        
+
         jdbcAupRepository.determinePrincipalId(context, c);
     }
 }
diff --git a/support/cas-server-support-openid/src/main/java/org/apereo/cas/support/openid/web/mvc/SmartOpenIdController.java b/support/cas-server-support-openid/src/main/java/org/apereo/cas/support/openid/web/mvc/SmartOpenIdController.java
index 6452a2d6a0..dbcc5a0cf6 100644
--- a/support/cas-server-support-openid/src/main/java/org/apereo/cas/support/openid/web/mvc/SmartOpenIdController.java
+++ b/support/cas-server-support-openid/src/main/java/org/apereo/cas/support/openid/web/mvc/SmartOpenIdController.java
@@ -15,6 +15,7 @@ import org.springframework.web.servlet.View;
 
 import javax.servlet.http.HttpServletRequest;
 import javax.servlet.http.HttpServletResponse;
+
 import java.io.Serializable;
 import java.util.HashMap;
 import java.util.Map;
@@ -33,6 +34,7 @@ public class SmartOpenIdController extends AbstractDelegateController implements
     private static final long serialVersionUID = -594058549445950430L;
 
     private final transient ServerManager serverManager;
+
     private final transient View successView;
 
     /**
@@ -62,12 +64,6 @@ public class SmartOpenIdController extends AbstractDelegateController implements
         return responseParams;
     }
 
-    @Override
-    protected ModelAndView handleRequestInternal(final HttpServletRequest request, final HttpServletResponse response) {
-        val parameters = new HashMap<String, String>(getAssociationResponse(request));
-        return new ModelAndView(this.successView, parameters);
-    }
-
     @Override
     public boolean canHandle(final HttpServletRequest request, final HttpServletResponse response) {
         val openIdMode = request.getParameter(OpenIdProtocolConstants.OPENID_MODE);
@@ -78,4 +74,10 @@ public class SmartOpenIdController extends AbstractDelegateController implements
         LOGGER.info(""Cannot handle request. openid.mode : [{}]"", openIdMode);
         return false;
     }
+
+    @Override
+    protected ModelAndView handleRequestInternal(final HttpServletRequest request, final HttpServletResponse response) {
+        val parameters = new HashMap<String, String>(getAssociationResponse(request));
+        return new ModelAndView(this.successView, parameters);
+    }
 }
diff --git a/support/cas-server-support-spnego-webflow/src/main/java/org/apereo/cas/web/flow/client/LdapSpnegoKnownClientSystemsFilterAction.java b/support/cas-server-support-spnego-webflow/src/main/java/org/apereo/cas/web/flow/client/LdapSpnegoKnownClientSystemsFilterAction.java
index 88873317d8..cfe20537e5 100644
--- a/support/cas-server-support-spnego-webflow/src/main/java/org/apereo/cas/web/flow/client/LdapSpnegoKnownClientSystemsFilterAction.java
+++ b/support/cas-server-support-spnego-webflow/src/main/java/org/apereo/cas/web/flow/client/LdapSpnegoKnownClientSystemsFilterAction.java
@@ -25,6 +25,7 @@ public class LdapSpnegoKnownClientSystemsFilterAction extends BaseSpnegoKnownCli
      * The must-have attribute name.
      */
     private final String spnegoAttributeName;
+
     private final SearchOperation searchOperation;
 
     /**
diff --git a/support/cas-server-support-spnego-webflow/src/main/java/org/apereo/cas/web/flow/config/SpnegoWebflowActionsConfiguration.java b/support/cas-server-support-spnego-webflow/src/main/java/org/apereo/cas/web/flow/config/SpnegoWebflowActionsConfiguration.java
index 4e5d36dcc2..5c8886ecd2 100644
--- a/support/cas-server-support-spnego-webflow/src/main/java/org/apereo/cas/web/flow/config/SpnegoWebflowActionsConfiguration.java
+++ b/support/cas-server-support-spnego-webflow/src/main/java/org/apereo/cas/web/flow/config/SpnegoWebflowActionsConfiguration.java
@@ -102,7 +102,7 @@ public class SpnegoWebflowActionsConfiguration {
         val searchRequest = LdapUtils.newLdaptiveSearchRequest(spnegoProperties.getLdap().getBaseDn(), filter);
         val searchOperation = new SearchOperation(connectionFactory, searchRequest);
         searchOperation.setTemplate(filter);
-        
+
         return new LdapSpnegoKnownClientSystemsFilterAction(RegexUtils.createPattern(spnegoProperties.getIpsToCheckPattern()),
             spnegoProperties.getAlternativeRemoteHostAttribute(),
             Beans.newDuration(spnegoProperties.getDnsTimeout()).toMillis(),",add more tests,"""Update MFA triggers, add PredicatedPrincipalAttributeMultifactorAuthenticationTrigger tests, and fix various issues""","Here is a possible commit message based on the provided diff:

""Refactor multifactor authentication triggers and password encoding, add test cases for Groovy script triggers, and make various minor improvements and bug fixes across the CAS codebase.""

However, a more concise and conventional commit message would be:

""Refactor multifactor authentication triggers and password encoding""

This commit message follows the conventional format of being short, descriptive, and in the imperative mood (i.e., it tells the reader what the commit does, rather than what it has done).","""Add PredicatedPrincipalAttributeMultifactorAuthenticationTrigger and tests""

This commit adds a new class called PredicatedPrincipalAttributeMultifactorAuthenticationTrigger and its corresponding tests. It also modifies some existing files related to multifactor authentication triggers and updates the MultifactorAuthenticationTestsSuite to include the new tests. Additionally, it includes a new Groovy script called GroovyPredicate.groovy which is used in the tests.","Added new MFA trigger tests, refactored existing tests, upgraded checkstyle version, and adjusted logging levels in ScriptingUtils.",Model 4
"diff --git a/src/components/org/apache/jmeter/control/RandomController.java b/src/components/org/apache/jmeter/control/RandomController.java
index ed7fdc0f7f..4e26c4d4c8 100644
--- a/src/components/org/apache/jmeter/control/RandomController.java
+++ b/src/components/org/apache/jmeter/control/RandomController.java
@@ -89,6 +89,7 @@ public class RandomController
 	 */
 	protected void incrementCurrent()
 	{
+		super.incrementCurrent();
 		current = rand.nextInt(this.getSubControllers().size());
 	}",Fixed a bug that lead to stack overflows in certain situations .,"""Added call to super.incrementCurrent() in RandomController""","""Added call to super.incrementCurrent() in RandomController's incrementCurrent() method""","""Added super.incrementCurrent() in RandomController's incrementCurrent() method""",Added call to super.incrementCurrent() in RandomController to ensure correct incrementing before selecting a random sub-controller.,Model 3
"diff --git a/runtime/Swift/Sources/Antlr4/Lexer.swift b/runtime/Swift/Sources/Antlr4/Lexer.swift
index e47aa1a93..453d92aac 100644
--- a/runtime/Swift/Sources/Antlr4/Lexer.swift
+++ b/runtime/Swift/Sources/Antlr4/Lexer.swift
@@ -92,7 +92,7 @@ open class Lexer: Recognizer<LexerATNSimulator>, TokenSource {
         self._tokenFactorySourcePair.tokenSource = self
     }
 
-    public init(_ input: CharStream) {
+    public required init(_ input: CharStream) {
         self._input = input
         self._tokenFactorySourcePair = TokenSourceAndStream()
         super.init()
diff --git a/runtime/Swift/Sources/Antlr4/LexerInterpreter.swift b/runtime/Swift/Sources/Antlr4/LexerInterpreter.swift
index 99d9f72d8..815ee5c3a 100644
--- a/runtime/Swift/Sources/Antlr4/LexerInterpreter.swift
+++ b/runtime/Swift/Sources/Antlr4/LexerInterpreter.swift
@@ -18,19 +18,6 @@ public class LexerInterpreter: Lexer {
     internal final var _decisionToDFA: [DFA]
     internal final var _sharedContextCache = PredictionContextCache()
 
-//   public override init() {
-//    super.init()}
-
-//    public  convenience   init(_ input : CharStream) {
-//        self.init()
-//        self._input = input;
-//        self._tokenFactorySourcePair = (self, input);
-//    }
-    //@Deprecated
-    public convenience init(_ grammarFileName: String, _ tokenNames: Array<String?>?, _ ruleNames: Array<String>, _ channelNames: Array<String>, _ modeNames: Array<String>, _ atn: ATN, _ input: CharStream) throws {
-        try self.init(grammarFileName, Vocabulary.fromTokenNames(tokenNames), ruleNames, channelNames, modeNames, atn, input)
-    }
-
     public init(_ grammarFileName: String, _ vocabulary: Vocabulary, _ ruleNames: Array<String>, _ channelNames: Array<String>, _ modeNames: Array<String>, _ atn: ATN, _ input: CharStream) throws {
 
         self.grammarFileName = grammarFileName
@@ -54,6 +41,10 @@ public class LexerInterpreter: Lexer {
         }
     }
 
+    public required init(_ input: CharStream) {
+        fatalError(""Use the other initializer"")
+    }
+
     override
     public func getATN() -> ATN {
         return atn
diff --git a/tool/resources/org/antlr/v4/tool/templates/codegen/Swift/Swift.stg b/tool/resources/org/antlr/v4/tool/templates/codegen/Swift/Swift.stg
index 2cae8daf2..6586a3878 100755
--- a/tool/resources/org/antlr/v4/tool/templates/codegen/Swift/Swift.stg
+++ b/tool/resources/org/antlr/v4/tool/templates/codegen/Swift/Swift.stg
@@ -964,7 +964,7 @@ open class <lexer.name>: <superClass; null=""Lexer""> {
         return <lexer.name>.VOCABULARY
     }
 
-	public override init(_ input: CharStream) {
+	public required init(_ input: CharStream) {
 	    RuntimeMetaData.checkVersion(""<lexerFile.ANTLRVersion>"", RuntimeMetaData.VERSION)
 		super.init(input)
 		_interp = LexerATNSimulator(self, <lexer.name>._ATN, <lexer.name>._decisionToDFA, <lexer.name>._sharedContextCache)",Make CharStream . init ( CharStream ) required ( in the Swift runtime ) . .,"""Mark Lexer init(_:) as required to enforce use of designated initializer""","""Added required initializer to Lexer and LexerInterpreter classes and updated code generation template to reflect the change.""","""Update Lexer and LexerInterpreter initializers in Swift""

Explanation:
The changes made in the provided diff are related to the initializers of the `Lexer` and `LexerInterpreter` classes in Swift. In the `Lexer` class, the initializer has been updated from `public init(_ input: CharStream)` to `public required init(_ input: CharStream)`. In the `LexerInterpreter` class, the deprecated initializer has been removed, and a new initializer with the same signature as the updated `Lexer` initializer has been added, which throws a fatal error when called. The commit message should reflect these changes.",Make `init(_ input: CharStream)` a required initializer for `Lexer` and adjust `LexerInterpreter`.,Model 4
"diff --git a/config/single_node_cluster/config/server.properties b/config/single_node_cluster/config/server.properties
index 37f9c3244..eb74fffb2 100644
--- a/config/single_node_cluster/config/server.properties
+++ b/config/single_node_cluster/config/server.properties
@@ -9,7 +9,8 @@ http.enable=true
 socket.enable=true
 
 # BDB
-bdb.sync.transactions=false
+bdb.write.transactions=false
+bdb.flush.transactions=false
 bdb.cache.size=1G
 
 # Mysql
diff --git a/config/test_config1/config/server.properties b/config/test_config1/config/server.properties
index b5dfe8392..b2862ad9b 100644
--- a/config/test_config1/config/server.properties
+++ b/config/test_config1/config/server.properties
@@ -10,7 +10,8 @@ socket.enable=true
 jmx.enable=true
 
 # BDB
-bdb.sync.transactions=false
+bdb.write.transactions=false
+bdb.flush.transactions=false
 bdb.cache.size=100MB
 
 # Mysql
diff --git a/config/test_config2/config/server.properties b/config/test_config2/config/server.properties
index fa8f77eb9..c423f7c8f 100644
--- a/config/test_config2/config/server.properties
+++ b/config/test_config2/config/server.properties
@@ -1,5 +1,6 @@
 # The size of the in-memory cache used by bdb
-bdb.sync.transactions=false
+bdb.write.transactions=false
+bdb.flush.transactions=false
 bdb.cache.size=100MB
 
 max.threads=100",Remove references to obsolete bdb property from example configs .,"""Update BDB transaction settings in server properties""

or 

""Replace bdb.sync.transactions with bdb.write.transactions and bdb.flush.transactions in server properties""","""Optimize BDB transaction settings and adjust cache sizes in server.properties across multiple configurations""","""Updated BDB configuration in server.properties for single_node_cluster, test_config1, and test_config2:

- Disabled bdb.sync.transactions
+ Disabled bdb.write.transactions and bdb.flush.transactions""",Update BDB transaction and cache settings in server.properties for single node and test configurations.,Model 4
"diff --git a/eureka-core/src/main/java/com/netflix/eureka/util/batcher/AcceptorExecutor.java b/eureka-core/src/main/java/com/netflix/eureka/util/batcher/AcceptorExecutor.java
index e5baae40..42fadd87 100644
--- a/eureka-core/src/main/java/com/netflix/eureka/util/batcher/AcceptorExecutor.java
+++ b/eureka-core/src/main/java/com/netflix/eureka/util/batcher/AcceptorExecutor.java
@@ -222,13 +222,14 @@ class AcceptorExecutor<ID, T> {
                 drainReprocessQueue();
                 drainAcceptorQueue();
 
-                if (!isShutdown.get()) {
-                    // If all queues are empty, block for a while on the acceptor queue
-                    if (reprocessQueue.isEmpty() && acceptorQueue.isEmpty() && pendingTasks.isEmpty()) {
-                        TaskHolder<ID, T> taskHolder = acceptorQueue.poll(10, TimeUnit.MILLISECONDS);
-                        if (taskHolder != null) {
-                            appendTaskHolder(taskHolder);
-                        }
+                if (isShutdown.get()) {
+                    break;
+                }
+",Resolve spinlock issue in AcceptorExecutor thread ( <issue_id> ),"""Fix AcceptorExecutor to exit loop when shutdown""

This commit message is based on the changes made in the diff. The original code checked if the executor was not shut down and then proceeded to block on the acceptor queue if all queues were empty. The updated code checks if the executor is shut down and breaks out of the loop if it is, which is a more logical and efficient way to handle the shutdown scenario.","According to the diff, the commit message should be:

""Add shutdown check before blocking on acceptor queue""

This commit message accurately describes the change made in the code, which is to add a shutdown check before blocking on the acceptor queue.","""Refactor AcceptorExecutor to break loop when shutdown and avoid unnecessary queue checks""

Explanation:
The code change introduces a break statement inside the while loop when the isShutdown flag is set to true. This ensures that the loop terminates immediately when the executor is shutdown, instead of continuing with unnecessary queue checks.

Additionally, the condition for blocking on the acceptor queue when all queues are empty has been removed. This simplifies the code and avoids potential delays in processing tasks. The new code simply checks if the executor is shutdown and breaks the loop if it is, without checking the state of the queues.","""Fixed premature termination by adding shutdown check before polling acceptor queue in AcceptorExecutor.""",Model 1
"diff --git a/lib/src/main/java/com/auth0/jwt/impl/PayloadDeserializer.java b/lib/src/main/java/com/auth0/jwt/impl/PayloadDeserializer.java
index 3806887..8f872cb 100644
--- a/lib/src/main/java/com/auth0/jwt/impl/PayloadDeserializer.java
+++ b/lib/src/main/java/com/auth0/jwt/impl/PayloadDeserializer.java
@@ -65,9 +65,12 @@ class PayloadDeserializer extends StdDeserializer<Payload> {
 
     Date getDateFromSeconds(Map<String, JsonNode> tree, String claimName) {
         JsonNode node = tree.get(claimName);
-        if (node == null || node.isNull() || !node.canConvertToLong()) {
+        if (node == null || node.isNull()) {
             return null;
         }
+        if (!node.canConvertToLong()) {
+            throw new JWTDecodeException(String.format(""The claim '%s' contained an unexpected value."", claimName));
+        }
         final long ms = node.asLong() * 1000;
         return new Date(ms);
     }
diff --git a/lib/src/test/java/com/auth0/jwt/JWTDecoderTest.java b/lib/src/test/java/com/auth0/jwt/JWTDecoderTest.java
index a482685..e164dc0 100644
--- a/lib/src/test/java/com/auth0/jwt/JWTDecoderTest.java
+++ b/lib/src/test/java/com/auth0/jwt/JWTDecoderTest.java
@@ -275,7 +275,7 @@ public class JWTDecoderTest {
 
     @Test
     public void shouldGetAvailableClaims() throws Exception {
-        DecodedJWT jwt = JWT.decode(""eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOiIxMjM0NTY3ODkwIiwiaWF0IjoiMTIzNDU2Nzg5MCIsIm5iZiI6IjEyMzQ1Njc4OTAiLCJqdGkiOiJodHRwczovL2p3dC5pby8iLCJhdWQiOiJodHRwczovL2RvbWFpbi5hdXRoMC5jb20iLCJzdWIiOiJsb2dpbiIsImlzcyI6ImF1dGgwIiwiZXh0cmFDbGFpbSI6IkpvaG4gRG9lIn0.TX9Ct4feGp9YyeGK9Zl91tO0YBOrguJ4As9jeqgHdZQ"");
+        DecodedJWT jwt = JWT.decode(""eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjEyMzQ1Njc4OTAsImlhdCI6MTIzNDU2Nzg5MCwibmJmIjoxMjM0NTY3ODkwLCJqdGkiOiJodHRwczovL2p3dC5pby8iLCJhdWQiOiJodHRwczovL2RvbWFpbi5hdXRoMC5jb20iLCJzdWIiOiJsb2dpbiIsImlzcyI6ImF1dGgwIiwiZXh0cmFDbGFpbSI6IkpvaG4gRG9lIn0.2_0nxDPJwOk64U5V5V9pt8U92jTPJbGsHYQ35HYhbdE"");
         assertThat(jwt, is(notNullValue()));
         assertThat(jwt.getClaims(), is(notNullValue()));
         assertThat(jwt.getClaims(), is(instanceOf(Map.class)));
diff --git a/lib/src/test/java/com/auth0/jwt/impl/PayloadDeserializerTest.java b/lib/src/test/java/com/auth0/jwt/impl/PayloadDeserializerTest.java
index 014ae83..7fe9145 100644
--- a/lib/src/test/java/com/auth0/jwt/impl/PayloadDeserializerTest.java
+++ b/lib/src/test/java/com/auth0/jwt/impl/PayloadDeserializerTest.java
@@ -198,13 +198,15 @@ public class PayloadDeserializerTest {
     }
 
     @Test
-    public void shouldGetNullDateWhenParsingNonNumericNode() throws Exception {
+    public void shouldThrowWhenParsingNonNumericNode() throws Exception {
+        exception.expect(JWTDecodeException.class);
+        exception.expectMessage(""The claim 'key' contained an unexpected value."");
+
         Map<String, JsonNode> tree = new HashMap<>();
         TextNode node = new TextNode(""123456789"");
         tree.put(""key"", node);
 
-        Date date = deserializer.getDateFromSeconds(tree, ""key"");
-        assertThat(date, is(nullValue()));
+        deserializer.getDateFromSeconds(tree, ""key"");
     }
 
     @Test",throw JWTDecodeException when date claim format is invalid,"""Throw JWTDecodeException when parsing non-numeric node in PayloadDeserializer""","""Improved date deserialization and added test for non-numeric claim values""","""Update PayloadDeserializer to throw exception when claim value is unexpected and update tests""

Explanation:

* The change in `PayloadDeserializer.java` adds a new check for the `node.canConvertToLong()` condition and throws a `JWTDecodeException` if it fails.
* The change in `JWTDecoderTest.java` updates the JWT token used for the test case.
* The change in `PayloadDeserializerTest.java` updates the test case to expect a `JWTDecodeException` to be thrown when parsing a non-numeric node.

Based on the changes, it appears that the library has been updated to throw an exception when a claim value is unexpected (i.e., not a long value) rather than returning a null date. The test cases have also been updated to reflect this new behavior.","Enhance PayloadDeserializer to handle non-numeric claims with JWTDecodeException, update relevant tests for better validation of such scenarios.",Model 4
"diff --git a/.hgtags b/.hgtags
index e583046c16..bd28104aa7 100644
--- a/.hgtags
+++ b/.hgtags
@@ -162,3 +162,4 @@ b3a91113026c99b0da010d41055719ab0d8938f0 jdk8-b37
 4cc5610a6dd6227da766ebf9742eb11ff5ded6c0 jdk8-b38
 35a5397278779a2f8f3013f81586dc8f30cb149d jdk8-b39
 6e4e654931b976304bf6e7b4d0d6db8f75bac5d9 jdk8-b40
+c029c972396cea042a0dc67c0f7ccf2fe68007d4 jdk8-b41",Added tag jdk8 - b41 for changeset c029c972396c,"""Added jdk8-b41 tag""",Added jdk8-b41 to .hgtags.,"Based on the diff you provided, the commit message should be:

```
""jdk8-b41""
```

This is the new line that has been added in the `.hgtags` file. The commit message should ideally provide a brief description of the changes made in the commit. In this case, it seems like a new tag `jdk8-b41` has been added.",Added a new tag jdk8-b41 with commit ID c029c972396cea042a0dc67c0f7ccf2fe68007d4 to .hgtags file.,Model 4
"diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Max.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Max.java
index f6460b6d12..91851bcbe9 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Max.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Max.java
@@ -212,14 +212,7 @@ public class Max {
 
   /////////////////////////////////////////////////////////////////////////////
 
-  /**
-   * A {@code CombineFn} that computes the maximum of a collection of elements of type {@code T}
-   * using an arbitrary {@link Comparator}, useful as an argument to {@link Combine#globally} or
-   * {@link Combine#perKey}.
-   *
-   * @param <T> the type of the values being compared
-   */
-  public static class MaxFn<T> extends BinaryCombineFn<T> {
+  private static class MaxFn<T> extends BinaryCombineFn<T> {
 
     private final T identity;
     private final Comparator<? super T> comparator;
@@ -248,11 +241,7 @@ public class Max {
     }
   }
 
-  /**
-   * A {@code CombineFn} that computes the maximum of a collection of {@code Integer}s, useful as an
-   * argument to {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class MaxIntegerFn extends Combine.BinaryCombineIntegerFn {
+  private static class MaxIntegerFn extends Combine.BinaryCombineIntegerFn {
 
     @Override
     public int apply(int left, int right) {
@@ -265,11 +254,7 @@ public class Max {
     }
   }
 
-  /**
-   * A {@code CombineFn} that computes the maximum of a collection of {@code Long}s, useful as an
-   * argument to {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class MaxLongFn extends Combine.BinaryCombineLongFn {
+  private static class MaxLongFn extends Combine.BinaryCombineLongFn {
 
     @Override
     public long apply(long left, long right) {
@@ -282,11 +267,7 @@ public class Max {
     }
   }
 
-  /**
-   * A {@code CombineFn} that computes the maximum of a collection of {@code Double}s, useful as an
-   * argument to {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class MaxDoubleFn extends Combine.BinaryCombineDoubleFn {
+  private static class MaxDoubleFn extends Combine.BinaryCombineDoubleFn {
 
     @Override
     public double apply(double left, double right) {
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Mean.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Mean.java
index 17dbe6cf42..5e7c00317a 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Mean.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Mean.java
@@ -101,17 +101,7 @@ public class Mean {
 
   /////////////////////////////////////////////////////////////////////////////
 
-  /**
-   * A {@code Combine.CombineFn} that computes the arithmetic mean
-   * (a.k.a. average) of an {@code Iterable} of numbers of type
-   * {@code N}, useful as an argument to {@link Combine#globally} or
-   * {@link Combine#perKey}.
-   *
-   * <p>Returns {@code Double.NaN} if combining zero elements.
-   *
-   * @param <NumT> the type of the {@code Number}s being combined
-   */
-  public static class MeanFn<NumT extends Number>
+  private static class MeanFn<NumT extends Number>
   extends Combine.AccumulatingCombineFn<NumT, CountSum<NumT>, Double> {
     /**
      * Constructs a combining function that computes the mean over
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Min.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Min.java
index 47d831ceb7..109f4e5cb5 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Min.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Min.java
@@ -212,14 +212,7 @@ public class Min {
 
   /////////////////////////////////////////////////////////////////////////////
 
-  /**
-   * A {@code CombineFn} that computes the maximum of a collection of elements of type {@code T}
-   * using an arbitrary {@link Comparator}, useful as an argument to {@link Combine#globally} or
-   * {@link Combine#perKey}.
-   *
-   * @param <T> the type of the values being compared
-   */
-  public static class MinFn<T> extends BinaryCombineFn<T> {
+  private static class MinFn<T> extends BinaryCombineFn<T> {
 
     private final T identity;
     private final Comparator<? super T> comparator;
@@ -248,11 +241,7 @@ public class Min {
     }
   }
 
-  /**
-   * A {@code CombineFn} that computes the minimum of a collection of {@code Integer}s, useful as an
-   * argument to {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class MinIntegerFn extends Combine.BinaryCombineIntegerFn {
+  private static class MinIntegerFn extends Combine.BinaryCombineIntegerFn {
 
     @Override
     public int apply(int left, int right) {
@@ -265,11 +254,7 @@ public class Min {
     }
   }
 
-  /**
-   * A {@code CombineFn} that computes the minimum of a collection of {@code Long}s, useful as an
-   * argument to {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class MinLongFn extends Combine.BinaryCombineLongFn {
+  private static class MinLongFn extends Combine.BinaryCombineLongFn {
 
     @Override
     public long apply(long left, long right) {
@@ -282,11 +267,7 @@ public class Min {
     }
   }
 
-  /**
-   * A {@code CombineFn} that computes the minimum of a collection of {@code Double}s, useful as an
-   * argument to {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class MinDoubleFn extends Combine.BinaryCombineDoubleFn {
+  private static class MinDoubleFn extends Combine.BinaryCombineDoubleFn {
 
     @Override
     public double apply(double left, double right) {
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Sum.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Sum.java
index 504473240d..ccade4db70 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Sum.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Sum.java
@@ -140,12 +140,7 @@ public class Sum {
 
   /////////////////////////////////////////////////////////////////////////////
 
-  /**
-   * A {@code SerializableFunction} that computes the sum of an
-   * {@code Iterable} of {@code Integer}s, useful as an argument to
-   * {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class SumIntegerFn extends Combine.BinaryCombineIntegerFn {
+  private static class SumIntegerFn extends Combine.BinaryCombineIntegerFn {
 
     @Override
     public int apply(int a, int b) {
@@ -158,12 +153,7 @@ public class Sum {
     }
   }
 
-  /**
-   * A {@code SerializableFunction} that computes the sum of an
-   * {@code Iterable} of {@code Long}s, useful as an argument to
-   * {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class SumLongFn extends Combine.BinaryCombineLongFn {
+  private static class SumLongFn extends Combine.BinaryCombineLongFn {
 
     @Override
     public long apply(long a, long b) {
@@ -176,12 +166,7 @@ public class Sum {
     }
   }
 
-  /**
-   * A {@code SerializableFunction} that computes the sum of an
-   * {@code Iterable} of {@code Double}s, useful as an argument to
-   * {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class SumDoubleFn extends Combine.BinaryCombineDoubleFn {
+  private static class SumDoubleFn extends Combine.BinaryCombineDoubleFn {
 
     @Override
     public double apply(double a, double b) {","Reduced visibility for Sum , Min , Max , Mean combine Fns .","""Internalize CombineFn implementations in Max, Mean, Min, and Sum transforms""","The commit message should be:

""Convert static inner classes to private static classes""

This commit message accurately reflects the changes made in the code, which involve changing the access modifier of the inner classes from `public` to `private`.","""Make Max, Mean, Min, and Sum CombineFn classes private in Apache Beam SDK""

This commit changes the access modifier of several CombineFn classes (MaxFn, MeanFn, MinFn, SumIntegerFn, SumLongFn, SumDoubleFn) from public to private in the Apache Beam SDK. This means that these classes can no longer be accessed directly from outside the package and must be used through the public methods provided by the Max, Mean, Min, and Sum classes.","""Modify Max, Mean, Min, and Sum classes to make various CombineFns private instead of public for encapsulation.""",Model 1
"diff --git a/engine/src/main/java/org/terasology/rendering/nui/layers/ingame/PauseMenu.java b/engine/src/main/java/org/terasology/rendering/nui/layers/ingame/PauseMenu.java
index 02492aeba..972cd1253 100644
--- a/engine/src/main/java/org/terasology/rendering/nui/layers/ingame/PauseMenu.java
+++ b/engine/src/main/java/org/terasology/rendering/nui/layers/ingame/PauseMenu.java
@@ -15,9 +15,7 @@
  */
 package org.terasology.rendering.nui.layers.ingame;
 
-import org.terasology.crashreporter.CrashReporter;
 import org.terasology.engine.GameEngine;
-import org.terasology.engine.LoggingContext;
 import org.terasology.engine.modes.StateMainMenu;
 import org.terasology.registry.CoreRegistry;
 import org.terasology.rendering.nui.CoreScreenLayer;",Delete two import,"""Remove unused imports in PauseMenu.java""","""Removed unused imports from PauseMenu.java""","""Remove unused imports in PauseMenu.java""",Removed unused CrashReporter and LoggingContext imports from PauseMenu in the Terasology engine rendering module.,Model 4
"diff --git a/wear/wear/src/main/java/androidx/wear/widget/WearArcLayout.java b/wear/wear/src/main/java/androidx/wear/widget/WearArcLayout.java
index bd5948cdb48..0edbebf49ca 100644
--- a/wear/wear/src/main/java/androidx/wear/widget/WearArcLayout.java
+++ b/wear/wear/src/main/java/androidx/wear/widget/WearArcLayout.java
@@ -287,6 +287,15 @@ public class WearArcLayout extends ViewGroup {
         a.recycle();
     }
 
+    @Override
+    public void requestLayout() {
+        super.requestLayout();
+
+        for (int i = 0; i < getChildCount(); i++) {
+            getChildAt(i).forceLayout();
+        }
+    }
+
     @Override
     protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) {
         // Need to derive the thickness of the curve from the children. We're a curve, so the
diff --git a/wear/wear/src/main/java/androidx/wear/widget/WearCurvedTextView.java b/wear/wear/src/main/java/androidx/wear/widget/WearCurvedTextView.java
index 6a3a8e57023..097dc1f90da 100644
--- a/wear/wear/src/main/java/androidx/wear/widget/WearCurvedTextView.java
+++ b/wear/wear/src/main/java/androidx/wear/widget/WearCurvedTextView.java
@@ -189,6 +189,7 @@ public class WearCurvedTextView extends View implements WearArcLayout.ArcLayoutW
         a.recycle();
 
         applyTextAppearance(attributes);
+        mPaint.setTextSize(mTextSize);
     }
 
     @Override
@@ -237,12 +238,13 @@ public class WearCurvedTextView extends View implements WearArcLayout.ArcLayoutW
         doUpdate();
     }
 
-    private void updatePaint() {
-        mPaint.setTextSize(mTextSize);
+    @Override
+    protected void onLayout(boolean changed, int l, int t, int r, int b) {
+        super.onLayout(changed, l, t, r, b);
+
         mPaint.getTextBounds(mText, 0, mText.length(), mBounds);
 
         // Note that ascent is negative.
-
         mPathRadius = min(getWidth(), getHeight()) / 2f
                 + (mClockwise ? mPaint.getFontMetrics().ascent - getPaddingTop() :
                 -mPaint.getFontMetrics().descent - getPaddingBottom());
@@ -292,7 +294,6 @@ public class WearCurvedTextView extends View implements WearArcLayout.ArcLayoutW
 
         mDirty = false;
         mLastUsedTextAlignment = (int) getTextAlignment();
-        mPaint.setTextSize(mTextSize);
 
         if (mTextSweepDegrees <= mMaxSweepDegrees) {
             mTextToDraw = mText;
@@ -649,7 +650,6 @@ public class WearCurvedTextView extends View implements WearArcLayout.ArcLayoutW
 
     private void doUpdate() {
         mDirty = true;
-        updatePaint();
         requestLayout();
         postInvalidate();
     }
@@ -735,6 +735,7 @@ public class WearCurvedTextView extends View implements WearArcLayout.ArcLayoutW
     /** sets the text size for rendering the text */
     public void setTextSize(float value) {
         mTextSize = value;
+        mPaint.setTextSize(mTextSize);
         doUpdate();
     }",Fix the layout issues with WearArcLayout & WearCurvedTextView .,"""Fix WearArcLayout and WearCurvedTextView layout issues""

or 

""Improve WearArcLayout and WearCurvedTextView layout handling""

or 

""Enhance WearArcLayout and WearCurvedTextView to correctly handle child layouts and text rendering""

The commit message should be short and descriptive, indicating the main purpose of the changes. In this case, the changes seem to be related to fixing layout issues in WearArcLayout and WearCurvedTextView, so the commit message should reflect that.","""Update WearArcLayout and WearCurvedTextView to force layout of children and update text size on layout changes""","""Add force layout to WearArcLayout and update text size in WearCurvedTextView""

Explanation:

* In WearArcLayout.java, a new method `requestLayout()` is added that calls `super.requestLayout()` and forces layout for all child views.
* In WearCurvedTextView.java, the `mPaint.setTextSize(mTextSize)` line is added in two places: in the constructor and in the `setTextSize()` method. This sets the text size for rendering the text in the `WearCurvedTextView`. Additionally, the `updatePaint()` method is removed and its contents are moved to the `onLayout()` method.","""Fix layout update and text size issues in WearArcLayout and WearCurvedTextView for consistent rendering.""",Model 3
"diff --git a/sulong/projects/com.oracle.truffle.llvm.runtime/src/com/oracle/truffle/llvm/runtime/nodes/intrinsics/llvm/LLVMExpect.java b/sulong/projects/com.oracle.truffle.llvm.runtime/src/com/oracle/truffle/llvm/runtime/nodes/intrinsics/llvm/LLVMExpect.java
index 5b7f50bab4e..2ead0b1750c 100644
--- a/sulong/projects/com.oracle.truffle.llvm.runtime/src/com/oracle/truffle/llvm/runtime/nodes/intrinsics/llvm/LLVMExpect.java
+++ b/sulong/projects/com.oracle.truffle.llvm.runtime/src/com/oracle/truffle/llvm/runtime/nodes/intrinsics/llvm/LLVMExpect.java
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2016, 2019, Oracle and/or its affiliates.
+ * Copyright (c) 2016, 2020, Oracle and/or its affiliates.
  *
  * All rights reserved.
  *
@@ -104,6 +104,6 @@ public abstract class LLVMExpect {
     }
 
     static ConditionProfile getExpectConditionProfile() {
-        return ConditionProfile.createBinaryProfile();
+        return ConditionProfile.create();
     }
 }
diff --git a/truffle/src/com.oracle.truffle.api.test/src/com/oracle/truffle/api/test/parser/PEParser.java b/truffle/src/com.oracle.truffle.api.test/src/com/oracle/truffle/api/test/parser/PEParser.java
index 1fee7a15618..27eeae4c99d 100644
--- a/truffle/src/com.oracle.truffle.api.test/src/com/oracle/truffle/api/test/parser/PEParser.java
+++ b/truffle/src/com.oracle.truffle.api.test/src/com/oracle/truffle/api/test/parser/PEParser.java
@@ -355,7 +355,7 @@ final class Sequence4<T, A, B, C, D> extends SequenceBase<T> {
 
 final class Alternative<T> extends Element<T> {
     @Children private final Element<? extends T>[] options;
-    private final ConditionProfile seenEof = ConditionProfile.createBinaryProfile();
+    private final ConditionProfile seenEof = ConditionProfile.create();
 
     Alternative(Element<? extends T>[] options) {
         this.options = options;
@@ -398,7 +398,7 @@ final class Repetition<T, ListT, R> extends Element<R> {
     private final Supplier<ListT> createList;
     private final BiFunction<ListT, T, ListT> addToList;
     private final Function<ListT, R> createResult;
-    private final ConditionProfile seenEof = ConditionProfile.createBinaryProfile();
+    private final ConditionProfile seenEof = ConditionProfile.create();
 
     Repetition(Element<T> element, Supplier<ListT> createList, BiFunction<ListT, T, ListT> addToList, Function<ListT, R> createResult) {
         this.element = element;
@@ -433,7 +433,7 @@ final class Repetition<T, ListT, R> extends Element<R> {
 
 final class StackRepetition<T> extends Element<LexerList<T>> {
     @Child private Element<T> element;
-    private final ConditionProfile seenEof = ConditionProfile.createBinaryProfile();
+    private final ConditionProfile seenEof = ConditionProfile.create();
 
     StackRepetition(Element<T> element) {
         this.element = element;
@@ -469,7 +469,7 @@ final class OptionalElement<T, R> extends Element<R> {
     @Child Element<T> element;
     private final Function<T, R> hasValueAction;
     private final Supplier<R> hasNoValueAction;
-    private final ConditionProfile seenEof = ConditionProfile.createBinaryProfile();
+    private final ConditionProfile seenEof = ConditionProfile.create();
 
     OptionalElement(Element<T> element, Function<T, R> hasValueAction, Supplier<R> hasNoValueAction) {
         this.element = element;
@@ -501,7 +501,7 @@ final class OptionalElement<T, R> extends Element<R> {
 final class TokenReference<T> extends Element<T> {
     private final byte token;
     private final TokenFunction<T> action;
-    private final ConditionProfile seenEof = ConditionProfile.createBinaryProfile();
+    private final ConditionProfile seenEof = ConditionProfile.create();
 
     TokenReference(byte token, TokenFunction<T> action) {
         this.token = token;
diff --git a/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotLimits.java b/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotLimits.java
index d46cde75725..b87d126e4f7 100644
--- a/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotLimits.java
+++ b/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotLimits.java
@@ -123,7 +123,7 @@ final class PolyglotLimits {
         final EventContext eventContext;
         final PolyglotEngineImpl engine;
         final FrameSlot readContext;
-        final ConditionProfile needsLookup = ConditionProfile.createBinaryProfile();
+        final ConditionProfile needsLookup = ConditionProfile.create();
         final FrameDescriptor descriptor;
         @CompilationFinal private boolean seenInnerContext;
 
diff --git a/wasm/src/org.graalvm.wasm/src/org/graalvm/wasm/memory/UnsafeWasmMemory.java b/wasm/src/org.graalvm.wasm/src/org/graalvm/wasm/memory/UnsafeWasmMemory.java
index 4e8f4272eb5..8b6cfe96bde 100644
--- a/wasm/src/org.graalvm.wasm/src/org/graalvm/wasm/memory/UnsafeWasmMemory.java
+++ b/wasm/src/org.graalvm.wasm/src/org/graalvm/wasm/memory/UnsafeWasmMemory.java
@@ -54,7 +54,7 @@ public class UnsafeWasmMemory extends WasmMemory {
     private long startAddress;
     private long pageSize;
     private final long maxPageSize;
-    private final ConditionProfile outOfBoundsAccesses = ConditionProfile.createBinaryProfile();
+    private final ConditionProfile outOfBoundsAccesses = ConditionProfile.create();
 
     public UnsafeWasmMemory(long initPageSize, long maxPageSize) {
         try {",Replace ConditionProfile . createBinaryProfile ( ) with ConditionProfile . create ( ),Replace ConditionProfile.createBinaryProfile() with ConditionProfile.create(),"""Update ConditionProfile creation to use the default constructor instead of createBinaryProfile()""","""Update copyright year and use ConditionProfile.create() instead of ConditionProfile.createBinaryProfile()""

This commit updates the copyright year from 2019 to 2020 in the file `LLVMExpect.java`. It also replaces the usage of `ConditionProfile.createBinaryProfile()` with `ConditionProfile.create()` in several files, including `PEParser.java`, `PolyglotLimits.java`, and `UnsafeWasmMemory.java`. The `ConditionProfile.create()` method is used to create a new condition profile, which is a performance optimization technique used in the Truffle framework.","""Refactor to use ConditionProfile.create() instead of ConditionProfile.createBinaryProfile() for improved flexibility in profiling conditions.""",Model 4
"diff --git a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/ExecutionEngineTest.scala b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/ExecutionEngineTest.scala
index 77532f9c48b..ec8b315e80f 100644
--- a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/ExecutionEngineTest.scala
+++ b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/ExecutionEngineTest.scala
@@ -1054,9 +1054,9 @@ order by a.COL1"""""")
 
   private def createReadOnlyEngine(): ExecutionEngine = {
     FileUtils.deleteRecursively(new File(""target/readonly""))
-    val old = new TestGraphDatabaseFactory().newEmbeddedDatabase(""target/readonly"")
+    val old = new TestGraphDatabaseFactory().newEmbeddedDatabase( new File( ""target/readonly"" ) )
     old.shutdown()
-    val db = new TestGraphDatabaseFactory().newEmbeddedDatabaseBuilder(""target/readonly"")
+    val db = new TestGraphDatabaseFactory().newEmbeddedDatabaseBuilder( new File( ""target/readonly"" ) )
       .setConfig( GraphDatabaseSettings.read_only, ""true"" )
       .newGraphDatabase()
     new ExecutionEngine(new GraphDatabaseCypherService(db))
diff --git a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/IndexOpAcceptanceTest.scala b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/IndexOpAcceptanceTest.scala
index 84fca67a234..21eddf2bbf9 100644
--- a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/IndexOpAcceptanceTest.scala
+++ b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/IndexOpAcceptanceTest.scala
@@ -96,8 +96,9 @@ class IndexOpAcceptanceTest extends ExecutionEngineFunSuite with QueryStatistics
   }
 
   private def createDbWithFailedIndex: GraphDatabaseService = {
-    new File(""target/test-data/impermanent-db"").deleteAll()
-    graph = new GraphDatabaseCypherService(new TestGraphDatabaseFactory().newEmbeddedDatabase(""target/test-data/impermanent-db""))
+    val storeDir = new File(""target/test-data/impermanent-db"")
+    storeDir.deleteAll()
+    graph = new GraphDatabaseCypherService(new TestGraphDatabaseFactory().newEmbeddedDatabase(storeDir))
     eengine = new ExecutionEngine(graph)
     execute(""CREATE INDEX ON :Person(name)"")
     execute(""create (:Person {name:42})"")
@@ -114,7 +115,7 @@ class IndexOpAcceptanceTest extends ExecutionEngineFunSuite with QueryStatistics
     stream.write(65)
     stream.close()
 
-    graph = new GraphDatabaseCypherService(new TestGraphDatabaseFactory().newEmbeddedDatabase(""target/test-data/impermanent-db""))
+    graph = new GraphDatabaseCypherService(new TestGraphDatabaseFactory().newEmbeddedDatabase(storeDir))
     eengine = new ExecutionEngine(graph)
     graph.getGraphDatabaseService
   }
diff --git a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/internal/compiler/v3_0/CompilerComparisonTest.scala b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/internal/compiler/v3_0/CompilerComparisonTest.scala
index ea34b869c6d..a7d7aa9a67b 100644
--- a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/internal/compiler/v3_0/CompilerComparisonTest.scala
+++ b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/internal/compiler/v3_0/CompilerComparisonTest.scala
@@ -379,7 +379,7 @@ class CompilerComparisonTest extends ExecutionEngineFunSuite with QueryStatistic
 
   private def executionResults: Seq[DataSetResults] = (for ((dataSet, queries) <- queriesByDataSet) yield {
     val (dataSetName, dataSetDir) = dataSet
-    val db = new GraphDatabaseCypherService(new GraphDatabaseFactory().newEmbeddedDatabase(dataSetDir))
+    val db = new GraphDatabaseCypherService(new GraphDatabaseFactory().newEmbeddedDatabase(new File(dataSetDir)))
     try {
       val queryResults = for ((queryName, queryText) <- queries) yield {
         val results = for ((compilerName, compilerCreator) <- compilers) yield {
diff --git a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/performance/DataImportTest.scala b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/performance/DataImportTest.scala
index b5d884a645e..662d534ac24 100644
--- a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/performance/DataImportTest.scala
+++ b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/performance/DataImportTest.scala
@@ -36,11 +36,10 @@ class DataImportTest extends CypherFunSuite {
   // This test creates a database
   ignore(""createDatabase"") {
     val sourceDir = new File(""/Users/ata/Downloads/apa/ml-10M100K"")
-    val targetDir = ""target/perf-graph.db""
-    val dir = new File(targetDir)
-    deleteAll(dir)
+    val targetDir = new File(""target/perf-graph.db"")
+    deleteAll(targetDir)
 
-    dir.exists() should equal(false)
+    targetDir.exists() should equal(false)
 
     val (inserter, moviesId, moviesTitles, indexProvider, typeIdx) = createInserters(targetDir)
 
@@ -82,7 +81,7 @@ class DataImportTest extends CypherFunSuite {
     moviesId
   }
 
-  private def createInserters(targetDir: String) = {
+  private def createInserters(targetDir: File) = {
     val inserter = BatchInserters.inserter(targetDir)
     val indexProvider = new LuceneBatchInserterIndexProviderNewImpl(inserter)
 
diff --git a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/performance/PerformanceTest.scala b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/performance/PerformanceTest.scala
index 31374c7b42c..2c54b8ce51e 100644
--- a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/performance/PerformanceTest.scala
+++ b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/performance/PerformanceTest.scala
@@ -19,6 +19,7 @@
  */
 package org.neo4j.cypher.performance
 
+import java.io.File
 import java.util.Collections
 
 import org.neo4j.cypher.internal.frontend.v3_0.test_helpers.CypherFunSuite
@@ -34,7 +35,7 @@ class PerformanceTest extends CypherFunSuite {
 
   override def beforeEach() {
     super.beforeEach()
-    db = new GraphDatabaseFactory().newEmbeddedDatabase(""target/db"")
+    db = new GraphDatabaseFactory().newEmbeddedDatabase(new File(""target/db""))
   }
 
   override def afterEach() {
diff --git a/community/graph-algo/src/test/java/org/neo4j/graphalgo/path/AStarPerformanceIT.java b/community/graph-algo/src/test/java/org/neo4j/graphalgo/path/AStarPerformanceIT.java
index 8f6da1b91f6..a9166edaa8a 100644
--- a/community/graph-algo/src/test/java/org/neo4j/graphalgo/path/AStarPerformanceIT.java
+++ b/community/graph-algo/src/test/java/org/neo4j/graphalgo/path/AStarPerformanceIT.java
@@ -74,7 +74,7 @@ public class AStarPerformanceIT
                 new long[]{291, 86707},
                 new long[]{188345, 158468}
         };
-        GraphDatabaseService db = new GraphDatabaseFactory().newEmbeddedDatabase( directory.getAbsolutePath() );
+        GraphDatabaseService db = new GraphDatabaseFactory().newEmbeddedDatabase( directory.getAbsoluteFile() );
         PathFinder<WeightedPath> algo = aStar( allTypesAndDirections(),
                 doubleCostEvaluator( ""weight"", 0 ), GeoDataGenerator.estimateEvaluator() );
         for ( int i = 0; i < 10; i++ )
diff --git a/community/graphviz/src/main/java/org/neo4j/visualization/graphviz/Script.java b/community/graphviz/src/main/java/org/neo4j/visualization/graphviz/Script.java
index 7759ad2134f..6abfe8533e9 100644
--- a/community/graphviz/src/main/java/org/neo4j/visualization/graphviz/Script.java
+++ b/community/graphviz/src/main/java/org/neo4j/visualization/graphviz/Script.java
@@ -41,7 +41,7 @@ public class Script extends ConfigurationParser
         super( format );
     }
 
-    protected String storeDir;
+    protected File storeDir;
 
     public static <S extends Script> S initialize( Class<S> scriptClass, String... args )
     {
@@ -115,7 +115,7 @@ public class Script extends ConfigurationParser
         {
             throw new UnsupportedOperationException( ""Could not initialize script"", e );
         }
-        script.storeDir = args[0];
+        script.storeDir = new File( args[0] );
         return script;
     }
 
@@ -154,7 +154,7 @@ public class Script extends ConfigurationParser
         }
     }
 
-    protected String storeDir()
+    protected File storeDir()
     {
         return storeDir;
     }
diff --git a/community/import-tool/src/test/java/org/neo4j/tooling/ImportToolDocIT.java b/community/import-tool/src/test/java/org/neo4j/tooling/ImportToolDocIT.java
index 3d5508fe296..48d02f4a7a5 100644
--- a/community/import-tool/src/test/java/org/neo4j/tooling/ImportToolDocIT.java
+++ b/community/import-tool/src/test/java/org/neo4j/tooling/ImportToolDocIT.java
@@ -104,7 +104,7 @@ public class ImportToolDocIT
 
         // WHEN
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", movies.getAbsolutePath(),
                 ""--nodes"", actors.getAbsolutePath(),
                 ""--relationships"", roles.getAbsolutePath() );
@@ -157,7 +157,7 @@ public class ImportToolDocIT
 
         // WHEN
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", movies.getAbsolutePath(),
                 ""--nodes"", actors.getAbsolutePath(),
                 ""--relationships"", roles.getAbsolutePath(),
@@ -224,7 +224,7 @@ public class ImportToolDocIT
 
         // WHEN
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", moviesHeader.getAbsolutePath() + MULTI_FILE_DELIMITER + movies.getAbsolutePath(),
                 ""--nodes"", actorsHeader.getAbsolutePath() + MULTI_FILE_DELIMITER + actors.getAbsolutePath(),
                 ""--relationships"", rolesHeader.getAbsolutePath() + MULTI_FILE_DELIMITER + roles.getAbsolutePath());
@@ -299,7 +299,7 @@ public class ImportToolDocIT
 
         // WHEN
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", moviesHeader.getAbsolutePath() + MULTI_FILE_DELIMITER + moviesPart1.getAbsolutePath() +
                         MULTI_FILE_DELIMITER + moviesPart2.getAbsolutePath(),
                 ""--nodes"", actorsHeader.getAbsolutePath() + MULTI_FILE_DELIMITER + actorsPart1.getAbsolutePath() +
@@ -360,7 +360,7 @@ public class ImportToolDocIT
         }
         // WHEN
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes:"" + join( new String[] { ""Movie"" }, "":"" ),
                     movies.getAbsolutePath(),
                 ""--nodes:"" + join( new String[] { ""Movie"", ""Sequel"" }, "":"" ),
@@ -416,7 +416,7 @@ public class ImportToolDocIT
         }
         // WHEN
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", movies.getAbsolutePath(),
                 ""--nodes"", actors.getAbsolutePath(),
                 ""--relationships:"" + join( new String[] { ""ACTED_IN"" }, "":"" ), roles.getAbsolutePath());
@@ -468,7 +468,7 @@ public class ImportToolDocIT
         }
         // WHEN
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", movies.getAbsolutePath(),
                 ""--nodes"", actors.getAbsolutePath(),
                 ""--relationships:"" + join( new String[] { ""ACTED_IN"" }, "":"" ), roles.getAbsolutePath());
@@ -523,7 +523,7 @@ public class ImportToolDocIT
         // WHEN
         File badFile = new File( directory.directory(), Configuration.BAD_FILE_NAME );
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", movies.getAbsolutePath(),
                 ""--nodes"", actors.getAbsolutePath(),
                 ""--relationships"", roles.getAbsolutePath() );
@@ -556,7 +556,7 @@ public class ImportToolDocIT
         // WHEN
         File badFile = new File( directory.directory(), Configuration.BAD_FILE_NAME );
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", actors.getAbsolutePath(),
                 ""--skip-duplicate-nodes"" );
         importTool( arguments );
@@ -604,7 +604,7 @@ public class ImportToolDocIT
 
         // WHEN
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", movies.getAbsolutePath(),
                 ""--nodes"", actors.getAbsolutePath(),
                 ""--relationships"", roles.getAbsolutePath() );
@@ -698,8 +698,8 @@ public class ImportToolDocIT
         }
         String documentationArgs = StringUtils.join( cleanedArguments, "" "" );
         documentationArgs =
-                documentationArgs.replace( dir + File.separator, """" ).replace( directory.absolutePath(),
-                        ""path_to_target_directory"" );
+                documentationArgs.replace( dir + File.separator, """" ).replace(
+                        directory.absolutePath().getAbsolutePath(), ""path_to_target_directory"" );
         String docsCommand = ""neo4j-import "" + documentationArgs;
         try ( PrintStream out = new PrintStream( file( ""ops"", fileName ) ) )
         {
diff --git a/community/io/src/test/java/org/neo4j/test/TargetDirectory.java b/community/io/src/test/java/org/neo4j/test/TargetDirectory.java
index b090cf66fff..3cbd2edb4ee 100644
--- a/community/io/src/test/java/org/neo4j/test/TargetDirectory.java
+++ b/community/io/src/test/java/org/neo4j/test/TargetDirectory.java
@@ -73,9 +73,9 @@ public class TargetDirectory
             return this;
         }
 
-        public String absolutePath()
+        public File absolutePath()
         {
-            return directory().getAbsolutePath();
+            return directory().getAbsoluteFile();
         }
 
         public File directory()
diff --git a/community/kernel/src/main/java/org/neo4j/graphdb/factory/GraphDatabaseFactory.java b/community/kernel/src/main/java/org/neo4j/graphdb/factory/GraphDatabaseFactory.java
index 691af8c0e07..d10fb09ca4d 100644
--- a/community/kernel/src/main/java/org/neo4j/graphdb/factory/GraphDatabaseFactory.java
+++ b/community/kernel/src/main/java/org/neo4j/graphdb/factory/GraphDatabaseFactory.java
@@ -20,20 +20,16 @@
 package org.neo4j.graphdb.factory;
 
 import java.io.File;
-import java.util.List;
 import java.util.Map;
 
 import org.neo4j.graphdb.GraphDatabaseService;
-import org.neo4j.kernel.extension.KernelExtensionFactory;
+import org.neo4j.graphdb.security.URLAccessRule;
 import org.neo4j.kernel.impl.factory.CommunityFacadeFactory;
 import org.neo4j.kernel.impl.factory.Edition;
 import org.neo4j.kernel.impl.factory.GraphDatabaseFacadeFactory;
 import org.neo4j.kernel.monitoring.Monitors;
-import org.neo4j.graphdb.security.URLAccessRule;
 import org.neo4j.logging.LogProvider;
 
-import static java.util.Arrays.asList;
-
 /**
  * Creates a {@link org.neo4j.graphdb.GraphDatabaseService}.
  * <p>
@@ -64,32 +60,11 @@ public class GraphDatabaseFactory
         return new GraphDatabaseFactoryState( getCurrentState() );
     }
 
-    /**
-     * @deprecated use {@link #newEmbeddedDatabase(File)} instead.
-     * @param storeDir the location of the database
-     * @return the database
-     */
-    @Deprecated
-    public GraphDatabaseService newEmbeddedDatabase( String storeDir )
-    {
-        return newEmbeddedDatabase( new File( storeDir ) );
-    }
-
     public GraphDatabaseService newEmbeddedDatabase( File storeDir )
     {
         return newEmbeddedDatabaseBuilder( storeDir ).newGraphDatabase();
     }
 
-    /**
-     * @deprecated use {@link #newEmbeddedDatabaseBuilder(File)} instead
-     * @param storeDir the location of the database
-     * @return a builder which is used to configure and start a database
-     */
-    @Deprecated
-    public GraphDatabaseBuilder newEmbeddedDatabaseBuilder( String storeDir )
-    {
-        return newEmbeddedDatabaseBuilder( new File( storeDir ) );
-    }
 
     public GraphDatabaseBuilder newEmbeddedDatabaseBuilder( File storeDir )
     {
@@ -108,15 +83,10 @@ public class GraphDatabaseFactory
     protected GraphDatabaseBuilder.DatabaseCreator createDatabaseCreator(
             final File storeDir, final GraphDatabaseFactoryState state )
     {
-        return new GraphDatabaseBuilder.DatabaseCreator()
-        {
-            @Override
-            public GraphDatabaseService newDatabase( Map<String,String> config )
-            {
-                config.put( ""unsupported.dbms.ephemeral"", ""false"" );
-                GraphDatabaseFacadeFactory.Dependencies dependencies = state.databaseDependencies();
-                return GraphDatabaseFactory.this.newDatabase( storeDir, config, dependencies );
-            }
+        return config -> {
+            config.put( ""unsupported.dbms.ephemeral"", ""false"" );
+            GraphDatabaseFacadeFactory.Dependencies dependencies = state.databaseDependencies();
+            return GraphDatabaseFactory.this.newDatabase( storeDir, config, dependencies );
         };
     }
 
@@ -130,57 +100,6 @@ public class GraphDatabaseFactory
         return new CommunityFacadeFactory().newFacade( storeDir, config, dependencies );
     }
 
-    /**
-     * @deprecated Manipulating kernel extensions is deprecated and will be moved to internal components.
-     *
-     * @return kernel extensions
-     */
-    @Deprecated
-    public Iterable<KernelExtensionFactory<?>> getKernelExtension()
-    {
-        return getCurrentState().getKernelExtension();
-    }
-
-    /**
-     * @deprecated Manipulating kernel extensions is deprecated and will be moved to internal components.
-     *
-     * @param newKernelExtensions New kernel extensions to add
-     * @return the factory
-     */
-    @Deprecated
-    public GraphDatabaseFactory addKernelExtensions( Iterable<KernelExtensionFactory<?>> newKernelExtensions )
-    {
-        getCurrentState().addKernelExtensions( newKernelExtensions );
-        return this;
-    }
-
-    /**
-     * @deprecated Manipulating kernel extensions is deprecated and will be moved to internal components.
-     *
-     * @param newKernelExtension New kernel extension too add
-     * @return the factory
-     */
-    @Deprecated
-    @SuppressWarnings({""rawtypes"", ""unchecked""})
-    public GraphDatabaseFactory addKernelExtension( KernelExtensionFactory<?> newKernelExtension )
-    {
-        List extensions = asList( newKernelExtension );
-        return addKernelExtensions( extensions );
-    }
-
-    /**
-     * @deprecated Manipulating kernel extensions is deprecated and will be moved to internal components.
-     *
-     * @param newKernelExtensions New kernel extensions to set
-     * @return the factory
-     */
-    @Deprecated
-    public GraphDatabaseFactory setKernelExtensions( Iterable<KernelExtensionFactory<?>> newKernelExtensions )
-    {
-        getCurrentState().setKernelExtensions( newKernelExtensions );
-        return this;
-    }
-
     public GraphDatabaseFactory addURLAccessRule( String protocol, URLAccessRule rule )
     {
         getCurrentState().addURLAccessRule( protocol, rule );
diff --git a/community/kernel/src/main/java/org/neo4j/kernel/impl/util/dbstructure/DbStructureTool.java b/community/kernel/src/main/java/org/neo4j/kernel/impl/util/dbstructure/DbStructureTool.java
index 8ffb572de3e..bc7aa6b3d49 100644
--- a/community/kernel/src/main/java/org/neo4j/kernel/impl/util/dbstructure/DbStructureTool.java
+++ b/community/kernel/src/main/java/org/neo4j/kernel/impl/util/dbstructure/DbStructureTool.java
@@ -57,7 +57,7 @@ public class DbStructureTool
                 generatedClassWithPackage
         );
 
-        GraphDatabaseService graph = new GraphDatabaseFactory().newEmbeddedDatabase( dbDir );
+        GraphDatabaseService graph = new GraphDatabaseFactory().newEmbeddedDatabase( new File( dbDir ) );
         try
         {
             if ( writeToFile )
diff --git a/community/kernel/src/main/java/org/neo4j/kernel/internal/GraphDatabaseAPI.java b/community/kernel/src/main/java/org/neo4j/kernel/internal/GraphDatabaseAPI.java
index 2101f7638d9..3dda0f100a9 100644
--- a/community/kernel/src/main/java/org/neo4j/kernel/internal/GraphDatabaseAPI.java
+++ b/community/kernel/src/main/java/org/neo4j/kernel/internal/GraphDatabaseAPI.java
@@ -48,6 +48,5 @@ public interface GraphDatabaseAPI extends GraphDatabaseService
      */
     URL validateURLAccess( URL url ) throws URLAccessValidationError;
 
-    @Deprecated
     String getStoreDir();
 }
diff --git a/community/kernel/src/main/java/org/neo4j/unsafe/batchinsert/BatchInserters.java b/community/kernel/src/main/java/org/neo4j/unsafe/batchinsert/BatchInserters.java
index 2c4c6bb7cf0..bf3f6b9927e 100644
--- a/community/kernel/src/main/java/org/neo4j/unsafe/batchinsert/BatchInserters.java
+++ b/community/kernel/src/main/java/org/neo4j/unsafe/batchinsert/BatchInserters.java
@@ -35,19 +35,6 @@ import static org.neo4j.helpers.collection.MapUtil.stringMap;
  */
 public final class BatchInserters
 {
-    /**
-     * Get a {@link BatchInserter} given a store directory.
-     *
-     * @param storeDir the store directory
-     * @return a new {@link BatchInserter}
-     * @deprecated use {@link #inserter(File)} instead
-     */
-    @Deprecated
-    public static BatchInserter inserter( String storeDir )
-    {
-        return inserter( storeDir, stringMap() );
-    }
-
     /**
      * Get a {@link BatchInserter} given a store directory.
      *
@@ -57,21 +44,12 @@ public final class BatchInserters
      */
     public static BatchInserter inserter( File storeDir ) throws IOException
     {
-        return inserter( storeDir, new DefaultFileSystemAbstraction(), stringMap() );
+        return inserter( storeDir, stringMap() );
     }
 
-    /**
-     * Get a {@link BatchInserter} given a store directory.
-     *
-     * @param storeDir the store directory
-     * @param config configuration settings to use
-     * @return a new {@link BatchInserter}
-     * @deprecated use {@link #inserter(File, Map)} instead
-     */
-    @Deprecated
-    public static BatchInserter inserter( String storeDir, Map<String,String> config )
+    public static BatchInserter inserter( File storeDir, FileSystemAbstraction fs ) throws IOException
     {
-        return inserter( storeDir, new DefaultFileSystemAbstraction(), config );
+        return inserter( storeDir, fs, stringMap(), (Iterable) Service.load( KernelExtensionFactory.class )  );
     }
 
     /**
@@ -84,96 +62,15 @@ public final class BatchInserters
      */
     public static BatchInserter inserter( File storeDir, Map<String,String> config ) throws IOException
     {
-        return inserter( storeDir, new DefaultFileSystemAbstraction(), config );
+        return inserter( storeDir, new DefaultFileSystemAbstraction(), config, (Iterable) Service.load( KernelExtensionFactory.class ) );
     }
 
-    /**
-     * @deprecated use {@link #inserter(File)} instead
-     * @param storeDir the store directory
-     * @param fileSystem the file system abstraction to use
-     * @return a new {@link BatchInserter}
-     */
-    @Deprecated
-    public static BatchInserter inserter( String storeDir, FileSystemAbstraction fileSystem )
-    {
-        return inserter( storeDir, fileSystem, stringMap() );
-    }
 
-    /**
-     * Get a {@link BatchInserter} given a store directory.
-     *
-     * @param storeDir the store directory
-     * @param fileSystem the file system abstraction to use
-     * @return a new {@link BatchInserter}
-     * @deprecated use {@link #inserter(File)} instead
-     * @throws IOException if there is an IO error
-     */
-    @Deprecated
-    public static BatchInserter inserter( File storeDir, FileSystemAbstraction fileSystem ) throws IOException
+    public static BatchInserter inserter( File storeDir, FileSystemAbstraction fs, Map<String,String> config ) throws IOException
     {
-        return inserter( storeDir, fileSystem, stringMap() );
+        return inserter( storeDir, fs, config, (Iterable) Service.load( KernelExtensionFactory.class )  );
     }
 
-    /**
-     * @deprecated use {@link #inserter(File, Map)} instead
-     * @param storeDir the store directory
-     * @param fileSystem the file system abstraction to use
-     * @param config configuration settings to use
-     * @return a new {@link BatchInserter}
-     */
-    @Deprecated
-    public static BatchInserter inserter( String storeDir, FileSystemAbstraction fileSystem,
-            Map<String,String> config )
-    {
-        try
-        {
-            return inserter( new File( storeDir ), fileSystem, config );
-        }
-        catch ( IOException e )
-        {
-            throw new RuntimeException( e );
-        }
-    }
-
-    /**
-     * Get a {@link BatchInserter} given a store directory.
-     *
-     * @param storeDir the store directory
-     * @param fileSystem the file system abstraction to use
-     * @param config configuration settings to use
-     * @return a new {@link BatchInserter}
-     * @deprecated use {@link #inserter(File, Map)} instead
-     * @throws IOException if there is",Remove deprecated methods from GraphDatabaseFactory,"""Remove deprecated methods and replace string paths with File objects""","The commit message should be:

""Convert all String paths to File paths in various places""

This commit message accurately reflects the changes made in the code, which involve replacing String paths with File paths in various places.","This commit updates several files in the Neo4j codebase to use the `File` object instead of a `String` to represent file paths. This change affects the following files:

* `ExecutionEngineTest.scala`
* `IndexOpAcceptanceTest.scala`
* `CompilerComparisonTest.scala`
* `DataImportTest.scala`
* `PerformanceTest.scala`
* `AStarPerformanceIT.java`
* `Script.java`
* `ImportToolDocIT.java`
* `TargetDirectory.java`
* `GraphDatabaseFactory.java`
* `DbStructureTool.java`
* `BatchInserters.java`

In general, the changes involve replacing `String` representations of file paths with `File` objects, and updating methods that accept or return file paths to use `File` objects instead of `String`s. This change may have been made to improve the consistency and robustness of the codebase, as `File` objects provide more functionality and error checking than `String` representations of file paths.

For example, in `ExecutionEngineTest.scala`, the `createReadOnlyEngine()` method is updated to use a `File` object to represent the database directory:
```
-    val old = new TestGraphDatabaseFactory().newEmbeddedDatabase(""target/readonly"")
+    val old = new TestGraphDatabaseFactory().newEmbeddedDatabase( new File( ""target/readonly"" ) )
```
Similarly, in `IndexOpAcceptanceTest.scala`, the `createDbWithFailedIndex` method is updated to use a `File` object to represent the database directory:
```
-    graph = new GraphDatabaseCypherService(new TestGraphDatabaseFactory().newEmbeddedDatabase(""target/test-data/impermanent-db""))
+    graph = new GraphDatabaseCypherService(new TestGraphDatabaseFactory().newEmbeddedDatabase(storeDir))
```
In `CompilerComparisonTest.scala`, the `executionResults` method is updated to use a `File` object to represent the database directory:
```
-    val db = new GraphDatabaseCypherService(new GraphDatabaseFactory().newEmbeddedDatabase(dataSetDir))
+    val db = new GraphDatabaseCypherService(new GraphDatabaseFactory().newEmbeddedDatabase(new File(dataSetDir)))
```
In `DataImportTest.scala`, the `createInserters()` method is updated to use a `File` object to represent the database directory:
```
-  private def createInserters(targetDir: String) = {
+  private def createInserters(targetDir: File) = {
```
In `PerformanceTest.scala`, the `beforeEach()` method is updated to use a `File` object to represent the database directory:
```
-    db = new GraphDatabaseFactory().newEmbeddedDatabase(""target/db"")
+    db = new GraphDatabaseFactory().newEmbeddedDatabase(new File(""target/db""))
```
In `AStarPerformanceIT.java`, the `setUp()` method is updated to use a `File` object to represent the database directory:
```
-        GraphDatabaseService db = new GraphDatabaseFactory().newEmbeddedDatabase( directory.getAbsolutePath() );
+        GraphDatabaseService db = new GraphDatabaseFactory().newEmbeddedDatabase( directory.getAbsoluteFile() );
```
In `Script.java`, the `storeDir` field is changed from a `String` to a `File`, and the `storeDir()` method is updated to return a `File` object:
```
-    protected String storeDir;
+    protected File storeDir;

     ...

-    protected String storeDir()
+    protected File storeDir()
     {
         return storeDir;
     }
```
In `ImportToolDocIT.java`, several methods are updated to use `File` objects to represent file paths:
```
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
```
In `TargetDirectory.java`, the `absolutePath()` method is updated to return a `File` object instead of a `String`:
```
-        public String absolutePath()
+        public File absolutePath()
         {
```","""Refactor: Replace string path with File objects across various Neo4j test and core classes for better file handling consistency.""",Model 4
"diff --git a/modules/activiti-engine/src/test/java/org/activiti/engine/test/api/runtime/RuntimeServiceTest.java b/modules/activiti-engine/src/test/java/org/activiti/engine/test/api/runtime/RuntimeServiceTest.java
index 29707dbc86..fab9ced37f 100644
--- a/modules/activiti-engine/src/test/java/org/activiti/engine/test/api/runtime/RuntimeServiceTest.java
+++ b/modules/activiti-engine/src/test/java/org/activiti/engine/test/api/runtime/RuntimeServiceTest.java
@@ -219,6 +219,86 @@ public class RuntimeServiceTest extends PluggableActivitiTestCase {
     }
   }
   
+  /**
+   * Testcase to reproduce ACT-950 (https://jira.codehaus.org/browse/ACT-950) 
+   */
+  @Deployment
+  public void testFindActiveActivityIdProcessWithErrorEventAndSubProcess() {
+    ProcessInstance processInstance = processEngine.getRuntimeService().startProcessInstanceByKey(""errorEventSubprocess"");
+    
+    List<String> activeActivities = runtimeService.getActiveActivityIds(processInstance.getId());
+    assertEquals(3, activeActivities.size());
+    
+    List<Task> tasks = taskService.createTaskQuery().list();
+    assertEquals(2, tasks.size());
+    
+    Task parallelUserTask = null;
+    for (Task task : tasks) {
+      if (!task.getName().equals(""ParallelUserTask"") && !task.getName().equals(""MainUserTask"")) {
+        fail(""Expected: <ParallelUserTask> or <MainUserTask> but was <"" + task.getName() + "">."");
+      }
+      if (task.getName().equals(""ParallelUserTask"")) {
+        parallelUserTask = task;
+      }
+    }
+    assertNotNull(parallelUserTask);
+
+    taskService.complete(parallelUserTask.getId());
+    
+    Execution execution = runtimeService.createExecutionQuery().processInstanceId(processInstance.getId()).activityId(""subprocess1WaitBeforeError"").singleResult();
+    runtimeService.signal(execution.getId());
+    
+    activeActivities = runtimeService.getActiveActivityIds(processInstance.getId());
+    assertEquals(2, activeActivities.size());
+    
+    tasks = taskService.createTaskQuery().list();
+    assertEquals(2, tasks.size());
+    
+    Task beforeErrorUserTask = null;
+    for (Task task : tasks) {
+      if (!task.getName().equals(""BeforeError"") && !task.getName().equals(""MainUserTask"")) {
+        fail(""Expected: <BeforeError> or <MainUserTask> but was <"" + task.getName() + "">."");
+      }
+      if (task.getName().equals(""BeforeError"")) {
+        beforeErrorUserTask = task;
+      }
+    }
+    assertNotNull(beforeErrorUserTask);
+    
+    taskService.complete(beforeErrorUserTask.getId());
+    
+    activeActivities = runtimeService.getActiveActivityIds(processInstance.getId());
+    assertEquals(2, activeActivities.size());
+    
+    tasks = taskService.createTaskQuery().list();
+    assertEquals(2, tasks.size());
+
+    Task afterErrorUserTask = null;
+    for (Task task : tasks) {
+      if (!task.getName().equals(""AfterError"") && !task.getName().equals(""MainUserTask"")) {
+        fail(""Expected: <AfterError> or <MainUserTask> but was <"" + task.getName() + "">."");
+      }
+      if (task.getName().equals(""AfterError"")) {
+        afterErrorUserTask = task;
+      }
+    }
+    assertNotNull(afterErrorUserTask);
+    
+    taskService.complete(afterErrorUserTask.getId());
+    
+    tasks = taskService.createTaskQuery().list();
+    assertEquals(1, tasks.size());
+    assertEquals(""MainUserTask"", tasks.get(0).getName());
+    
+    activeActivities = runtimeService.getActiveActivityIds(processInstance.getId());
+    assertEquals(1, activeActivities.size());
+    assertEquals(""MainUserTask"", activeActivities.get(0));
+    
+    taskService.complete(tasks.get(0).getId());
+    
+    assertProcessEnded(processInstance.getId());
+  }
+  
   public void testSignalUnexistingExecututionId() {
     try {
       runtimeService.signal(""unexistingExecutionId"");      
diff --git a/modules/activiti-engine/src/test/resources/org/activiti/engine/test/api/runtime/RuntimeServiceTest.testFindActiveActivityIdProcessWithErrorEventAndSubProcess.bpmn20.xml b/modules/activiti-engine/src/test/resources/org/activiti/engine/test/api/runtime/RuntimeServiceTest.testFindActiveActivityIdProcessWithErrorEventAndSubProcess.bpmn20.xml
new file mode 100644
index 0000000000..0650b280d8
--- /dev/null
+++ b/modules/activiti-engine/src/test/resources/org/activiti/engine/test/api/runtime/RuntimeServiceTest.testFindActiveActivityIdProcessWithErrorEventAndSubProcess.bpmn20.xml
@@ -0,0 +1,76 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<definitions id=""definitions"" xmlns=""http://www.omg.org/spec/BPMN/20100524/MODEL""
+  xmlns:activiti=""http://activiti.org/bpmn"" targetNamespace=""Examples"">
+
+  <process id=""errorEventSubprocess"" name=""ErrorEventSubprocess"">
+  
+    <startEvent id=""startevent1"" name=""Start"" />
+    
+    <subProcess id=""subprocess1"" name=""Sub Process"">
+    
+      <startEvent id=""subprocess1startevent2"" name=""Start"" />
+      
+      <sequenceFlow id=""subprocess1flow2"" name="""" sourceRef=""subprocess1startevent2"" targetRef=""subprocess1parallelgateway1"" />
+      
+      <parallelGateway id=""subprocess1parallelgateway1"" name=""Parallel Gateway"" />
+      
+      <userTask id=""subprocess1ParallelUserTask"" name=""ParallelUserTask"" activiti:assignee=""user1"" />
+      
+      <sequenceFlow id=""subprocess1flow3"" name="""" sourceRef=""subprocess1parallelgateway1"" targetRef=""subprocess1ParallelUserTask"" />
+      
+      <endEvent id=""subprocess1endevent1"" name=""ErrorEnd"">
+        <errorEventDefinition errorRef=""err1"" />
+      </endEvent>
+      
+      <endEvent id=""subprocess1endevent2"" name=""End"" />
+      
+      <sequenceFlow id=""subprocess1flow6"" name="""" sourceRef=""subprocess1ParallelUserTask"" targetRef=""subprocess1endevent2"" />
+      
+      <receiveTask id=""subprocess1WaitBeforeError"" name=""WaitBeforeError""/>
+      
+      <sequenceFlow id=""subprocess1flow9"" name="""" sourceRef=""subprocess1parallelgateway1"" targetRef=""subprocess1WaitBeforeError"" />
+      
+      <userTask id=""subprocess1BeforeError"" name=""BeforeError"" />
+      
+      <sequenceFlow id=""subprocess1flow10"" name="""" sourceRef=""subprocess1WaitBeforeError"" targetRef=""subprocess1BeforeError"" />
+      
+      <sequenceFlow id=""subprocess1flow11"" name="""" sourceRef=""subprocess1BeforeError"" targetRef=""subprocess1endevent1""/>
+      
+    </subProcess>
+    
+    <sequenceFlow id=""flow1"" name="""" sourceRef=""startevent1"" targetRef=""parallelgateway2"" />
+    
+    <endEvent id=""EndSuccess"" name=""EndSuccess"" />
+    
+    <userTask id=""AfterSuccess"" name=""AfterSuccess"" />
+    
+    <sequenceFlow id=""flow12"" name="""" sourceRef=""subprocess1"" targetRef=""AfterSuccess"" />
+    
+    <sequenceFlow id=""flow13"" name="""" sourceRef=""AfterSuccess"" targetRef=""EndSuccess"" />
+    
+    <boundaryEvent id=""boundaryerror1"" attachedToRef=""subprocess1"">
+      <errorEventDefinition errorRef=""err1"" />
+    </boundaryEvent>
+    
+    <userTask id=""AfterError"" name=""AfterError"" />
+    
+    <sequenceFlow id=""flow14"" name="""" sourceRef=""boundaryerror1"" targetRef=""AfterError"" />
+    
+    <endEvent id=""EndError"" name=""EndError"" />
+    
+    <sequenceFlow id=""flow15"" name="""" sourceRef=""AfterError"" targetRef=""EndError"" />
+    
+    <parallelGateway id=""parallelgateway2"" name=""Parallel Gateway"" />
+    
+    <sequenceFlow id=""flow16"" name="""" sourceRef=""parallelgateway2"" targetRef=""subprocess1"" />
+    
+    <userTask id=""MainUserTask"" name=""MainUserTask"" activiti:assignee=""user1"" />
+    
+    <sequenceFlow id=""flow17"" name="""" sourceRef=""parallelgateway2"" targetRef=""MainUserTask"" />
+    
+    <endEvent id=""EndMainUserTask"" name=""EndMainUserTask"" />
+    
+    <sequenceFlow id=""flow18"" name="""" sourceRef=""MainUserTask"" targetRef=""EndMainUserTask""/>
+  </process>
+
+</definitions>
\ No newline at end of file",Added testcase for Issue ACT - 950,"""Added test case for ACT-950: Find active activity id process with error event and sub process""","""Added test case for ACT-950: Find active activity IDs in a process with error event and sub-process""","""Added test case for reproducing ACT-950 (<https://jira.codehaus.org/browse/ACT-950>) and corresponding BPMN file.""

The commit adds a new test case to the `RuntimeServiceTest` class to reproduce the issue described in ACT-950. The test case starts a process instance of the process defined in the `RuntimeServiceTest.testFindActiveActivityIdProcessWithErrorEventAndSubProcess.bpmn20.xml` file, which is also added in this commit. The test case then checks that the process behaves as expected when an error event occurs in a subprocess.",Add test to reproduce ACT-950 with error event and subprocess. Include BPMN XML for the process definition.,Model 3
"diff --git a/motan-extension/protocol-extension/motan-protocol-grpc/pom.xml b/motan-extension/protocol-extension/motan-protocol-grpc/pom.xml
index 09d4079..02db166 100644
--- a/motan-extension/protocol-extension/motan-protocol-grpc/pom.xml
+++ b/motan-extension/protocol-extension/motan-protocol-grpc/pom.xml
@@ -14,7 +14,7 @@
     <parent>
         <groupId>com.weibo</groupId>
         <artifactId>protocol-extension</artifactId>
-        <version>0.2.2-SNAPSHOT</version>
+        <version>0.2.3-SNAPSHOT</version>
     </parent>
     <artifactId>motan-protocol-grpc</artifactId>
     <name>motan-protocol-grpc</name>",update version,"""Bump motan-protocol-grpc parent version to 0.2.3-SNAPSHOT""","""Update motan-protocol-grpc parent version to 0.2.3-SNAPSHOT""","""Update motan-protocol-grpc pom.xml parent version from 0.2.2-SNAPSHOT to 0.2.3-SNAPSHOT""",Update motan-protocol-grpc version from 0.2.2-SNAPSHOT to 0.2.3-SNAPSHOT in pom.xml,Model 4
"diff --git a/api/src/main/java/org/geysermc/api/Geyser.java b/api/src/main/java/org/geysermc/api/Geyser.java
index 4bb13a41..37099339 100644
--- a/api/src/main/java/org/geysermc/api/Geyser.java
+++ b/api/src/main/java/org/geysermc/api/Geyser.java
@@ -30,10 +30,6 @@ import org.geysermc.api.logger.Logger;
 import org.geysermc.api.plugin.PluginManager;
 
 import java.util.Collection;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Objects;
-import java.util.UUID;
 import java.util.concurrent.ScheduledExecutorService;
 
 public class Geyser {
diff --git a/connector/src/main/java/org/geysermc/connector/network/translators/item/ItemTranslator.java b/connector/src/main/java/org/geysermc/connector/network/translators/item/ItemTranslator.java
index 9bf5d3c4..437a8dc4 100644
--- a/connector/src/main/java/org/geysermc/connector/network/translators/item/ItemTranslator.java
+++ b/connector/src/main/java/org/geysermc/connector/network/translators/item/ItemTranslator.java
@@ -85,7 +85,7 @@ public class ItemTranslator {
     }
 
     public ItemEntry getItem(ItemData data) {
-        for (ItemEntry itemEntry : Toolbox.ITEM_ENTRIES.values()) {
+        for (ItemEntry itemEntry : Toolbox.ITEM_ENTRIES.valueCollection()) {
             if (itemEntry.getBedrockId() == data.getId() && itemEntry.getBedrockData() == data.getDamage()) {
                 return itemEntry;
             }
diff --git a/connector/src/main/java/org/geysermc/connector/utils/Toolbox.java b/connector/src/main/java/org/geysermc/connector/utils/Toolbox.java
index be32ada7..4aee4d70 100644
--- a/connector/src/main/java/org/geysermc/connector/utils/Toolbox.java
+++ b/connector/src/main/java/org/geysermc/connector/utils/Toolbox.java
@@ -4,6 +4,8 @@ import com.fasterxml.jackson.databind.ObjectMapper;
 import com.nukkitx.network.VarInts;
 import com.nukkitx.protocol.bedrock.packet.StartGamePacket;
 import com.nukkitx.protocol.bedrock.v361.BedrockUtils;
+import gnu.trove.map.TIntObjectMap;
+import gnu.trove.map.hash.TIntObjectHashMap;
 import io.netty.buffer.ByteBuf;
 import io.netty.buffer.Unpooled;
 import org.geysermc.connector.console.GeyserLogger;
@@ -19,8 +21,8 @@ public class Toolbox {
     public static final Collection<StartGamePacket.ItemEntry> ITEMS;
     public static final ByteBuf CACHED_PALLETE;
 
-    public static final Map<Integer, ItemEntry> ITEM_ENTRIES;
-    public static final Map<Integer, BlockEntry> BLOCK_ENTRIES;
+    public static final TIntObjectMap<ItemEntry> ITEM_ENTRIES;
+    public static final TIntObjectMap<BlockEntry> BLOCK_ENTRIES;
 
     static {
         InputStream stream = Toolbox.class.getClassLoader().getResourceAsStream(""bedrock/cached_palette.json"");
@@ -79,7 +81,7 @@ public class Toolbox {
             ex.printStackTrace();
         }
 
-        Map<Integer, ItemEntry> itemEntries = new HashMap<>();
+        TIntObjectMap<ItemEntry> itemEntries = new TIntObjectHashMap<>();
         int itemIndex = 0;
 
         for (Map.Entry<String, Map<String, Object>> itemEntry : items.entrySet()) {
@@ -87,7 +89,7 @@ public class Toolbox {
             itemIndex++;
         }
 
-        ITEM_ENTRIES = Collections.unmodifiableMap(itemEntries);
+        ITEM_ENTRIES = itemEntries;
 
         InputStream blockStream = Toolbox.class.getClassLoader().getResourceAsStream(""blocks.json"");
         ObjectMapper blockMapper = new ObjectMapper();
@@ -99,7 +101,7 @@ public class Toolbox {
             ex.printStackTrace();
         }
 
-        Map<Integer, BlockEntry> blockEntries = new HashMap<>();
+        TIntObjectMap<BlockEntry> blockEntries = new TIntObjectHashMap<>();
         int blockIndex = 0;
 
         for (Map.Entry<String, Map<String, Object>> itemEntry : blocks.entrySet()) {
@@ -113,6 +115,6 @@ public class Toolbox {
             blockIndex++;
         }
 
-        BLOCK_ENTRIES = Collections.unmodifiableMap(blockEntries);
+        BLOCK_ENTRIES = blockEntries;
     }
 }
\ No newline at end of file",Convert item and block maps in Toolbox to TIntObjectMaps,"""Replace HashMap with TIntObjectHashMap in Toolbox for improved performance""","""Switched from using Java's built-in `Map` and `HashMap` to Trove's `TIntObjectMap` for improved performance.""","""Refactor Geyser and Toolbox classes to use Trove's TIntObjectMap instead of HashMap for ITEM_ENTRIES and BLOCK_ENTRIES""

This commit appears to refactor the `Geyser` and `Toolbox` classes to use the `TIntObjectMap` class from the Trove library instead of `HashMap` for the `ITEM_ENTRIES` and `BLOCK_ENTRIES` fields. The `TIntObjectMap` class is a specialized map implementation for mapping integers to objects, which may offer better performance or memory usage than `HashMap` in certain situations.

In `Geyser.java`, the import for `java.util.Map` and the declaration of `ITEM_ENTRIES` as a `Map` have been removed.

In `Toolbox.java`, the imports for `java.util.Map` and `java.util.HashMap` have been replaced with imports for `gnu.trove.map.TIntObjectMap` and `gnu.trove.map.hash.TIntObjectHashMap`. The declarations of `ITEM_ENTRIES` and `BLOCK_ENTRIES` have also been changed to use `TIntObjectMap` instead of `Map`. The initialization of `ITEM_ENTRIES` and `BLOCK_ENTRIES` has been changed to use the `TIntObjectHashMap` constructor instead of the `HashMap` constructor.

Additionally, in `ItemTranslator.java`, the loop that iterates over `ITEM_ENTRIES` has been updated to use the `valueCollection()` method instead of `values()`. This is likely because `TIntObjectMap` does not have a `values()` method, but it does have a `valueCollection()` method that returns a collection of the map's values.","""Refactor data structures to use TIntObjectMap for performance improvements in Toolbox class.""",Model 1
"diff --git a/nashorn/make/build.xml b/nashorn/make/build.xml
index 93342248de5..78a713bfc46 100644
--- a/nashorn/make/build.xml
+++ b/nashorn/make/build.xml
@@ -282,6 +282,11 @@ grant codeBase ""file:/${basedir}/test/script/trusted/*"" {
     permission java.security.AllPermission;
 };
 
+grant codeBase ""file:/${basedir}/test/script/maptests/*"" {
+    permission java.io.FilePermission ""${basedir}/test/script/maptests/*"",""read"";
+    permission java.lang.RuntimePermission ""nashorn.debugMode"";
+};
+
 grant codeBase ""file:/${basedir}/test/script/basic/*"" {
     permission java.io.FilePermission ""${basedir}/test/script/-"", ""read"";
     permission java.io.FilePermission ""$${user.dir}"", ""read"";
diff --git a/nashorn/make/project.properties b/nashorn/make/project.properties
index ad36744836b..d51e72e4180 100644
--- a/nashorn/make/project.properties
+++ b/nashorn/make/project.properties
@@ -115,6 +115,7 @@ run.classpath=\
 test.dir=test
 test.script.dir=test/script
 test.basic.dir=test/script/basic
+test.maptests.dir=test/script/maptests
 test.error.dir=test/script/error
 test.sandbox.dir=test/script/sandbox
 test.trusted.dir=test/script/trusted
@@ -125,7 +126,7 @@ testjfx.dir=${test.script.dir}/jfx
 testmarkdown.dir=${test.script.dir}/markdown
 
 test-sys-prop.test.dir=${test.dir}
-test-sys-prop.test.js.roots=${test.basic.dir} ${test.error.dir} ${test.sandbox.dir} ${test.trusted.dir}
+test-sys-prop.test.js.roots=${test.basic.dir} ${test.maptests.dir} ${test.error.dir} ${test.sandbox.dir} ${test.trusted.dir}
 test-sys-prop.test262.suite.dir=${test262.suite.dir}
 test-sys-prop.es5conform.testcases.dir=${test.external.dir}/ES5Conform/TestCases
 test-sys-prop.test.basic.dir=${test.basic.dir}
@@ -278,7 +279,7 @@ run.test.jvmargs.octane.main=${run.test.jvmargs.common}
 run.test.jvmsecurityargs=-Xverify:all -Djava.security.manager -Djava.security.policy=${basedir}/build/nashorn.policy
 
 # VM options for script tests with @fork option
-test-sys-prop.test.fork.jvm.options=${run.test.jvmargs.main} -Xmx${run.test.xmx} ${run.test.jvmsecurityargs}
+test-sys-prop.test.fork.jvm.options=${run.test.jvmargs.main} -Xmx${run.test.xmx} ${run.test.jvmsecurityargs} -cp ${run.test.classpath}
 
 # path of rhino.jar for benchmarks
 rhino.jar=
diff --git a/nashorn/test/script/currently-failing/gettersetter.js b/nashorn/test/script/currently-failing/gettersetter.js
new file mode 100644
index 00000000000..88f6949233c
--- /dev/null
+++ b/nashorn/test/script/currently-failing/gettersetter.js
@@ -0,0 +1,48 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @test
+ * @option -Dnashorn.debug=true
+ * @fork
+ */
+
+load(__DIR__ + ""maputil.js"");
+
+function Foo() {
+    return {
+       get foo() { return 42; },
+       set foo(x) {}
+    }
+}
+
+var obj1 = Foo();
+var obj2 = Foo();
+
+assertSameMap(obj1, obj2, ""Object literals before change"");
+
+Object.defineProperty(obj2, ""foo"", { get: function() { return 'hello' } });
+assertSameMap(obj1, obj2);
+
+Object.defineProperty(obj2, ""foo"", { set: function(x) { print(x) } });
+assertSameMap(obj1, obj2);
diff --git a/nashorn/test/script/maptests/builtins.js b/nashorn/test/script/maptests/builtins.js
new file mode 100644
index 00000000000..4de2ec9a8da
--- /dev/null
+++ b/nashorn/test/script/maptests/builtins.js
@@ -0,0 +1,58 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @test
+ * @option -Dnashorn.debug=true
+ * @fork
+ */
+
+load(__DIR__ + ""maputil.js"");
+
+// check that builtin objects share property map
+
+assertSameMap(new Boolean(true), new Boolean(false));
+assertSameMap(new Number(3), new Number(Math.PI));
+assertSameMap(new String('hello'), new String('world'));
+assertSameMap(new Object(), new Object());
+assertSameMap(/hello/, /world/);
+// try w/without regexp flags
+assertSameMap(/hello/i, /world/g);
+assertSameMap(new Date(), new Date());
+assertSameMap(new Date(2000, 1, 1), new Date(1972, 5, 6));
+assertSameMap(Function(), Function());
+assertSameMap(Function(""x"", ""return x""), Function(""x"", ""return x*x""));
+assertSameMap(new Error(), new Error());
+assertSameMap(new Error('foo'), new Error('bar'));
+assertSameMap(new EvalError(), new EvalError());
+assertSameMap(new EvalError('foo'), new EvalError('bar'));
+assertSameMap(new RangeError(), new RangeError());
+assertSameMap(new RangeError('foo'), new RangeError('bar'));
+assertSameMap(new ReferenceError(), new ReferenceError());
+assertSameMap(new ReferenceError('foo'), new ReferenceError('bar'));
+assertSameMap(new SyntaxError(), new SyntaxError());
+assertSameMap(new SyntaxError('foo'), new SyntaxError('bar'));
+assertSameMap(new TypeError(), new TypeError());
+assertSameMap(new TypeError('foo'), new TypeError('bar'));
+assertSameMap(new URIError(), new URIError());
+assertSameMap(new URIError('foo'), new URIError('bar'));
diff --git a/nashorn/test/script/maptests/constructor.js b/nashorn/test/script/maptests/constructor.js
new file mode 100644
index 00000000000..5722a3c15b9
--- /dev/null
+++ b/nashorn/test/script/maptests/constructor.js
@@ -0,0 +1,36 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @test
+ * @option -Dnashorn.debug=true
+ * @fork
+ */
+
+load(__DIR__ + ""point.js"");
+
+// use constructor defined in a different script file
+// These objects should share the map
+assertSameMap(new Point(2, 3), new Point(43, 23));
+assertSameMap(new Point(), new Point());
+assertSameMap(new Point(), new Point(3, 1));
diff --git a/nashorn/test/script/maptests/maputil.js b/nashorn/test/script/maptests/maputil.js
new file mode 100644
index 00000000000..aa85d7f1220
--- /dev/null
+++ b/nashorn/test/script/maptests/maputil.js
@@ -0,0 +1,38 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @subtest
+ */
+
+function assertSameMap(obj1, obj2, msg) {
+    if (! Debug.identical(Debug.map(obj1), Debug.map(obj2))) {
+        fail(obj1.constructor + "" instances don't share map"");
+    }
+}
+
+function assertNotSameMap(obj1, obj2, msg) {
+    if (Debug.identical(Debug.map(obj1), Debug.map(obj2))) {
+        fail(obj1.constructor + "" and "" + obj2.constructor + "" instances share map"");
+    }
+}
diff --git a/nashorn/test/script/maptests/object_create.js b/nashorn/test/script/maptests/object_create.js
new file mode 100644
index 00000000000..1b1bd604c85
--- /dev/null
+++ b/nashorn/test/script/maptests/object_create.js
@@ -0,0 +1,40 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @test
+ * @option -Dnashorn.debug=true
+ * @fork
+ */
+
+load(__DIR__ + ""maputil.js"");
+
+// Objects created by Object.create
+var obj1 = Object.create(Object.prototype);
+var obj2 = Object.create(Object.prototype);
+assertSameMap(obj1, obj2);
+
+var proto = { foo: 233 };
+obj1 = Object.create(proto);
+obj2 = Object.create(proto);
+assertSameMap(obj1, obj2);
diff --git a/nashorn/test/script/maptests/object_literals.js b/nashorn/test/script/maptests/object_literals.js
new file mode 100644
index 00000000000..c73d80140c7
--- /dev/null
+++ b/nashorn/test/script/maptests/object_literals.js
@@ -0,0 +1,46 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @test
+ * @option -Dnashorn.debug=true
+ * @fork
+ */
+
+load(__DIR__ + ""maputil.js"");
+
+// Object literals created at the same callsite
+function makeObject() {
+    return { foo: 34 }
+}
+assertSameMap(makeObject(), makeObject());
+
+function makeObject2() {
+    return { foo: 42, bar: 'hello' }
+}
+assertSameMap(makeObject2(), makeObject2());
+
+// Object literals created at different callsites
+assertSameMap({}, {});
+assertSameMap({foo: 4}, {foo: 'hello'});
+assertSameMap({foo: 34, bar: 'fdgd'}, {foo: 'world', bar: 54});
diff --git a/nashorn/test/script/maptests/point.js b/nashorn/test/script/maptests/point.js
new file mode 100644
index 00000000000..38b8fa2513a
--- /dev/null
+++ b/nashorn/test/script/maptests/point.js
@@ -0,0 +1,49 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+
+/**
+ * @subtest
+ */
+
+function Point(x, y) {
+   this.x =x; this.y =y;
+}
+
+Point.prototype.toString = function() {
+    return ""("" + this.x + "","" + this.y + "")"";
+}
+
+Point.prototype.modulus = function() {
+    return Math.sqrt(this.x*this.x + this.y*this.y);
+}
+
+Point.prototype.argument = function() {
+    return Math.atan2(this.y, this.x);
+}
+
+load(__DIR__ + ""maputil.js"");
+
+assertSameMap(new Point(2, 3), new Point(43, 23));
+assertSameMap(new Point(), new Point());
+assertSameMap(new Point(), new Point(3, 1));
diff --git a/nashorn/test/script/maptests/property_add.js b/nashorn/test/script/maptests/property_add.js
new file mode 100644
index 00000000000..2026455459d
--- /dev/null
+++ b/nashorn/test/script/maptests/property_add.js
@@ -0,0 +1,46 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @test
+ * @option -Dnashorn.debug=true
+ * @fork
+ */
+
+load(__DIR__ + ""maputil.js"");
+
+function Foo() {}
+
+var obj1 = new Foo();
+var obj2 = new Foo();
+
+assertSameMap(obj1, obj2);
+
+// property addition at same callsite
+function addX(obj, val) {
+   obj.x = val;
+}
+addX(obj1, 3);
+addX(obj2, 'hello');
+
+assertSameMap(obj1, obj2);
diff --git a/nashorn/test/script/maptests/property_delete.js b/nashorn/test/script/maptests/property_delete.js
new file mode 100644
index 00000000000..e2824dd6315
--- /dev/null
+++ b/nashorn/test/script/maptests/property_delete.js
@@ -0,0 +1,48 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @test
+ * @option -Dnashorn.debug=true
+ * @fork
+ */
+
+load(__DIR__ + ""maputil.js"");
+
+function Foo() {
+    this.x = 33;
+}
+
+var obj1 = new Foo();
+var obj2 = new Foo();
+
+assertSameMap(obj1, obj2);
+
+// property deletion at same callsite
+function deleteX(obj) {
+   delete obj.x;
+}
+deleteX(obj1);
+deleteX(obj2);
+
+assertSameMap(obj1, obj2);
diff --git a/nashorn/test/script/maptests/proto.js b/nashorn/test/script/maptests/proto.js
new file mode 100644
index 00000000000..afb59509a0a
--- /dev/null
+++ b/nashorn/test/script/maptests/proto.js
@@ -0,0 +1,56 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @test
+ * @option -Dnashorn.debug=true
+ * @fork
+ */
+
+load(__DIR__ + ""maputil.js"");
+
+// add/delete property to proto (direct/indirect) should
+// not affect the property map of the objects
+
+var proto2 = { foo: 334 }
+var proto  = Object.create(proto2);
+proto.bar = ""hello"";
+
+var obj1 = Object.create(proto);
+var obj2 = Object.create(proto);
+
+assertSameMap(obj1, obj2);
+
+proto.newX = 'world';
+assertSameMap(obj1, obj2);
+
+delete proto.newX;
+assertSameMap(obj1, obj2);
+
+proto2.newX = ""foo"";
+assertSameMap(obj1, obj2);
+
+delete proto2.newX;
+assertSameMap(obj1, obj2);
+
+",Add tests to assert map identity of certain objects .,"""Added tests for property map sharing in Nashorn""","Added tests for property maps in Nashorn

This commit adds a new directory `maptests` with several test scripts that verify the behavior of property maps in Nashorn. The tests cover various scenarios, including:

* Object literals created at the same callsite
* Object literals created at different callsites
* Objects created by `Object.create`
* Property addition and deletion at the same callsite
* Property addition and deletion to a prototype object
* Constructor functions

The tests use the `assertSameMap` function to verify that the property maps of two objects are identical. The tests are designed to ensure that Nashorn's property map implementation is correct and consistent.","The commit message could be:

""Adding currently-failing and maptests directories and test files for Nashorn

The currently-failing directory contains the gettersetter.js test file, which tests the behavior of getter and setter functions in Nashorn. The maptests directory contains several test files that test the behavior of Nashorn's property maps for built-in objects, constructors, object literals, object creation, property addition, and property deletion. The test files use a utility function, assertSameMap, to check whether two objects share the same property map.""

Additionally, it appears that the project.properties file has been updated to include the new test directories and test files, and the build.xml file has been updated to grant permissions for the new test files. The commit message could include a brief description of these changes as well.","""Added new map tests and adjusted permissions and properties for Nashorn project for better debugging and validation.""",Label
"diff --git a/transport-native-epoll/src/main/c/io_netty_channel_epoll_Native.c b/transport-native-epoll/src/main/c/io_netty_channel_epoll_Native.c
index 6d7c407f74..d8b3184454 100644
--- a/transport-native-epoll/src/main/c/io_netty_channel_epoll_Native.c
+++ b/transport-native-epoll/src/main/c/io_netty_channel_epoll_Native.c
@@ -27,6 +27,7 @@
 #include <unistd.h>
 #include <arpa/inet.h>
 #include <fcntl.h>
+#include <sys/utsname.h>
 #include ""io_netty_channel_epoll_Native.h""
 
 
@@ -896,6 +897,10 @@ JNIEXPORT void JNICALL Java_io_netty_channel_epoll_Native_setReuseAddress(JNIEnv
     setOption(env, fd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof(optval));
 }
 
+JNIEXPORT void JNICALL Java_io_netty_channel_epoll_Native_setReusePort(JNIEnv * env, jclass clazz, jint fd, jint optval) {
+    setOption(env, fd, SOL_SOCKET, SO_REUSEPORT, &optval, sizeof(optval));
+}
+
 JNIEXPORT void JNICALL Java_io_netty_channel_epoll_Native_setTcpNoDelay(JNIEnv *env, jclass clazz, jint fd, jint optval) {
     setOption(env, fd, IPPROTO_TCP, TCP_NODELAY, &optval, sizeof(optval));
 }
@@ -940,6 +945,14 @@ JNIEXPORT jint JNICALL Java_io_netty_channel_epoll_Native_isReuseAddresss(JNIEnv
     return optval;
 }
 
+JNIEXPORT jint JNICALL Java_io_netty_channel_epoll_Native_isReusePort(JNIEnv *env, jclass clazz, jint fd) {
+    int optval;
+    if (getOption(env, fd, SOL_SOCKET, SO_REUSEPORT, &optval, sizeof(optval)) == -1) {
+        return -1;
+    }
+    return optval;
+}
+
 JNIEXPORT jint JNICALL Java_io_netty_channel_epoll_Native_isTcpNoDelay(JNIEnv *env, jclass clazz, jint fd) {
     int optval;
     if (getOption(env, fd, IPPROTO_TCP, TCP_NODELAY, &optval, sizeof(optval)) == -1) {
@@ -991,3 +1004,16 @@ JNIEXPORT jint JNICALL Java_io_netty_channel_epoll_Native_getTrafficClass(JNIEnv
     }
     return optval;
 }
+
+JNIEXPORT jstring JNICALL Java_io_netty_channel_epoll_Native_kernelVersion(JNIEnv *env, jclass clazz) {
+    struct utsname name;
+
+    int res = uname(&name);
+    if (res == 0) {
+        return (*env)->NewStringUTF(env, name.release);
+    }
+    int err = errno;
+    throwRuntimeException(env, exceptionMessage(""Error during uname(...): "", err));
+    return NULL;
+
+}
diff --git a/transport-native-epoll/src/main/c/io_netty_channel_epoll_Native.h b/transport-native-epoll/src/main/c/io_netty_channel_epoll_Native.h
index 6b6943da45..a82107ee02 100644
--- a/transport-native-epoll/src/main/c/io_netty_channel_epoll_Native.h
+++ b/transport-native-epoll/src/main/c/io_netty_channel_epoll_Native.h
@@ -48,6 +48,7 @@ jlong Java_io_netty_channel_epoll_Native_sendfile(JNIEnv *env, jclass clazz, jin
 jobject Java_io_netty_channel_epoll_Native_remoteAddress(JNIEnv * env, jclass clazz, jint fd);
 jobject Java_io_netty_channel_epoll_Native_localAddress(JNIEnv * env, jclass clazz, jint fd);
 void Java_io_netty_channel_epoll_Native_setReuseAddress(JNIEnv * env, jclass clazz, jint fd, jint optval);
+void Java_io_netty_channel_epoll_Native_setReusePort(JNIEnv * env, jclass clazz, jint fd, jint optval);
 void Java_io_netty_channel_epoll_Native_setTcpNoDelay(JNIEnv *env, jclass clazz, jint fd, jint optval);
 void Java_io_netty_channel_epoll_Native_setReceiveBufferSize(JNIEnv *env, jclass clazz, jint fd, jint optval);
 void Java_io_netty_channel_epoll_Native_setSendBufferSize(JNIEnv *env, jclass clazz, jint fd, jint optval);
@@ -56,9 +57,11 @@ void Java_io_netty_channel_epoll_Native_setTcpCork(JNIEnv *env, jclass clazz, ji
 void Java_io_netty_channel_epoll_Native_setSoLinger(JNIEnv *env, jclass clazz, jint fd, jint optval);
 void Java_io_netty_channel_epoll_Native_setTrafficClass(JNIEnv *env, jclass clazz, jint fd, jint optval);
 jint Java_io_netty_channel_epoll_Native_isReuseAddresss(JNIEnv *env, jclass clazz, jint fd);
+jint Java_io_netty_channel_epoll_Native_isReusePort(JNIEnv *env, jclass clazz, jint fd);
 jint Java_io_netty_channel_epoll_Native_isTcpNoDelay(JNIEnv *env, jclass clazz, jint fd);
 jint Java_io_netty_channel_epoll_Native_getReceiveBufferSize(JNIEnv * env, jclass clazz, jint fd);
 jint Java_io_netty_channel_epoll_Native_getSendBufferSize(JNIEnv *env, jclass clazz, jint fd);
 jint Java_io_netty_channel_epoll_Native_isTcpCork(JNIEnv *env, jclass clazz, jint fd);
 jint Java_io_netty_channel_epoll_Native_getSoLinger(JNIEnv *env, jclass clazz, jint fd);
 jint Java_io_netty_channel_epoll_Native_getTrafficClass(JNIEnv *env, jclass clazz, jint fd);
+jstring Java_io_netty_channel_epoll_Native_kernelVersion(JNIEnv *env, jclass clazz);
diff --git a/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollChannelOption.java b/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollChannelOption.java
index 58f189641f..060874563b 100644
--- a/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollChannelOption.java
+++ b/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollChannelOption.java
@@ -21,6 +21,8 @@ public final class EpollChannelOption {
     private static final Class<EpollChannelOption> T = EpollChannelOption.class;
 
     public static final ChannelOption<Boolean> TCP_CORK = ChannelOption.valueOf(T, ""TCP_CORK"");
+    public static final ChannelOption<Boolean> SO_REUSEPORT = ChannelOption.valueOf(T, ""SO_REUSEPORT"");
 
     private EpollChannelOption() { }
+
 }
diff --git a/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollServerSocketChannel.java b/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollServerSocketChannel.java
index fb851e1ab8..ae5d545b87 100644
--- a/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollServerSocketChannel.java
+++ b/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollServerSocketChannel.java
@@ -20,7 +20,6 @@ import io.netty.channel.ChannelPipeline;
 import io.netty.channel.ChannelPromise;
 import io.netty.channel.EventLoop;
 import io.netty.channel.socket.ServerSocketChannel;
-import io.netty.channel.socket.ServerSocketChannelConfig;
 
 import java.net.InetSocketAddress;
 import java.net.SocketAddress;
@@ -55,7 +54,7 @@ public final class EpollServerSocketChannel extends AbstractEpollChannel impleme
     }
 
     @Override
-    public ServerSocketChannelConfig config() {
+    public EpollServerSocketChannelConfig config() {
         return config;
     }
 
diff --git a/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollServerSocketChannelConfig.java b/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollServerSocketChannelConfig.java
index 791a65b46a..9b8a947def 100644
--- a/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollServerSocketChannelConfig.java
+++ b/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollServerSocketChannelConfig.java
@@ -29,7 +29,7 @@ import static io.netty.channel.ChannelOption.SO_BACKLOG;
 import static io.netty.channel.ChannelOption.SO_RCVBUF;
 import static io.netty.channel.ChannelOption.SO_REUSEADDR;
 
-final class EpollServerSocketChannelConfig extends DefaultChannelConfig
+public final class EpollServerSocketChannelConfig extends DefaultChannelConfig
         implements ServerSocketChannelConfig {
 
     private final EpollServerSocketChannel channel;
@@ -42,7 +42,7 @@ final class EpollServerSocketChannelConfig extends DefaultChannelConfig
 
     @Override
     public Map<ChannelOption<?>, Object> getOptions() {
-        return getOptions(super.getOptions(), SO_RCVBUF, SO_REUSEADDR, SO_BACKLOG);
+        return getOptions(super.getOptions(), SO_RCVBUF, SO_REUSEADDR, SO_BACKLOG, EpollChannelOption.SO_REUSEPORT);
     }
 
     @SuppressWarnings(""unchecked"")
@@ -57,7 +57,9 @@ final class EpollServerSocketChannelConfig extends DefaultChannelConfig
         if (option == SO_BACKLOG) {
             return (T) Integer.valueOf(getBacklog());
         }
-
+        if (option == EpollChannelOption.SO_REUSEPORT) {
+            return (T) Boolean.valueOf(isReusePort());
+        }
         return super.getOption(option);
     }
 
@@ -71,6 +73,8 @@ final class EpollServerSocketChannelConfig extends DefaultChannelConfig
             setReuseAddress((Boolean) value);
         } else if (option == SO_BACKLOG) {
             setBacklog((Integer) value);
+        } else if (option == EpollChannelOption.SO_REUSEPORT) {
+            setReusePort((Boolean) value);
         } else {
             return super.setOption(option, value);
         }
@@ -84,7 +88,7 @@ final class EpollServerSocketChannelConfig extends DefaultChannelConfig
     }
 
     @Override
-    public ServerSocketChannelConfig setReuseAddress(boolean reuseAddress) {
+    public EpollServerSocketChannelConfig setReuseAddress(boolean reuseAddress) {
         Native.setReuseAddress(channel.fd, reuseAddress ? 1 : 0);
         return this;
     }
@@ -95,14 +99,14 @@ final class EpollServerSocketChannelConfig extends DefaultChannelConfig
     }
 
     @Override
-    public ServerSocketChannelConfig setReceiveBufferSize(int receiveBufferSize) {
+    public EpollServerSocketChannelConfig setReceiveBufferSize(int receiveBufferSize) {
         Native.setReceiveBufferSize(channel.fd, receiveBufferSize);
 
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setPerformancePreferences(int connectionTime, int latency, int bandwidth) {
+    public EpollServerSocketChannelConfig setPerformancePreferences(int connectionTime, int latency, int bandwidth) {
         return this;
     }
 
@@ -112,7 +116,7 @@ final class EpollServerSocketChannelConfig extends DefaultChannelConfig
     }
 
     @Override
-    public ServerSocketChannelConfig setBacklog(int backlog) {
+    public EpollServerSocketChannelConfig setBacklog(int backlog) {
         if (backlog < 0) {
             throw new IllegalArgumentException(""backlog: "" + backlog);
         }
@@ -121,56 +125,76 @@ final class EpollServerSocketChannelConfig extends DefaultChannelConfig
     }
 
     @Override
-    public ServerSocketChannelConfig setConnectTimeoutMillis(int connectTimeoutMillis) {
+    public EpollServerSocketChannelConfig setConnectTimeoutMillis(int connectTimeoutMillis) {
         super.setConnectTimeoutMillis(connectTimeoutMillis);
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setMaxMessagesPerRead(int maxMessagesPerRead) {
+    public EpollServerSocketChannelConfig setMaxMessagesPerRead(int maxMessagesPerRead) {
         super.setMaxMessagesPerRead(maxMessagesPerRead);
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setWriteSpinCount(int writeSpinCount) {
+    public EpollServerSocketChannelConfig setWriteSpinCount(int writeSpinCount) {
         super.setWriteSpinCount(writeSpinCount);
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setAllocator(ByteBufAllocator allocator) {
+    public EpollServerSocketChannelConfig setAllocator(ByteBufAllocator allocator) {
         super.setAllocator(allocator);
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setRecvByteBufAllocator(RecvByteBufAllocator allocator) {
+    public EpollServerSocketChannelConfig setRecvByteBufAllocator(RecvByteBufAllocator allocator) {
         super.setRecvByteBufAllocator(allocator);
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setAutoRead(boolean autoRead) {
+    public EpollServerSocketChannelConfig setAutoRead(boolean autoRead) {
         super.setAutoRead(autoRead);
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setWriteBufferHighWaterMark(int writeBufferHighWaterMark) {
+    public EpollServerSocketChannelConfig setWriteBufferHighWaterMark(int writeBufferHighWaterMark) {
         super.setWriteBufferHighWaterMark(writeBufferHighWaterMark);
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setWriteBufferLowWaterMark(int writeBufferLowWaterMark) {
+    public EpollServerSocketChannelConfig setWriteBufferLowWaterMark(int writeBufferLowWaterMark) {
         super.setWriteBufferLowWaterMark(writeBufferLowWaterMark);
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setMessageSizeEstimator(MessageSizeEstimator estimator) {
+    public EpollServerSocketChannelConfig setMessageSizeEstimator(MessageSizeEstimator estimator) {
         super.setMessageSizeEstimator(estimator);
         return this;
     }
+
+    /**
+     * Returns {@code true} if the SO_REUSEPORT option is set.
+     */
+    public boolean isReusePort() {
+        return Native.isReusePort(channel.fd) == 1;
+    }
+
+    /**
+     * Set the SO_REUSEPORT option on the underlying Channel. This will allow to bind multiple
+     * {@link EpollSocketChannel}s to the same port and so accept connections with multiple threads.
+     *
+     * Be aware this method needs be called before {@link EpollSocketChannel#bind(java.net.SocketAddress)} to have
+     * any affect.
+     */
+    public EpollServerSocketChannelConfig setReusePort(boolean reusePort) {
+        Native.setReusePort(channel.fd, reusePort ? 1 : 0);
+        return this;
+    }
+
 }
diff --git a/transport-native-epoll/src/main/java/io/netty/channel/epoll/Native.java b/transport-native-epoll/src/main/java/io/netty/channel/epoll/Native.java
index 43f7cfeebb..0a9532ede4 100644
--- a/transport-native-epoll/src/main/java/io/netty/channel/epoll/Native.java
+++ b/transport-native-epoll/src/main/java/io/netty/channel/epoll/Native.java
@@ -127,6 +127,7 @@ final class Native {
     public static native int getSendBufferSize(int fd);
     public static native int isKeepAlive(int fd);
     public static native int isReuseAddress(int fd);
+    public static native int isReusePort(int fd);
     public static native int isTcpNoDelay(int fd);
     public static native int isTcpCork(int fd);
     public static native int getSoLinger(int fd);
@@ -135,12 +136,14 @@ final class Native {
     public static native void setKeepAlive(int fd, int keepAlive);
     public static native void setReceiveBufferSize(int fd, int receiveBufferSize);
     public static native void setReuseAddress(int fd, int reuseAddress);
+    public static native void setReusePort(int fd, int reuseAddress);
     public static native void setSendBufferSize(int fd, int sendBufferSize);
     public static native void setTcpNoDelay(int fd, int tcpNoDelay);
     public static native void setTcpCork(int fd, int tcpCork);
     public static native void setSoLinger(int fd, int soLinger);
     public static native void setTrafficClass(int fd, int tcpNoDelay);
 
+    public static native String kernelVersion();
     private Native() {
         // utility
     }
diff --git a/transport-native-epoll/src/test/java/io/netty/channel/epoll/EpollReuseAddrTest.java b/transport-native-epoll/src/test/java/io/netty/channel/epoll/EpollReuseAddrTest.java
new file mode 100644
index 0000000000..5b5fc5a5ff
--- /dev/null
+++ b/transport-native-epoll/src/test/java/io/netty/channel/epoll/EpollReuseAddrTest.java
@@ -0,0 +1,132 @@
+/*
+ * Copyright 2014 The Netty Project
+ *
+ * The Netty Project licenses this file to you under the Apache License,
+ * version 2.0 (the ""License""); you may not use this file except in compliance
+ * with the License. You may obtain a copy of the License at:
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations
+ * under the License.
+ */
+package io.netty.channel.epoll;
+
+import io.netty.bootstrap.ServerBootstrap;
+import io.netty.channel.ChannelFuture;
+import io.netty.channel.ChannelHandler;
+import io.netty.channel.ChannelHandlerAdapter;
+import io.netty.channel.ChannelHandlerContext;
+import io.netty.channel.ChannelInboundHandlerAdapter;
+import io.netty.channel.ChannelOption;
+import io.netty.testsuite.util.TestUtils;
+import org.junit.Assert;
+import org.junit.Assume;
+import org.junit.Test;
+
+import java.io.IOException;
+import java.net.InetSocketAddress;
+import java.net.Socket;
+import java.util.concurrent.atomic.AtomicBoolean;
+
+public class EpollReuseAddrTest {
+    private static final int MAJOR;
+    private static final int MINOR;
+    private static final int BUGFIX;
+    static {
+        String kernelVersion = Native.kernelVersion();
+        int index = kernelVersion.indexOf(""-"");
+        if (index > -1) {
+            kernelVersion = kernelVersion.substring(0, index);
+        }
+        String[] versionParts = kernelVersion.split(""\\."");
+        if (versionParts.length == 3) {
+            MAJOR = Integer.parseInt(versionParts[0]);
+            MINOR = Integer.parseInt(versionParts[1]);
+            BUGFIX = Integer.parseInt(versionParts[2]);
+        } else {
+            throw new IllegalStateException();
+        }
+    }
+
+    @Test
+    public void testMultipleBindWithoutReusePortFails() {
+        Assume.assumeTrue(versionEqOrGt(3, 9, 0));
+        ServerBootstrap bootstrap = createBootstrap();
+        ChannelFuture future = bootstrap.bind().syncUninterruptibly();
+        try {
+            bootstrap.bind().syncUninterruptibly();
+            Assert.fail();
+        } catch (Exception e) {
+            Assert.assertTrue(e instanceof IOException);
+        }
+        future.channel().close().syncUninterruptibly();
+    }
+
+    @Test(timeout = 10000)
+    public void testMultipleBind() throws Exception {
+        Assume.assumeTrue(versionEqOrGt(3, 9, 0));
+        ServerBootstrap bootstrap = createBootstrap();
+        bootstrap.option(EpollChannelOption.SO_REUSEPORT, true);
+        final AtomicBoolean accepted1 = new AtomicBoolean();
+        bootstrap.childHandler(new TestHandler(accepted1));
+        ChannelFuture future = bootstrap.bind().syncUninterruptibly();
+
+        final AtomicBoolean accepted2 = new AtomicBoolean();
+        bootstrap.childHandler(new TestHandler(accepted2));
+        ChannelFuture future2 = bootstrap.bind().syncUninterruptibly();
+        InetSocketAddress address = (InetSocketAddress) future2.channel().localAddress();
+
+        while (!accepted1.get() || !accepted2.get()) {
+            Socket socket = new Socket(address.getAddress(), address.getPort());
+            socket.setReuseAddress(true);
+            socket.close();
+        }
+        future.channel().close().syncUninterruptibly();
+        future2.channel().close().syncUninterruptibly();
+    }
+
+    private ServerBootstrap createBootstrap() {
+        ServerBootstrap bootstrap = new ServerBootstrap();
+        bootstrap.group(EpollSocketTestPermutation.EPOLL_BOSS_GROUP, EpollSocketTestPermutation.EPOLL_WORKER_GROUP);
+        bootstrap.channel(EpollServerSocketChannel.class);
+        bootstrap.childHandler(new ChannelHandlerAdapter() { });
+        bootstrap.option(ChannelOption.SO_REUSEADDR, true);
+        InetSocketAddress address = new InetSocketAddress(TestUtils.getFreePort());
+        bootstrap.localAddress(address);
+        return bootstrap;
+    }
+
+    private static boolean versionEqOrGt(int major, int minor, int bugfix)  {
+        if (MAJOR > major) {
+            return true;
+        } else if (MAJOR == major) {
+            if (MINOR > minor) {
+                return true;
+            } else if (MINOR == minor) {
+                if (BUGFIX >= bugfix) {
+                    return true;
+                }
+            }
+        }
+        return false;
+    }
+
+    @ChannelHandler.Sharable
+    private static class TestHandler extends ChannelInboundHandlerAdapter {
+        private final AtomicBoolean accepted;
+
+        TestHandler(AtomicBoolean accepted) {
+            this.accepted = accepted;
+        }
+
+        @Override
+        public void channelActive(ChannelHandlerContext ctx) throws Exception {
+            accepted.set(true);
+            ctx.close();
+        }
+    }
+}
diff --git a/transport-native-epoll/src/test/java/io/netty/channel/epoll/EpollSocketTestPermutation.java b/transport-native-epoll/src/test/java/io/netty/channel/epoll/EpollSocketTestPermutation.java
index a452a956e4..e08562e5e6 100644
--- a/transport-native-epoll/src/test/java/io/netty/channel/epoll/EpollSocketTestPermutation.java
+++ b/transport-native-epoll/src/test/java/io/netty/channel/epoll/EpollSocketTestPermutation.java
@@ -32,9 +32,9 @@ class EpollSocketTestPermutation extends SocketTestPermutation {
 
     static final SocketTestPermutation INSTANCE = new EpollSocketTestPermutation();
 
-    private final EventLoopGroup epollBossGroup =
+    static final EventLoopGroup EPOLL_BOSS_GROUP =
             new EpollEventLoopGroup(BOSSES, new DefaultThreadFactory(""testsuite-epoll-boss"", true));
-    private final EventLoopGroup epollWorkerGroup =
+    static final EventLoopGroup EPOLL_WORKER_GROUP =
             new EpollEventLoopGroup(WORKERS, new DefaultThreadFactory(""testsuite-epoll-worker"", true));
 
     @Override
@@ -54,7 +54,7 @@ class EpollSocketTestPermutation extends SocketTestPermutation {
                 new BootstrapFactory<ServerBootstrap>() {
                     @Override
                     public ServerBootstrap newInstance() {
-                        return new ServerBootstrap().group(epollBossGroup, epollWorkerGroup)
+                        return new ServerBootstrap().group(EPOLL_BOSS_GROUP, EPOLL_WORKER_GROUP)
                                 .channel(EpollServerSocketChannel.class);
                     }
                 },
@@ -74,7 +74,7 @@ class EpollSocketTestPermutation extends SocketTestPermutation {
                 new BootstrapFactory<Bootstrap>() {
                     @Override
                     public Bootstrap newInstance() {
-                        return new Bootstrap().group(epollWorkerGroup).channel(EpollSocketChannel.class);
+                        return new Bootstrap().group(EPOLL_WORKER_GROUP).channel(EpollSocketChannel.class);
                     }
                 },
                 new BootstrapFactory<Bootstrap>() {",Add support for SO_REUSEPORT in native transport .,"""Added support for SO_REUSEPORT option on EpollServerSocketChannel""","""Added support for SO_REUSEPORT option and kernel version retrieval""","""Added SO_REUSEPORT option to EpollChannelOption and EpollServerSocketChannelConfig, and a new JNI method to set it. Also added a new JNI method to retrieve the kernel version.""

Explanation:

* In `EpollChannelOption.java`, a new constant `SO_REUSEPORT` has been added.
* In `EpollServerSocketChannelConfig.java`, a new method `setReusePort(boolean)` has been added, as well as a new condition in the `getOptions()` method to include `EpollChannelOption.SO_REUSEPORT`.
* In `Native.java`, two new native methods `setReusePort(int, int)` and `isReusePort(int)` have been added, as well as a new method `kernelVersion()`.
* In `io_netty_channel_epoll_Native.c`, two new JNI methods `Java_io_netty_channel_epoll_Native_setReusePort` and `Java_io_netty_channel_epoll_Native_isReusePort` have been added, as well as a new method `Java_io_netty_channel_epoll_Native_kernelVersion`.
* In `io_netty_channel_epoll_Native.h`, the declarations for the new JNI methods have been added.

This commit adds the ability to set the `SO_REUSEPORT` socket option for Epoll Server Socket Channels, as well as a new JNI method to retrieve the kernel version. The `SO_REUSEPORT` option allows multiple sockets to bind to the same address and port, which can be useful for load balancing incoming connections across multiple processes or threads. The kernel version method is used to check the version of the Linux kernel, which can be useful for determining whether certain features or bug fixes are present.",Add support for SO_REUSEPORT and kernel version fetching in Epoll transport.,Model 4
"diff --git a/AnkiDroid/src/main/java/com/ichi2/utils/JSONException.java b/AnkiDroid/src/main/java/com/ichi2/utils/JSONException.java
new file mode 100644
index 0000000000..1d4bef5a7e
--- /dev/null
+++ b/AnkiDroid/src/main/java/com/ichi2/utils/JSONException.java
@@ -0,0 +1,39 @@
+package com.ichi2.utils;
+
+
+
+/**
+   Similar to JSONException in meaning, but unchecked */
+public class JSONException extends RuntimeException {
+
+    private JSONException exc = null;
+
+    public JSONException(String s) {
+        super(s);
+    }
+
+    public JSONException() {
+        super();
+    }
+
+    public JSONException(Throwable e) {
+        super(e);
+    }
+
+    public JSONException(JSONException e) {
+        super(e);
+        exc = e;
+    }
+
+    public JSONException asException() {
+        if (exc!=null) {
+            return exc;
+        } else {
+            return new JSONException(toString());
+        }
+    }
+
+    public void throwAsException() throws JSONException {
+        throw asException();
+    }
+}",Add an unchecked exception for JSON .,"""Added unchecked JSONException class to com.ichi2.utils package""","""Added JSONException utility class for unchecked JSON exceptions.""","""Added new unchecked JSONException class to com.ichi2.utils package""",Add JSONException class to utils package: an unchecked exception for handling JSON errors similar to RuntimeException.,Model 1
"diff --git a/logback-examples/src/main/java/chapters/appenders/socket/ssl/SocketClient.java b/logback-examples/src/main/java/chapters/appenders/socket/ssl/SocketClient.java
new file mode 100644
index 000000000..f3da32c52
--- /dev/null
+++ b/logback-examples/src/main/java/chapters/appenders/socket/ssl/SocketClient.java
@@ -0,0 +1,73 @@
+/**
+ * Logback: the reliable, generic, fast and flexible logging framework.
+ * Copyright (C) 1999-2011, QOS.ch. All rights reserved.
+ *
+ * This program and the accompanying materials are dual-licensed under
+ * either the terms of the Eclipse Public License v1.0 as published by
+ * the Eclipse Foundation
+ *
+ *   or (per the licensee's choosing)
+ *
+ * under the terms of the GNU Lesser General Public License version 2.1
+ * as published by the Free Software Foundation.
+ */
+package chapters.appenders.socket.ssl;
+
+import java.io.BufferedReader;
+import java.io.InputStreamReader;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import ch.qos.logback.classic.LoggerContext;
+import ch.qos.logback.classic.joran.JoranConfigurator;
+
+
+/**
+ * This application uses an SSLSocketAppender that log messages to a
+ * server on a host and port specified by the user. It waits for the
+ * user to type a message which will be sent to the server.
+ * */
+public class SocketClient {
+  static void usage(String msg) {
+    System.err.println(msg);
+    System.err.println(""Usage: java "" + SocketClient.class.getName() +
+      "" configFile\n"" +
+      ""   configFile a logback configuration file"" +
+      ""   in XML format."");
+    System.exit(1);
+  }
+
+  static public void main(String[] args) throws Exception {
+    if (args.length != 1) {
+      usage(""Wrong number of arguments."");
+    }
+
+    String configFile = args[0];
+
+    if (configFile.endsWith("".xml"")) {
+      LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory();
+      JoranConfigurator configurator = new JoranConfigurator();
+      lc.stop();
+      configurator.setContext(lc);
+      configurator.doConfigure(configFile);
+    }
+
+    Logger logger = LoggerFactory.getLogger(SocketClient.class);
+
+    BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));
+
+    while (true) {
+      System.out.println(
+        ""Type a message to send to log server. Type 'q' to quit."");
+
+      String s = reader.readLine();
+
+      if (s.equals(""q"")) {
+        break;
+      } else {
+        logger.debug(s);
+      }
+    }
+  }
+}
diff --git a/logback-examples/src/main/java/chapters/appenders/socket/ssl/SocketServer.java b/logback-examples/src/main/java/chapters/appenders/socket/ssl/SocketServer.java
new file mode 100644
index 000000000..66e8a0355
--- /dev/null
+++ b/logback-examples/src/main/java/chapters/appenders/socket/ssl/SocketServer.java
@@ -0,0 +1,54 @@
+/**
+ * Logback: the reliable, generic, fast and flexible logging framework.
+ * Copyright (C) 1999-2011, QOS.ch. All rights reserved.
+ *
+ * This program and the accompanying materials are dual-licensed under
+ * either the terms of the Eclipse Public License v1.0 as published by
+ * the Eclipse Foundation
+ *
+ *   or (per the licensee's choosing)
+ *
+ * under the terms of the GNU Lesser General Public License version 2.1
+ * as published by the Free Software Foundation.
+ */
+package chapters.appenders.socket.ssl;
+
+import org.slf4j.LoggerFactory;
+
+import ch.qos.logback.classic.LoggerContext;
+import ch.qos.logback.classic.joran.JoranConfigurator;
+
+
+/**
+ * This application uses an SSLSocketServer that log messages to a
+ * server on a host and port specified by the user. It waits for the
+ * user to type a message which will be sent to the server.
+ * */
+public class SocketServer {
+  static void usage(String msg) {
+    System.err.println(msg);
+    System.err.println(""Usage: java "" + SocketServer.class.getName() +
+      "" configFile\n"" +
+      ""   configFile a logback configuration file"" +
+      ""   in XML format."");
+    System.exit(1);
+  }
+
+  static public void main(String[] args) throws Exception {
+    if (args.length != 1) {
+      usage(""Wrong number of arguments."");
+    }
+
+    String configFile = args[0];
+
+    if (configFile.endsWith("".xml"")) {
+      LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory();
+      JoranConfigurator configurator = new JoranConfigurator();
+      lc.stop();
+      configurator.setContext(lc);
+      configurator.doConfigure(configFile);
+    }
+
+    Thread.sleep(Long.MAX_VALUE);
+  }
+}
diff --git a/logback-examples/src/main/java/chapters/appenders/socket/ssl/client.xml b/logback-examples/src/main/java/chapters/appenders/socket/ssl/client.xml
new file mode 100644
index 000000000..0dbc8fc8e
--- /dev/null
+++ b/logback-examples/src/main/java/chapters/appenders/socket/ssl/client.xml
@@ -0,0 +1,28 @@
+<?xml version=""1.0"" encoding=""UTF-8"" ?>
+
+<!-- ==================================================================== -->
+<!-- Sample SSLSocketAppender configuration.                                 -->
+<!-- ==================================================================== -->
+
+<configuration debug=""true"">
+	  
+  <appender name=""SOCKET"" class=""ch.qos.logback.classic.net.SSLSocketAppender"">
+    <remoteHost>${host}</remoteHost>
+    <port>${port}</port>
+    <reconnectionDelay>10000</reconnectionDelay>
+    <ssl>
+      <trustStore>
+        <location>${truststore}</location>
+        <passphrase>${passphrase}</passphrase>
+      </trustStore>
+    </ssl>
+  </appender>
+
+  <root level=""debug"">
+    <appender-ref ref=""SOCKET"" />
+  </root>  
+
+</configuration>
+
+
+
diff --git a/logback-examples/src/main/java/chapters/appenders/socket/ssl/keystore.jks b/logback-examples/src/main/java/chapters/appenders/socket/ssl/keystore.jks
new file mode 100644
index 000000000..274e4d159
Binary files /dev/null and b/logback-examples/src/main/java/chapters/appenders/socket/ssl/keystore.jks differ
diff --git a/logback-examples/src/main/java/chapters/appenders/socket/ssl/server.xml b/logback-examples/src/main/java/chapters/appenders/socket/ssl/server.xml
new file mode 100644
index 000000000..aa7fe3757
--- /dev/null
+++ b/logback-examples/src/main/java/chapters/appenders/socket/ssl/server.xml
@@ -0,0 +1,32 @@
+<?xml version=""1.0"" encoding=""UTF-8"" ?>
+
+<!-- ==================================================================== -->
+<!-- Sample SSLSocketServer configuration.                                 -->
+<!-- ==================================================================== -->
+
+<configuration debug=""true"">
+
+  <server class=""ch.qos.logback.classic.net.server.SSLSocketServer"">
+    <port>${port}</port>
+    <ssl>
+      <keyStore>
+        <location>${keystore}</location>
+        <passphrase>${passphrase}</passphrase>
+      </keyStore>
+    </ssl>
+  </server>
+  
+  <appender name=""CONSOLE"" class=""ch.qos.logback.core.ConsoleAppender"">
+    <encoder>
+      <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n</pattern>
+    </encoder>
+  </appender>
+  
+  <root level=""debug"">
+    <appender-ref ref=""CONSOLE"" />
+  </root>
+  
+</configuration>
+
+
+
diff --git a/logback-examples/src/main/java/chapters/appenders/socket/ssl/truststore.jks b/logback-examples/src/main/java/chapters/appenders/socket/ssl/truststore.jks
new file mode 100644
index 000000000..93498fb44
Binary files /dev/null and b/logback-examples/src/main/java/chapters/appenders/socket/ssl/truststore.jks differ",added an example of using the SSL enabled components,"""Added SSL socket client and server examples to logback-examples""","Added examples for SSLSocketAppender and SSLSocketServer in Logback. 

This commit includes the addition of two new classes, SocketClient and SocketServer, which demonstrate the use of SSLSocketAppender and SSLSocketServer respectively. It also includes the creation of two new configuration files, client.xml and server.xml, which are used to configure the SSLSocketAppender and SSLSocketServer. Additionally, two new keystore files, keystore.jks and truststore.jks, are added to the project.","""Added SSL socket appender and server examples in logback-examples""

This commit adds two new Java classes, `SocketClient` and `SocketServer`, which demonstrate how to use the SSLSocketAppender and SSLSocketServer in Logback. It also includes configuration files and security certificates needed to run the examples. The code is licensed under the Eclipse Public License v1.0 or the GNU Lesser General Public License version 2.1.","Added SSL socket client and server examples with corresponding XML configurations, keystore, and truststore files.",Model 1
"diff --git a/sopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/jsondatamodel/JsonNodeTest.java b/sopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/jsondatamodel/JsonNodeTest.java
new file mode 100644
index 00000000000..2be4985fbdf
--- /dev/null
+++ b/sopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/jsondatamodel/JsonNodeTest.java
@@ -0,0 +1,5 @@
+package eu.stratosphere.sopremo.jsondatamodel;
+
+public class JsonNodeTest {
+	//generic tests for every JsonNode
+}
diff --git a/sopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/jsondatamodel/TextNodeTest.java b/sopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/jsondatamodel/TextNodeTest.java
new file mode 100644
index 00000000000..01c4c779f4b
--- /dev/null
+++ b/sopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/jsondatamodel/TextNodeTest.java
@@ -0,0 +1,5 @@
+package eu.stratosphere.sopremo.jsondatamodel;
+
+public class TextNodeTest extends JsonNodeTest {
+
+}",added teststubs,"""Added JsonNodeTest and TextNodeTest classes for testing JSON data model""","Added test classes for JsonNode and TextNode.

Or, in a more conventional commit message format:

`Add JsonNode and TextNode test classes`

This commit message is concise and accurately describes the changes made in the commit.","""Added test classes for JsonNode and TextNode in sopremo-common""

This commit contains two new files:

1. JsonNodeTest.java: This is a new test class for the package eu.stratosphere.sopremo.jsondatamodel. The class doesn't contain any tests yet, but it's a placeholder for future generic tests for every JsonNode.

2. TextNodeTest.java: This is another new test class for the same package that extends JsonNodeTest. This class also doesn't contain any tests yet.

The changes made in this commit are related to testing functionality in the sopremo-common project, specifically for the JsonNode and TextNode classes. The commit message should reflect these changes.","""Add initial test classes for JsonNode and TextNode in sopremo-common module.""",Model 1
"diff --git a/sql/jdbc/src/test/java/org/elasticsearch/xpack/sql/jdbc/DebugCsvSpec.java b/sql/jdbc/src/test/java/org/elasticsearch/xpack/sql/jdbc/DebugCsvSpecIT.java
similarity index 88%
rename from sql/jdbc/src/test/java/org/elasticsearch/xpack/sql/jdbc/DebugCsvSpec.java
rename to sql/jdbc/src/test/java/org/elasticsearch/xpack/sql/jdbc/DebugCsvSpecIT.java
index cd061a5d0a6..ae567fe3bb9 100644
--- a/sql/jdbc/src/test/java/org/elasticsearch/xpack/sql/jdbc/DebugCsvSpec.java
+++ b/sql/jdbc/src/test/java/org/elasticsearch/xpack/sql/jdbc/DebugCsvSpecIT.java
@@ -16,7 +16,7 @@ import java.sql.SQLException;
 import java.util.List;
 
 @TestLogging(""org.elasticsearch.xpack.sql:TRACE"")
-public class DebugCsvSpec extends CsvSpecIT {
+public class DebugCsvSpecIT extends CsvSpecIT {
 
     @ParametersFactory(shuffle = false, argumentFormatting = SqlSpecIT.PARAM_FORMATTING) // NOCOMMIT are we sure?!
     public static List<Object[]> readScriptSpec() throws Exception {
@@ -26,7 +26,7 @@ public class DebugCsvSpec extends CsvSpecIT {
         return readScriptSpec(""/debug.csv-spec"", parser);
     }
 
-    public DebugCsvSpec(String groupName, String testName, Integer lineNumber, Path source, CsvTestCase testCase) {
+    public DebugCsvSpecIT(String groupName, String testName, Integer lineNumber, Path source, CsvTestCase testCase) {
         super(groupName, testName, lineNumber, source, testCase);
     }",Rename DebugCsvSpec to match test naming convention .,"""Rename DebugCsvSpec to DebugCsvSpecIT""",Rename DebugCsvSpec to DebugCsvSpecIT to match the test class suffix convention.,"""Rename DebugCsvSpec.java to DebugCsvSpecIT.java and update class name accordingly""",Renamed `DebugCsvSpec` to `DebugCsvSpecIT` to follow the integration test naming convention.,Model 2
"diff --git a/app/src/main/res/layout/fragment_options_notifications.xml b/app/src/main/res/layout/fragment_options_notifications.xml
index 909a0afdec..637b256c74 100644
--- a/app/src/main/res/layout/fragment_options_notifications.xml
+++ b/app/src/main/res/layout/fragment_options_notifications.xml
@@ -144,6 +144,18 @@
                 app:layout_constraintStart_toStartOf=""parent""
                 app:layout_constraintTop_toBottomOf=""@id/tvNotifyActionsPro"" />
 
+            <TextView
+                android:id=""@+id/tvManageHint""
+                android:layout_width=""0dp""
+                android:layout_height=""wrap_content""
+                android:layout_marginEnd=""48dp""
+                android:text=""@string/title_advanced_notify_manage_hint""
+                android:textAppearance=""@style/TextAppearance.AppCompat.Small""
+                android:textStyle=""italic""
+                app:layout_constraintEnd_toEndOf=""parent""
+                app:layout_constraintStart_toStartOf=""parent""
+                app:layout_constraintTop_toBottomOf=""@id/btnManage"" />
+
             <androidx.appcompat.widget.SwitchCompat
                 android:id=""@+id/swLight""
                 android:layout_width=""match_parent""
@@ -151,7 +163,7 @@
                 android:layout_marginTop=""12dp""
                 android:text=""@string/title_advanced_light""
                 app:layout_constraintStart_toStartOf=""parent""
-                app:layout_constraintTop_toBottomOf=""@id/btnManage""
+                app:layout_constraintTop_toBottomOf=""@id/tvManageHint""
                 app:switchPadding=""12dp"" />
 
             <Button
diff --git a/app/src/main/res/values/strings.xml b/app/src/main/res/values/strings.xml
index 5ccfe79597..b4be65537d 100644
--- a/app/src/main/res/values/strings.xml
+++ b/app/src/main/res/values/strings.xml
@@ -222,6 +222,7 @@
     <string name=""title_advanced_notify_action_flag"">Star</string>
     <string name=""title_advanced_notify_action_seen"">Read</string>
     <string name=""title_advanced_notify_action_hint"">At",Added hint about notification channel settings,"""Added notification management hint in fragment options notifications""","""Added hint for managing notifications and updated layout constraints""","""Added manage hint textview and adjusted layout constraints in fragment_options_notifications.xml. Also added a new string resource in strings.xml.""

This commit seems to have added a new TextView with the id ""tvManageHint"" in the layout file ""fragment_options_notifications.xml"". The layout constraints of an existing SwitchCompat with the id ""swLight"" have also been adjusted to accommodate the new TextView. Additionally, a new string resource has been added in ""strings.xml"" which is likely used in the new TextView.","""Added a TextView to provide a hint below the 'Manage' button in the notification options fragment.""",Model 3
"diff --git a/app/src/processing/app/Base.java b/app/src/processing/app/Base.java
index 112c96193..df06857e6 100644
--- a/app/src/processing/app/Base.java
+++ b/app/src/processing/app/Base.java
@@ -55,9 +55,9 @@ import processing.data.StringList;
 public class Base {
   // Added accessors for 0218 because the UpdateCheck class was not properly
   // updating the values, due to javac inlining the static final values.
-  static private final int REVISION = 246;
+  static private final int REVISION = 247;
   /** This might be replaced by main() if there's a lib/version.txt file. */
-  static private String VERSION_NAME = ""0246""; //$NON-NLS-1$
+  static private String VERSION_NAME = ""0247""; //$NON-NLS-1$
   /** Set true if this a proper release rather than a numbered revision. */
 
   /** True if heavy debugging error/log messages are enabled */
diff --git a/build/shared/revisions.txt b/build/shared/revisions.txt
index 64143b349..11a3ded0a 100644
--- a/build/shared/revisions.txt
+++ b/build/shared/revisions.txt
@@ -1,4 +1,4 @@
-PROCESSING 3.0 (REV 0246) - 30 September 2015
+PROCESSING 3.0 (REV 0246) - 30 September 2015, 3pm ET
 
 This one is huge. 
 
diff --git a/core/done.txt b/core/done.txt
index edd46e6af..6e4efb735 100644
--- a/core/done.txt
+++ b/core/done.txt
@@ -1,3 +1,38 @@
+0246 the papal visit (3.0)
+X implement high-performance/async image saving
+X   Use PBOs for async texture copy
+X   https://github.com/processing/processing/issues/3569
+X   https://github.com/processing/processing/pull/3863
+X   https://github.com/processing/processing/pull/3869
+X Textures disappearing in beta 7 (might be WeakReference regression)
+X   https://github.com/processing/processing/issues/3858
+X   https://github.com/processing/processing/pull/3874
+X   https://github.com/processing/processing/pull/3875
+X Convert all documented hacky keys in OpenGL
+X   https://github.com/processing/processing/pull/3888
+X Frame size displays incorrectly if surface.setResizable(true)
+X   https://github.com/processing/processing/issues/3868
+X   https://github.com/processing/processing/pull/3880
+X displayWidth, displayHeight, full screen, display number
+X   https://github.com/processing/processing/pull/3893
+X   https://github.com/processing/processing/issues/3865
+X OpenGL with fullScreen() always opens on default display
+X   https://github.com/processing/processing/issues/3889
+X   https://github.com/processing/processing/issues/3797
+X   https://github.com/processing/processing/pull/3892
+
+cleaning
+o move AWT image loading into PImageAWT
+o   look into how GL and FX will handle from there
+o run only the necessary pieces on the EDT
+o   in part because FX doesn't even use the EDT
+o   re-check the Linux frame visibility stuff
+X   cleaned most of this as far as we can go
+o Ubuntu Unity prevents full screen from working properly
+X   https://github.com/processing/processing/issues/3158
+X   can't fix; upstream problem, added to the wiki
+
+
 0245 core (3.0b7)
 X surface.setLocation(x,y) not working with the default renderer
 X   https://github.com/processing/processing/issues/3821
diff --git a/core/todo.txt b/core/todo.txt
index 2ec573242..c230e295d 100644
--- a/core/todo.txt
+++ b/core/todo.txt
@@ -1,36 +1,4 @@
-0246 the papal visit (3.0)
-X implement high-performance/async image saving
-X   Use PBOs for async texture copy
-X   https://github.com/processing/processing/issues/3569
-X   https://github.com/processing/processing/pull/3863
-X   https://github.com/processing/processing/pull/3869
-X Textures disappearing in beta 7 (might be WeakReference regression)
-X   https://github.com/processing/processing/issues/3858
-X   https://github.com/processing/processing/pull/3874
-X   https://github.com/processing/processing/pull/3875
-X Convert all documented hacky keys in OpenGL
-X   https://github.com/processing/processing/pull/3888
-X Frame size displays incorrectly if surface.setResizable(true)
-X   https://github.com/processing/processing/issues/3868
-X   https://github.com/processing/processing/pull/3880
-X displayWidth, displayHeight, full screen, display number
-X   https://github.com/processing/processing/pull/3893
-X   https://github.com/processing/processing/issues/3865
-X OpenGL with fullScreen() always opens on default display
-X   https://github.com/processing/processing/issues/3889
-X   https://github.com/processing/processing/issues/3797
-X   https://github.com/processing/processing/pull/3892
-
-cleaning
-o move AWT image loading into PImageAWT
-o   look into how GL and FX will handle from there
-o run only the necessary pieces on the EDT
-o   in part because FX doesn't even use the EDT
-o   re-check the Linux frame visibility stuff
-X   cleaned most of this as far as we can go
-o Ubuntu Unity prevents full screen from working properly
-X   https://github.com/processing/processing/issues/3158
-X   can't fix; upstream problem, added to the wiki
+0247 (3.0.1)
 
 
 known
diff --git a/done.txt b/done.txt
index cde20c1b0..26cc9862c 100644
--- a/done.txt
+++ b/done.txt
@@ -1,3 +1,114 @@
+0246 the holy land (3.0)
+X ""Saving"" messages never clear on ""Save As""
+X   https://github.com/processing/processing/issues/3861
+X error checker/suggestions fixes
+X   https://github.com/processing/processing/pull/3871
+X   https://github.com/processing/processing/pull/3879
+X contributions filter is ignored after clicking Install
+X   https://github.com/processing/processing/issues/3826
+X   https://github.com/processing/processing/pull/3872
+X   https://github.com/processing/processing/pull/3883
+X Exception in thread ""Contribution List Downloader""
+X   https://github.com/processing/processing/issues/3882
+X   https://github.com/processing/processing/pull/3884
+X Hide useless error in error checker
+X   https://github.com/processing/processing/pull/3887
+X grab bag of CM work from Jakub
+X   https://github.com/processing/processing/issues/3895
+X   https://github.com/processing/processing/pull/3897
+X Clean up delete dir function
+X   https://github.com/processing/processing/pull/3910
+X don't follow symlinks when deleting directories
+X   https://github.com/processing/processing/pull/3916
+X show number of updates available in the footer
+X   https://github.com/processing/processing/issues/3518
+X   https://github.com/processing/processing/pull/3896
+X   https://github.com/processing/processing/pull/3901
+o   total number of updates available is not correct? (may be fixed)
+o ArrayIndexOutOfBoundsException freak out when clicking the header line
+o   think this was on name, with libraries, but not sure
+X   should be fixed with the updates from Jakub
+X error checker updates for toggle and listeners
+X   https://github.com/processing/processing/pull/3915
+X file file counting in the change detector
+X   https://github.com/processing/processing/pull/3917
+X   https://github.com/processing/processing/issues/3898
+X   https://github.com/processing/processing/issues/3387
+X Windows suggests ""Documents"" as a new location for the 3.0 sketchbook
+X   maybe prevent users from accepting that?
+X   https://github.com/processing/processing/issues/3920
+
+gui
+X distinguish errors and warnings
+X   https://github.com/processing/processing/issues/3406
+X make breakpoints more prominent
+X   https://github.com/processing/processing/issues/3307 (comp is set)
+X clean up statusMessage() inside JavaEditor
+o   do we want to bring back the delays?
+X implement side gradient on the editor
+X if fewer lines in sketch than can be shown in window, show ticks adjacent
+X   error/warning location is awkward when no scroll bar is in use
+X   when only one screen-full, show ticks at exact location
+X   simpler/less confusing to not show at all? 
+X   MarkerColumn.recalculateMarkerPositions()
+X   https://github.com/processing/processing/pull/3903
+X Update status error/warning when changing the line
+X   https://github.com/processing/processing/pull/3907
+X Update status error/warning when changing the line
+X   when moving away from an error/warning line, de-select it below
+X   selecting a warning should also show the warning in the status area
+X   https://github.com/processing/processing/pull/3907
+X clicking an error or warning should give the focus back to the editor
+X   https://github.com/processing/processing/pull/3905
+X replace startup/about screen (1x and 2x versions)
+X   change 'alpha' to correct name
+X   also change the revision in the ""about processing"" dialog
+X   https://github.com/processing/processing/issues/3665
+X implement splash screen on OS X
+X   http://www.randelshofer.ch/oop/javasplash/javasplash.html
+X   also implement special retina version
+X Fix placement and visual design when showing error on hover
+X   https://github.com/processing/processing/issues/3173
+X   implement custom tooltip for error/warning hover
+X   applies to both MarkerColumn and JavaTextAreaPainter
+X make gutter of console match error list
+X   https://github.com/processing/processing/issues/3904
+o bring back the # of updates on the update tab
+o   use this instead of the 'icon' stuff?
+o   or in addition, since only the 'updates' tab has it
+X   https://github.com/processing/processing/issues/3855
+X for updates available, have it be clickable to open the manager
+X fix the design of the completions window
+X   remove extra border around the outside
+X   change font
+X   add 2x version of the icons
+X   change selection highlight color
+o   put some margin around it
+X   https://github.com/processing/processing/issues/3906
+X completion panel
+X   what should the background color be? 
+X   test fg/bg color on other operating systems
+J   fix icon sizes/design
+X set a better minimum size for the number of updates available
+
+earlier/cleaning
+X list with contrib types separated is really wonky
+o   do we keep the list?
+o   does it even work for different contrib types?
+X   cleaned this up in the last release
+X remove the dated releases from download.processing.org
+X new Android release (EditorButton constructor changed)
+o JavaEditor has several null colors, remove color support
+o   once the design is complete and we for sure do not need color
+X remove deprecated methods
+X do the right thing on passing around List vs ArrayList and others
+o wonder if ""Save As"" is causing the problems with auto-reload
+X   found and fixed
+X look at the sound library https://github.com/wirsing/ProcessingSound
+o   sound is not yet supported on Windows
+X implement the new gui
+
+
 0245 (3.0b7)
 X add jar files from 'code' folder to the library path
 X   Code editor wrongly detects errors for libraries in code folder
diff --git a/todo.txt b/todo.txt
index 6d4db7b94..e27b2b5f7 100644
--- a/todo.txt
+++ b/todo.txt
@@ -1,112 +1,4 @@
-0246 the holy land (3.0)
-X ""Saving"" messages never clear on ""Save As""
-X   https://github.com/processing/processing/issues/3861
-X error checker/suggestions fixes
-X   https://github.com/processing/processing/pull/3871
-X   https://github.com/processing/processing/pull/3879
-X contributions filter is ignored after clicking Install
-X   https://github.com/processing/processing/issues/3826
-X   https://github.com/processing/processing/pull/3872
-X   https://github.com/processing/processing/pull/3883
-X Exception in thread ""Contribution List Downloader""
-X   https://github.com/processing/processing/issues/3882
-X   https://github.com/processing/processing/pull/3884
-X Hide useless error in error checker
-X   https://github.com/processing/processing/pull/3887
-X grab bag of CM work from Jakub
-X   https://github.com/processing/processing/issues/3895
-X   https://github.com/processing/processing/pull/3897
-X Clean up delete dir function
-X   https://github.com/processing/processing/pull/3910
-X don't follow symlinks when deleting directories
-X   https://github.com/processing/processing/pull/3916
-X show number of updates available in the footer
-X   https://github.com/processing/processing/issues/3518
-X   https://github.com/processing/processing/pull/3896
-X   https://github.com/processing/processing/pull/3901
-o   total number of updates available is not correct? (may be fixed)
-o ArrayIndexOutOfBoundsException freak out when clicking the header line
-o   think this was on name, with libraries, but not sure
-X   should be fixed with the updates from Jakub
-X error checker updates for toggle and listeners
-X   https://github.com/processing/processing/pull/3915
-X file file counting in the change detector
-X   https://github.com/processing/processing/pull/3917
-X   https://github.com/processing/processing/issues/3898
-X   https://github.com/processing/processing/issues/3387
-X Windows suggests ""Documents"" as a new location for the 3.0 sketchbook
-X   maybe prevent users from accepting that?
-X   https://github.com/processing/processing/issues/3920
-
-gui
-X distinguish errors and warnings
-X   https://github.com/processing/processing/issues/3406
-X make breakpoints more prominent
-X   https://github.com/processing/processing/issues/3307 (comp is set)
-X clean up statusMessage() inside JavaEditor
-o   do we want to bring back the delays?
-X implement side gradient on the editor
-X if fewer lines in sketch than can be shown in window, show ticks adjacent
-X   error/warning location is awkward when no scroll bar is in use
-X   when only one screen-full, show ticks at exact location
-X   simpler/less confusing to not show at all? 
-X   MarkerColumn.recalculateMarkerPositions()
-X   https://github.com/processing/processing/pull/3903
-X Update status error/warning when changing the line
-X   https://github.com/processing/processing/pull/3907
-X Update status error/warning when changing the line
-X   when moving away from an error/warning line, de-select it below
-X   selecting a warning should also show the warning in the status area
-X   https://github.com/processing/processing/pull/3907
-X clicking an error or warning should give the focus back to the editor
-X   https://github.com/processing/processing/pull/3905
-X replace startup/about screen (1x and 2x versions)
-X   change 'alpha' to correct name
-X   also change the revision in the ""about processing"" dialog
-X   https://github.com/processing/processing/issues/3665
-X implement splash screen on OS X
-X   http://www.randelshofer.ch/oop/javasplash/javasplash.html
-X   also implement special retina version
-X Fix placement and visual design when showing error on hover
-X   https://github.com/processing/processing/issues/3173
-X   implement custom tooltip for error/warning hover
-X   applies to both MarkerColumn and JavaTextAreaPainter
-X make gutter of console match error list
-X   https://github.com/processing/processing/issues/3904
-o bring back the # of updates on the update tab
-o   use this instead of the 'icon' stuff?
-o   or in addition, since only the 'updates' tab has it
-X   https://github.com/processing/processing/issues/3855
-X for updates available, have it be clickable to open the manager
-X fix the design of the completions window
-X   remove extra border around the outside
-X   change font
-X   add 2x version of the icons
-X   change selection highlight color
-o   put some margin around it
-X   https://github.com/processing/processing/issues/3906
-X completion panel
-X   what should the background color be? 
-X   test fg/bg color on other operating systems
-J   fix icon sizes/design
-X set a better minimum size for the number of updates available
-
-earlier/cleaning
-X list with contrib types separated is really wonky
-o   do we keep the list?
-o   does it even work for different contrib types?
-X   cleaned this up in the last release
-X remove the dated releases from download.processing.org
-X new Android release (EditorButton constructor changed)
-o JavaEditor has several null colors, remove color support
-o   once the design is complete and we for sure do not need color
-X remove deprecated methods
-X do the right thing on passing around List vs ArrayList and others
-o wonder if ""Save As"" is causing the problems with auto-reload
-X   found and fixed
-X look at the sound library https://github.com/wirsing/ProcessingSound
-o   sound is not yet supported on Windows
-X implement the new gui
+0247 (3.0.1)
 
 
 known issues",starting the next release,"""Bump version to 3.0.1 (REV 0247)""","""Release Processing 3.0.1 (revision 0247)""","It seems like you're sharing some version control diff outputs and change logs for a software project named Processing. From the information provided, it appears that the project has gone through several changes and revisions, with the most recent one being 0246.

The changes seem to be related to various aspects of the project, including the core, GUI, error handling, and cleaning. Some of the changes include implementing high-performance/async image saving, fixing various bugs related to textures and frames, and updating the error checker. Additionally, there have been changes to the GUI, such as distinguishing errors and warnings, making breakpoints more prominent, and updating the status message in the JavaEditor.

The project also seems to have addressed some issues related to file handling, such as not following symlinks when deleting directories and fixing file counting in the change detector. Furthermore, there have been contributions from other developers, and the project has updated the number of updates available in the footer.

The next planned version appears to be 0247, but the specific changes for that version have not been detailed yet.",Update version number to 0247 and revise related files for release 3.0.1.,Model 2
"diff --git a/src/main/java/reactor/core/publisher/EventLoopProcessor.java b/src/main/java/reactor/core/publisher/EventLoopProcessor.java
index cb830ea52..ddd43abea 100644
--- a/src/main/java/reactor/core/publisher/EventLoopProcessor.java
+++ b/src/main/java/reactor/core/publisher/EventLoopProcessor.java
@@ -23,7 +23,6 @@ import java.util.concurrent.ThreadFactory;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;
-import java.util.concurrent.atomic.AtomicLong;
 import java.util.function.Supplier;
 
 import org.reactivestreams.Processor;
@@ -33,6 +32,7 @@ import reactor.core.flow.Cancellation;
 import reactor.core.flow.Loopback;
 import reactor.core.flow.MultiProducer;
 import reactor.core.flow.Receiver;
+import reactor.core.queue.QueueSupplier;
 import reactor.core.queue.RingBuffer;
 import reactor.core.queue.Slot;
 import reactor.core.scheduler.Scheduler;
@@ -104,7 +104,7 @@ abstract class EventLoopProcessor<IN> extends FluxProcessor<IN, IN>
 			Supplier<Slot<IN>> factory,
 			WaitStrategy strategy) {
 
-		if (!RingBuffer.isPowerOfTwo(bufferSize)) {
+		if (!QueueSupplier.isPowerOfTwo(bufferSize)) {
 			throw new IllegalArgumentException(""bufferSize must be a power of 2 : "" + bufferSize);
 		}
 		
diff --git a/src/main/java/reactor/core/queue/MultiProducer.java b/src/main/java/reactor/core/queue/MultiProducer.java
index 451f83eb0..a269d7fc6 100644
--- a/src/main/java/reactor/core/queue/MultiProducer.java
+++ b/src/main/java/reactor/core/queue/MultiProducer.java
@@ -54,7 +54,7 @@ final class MultiProducer extends RingBufferProducer
     MultiProducer(int bufferSize, final WaitStrategy waitStrategy, Runnable spinObserver) {
         super(bufferSize, waitStrategy, spinObserver);
 
-        if (!RingBuffer.isPowerOfTwo(bufferSize)) {
+        if (!QueueSupplier.isPowerOfTwo(bufferSize)) {
             throw new IllegalArgumentException(""bufferSize must be a power of 2"");
         }
 
diff --git a/src/main/java/reactor/core/queue/QueueSupplier.java b/src/main/java/reactor/core/queue/QueueSupplier.java
index 96657e3c5..c4bd11804 100644
--- a/src/main/java/reactor/core/queue/QueueSupplier.java
+++ b/src/main/java/reactor/core/queue/QueueSupplier.java
@@ -28,17 +28,17 @@ import reactor.core.util.PlatformDependent;
  */
 public final class QueueSupplier<T> implements Supplier<Queue<T>> {
 
-	static final Supplier CLQ_SUPPLIER             = new QueueSupplier<>(Long.MAX_VALUE, false, false);
-	static final Supplier ONE_SUPPLIER             = new QueueSupplier<>(1, false, true);
-	static final Supplier XSRB_SUPPLIER            = new QueueSupplier<>(PlatformDependent.XS_BUFFER_SIZE, false, false);
-	static final Supplier SMALLRB_SUPPLIER         = new QueueSupplier<>(PlatformDependent.SMALL_BUFFER_SIZE, false, false);
-	static final Supplier WAITING_XSRB_SUPPLIER    = new QueueSupplier<>(PlatformDependent.XS_BUFFER_SIZE, true, false);
-	static final Supplier WAITING_SMALLRB_SUPPLIER = new QueueSupplier<>(PlatformDependent.SMALL_BUFFER_SIZE, true, false);
-
-	final long    batchSize;
-	final boolean waiting;
-	final boolean multiproducer;
-
+	/**
+	 * Calculate the next power of 2, greater than or equal to x.<p> From Hacker's Delight, Chapter 3, Harry S. Warren
+	 * Jr.
+	 *
+	 * @param x Value to round up
+	 *
+	 * @return The next power of 2 from x inclusive
+	 */
+	public static int ceilingNextPowerOfTwo(final int x) {
+		return 1 << (32 - Integer.numberOfLeadingZeros(x - 1));
+	}
 
 	/**
 	 *
@@ -84,7 +84,16 @@ public final class QueueSupplier<T> implements Supplier<Queue<T>> {
 		}
 		return new QueueSupplier<>(batchSize, waiting, multiproducer);
 	}
-	
+
+	/**
+	 * @param x the int to test
+	 *
+	 * @return true if x is a power of 2
+	 */
+	public static boolean isPowerOfTwo(final int x) {
+		return Integer.bitCount(x) == 1;
+	}
+
 	/**
 	 *
 	 * @param <T> the reified {@link Queue} generic type
@@ -166,6 +175,9 @@ public final class QueueSupplier<T> implements Supplier<Queue<T>> {
 			return (Supplier<Queue<T>>) WAITING_XSRB_SUPPLIER;
 		}
 	}
+	final long    batchSize;
+	final boolean waiting;
+	final boolean multiproducer;
 
 	QueueSupplier(long batchSize, boolean waiting, boolean multiproducer) {
 		this.batchSize = batchSize;
@@ -198,17 +210,49 @@ public final class QueueSupplier<T> implements Supplier<Queue<T>> {
 	}
 
 	static final class OneQueue<T> extends AtomicReference<T> implements Queue<T> {
-		/** */
-        private static final long serialVersionUID = -6079491923525372331L;
-
         @Override
 		public boolean add(T t) {
 
 		    while (!offer(t));
-		    
+
 		    return true;
 		}
 
+		@Override
+		public boolean addAll(Collection<? extends T> c) {
+			return false;
+		}
+
+		@Override
+		public void clear() {
+			set(null);
+		}
+
+		@Override
+		public boolean contains(Object o) {
+			return Objects.equals(get(), o);
+		}
+
+		@Override
+		public boolean containsAll(Collection<?> c) {
+			return false;
+		}
+
+		@Override
+		public T element() {
+			return get();
+		}
+
+		@Override
+		public boolean isEmpty() {
+			return get() == null;
+		}
+
+		@Override
+		public Iterator<T> iterator() {
+			return new QueueIterator<>(this);
+		}
+
 		@Override
 		public boolean offer(T t) {
 			if (get() != null) {
@@ -219,8 +263,8 @@ public final class QueueSupplier<T> implements Supplier<Queue<T>> {
 		}
 
 		@Override
-		public T remove() {
-			return getAndSet(null);
+		public T peek() {
+			return get();
 		}
 
 		@Override
@@ -233,33 +277,28 @@ public final class QueueSupplier<T> implements Supplier<Queue<T>> {
 		}
 
 		@Override
-		public T element() {
-			return get();
-		}
-
-		@Override
-		public T peek() {
-			return get();
+		public T remove() {
+			return getAndSet(null);
 		}
 
 		@Override
-		public int size() {
-			return get() == null ? 0 : 1;
+		public boolean remove(Object o) {
+			return false;
 		}
 
 		@Override
-		public boolean isEmpty() {
-			return get() == null;
+		public boolean removeAll(Collection<?> c) {
+			return false;
 		}
 
 		@Override
-		public boolean contains(Object o) {
-			return Objects.equals(get(), o);
+		public boolean retainAll(Collection<?> c) {
+			return false;
 		}
 
 		@Override
-		public Iterator<T> iterator() {
-			return new QueueIterator<>(this);
+		public int size() {
+			return get() == null ? 0 : 1;
 		}
 
 		@Override
@@ -283,36 +322,8 @@ public final class QueueSupplier<T> implements Supplier<Queue<T>> {
 			}
 			return (T1[])toArray();
 		}
-
-		@Override
-		public boolean remove(Object o) {
-			return false;
-		}
-
-		@Override
-		public boolean containsAll(Collection<?> c) {
-			return false;
-		}
-
-		@Override
-		public boolean addAll(Collection<? extends T> c) {
-			return false;
-		}
-
-		@Override
-		public boolean removeAll(Collection<?> c) {
-			return false;
-		}
-
-		@Override
-		public boolean retainAll(Collection<?> c) {
-			return false;
-		}
-
-		@Override
-		public void clear() {
-			set(null);
-		}
+		/** */
+        private static final long serialVersionUID = -6079491923525372331L;
 	}
 
 	static class QueueIterator<T> implements Iterator<T> {
@@ -338,4 +349,10 @@ public final class QueueSupplier<T> implements Supplier<Queue<T>> {
 			queue.remove();
 		}
 	}
+	static final Supplier CLQ_SUPPLIER          = new QueueSupplier<>(Long.MAX_VALUE, false, false);
+	static final Supplier ONE_SUPPLIER          = new QueueSupplier<>(1, false, true);
+	static final Supplier XSRB_SUPPLIER         = new QueueSupplier<>(PlatformDependent.XS_BUFFER_SIZE, false, false);
+	static final Supplier SMALLRB_SUPPLIER      = new QueueSupplier<>(PlatformDependent.SMALL_BUFFER_SIZE, false, false);
+	static final Supplier WAITING_XSRB_SUPPLIER = new QueueSupplier<>(PlatformDependent.XS_BUFFER_SIZE, true, false);
+	static final Supplier WAITING_SMALLRB_SUPPLIER = new QueueSupplier<>(PlatformDependent.SMALL_BUFFER_SIZE, true, false);
 }
diff --git a/src/main/java/reactor/core/queue/RingBuffer.java b/src/main/java/reactor/core/queue/RingBuffer.java
index 868b809c1..01ab7a23c 100644
--- a/src/main/java/reactor/core/queue/RingBuffer.java
+++ b/src/main/java/reactor/core/queue/RingBuffer.java
@@ -50,18 +50,6 @@ public abstract class RingBuffer<E> implements LongSupplier, Backpressurable {
 	 */
 	public static final long     INITIAL_CURSOR_VALUE = -1L;
 
-	/**
-	 * Calculate the next power of 2, greater than or equal to x.<p> From Hacker's Delight, Chapter 3, Harry S. Warren
-	 * Jr.
-	 *
-	 * @param x Value to round up
-	 *
-	 * @return The next power of 2 from x inclusive
-	 */
-	public static int ceilingNextPowerOfTwo(final int x) {
-		return 1 << (32 - Integer.numberOfLeadingZeros(x - 1));
-	}
-
 	/**
 	 *
 	 * Create a
@@ -106,17 +94,6 @@ public abstract class RingBuffer<E> implements LongSupplier, Backpressurable {
 		return createMultiProducer(EMITTED, bufferSize, WaitStrategy.blocking());
 	}
 
-	/**
-	 * Create a new multiple producer RingBuffer using the default wait strategy   {@link WaitStrategy#busySpin()}.
-	 * @param factory used to create the events within the ring buffer.
-	 * @param bufferSize number of elements to create within the ring buffer.
-	 * @throws IllegalArgumentException if <tt>bufferSize</tt> is less than 1 or not a power of 2
-	 * @see MultiProducer
-	 */
-	public static <E> RingBuffer<E> createMultiProducer(Supplier<E> factory, int bufferSize) {
-		return createMultiProducer(factory, bufferSize, WaitStrategy.busySpin());
-	}
-
 	/**
 	 * Create a new multiple producer RingBuffer with the specified wait strategy.
 	 * @param factory used to create the events within the ring buffer.
@@ -143,7 +120,7 @@ public abstract class RingBuffer<E> implements LongSupplier, Backpressurable {
 			int bufferSize,
 			WaitStrategy waitStrategy, Runnable spinObserver) {
 
-		if (PlatformDependent.hasUnsafe() && isPowerOfTwo(bufferSize)) {
+		if (PlatformDependent.hasUnsafe() && QueueSupplier.isPowerOfTwo(bufferSize)) {
 			MultiProducer sequencer = new MultiProducer(bufferSize, waitStrategy, spinObserver);
 
 			return new UnsafeRingBuffer<E>(factory, sequencer);
@@ -195,16 +172,6 @@ public abstract class RingBuffer<E> implements LongSupplier, Backpressurable {
 		return createSingleProducer(EMITTED, bufferSize, WaitStrategy.busySpin());
 	}
 
-	/**
-	 * Create a new single producer RingBuffer using the default wait strategy  {@link WaitStrategy#busySpin()}.
-	 * @param bufferSize number of elements to create within the ring buffer.
-	 * @see MultiProducer
-	 */
-	@SuppressWarnings(""unchecked"")
-	public static <E> RingBuffer<Slot<E>> createSingleProducer(int bufferSize, Runnable spinObserver) {
-		return createSingleProducer(EMITTED, bufferSize, WaitStrategy.busySpin(), spinObserver);
-	}
-
 	/**
 	 * Create a new single producer RingBuffer using the default wait strategy   {@link WaitStrategy#busySpin()}.
 	 * @param factory used to create the events within the ring buffer.
@@ -244,7 +211,7 @@ public abstract class RingBuffer<E> implements LongSupplier, Backpressurable {
 			Runnable spinObserver) {
 		SingleProducerSequencer sequencer = new SingleProducerSequencer(bufferSize, waitStrategy, spinObserver);
 
-		if (PlatformDependent.hasUnsafe() && isPowerOfTwo(bufferSize)) {
+		if (PlatformDependent.hasUnsafe() && QueueSupplier.isPowerOfTwo(bufferSize)) {
 			return new UnsafeRingBuffer<>(factory, sequencer);
 		}
 		else {
@@ -289,15 +256,6 @@ public abstract class RingBuffer<E> implements LongSupplier, Backpressurable {
 		return minimum;
 	}
 
-	/**
-	 * @param x the int to test
-	 *
-	 * @return true if x is a power of 2
-	 */
-	public static boolean isPowerOfTwo(final int x) {
-		return Integer.bitCount(x) == 1;
-	}
-
 	/**
 	 * Calculate the log base 2 of the supplied integer, essentially reports the location of the highest bit.
 	 *
diff --git a/src/main/java/reactor/core/queue/SpscArrayQueue.java b/src/main/java/reactor/core/queue/SpscArrayQueue.java
index ad1e7bb21..48cb0d627 100644
--- a/src/main/java/reactor/core/queue/SpscArrayQueue.java
+++ b/src/main/java/reactor/core/queue/SpscArrayQueue.java
@@ -39,7 +39,7 @@ final class SpscArrayQueue<T> extends SpscArrayQueueP3<T> implements Queue<T> {
     private static final long serialVersionUID = 494623116936946976L;
 
     public SpscArrayQueue(int capacity) {
-        super(RingBuffer.ceilingNextPowerOfTwo(capacity));
+        super(QueueSupplier.ceilingNextPowerOfTwo(capacity));
     }
     
     @Override
diff --git a/src/main/java/reactor/core/queue/SpscLinkedArrayQueue.java b/src/main/java/reactor/core/queue/SpscLinkedArrayQueue.java
index 413d204b6..b265cf6e6 100644
--- a/src/main/java/reactor/core/queue/SpscLinkedArrayQueue.java
+++ b/src/main/java/reactor/core/queue/SpscLinkedArrayQueue.java
@@ -45,7 +45,7 @@ final class SpscLinkedArrayQueue<T> extends AbstractQueue<T> {
     static final Object NEXT = new Object();
     
     public SpscLinkedArrayQueue(int linkSize) {
-        int c = RingBuffer.ceilingNextPowerOfTwo(Math.min(2, linkSize));
+        int c = QueueSupplier.ceilingNextPowerOfTwo(Math.min(2, linkSize));
         this.producerArray = this.consumerArray = new AtomicReferenceArray<>(c + 1);
         this.mask = c - 1;
     }
diff --git a/src/main/java/reactor/core/queue/UnsafeRingBuffer.java b/src/main/java/reactor/core/queue/UnsafeRingBuffer.java
index 34f1653df..b7dfc4307 100644
--- a/src/main/java/reactor/core/queue/UnsafeRingBuffer.java
+++ b/src/main/java/reactor/core/queue/UnsafeRingBuffer.java
@@ -61,7 +61,7 @@ abstract class RingBufferFields<E> extends RingBufferPad<E>
         if (bufferSize < 1) {
             throw new IllegalArgumentException(""bufferSize must not be less than 1"");
         }
-        if (!RingBuffer.isPowerOfTwo(bufferSize))
+        if (!QueueSupplier.isPowerOfTwo(bufferSize))
         {
             throw new IllegalArgumentException(""bufferSize must be a power of 2"");
         }
diff --git a/src/main/java/reactor/core/scheduler/OpenHashSet.java b/src/main/java/reactor/core/scheduler/OpenHashSet.java
index 456a11aca..2e2b09597 100644
--- a/src/main/java/reactor/core/scheduler/OpenHashSet.java
+++ b/src/main/java/reactor/core/scheduler/OpenHashSet.java
@@ -25,7 +25,7 @@ package reactor.core.scheduler;
 import java.util.Arrays;
 import java.util.function.Consumer;
 
-import reactor.core.queue.RingBuffer;
+import reactor.core.queue.QueueSupplier;
 
 /**
  * A simple open hash set with add, remove and clear capabilities only.
@@ -55,7 +55,7 @@ final class OpenHashSet<T> {
     @SuppressWarnings(""unchecked"")
     public OpenHashSet(int capacity, float loadFactor) {
         this.loadFactor = loadFactor;
-        int c = RingBuffer.ceilingNextPowerOfTwo(capacity);
+        int c = QueueSupplier.ceilingNextPowerOfTwo(capacity);
         this.mask = c - 1;
         this.maxSize = (int)(loadFactor * c);
         this.keys = (T[])new Object[c];",tweaks QueueSupplier utils,"""Extract power of 2 checks and ceiling calculation to QueueSupplier""","""Replace RingBuffer.isPowerOfTwo with QueueSupplier.isPowerOfTwo""","""Update to use QueueSupplier for power of 2 checks and OneQueue implementation""

This commit makes several changes to the codebase:

* It introduces a new class `QueueSupplier` that provides a static method `isPowerOfTwo` for checking if a given integer is a power of 2. This method is used in several places throughout the codebase to replace similar checks that were previously implemented using `Integer.bitCount`.
* It updates the `EventLoopProcessor` and `MultiProducer` classes to use `QueueSupplier.isPowerOfTwo` instead of `RingBuffer.isPowerOfTwo`.
* It adds several new methods to the `OneQueue` class to make it a full implementation of the `Queue` interface. These methods include `addAll`, `clear`, `contains`, `containsAll`, `element`, `isEmpty`, `iterator`, `remove`, `removeAll`, `retainAll`, and `size`.
* It adds a `serialVersionUID` field to the `OneQueue` class to make it compatible with Java's serialization mechanism.
* It updates the `QueueSupplier` class to define several new constants for creating `Queue` instances with different characteristics, such as waiting or non-waiting, single-producer or multi-producer, and with different buffer sizes.

Overall, this commit seems to be focused on improving the consistency and flexibility of the codebase by introducing a new abstraction for creating `Queue` instances and updating existing code to use this abstraction. It also includes some minor improvements to the `OneQueue` class to make it a full implementation of the `Queue` interface.","Refactored to utilize `QueueSupplier`'s `isPowerOfTwo` and `ceilingNextPowerOfTwo` methods, removing duplicates from `RingBuffer`.",Model 1
"diff --git a/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/_operations.html.erb b/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/_operations.html.erb
index dec69e8c8f8..1236878d716 100644
--- a/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/_operations.html.erb
+++ b/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/_operations.html.erb
@@ -16,7 +16,7 @@
     <li><%= uninstall -%></li>
   <% end %>
   </ul>
-  <input type=""submit"" value=""Cancel uninstalls""/>
+  <input type=""submit"" value=""Cancel uninstalls"" id=""cancel-uninstall""/>
 </p>
 </form>
 <% end %>
@@ -28,7 +28,7 @@
     <li><%= download -%></li>
   <% end %>
   </ul>
-  <input type=""submit"" value=""Cancel pending installations""/>
+  <input type=""submit"" value=""Cancel pending installations"" id=""cancel-pending-installations""/>
 </p>
 </form>
 <% end %>
diff --git a/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/available.html.erb b/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/available.html.erb
index 6bc0f196fc7..9487480fb5a 100644
--- a/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/available.html.erb
+++ b/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/available.html.erb
@@ -35,7 +35,7 @@ function installPlugin(key) {
         plugin = update.plugin
         release = update.release
     %>
-      <tr class=""<%= cycle('even','odd', :name => category) -%>"">
+      <tr class=""<%= cycle('even','odd', :name => category) -%>"" id=""select-<%= plugin.getKey() -%>"">
         <td width=""150"" nowrap>
           <b><a href=""#plugin"" onClick=""showPlugin('<%= plugin.getKey() -%>');""><%= h(plugin.getName()) -%></a></b>
         </td>
diff --git a/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/index.html.erb b/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/index.html.erb
index 4d5f853e752..31d566f9073 100644
--- a/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/index.html.erb
+++ b/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/index.html.erb
@@ -85,7 +85,7 @@
           <tr>
             <td colspan=""2"">
              <form method=""post"" action=""<%= ApplicationController.root_context -%>/updatecenter/uninstall?key=<%= plugin.getKey() -%>"" style=""display: inline-block"">
-               <input type=""submit"" value=""Uninstall"" class=""red-button""/>
+               <input type=""submit"" value=""Uninstall"" class=""red-button"" id=""uninstall-<%= plugin.getKey() -%>""/>
              </form>
               </td>
             </tr>
diff --git a/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/updates.html.erb b/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/updates.html.erb
index 05a59b023a3..ad2891711b6 100644
--- a/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/updates.html.erb
+++ b/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/updates.html.erb
@@ -31,7 +31,7 @@ function upgradePlugin(key) {
            updates.each_with_index do |update, index|
             release=update.release
        %>
-        <tr class=""<%= css -%>"">
+        <tr class=""<%= css -%>"" id=""select_<%= plugin.getKey() -%>"">
           <td width=""1%"" nowrap><% if index==0 %><b><%= h(plugin.getName()) -%></b> <%= @installed_plugins[plugin.getKey()] -%> -> <% end %></td>
           <td width=""1%"" nowrap><b><%= release.getVersion() -%></b></td>
           <td width=""1%"" nowrap><%= release_date(release.getDate()) if release.getDate() -%></td>",Add HTML Id,"""Add IDs to update center buttons and table rows for better accessibility and styling""","""Added unique IDs to UI elements for better accessibility and identification""","This commit contains changes to the Sonar server's update center view files.

1. In `_operations.html.erb`, IDs have been added to the ""Cancel uninstalls"" and ""Cancel pending installations"" buttons.
2. In `available.html.erb`, an ID has been added to the table row for plugin selection.
3. In `index.html.erb`, an ID has been added to the ""Uninstall"" button for each plugin.
4. In `updates.html.erb`, an ID has been added to the table row for plugin selection.

These changes may be used for referencing these elements in JavaScript or CSS.",Added unique IDs to input buttons and table rows for better DOM element selection and manipulation.,Model 1
"diff --git a/spring-security-oauth2/src/main/java/org/springframework/security/oauth2/config/ResourceServerBeanDefinitionParser.java b/spring-security-oauth2/src/main/java/org/springframework/security/oauth2/config/ResourceServerBeanDefinitionParser.java
index adada9a5..0221fcfa 100755
--- a/spring-security-oauth2/src/main/java/org/springframework/security/oauth2/config/ResourceServerBeanDefinitionParser.java
+++ b/spring-security-oauth2/src/main/java/org/springframework/security/oauth2/config/ResourceServerBeanDefinitionParser.java
@@ -47,7 +47,7 @@ public class ResourceServerBeanDefinitionParser extends ProviderBeanDefinitionPa
 		}
 		protectedResourceFilterBean.addPropertyValue(""authenticationManager"", authenticationManagerBean.getBeanDefinition());
 		if (StringUtils.hasText(entryPointRef)) {
-			protectedResourceFilterBean.addPropertyValue(""authenticationEntryPoint"", entryPointRef);
+			protectedResourceFilterBean.addPropertyReference(""authenticationEntryPoint"", entryPointRef);
 		}
 
 		return protectedResourceFilterBean.getBeanDefinition();
diff --git a/spring-security-oauth2/src/main/resources/org/springframework/security/oauth2/spring-security-oauth2-1.0.xsd b/spring-security-oauth2/src/main/resources/org/springframework/security/oauth2/spring-security-oauth2-1.0.xsd
index f2802bdd..0fca0112 100644
--- a/spring-security-oauth2/src/main/resources/org/springframework/security/oauth2/spring-security-oauth2-1.0.xsd
+++ b/spring-security-oauth2/src/main/resources/org/springframework/security/oauth2/spring-security-oauth2-1.0.xsd
@@ -339,16 +339,11 @@
 						</xs:annotation>
 					</xs:attribute>
 
-					<xs:attribute name=""serialization-service-ref"" type=""xs:string"">
+					<xs:attribute name=""entry-point-ref"" type=""xs:string"">
 						<xs:annotation>
 							<xs:documentation>
-								The reference to the bean that defines the
-								serialization service for
-								an OAuth 2 response
-								Default
-								value is an
-								instance of
-								""org.springframework.security.oauth2.common.DefaultOAuth2SerializationService"".
+								The reference to the bean that defines the entry point for failed authentications.  Defaults to a vanilla
+								org.springframework.security.oauth2.provider.error.OAuth2AuthenticationEntryPoint.
 							</xs:documentation>
 						</xs:annotation>
 					</xs:attribute>",add entry point to xsd !,"""Change ResourceServerBeanDefinitionParser to use property reference for authenticationEntryPoint and update XSD to reflect entry-point-ref attribute""","""Update ResourceServerBeanDefinitionParser to use addPropertyReference for authenticationEntryPoint and update xsd to reflect the change in attribute name from serialization-service-ref to entry-point-ref""","""Updated ResourceServerBeanDefinitionParser to use addPropertyReference instead of addPropertyValue for authenticationEntryPoint, and removed serialization-service-ref attribute from spring-security-oauth2-1.0.xsd""",Fix bean attribute reference and update XSD documentation for authentication entry point in ResourceServer configuration.,Model 4
"diff --git a/src/main/java/hex/deeplearning/DeepLearningModel.java b/src/main/java/hex/deeplearning/DeepLearningModel.java
index 8e03aeca1..c193189a5 100644
--- a/src/main/java/hex/deeplearning/DeepLearningModel.java
+++ b/src/main/java/hex/deeplearning/DeepLearningModel.java
@@ -1188,7 +1188,8 @@ public class DeepLearningModel extends Model implements Comparable<DeepLearningM
             + water.api.Predict.link(_key, ""Score on dataset"") + "", ""
             + DeepLearning.link(_dataKey, ""Compute new model"", null, responseName(), val_key)
             + (actual_best_model_key != null && UKV.get(actual_best_model_key) != null && actual_best_model_key != _key ? "", "" + DeepLearningModelView.link(""Go to best model"", actual_best_model_key) : """")
-            + (jobKey == null || ((jobKey != null && UKV.get(jobKey) == null)) || (jobKey != null && UKV.get(jobKey) != null && Job.isEnded(jobKey)) ? "", <i class=\""icon-play\""></i>"" + DeepLearning.link(_dataKey, ""Continue training this model"", _key, responseName(), val_key) : """")
+            + (jobKey == null || ((jobKey != null && UKV.get(jobKey) == null)) || (jobKey != null && UKV.get(jobKey) != null && Job.isEnded(jobKey)) ? "", <i class=\""icon-play\""></i>"" + DeepLearning.link(_dataKey, ""Continue training this model"", _key, responseName(), val_key) : """") + "", ""
+            + UIUtils.qlink(SaveModel.class, ""model"", _key, ""Save model"") + "", ""
             + ""</div>"");
 
     DocGen.HTML.paragraph(sb, ""Model Key: "" + _key);",Add saveModel link to DL Model web page .,"""Added 'Save model' link to DeepLearningModel""","Added ""Save model"" option to DeepLearningModel view.","""Added a 'Save model' link to the DeepLearningModel view""","Added ""Save model"" and its corresponding link in the DeepLearningModel view for saving models.",Model 3
"diff --git a/build/build_release.sh b/build/build_release.sh
index ed539dcef5..8fa8441c87 100755
--- a/build/build_release.sh
+++ b/build/build_release.sh
@@ -95,10 +95,6 @@ echo ""  geowebcache = $gwc_ver""
 echo ""maven/java settings:""
 mvn -version
 
-if [ ! -z $git_user ] && [ ! -z $git_email ]; then
-  git_opts=""--author='$git_user <$git_email>'""
-fi
-
 # move to root of source tree
 pushd .. > /dev/null
 
@@ -364,6 +360,16 @@ fi
 
 # git commit changes on the release branch
 pushd .. > /dev/null
+
+# setup the author, for some reason I can;t for the life of me get to this
+# to work properly from a script using the --author option to git commit
+git config --unset user.name
+git config --unset user.email
+if [ ! -z $git_user ] && [ ! -z $git_email ]; then
+  git config user.name $git_user
+  git config user.email $git_email
+fi
+
 git add . 
 git commit $git_opts -m ""updating version numbers and release notes for $tag"" .
 popd > /dev/null",using git config to set author for release commits rather than - - author option,"""Fix setting author for release commits""","""Fix author configuration for git commit on release branch""

However, considering the commit message is already specified in the code, a more accurate commit message would be:

""update git commit author configuration""

This commit message directly reflects the changes made in the code.","""updating version numbers and release notes for $tag""

This commit message indicates that the purpose of the commit is to update version numbers and release notes for a specific tag (represented by the variable $tag). This commit is likely part of a release process for a software project.

The changes in the code also suggest that the script has been updated to remove some code related to setting the Git author and email configuration, and instead configure the user name and email using Git config commands directly in the script. This change may have been made to ensure that the correct author and email are used for the commit, regardless of the user's local Git configuration.","""Moved git author config setup from initial check to commit step for setting author details dynamically during release.""",Model 4
"diff --git a/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_constants.bal b/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_constants.bal
index 3b7e816b94c..45bee4b4591 100644
--- a/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_constants.bal
+++ b/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_constants.bal
@@ -193,10 +193,12 @@ const string MAP_VALUE = ""org/ballerinalang/jvm/values/MapValue"";
 const string ARRAY_VALUE = ""org/ballerinalang/jvm/values/ArrayValue"";
 const string OBJECT_VALUE = ""org/ballerinalang/jvm/values/ObjectValue"";
 const string STRING_VALUE = ""java/lang/String"";
-const string OBJECT = ""java/lang/Object"";
 const string LONG_VALUE = ""java/lang/Long"";
 const string BOOLEAN_VALUE = ""java/lang/Boolean"";
+const string DOUBLE_VALUE = ""java/lang/Double"";
+const string BYTE_VALUE = ""java/lang/Byte"";
 
+const string OBJECT = ""java/lang/Object"";
 const string MAP = ""java/util/Map"";
 const string LINKED_HASH_MAP = ""java/util/LinkedHashMap"";
 
diff --git a/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_instruction_gen.bal b/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_instruction_gen.bal
index 37812f77e1b..0c28b5f1a12 100644
--- a/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_instruction_gen.bal
+++ b/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_instruction_gen.bal
@@ -27,6 +27,10 @@ type InstructionGenerator object {
             int index = self.getJVMIndexOfVarRef(loadIns.lhsOp.variableDcl);
             //io:println(""Const Store Index is :::::::::::"", index);
             self.mv.visitVarInsn(ASTORE, index);
+        } else if (bType is bir:BTypeNil) {
+            self.mv.visitInsn(ACONST_NULL);
+            int index = self.getJVMIndexOfVarRef(loadIns.lhsOp.variableDcl);
+            self.mv.visitVarInsn(ASTORE, index);
         } else {
             error err = error( ""JVM generation is not supported for type : "" + io:sprintf(""%s"", bType));
             panic err;
@@ -44,16 +48,22 @@ type InstructionGenerator object {
         if (bType is bir:BTypeInt) {
             self.mv.visitVarInsn(LLOAD, rhsIndex);
             self.mv.visitVarInsn(LSTORE, lhsLndex);
-        } else if (bType is bir:BTypeBoolean) {
-            self.mv.visitVarInsn(ILOAD, rhsIndex);
-            self.mv.visitVarInsn(ISTORE, lhsLndex);
+        } else if (bType is bir:BTypeFloat) {
+            self.mv.visitVarInsn(DLOAD, rhsIndex);
+            self.mv.visitVarInsn(DSTORE, lhsLndex);
         } else if (bType is bir:BTypeString) {
             self.mv.visitVarInsn(ALOAD, rhsIndex);
             self.mv.visitVarInsn(ASTORE, lhsLndex);
-        } else if (bType is bir:BArrayType) {
-            self.mv.visitVarInsn(ALOAD, rhsIndex);
-            self.mv.visitVarInsn(ASTORE, lhsLndex);
-        } else if (bType is bir:BMapType) {
+        } else if (bType is bir:BTypeBoolean) {
+            self.mv.visitVarInsn(ILOAD, rhsIndex);
+            self.mv.visitVarInsn(ISTORE, lhsLndex);
+        } else if (bType is bir:BTypeByte) {
+            self.mv.visitVarInsn(ILOAD, rhsIndex);
+            self.mv.visitVarInsn(ISTORE, lhsLndex);
+        } else if (bType is bir:BArrayType ||
+                        bType is bir:BMapType ||
+                        bType is bir:BTypeAny ||
+                        bType is bir:BTypeNil) {
             self.mv.visitVarInsn(ALOAD, rhsIndex);
             self.mv.visitVarInsn(ASTORE, lhsLndex);
         } else {
diff --git a/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_method_gen.bal b/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_method_gen.bal
index afef2790e21..f2b35e4afdf 100644
--- a/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_method_gen.bal
+++ b/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_method_gen.bal
@@ -1,14 +1,11 @@
 function generateMethod(bir:Function func, jvm:ClassWriter cw) {
     BalToJVMIndexMap indexMap = new;
     string funcName = untaint func.name.value;
-
     int returnVarRefIndex = -1;
 
     // generate method desc
     string desc = getMethodDesc(func);
-
     jvm:MethodVisitor mv = cw.visitMethod(ACC_PUBLIC + ACC_STATIC, funcName, desc, null, null);
-
     mv.visitCode();
 
     // generate method body
@@ -29,26 +26,7 @@ function generateMethod(bir:Function func, jvm:ClassWriter cw) {
         var index = indexMap.getIndex(localVar);
         if(localVar.kind != ""ARG""){
             bir:BType bType = localVar.typeValue;
-            if (bType is bir:BTypeInt) {
-                mv.visitInsn(LCONST_0);
-                mv.visitVarInsn(LSTORE, index);
-            } else if (bType is bir:BTypeBoolean) {
-                mv.visitInsn(ICONST_0);
-                mv.visitVarInsn(ISTORE, index);
-            } else if (bType is bir:BTypeString) {
-                mv.visitInsn(ACONST_NULL);
-                mv.visitVarInsn(ASTORE, index);
-            } else if (bType is bir:BMapType) {
-                mv.visitInsn(ACONST_NULL);
-                mv.visitVarInsn(ASTORE, index);
-            } else if (bType is bir:BArrayType) {
-                mv.visitInsn(ACONST_NULL);
-                mv.visitVarInsn(ASTORE, index);
-            } else {
-                error err = error( ""JVM generation is not supported for type "" +
-                                            io:sprintf(""%s"", bType));
-                panic err;
-            }
+            genDefaultValue(mv, bType, index);
         }
         k += 1;
     }
@@ -72,26 +50,7 @@ function generateMethod(bir:Function func, jvm:ClassWriter cw) {
     if (!isVoidFunc) {
         returnVarRefIndex = indexMap.getIndex(localVars[0]);
         bir:BType returnType = func.typeValue.retType;
-        if (returnType is bir:BTypeInt) {
-            mv.visitInsn(LCONST_0);
-            mv.visitVarInsn(LSTORE, returnVarRefIndex);
-        } else if (returnType is bir:BTypeBoolean) {
-            mv.visitInsn(ICONST_0);
-            mv.visitVarInsn(ISTORE, returnVarRefIndex);
-        } else if (returnType is bir:BTypeString) {
-            mv.visitInsn(ACONST_NULL);
-            mv.visitVarInsn(ASTORE, returnVarRefIndex);
-        } else if (returnType is bir:BMapType) {
-            mv.visitInsn(ACONST_NULL);
-            mv.visitVarInsn(ASTORE, returnVarRefIndex);
-        } else if (returnType is bir:BArrayType) {
-            mv.visitInsn(ACONST_NULL);
-            mv.visitVarInsn(ASTORE, returnVarRefIndex);
-        } else {
-            error err = error( ""JVM generation is not supported for type "" +
-                                            io:sprintf(""%s"", returnType));
-            panic err;
-        }
+        genDefaultValue(mv, returnType, returnVarRefIndex);
     }
 
     // uncomment to test yield
@@ -222,13 +181,19 @@ function generateMethod(bir:Function func, jvm:ClassWriter cw) {
         if (bType is bir:BTypeInt) {
             mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""J"");
             mv.visitVarInsn(LSTORE, index);
-        } else if (bType is bir:BTypeBoolean) {
-            mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""Z"");
-            mv.visitVarInsn(ISTORE, index);
+        } else if (bType is bir:BTypeFloat) {
+            mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""D"");
+            mv.visitVarInsn(DSTORE, index);
         } else if (bType is bir:BTypeString) {
             mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), 
                     io:sprintf(""L%s;"", STRING_VALUE));
             mv.visitVarInsn(ASTORE, index);
+        } else if (bType is bir:BTypeBoolean) {
+            mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""Z"");
+            mv.visitVarInsn(ISTORE, index);
+        } else if (bType is bir:BTypeByte) {
+            mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""B"");
+            mv.visitVarInsn(ISTORE, index);
         } else if (bType is bir:BMapType) {
             mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), 
                     io:sprintf(""L%s;"", MAP_VALUE));
@@ -237,6 +202,10 @@ function generateMethod(bir:Function func, jvm:ClassWriter cw) {
             mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), 
                     io:sprintf(""L%s;"", ARRAY_VALUE));
             mv.visitVarInsn(ASTORE, index);
+        } else if (bType is bir:BTypeNil || bType is bir:BTypeAny) {
+            mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), 
+                    io:sprintf(""L%s;"", OBJECT));
+            mv.visitVarInsn(ASTORE, index);
         } else {
             error err = error( ""JVM generation is not supported for type "" +
                                         io:sprintf(""%s"", bType));
@@ -266,13 +235,19 @@ function generateMethod(bir:Function func, jvm:ClassWriter cw) {
         if (bType is bir:BTypeInt) {
             mv.visitVarInsn(LLOAD, index);
             mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""J"");
-        } else if (bType is bir:BTypeBoolean) {
-            mv.visitVarInsn(ILOAD, index);
-            mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""Z"");
+        } else if (bType is bir:BTypeFloat) {
+            mv.visitVarInsn(DLOAD, index);
+            mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""D"");
         } else if (bType is bir:BTypeString) {
             mv.visitVarInsn(ALOAD, index);
             mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""),
                     io:sprintf(""L%s;"", STRING_VALUE));
+        } else if (bType is bir:BTypeBoolean) {
+            mv.visitVarInsn(ILOAD, index);
+            mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""Z"");
+        } else if (bType is bir:BTypeByte) {
+            mv.visitVarInsn(ILOAD, index);
+            mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""B"");
         } else if (bType is bir:BMapType) {
             mv.visitVarInsn(ALOAD, index);
             mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""),
@@ -281,6 +256,10 @@ function generateMethod(bir:Function func, jvm:ClassWriter cw) {
             mv.visitVarInsn(ALOAD, index);
             mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""),
                     io:sprintf(""L%s;"", ARRAY_VALUE));
+        } else if (bType is bir:BTypeNil || bType is bir:BTypeAny) {
+            mv.visitVarInsn(ALOAD, index);
+            mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""),
+                    io:sprintf(""L%s;"", OBJECT));
         } else {
             error err = error( ""JVM generation is not supported for type "" +
                                         io:sprintf(""%s"", bType));
@@ -319,6 +298,38 @@ function generateMethod(bir:Function func, jvm:ClassWriter cw) {
     mv.visitEnd();
 }
 
+function genDefaultValue(jvm:MethodVisitor mv, bir:BType bType, int index) {
+    if (bType is bir:BTypeInt) {
+        mv.visitInsn(LCONST_0);
+        mv.visitVarInsn(LSTORE, index);
+    } else if (bType is bir:BTypeFloat) {
+        mv.visitInsn(DCONST_0);
+        mv.visitVarInsn(DSTORE, index);
+    } else if (bType is bir:BTypeString) {
+        mv.visitInsn(ACONST_NULL);
+        mv.visitVarInsn(ASTORE, index);
+    } else if (bType is bir:BTypeBoolean) {
+        mv.visitInsn(ICONST_0);
+        mv.visitVarInsn(ISTORE, index);
+    } else if (bType is bir:BTypeByte) {
+        mv.visitInsn(ICONST_0);
+        mv.visitVarInsn(ISTORE, index);
+    } else if (bType is bir:BMapType) {
+        mv.visitInsn(ACONST_NULL);
+        mv.visitVarInsn(ASTORE, index);
+    } else if (bType is bir:BArrayType) {
+        mv.visitInsn(ACONST_NULL);
+        mv.visitVarInsn(ASTORE, index);
+    } else if (bType is bir:BTypeNil || bType is bir:BTypeAny) {
+        mv.visitInsn(ACONST_NULL);
+        mv.visitVarInsn(ASTORE, index);
+    } else {
+        error err = error( ""JVM generation is not supported for type "" +
+                                        io:sprintf(""%s"", bType));
+        panic err;
+    }
+}
+
 function getMethodDesc(bir:Function func) returns string {
     string desc = ""(Lorg/ballerina/jvm/Strand;"";
     int i = 0;
@@ -335,14 +346,22 @@ function getMethodDesc(bir:Function func) returns string {
 function getTypeDesc(bir:BType bType) returns string {
     if (bType is bir:BTypeInt) {
         return ""J"";
+    } else if (bType is bir:BTypeFloat) {
+        return ""D"";
     } else if (bType is bir:BTypeString) {
-        return ""Ljava/lang/String;"";
+        return io:sprintf(""L%s;"", STRING_VALUE);
     } else if (bType is bir:BTypeBoolean) {
         return ""Z"";
+    } else if (bType is bir:BTypeByte) {
+        return ""B"";
+    } else if (bType is bir:BTypeNil) {
+        return io:sprintf(""L%s;"", OBJECT);
     } else if (bType is bir:BMapType) {
         return io:sprintf(""L%s;"", OBJECT_VALUE);
     } else if (bType is bir:BArrayType) {
         return io:sprintf(""L%s;"", ARRAY_VALUE);
+    } else if (bType is bir:BTypeAny) {
+        return io:sprintf(""L%s;"", OBJECT);
     } else {
         error err = error( ""JVM generation is not supported for type "" + io:sprintf(""%s"", bType));
         panic err;
@@ -350,18 +369,24 @@ function getTypeDesc(bir:BType bType) returns string {
 }
 
 function generateReturnType(bir:BType? bType) returns string {
-    if (bType is bir:BTypeNil) {
-        return "")V"";
-    } else if (bType is bir:BTypeInt) {
+    if (bType is bir:BTypeInt) {
         return "")J"";
+    } else if (bType is bir:BTypeFloat) {
+        return "")D"";
     } else if (bType is bir:BTypeString) {
-        return "")Ljava/lang/String;"";
+        return io:sprintf("")L%s;"", STRING_VALUE);
     } else if (bType is bir:BTypeBoolean) {
         return "")Z"";
+    } else if (bType is bir:BTypeByte) {
+        return "")B"";
+    } else if (bType is bir:BTypeNil) {
+        return "")V"";
     } else if (bType is bir:BArrayType) {
         return io:sprintf("")L%s;"", ARRAY_VALUE);
     } else if (bType is bir:BMapType) {
         return io:sprintf("")L%s;"", OBJECT_VALUE);
+    } else if (bType is bir:BTypeAny) {
+        return io:sprintf("")L%s;"", OBJECT);
     } else {
         error err = error( ""JVM generation is not supported for type "" + io:sprintf(""%s"", bType));
         panic err;
@@ -420,8 +445,12 @@ function generateMainMethod(bir:Function userMainFunc, jvm:ClassWriter cw, bir:P
         bir:BType returnType = userMainFunc.typeValue.retType;
         if (returnType is bir:BTypeInt) {
             mv.visitMethodInsn(INVOKEVIRTUAL, ""java/io/PrintStream"", ""println"", ""(J)V"", false);
+        } else if (returnType is bir:BTypeFloat) {
+            mv.visitMethodInsn(INVOKEVIRTUAL, ""java/io/PrintStream"", ""println"", ""(D)V"", false);
         } else if (returnType is bir:BTypeBoolean) {
             mv.visitMethodInsn(INVOKEVIRTUAL, ""java/io/PrintStream"", ""println"", ""(Z)V"", false);
+        } else if (returnType is bir:BTypeByte) {
+            mv.visitMethodInsn(INVOKEVIRTUAL, ""java/io/PrintStream"", ""println"", ""(I)V"", false);
         } else {
             mv.visitMethodInsn(INVOKEVIRTUAL, ""java/io/PrintStream"", ""println"", ""(Ljava/lang/Object;)V"", false);
         }
@@ -443,12 +472,24 @@ function generateCast(int paramIndex, bir:BType targetType, jvm:MethodVisitor mv
 
     if (targetType is bir:BTypeInt) {
         mv.visitMethodInsn(INVOKESTATIC, LONG_VALUE, ""parseLong"", ""(Ljava/lang/String;)J"", false);
-    } if (targetType is bir:BTypeBoolean) {
-        mv.visitMethodInsn(INVOKESTATIC, BOOLEAN_VALUE, ""parseBoolean"", ""(Ljava/lang/String;)Z"", false);
+    } else if (targetType is bir:BTypeFloat) {
+        mv.visitMethodInsn(INVOKESTATIC, DOUBLE_VALUE, ""parseDouble"", ""(Ljava/lang/String;)D"", false);
     } else if (targetType is bir:BTypeString) {
         mv.visitTypeInsn(CHECKCAST, STRING_VALUE);
+    } else if (targetType is bir:BTypeBoolean) {
+        mv.visitMethodInsn(INVOKESTATIC, BOOLEAN_VALUE, ""parseBoolean"", ""(Ljava/lang/String;)Z"", false);
+    } else if (targetType is bir:BTypeByte) {
+        mv.visitMethodInsn(INVOKESTATIC, BYTE_VALUE, ""parseByte"", ""(Ljava/lang/String;)B"", false);
+    } else if (targetType is bir:BTypeNil) {
+        // do nothing
+        return;
     } else if (targetType is bir:BArrayType) {
         mv.visitTypeInsn(CHECKCAST, ARRAY_VALUE);
+    } else if (targetType is bir:BMapType) {
+        mv.visitTypeInsn(CHECKCAST, MAP_VALUE);
+    } else if (targetType is bir:BTypeAny) {
+        // do nothing
+        return;
     } else {
         error err = error(""JVM generation is not supported for type "" + io:sprintf(""%s"", targetType));
         panic err;
@@ -503,18 +544,30 @@ function generateFrameClasses(bir:Package pkg, map<byte[]> pkgEntries) {
             if (bType is bir:BTypeInt) {
                 jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, ""J"");
                 fv.visitEnd();
-            } else if (bType is bir:BTypeBoolean) {
+            } else if (bType is bir:BTypeFloat) {
                 jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, ""Z"");
                 fv.visitEnd();
             } else if (bType is bir:BTypeString) {
                 jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, io:sprintf(""L%s;"", STRING_VALUE));
                 fv.visitEnd();
+            } else if (bType is bir:BTypeBoolean) {
+                jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, ""D"");
+                fv.visitEnd();
+            } else if (bType is bir:BTypeByte) {
+                jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, ""B"");
+                fv.visitEnd();
+            } else if (bType is bir:BTypeNil) {
+                jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, io:sprintf(""L%s;"", OBJECT));
+                fv.visitEnd();
             } else if (bType is bir:BMapType) {
                 jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, io:sprintf(""L%s;"", MAP_VALUE));
                 fv.visitEnd();
             } else if (bType is bir:BArrayType) {
                 jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, io:sprintf(""L%s;"", ARRAY_VALUE));
                 fv.visitEnd();
+            } else if (bType is bir:BTypeAny) {
+                jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, io:sprintf(""L%s;"", OBJECT));
+","Add support for float , byte , nil and any","""Added support for float and byte types in JVM backend""","Added support for Float, Byte, and Any types in JVM backend.

This commit message is concise and accurately reflects the changes made in the code. It mentions the specific types that are now supported, which is Float, Byte, and Any.","""Adding support for byte and double types in JVM backend""

The changes in the code seem to be adding support for byte and double types in the JVM backend for Ballerina, a programming language. The changes include adding new constants for byte and double types, updating the instruction generator to handle these types, and updating the method generator to handle these types as well. The changes also include updating the code to handle nil and any types. The changes appear to be well-structured and follow the existing coding style.","""Add JVM support for Float and Byte types, and refactor common code into genDefaultValue function.""",Model 4
"diff --git a/stdlib/streams/src/main/ballerina/streams/windows.bal b/stdlib/streams/src/main/ballerina/streams/windows.bal
index 10b77e8b843..06dc2c10cf9 100644
--- a/stdlib/streams/src/main/ballerina/streams/windows.bal
+++ b/stdlib/streams/src/main/ballerina/streams/windows.bal
@@ -24,7 +24,7 @@ public type Window abstract object {
 
     public function getCandidateEvents(
                         StreamEvent originEvent,
-                        (function (map<any> e1Data, map<any> e2Data) returns boolean)? conditionFunc,
+                        (function (map<anydata> e1Data, map<anydata> e2Data) returns boolean)? conditionFunc,
                         boolean isLHSTrigger = true)
                         returns (StreamEvent?, StreamEvent?)[];
 };
@@ -36,20 +36,22 @@ public type LengthWindow object {
     public any[] windowParameters;
     public function (StreamEvent[])? nextProcessPointer;
 
-    public new(nextProcessPointer, windowParameters) {
+    public function __init(function (StreamEvent[])? nextProcessPointer, any[] windowParameters) {
+        self.nextProcessPointer = nextProcessPointer;
+        self.windowParameters = windowParameters;
         self.linkedList = new;
         self.initParameters(windowParameters);
         self.size = 0;
     }
 
     public function initParameters(any[] parameters) {
-        if(parameters.length() == 1) {
-            match parameters[0] {
-                int value => self.size = value;
-                any anyValue => {
-                    error err = error(""Length window expects an int parameter"");
-                    panic err;
-                }
+        if (parameters.length() == 1) {
+            any value = parameters[0];
+            if (value is int) {
+                self.size = value;
+            } else {
+                error err = error(""Length window expects an int parameter"");
+                panic err;
             }
         } else {
             error err = error(""Length window should only have one parameter (<int> "" +
@@ -62,18 +64,10 @@ public type LengthWindow object {
         StreamEvent[] outputEvents = [];
         foreach event in streamEvents {
             if (self.linkedList.getSize() == self.size) {
-                match self.linkedList.removeFirst() {
-                    StreamEvent streamEvent => {
-                        outputEvents[outputEvents.length()] = streamEvent;
-                    }
 
-                    () => {
-                        // do nothing
-                    }
-
-                    any anyValue => {
-                        // do nothing
-                    }
+                any? anyValue = self.linkedList.removeFirst();
+                if (anyValue is StreamEvent) {
+                    outputEvents[outputEvents.length()] = anyValue;
                 }
             }
 
@@ -82,42 +76,33 @@ public type LengthWindow object {
             expiredVeresionOfEvent.eventType = ""EXPIRED"";
             self.linkedList.addLast(expiredVeresionOfEvent);
         }
-        match (self.nextProcessPointer) {
-            function (StreamEvent[]) nxtProc => {
-                nxtProc(outputEvents);
-            }
-            () => {
-                //do nothing
-            }
+
+        any nextProcessFuncPointer = self.nextProcessPointer;
+        if (nextProcessFuncPointer is function (StreamEvent[])) {
+            nextProcessFuncPointer.call(outputEvents);
         }
     }
 
     public function getCandidateEvents(
                         StreamEvent originEvent,
-                        (function (map<any> e1Data, map<any> e2Data) returns boolean)? conditionFunc,
+                        (function (map<anydata> e1Data, map<anydata> e2Data) returns boolean)? conditionFunc,
                         boolean isLHSTrigger = true)
                         returns (StreamEvent?, StreamEvent?)[] {
         (StreamEvent?, StreamEvent?)[] events = [];
         int i = 0;
         foreach e in self.linkedList.asArray() {
-            match e {
-                StreamEvent s => {
-                    StreamEvent lshEvent = (isLHSTrigger) ? originEvent : s;
-                    StreamEvent rhsEvent = (isLHSTrigger) ? s : originEvent;
-                    match (conditionFunc) {
-                        function (map<any> e1Data, map<any> e2Data) returns boolean conditionCheckFunc => {
-                            if (conditionCheckFunc(lshEvent.data, rhsEvent.data)) {
-                                events[i] = (lshEvent, rhsEvent);
-                                i += 1;
-                            }
-                        }
-                        () => {
-                            events[i] = (lshEvent, rhsEvent);
-                            i += 1;
-                        }
+            if (e is StreamEvent) {
+                StreamEvent lshEvent = (isLHSTrigger) ? originEvent : e;
+                StreamEvent rhsEvent = (isLHSTrigger) ? e : originEvent;
+
+                if (conditionFunc is function (map<anydata> e1Data, map<anydata> e2Data) returns boolean) {
+                    if (conditionFunc.call(lshEvent.data, rhsEvent.data)) {
+                        events[i] = (lshEvent, rhsEvent);
+                        i += 1;
                     }
-                }
-                any a => {
+                } else if (conditionFunc is ()) {
+                    events[i] = (lshEvent, rhsEvent);
+                    i += 1;
                 }
             }
         }
@@ -140,7 +125,9 @@ public type TimeWindow object {
     public function (StreamEvent[])? nextProcessPointer;
     public int lastTimestamp = -0x8000000000000000;
 
-    public new(nextProcessPointer, windowParameters) {
+    public function __init(function (StreamEvent[])? nextProcessPointer, any[] windowParameters) {
+        self.nextProcessPointer = nextProcessPointer;
+        self.windowParameters = windowParameters;
         self.timeInMillis = 0;
         self.expiredEventQueue = new;
         self.timerQueue = new;
@@ -148,13 +135,13 @@ public type TimeWindow object {
     }
 
     public function initParameters(any[] parameters) {
-        if(parameters.length() == 1) {
-            match parameters[0] {
-                int value => self.timeInMillis = value;
-                any anyValue => {
-                    error err = error(""Time window expects an int parameter"");
-                    panic err;
-                }
+        if (parameters.length() == 1) {
+            any parameter0 = parameters[0];
+            if (parameter0 is int) {
+                self.timeInMillis = parameter0;
+            } else {
+                error err = error(""Time window expects an int parameter"");
+                panic err;
             }
         } else {
             error err = error(""Time window should only have one parameter (<int> "" +
@@ -173,14 +160,7 @@ public type TimeWindow object {
             streamEventChunk.resetToFront();
 
             while (streamEventChunk.hasNext()) {
-                StreamEvent streamEvent;
-                any? next = streamEventChunk.next();
-                if (next is StreamEvent) {
-                    streamEvent = next;
-                } else {
-                    return;
-                }
-
+                StreamEvent streamEvent = <StreamEvent>streamEventChunk.next();
                 int currentTime = time:currentTime().time;
                 self.expiredEventQueue.resetToFront();
 
@@ -202,7 +182,8 @@ public type TimeWindow object {
                     self.expiredEventQueue.addLast(clonedEvent);
 
                     if (self.lastTimestamp < clonedEvent.timestamp) {
-                        task:Timer timer = new task:Timer(self.invokeProcess, self.handleError, self.timeInMillis,
+                        task:Timer timer = new task:Timer(function () returns error? {return self.invokeProcess();},
+                            function (error e) {self.handleError(e);}, self.timeInMillis,
                             delay = self.timeInMillis - (time:currentTime().time - clonedEvent.timestamp));
                         _ = timer.start();
                         self.timerQueue.addLast(timer);
@@ -214,31 +195,29 @@ public type TimeWindow object {
             }
             self.expiredEventQueue.resetToFront();
         }
-        match (self.nextProcessPointer) {
-            function (StreamEvent[]) nxtProc => {
-                if (streamEventChunk.getSize() != 0) {
-                    StreamEvent[] events = [];
-                    streamEventChunk.resetToFront();
-                    while (streamEventChunk.hasNext()) {
-                        StreamEvent streamEvent = getStreamEvent(streamEventChunk.next());
-                        events[events.length()] = streamEvent;
-                    }
-                    nxtProc(events);
+
+        any nextProcessFuncPointer = self.nextProcessPointer;
+        if (nextProcessFuncPointer is function (StreamEvent[])) {
+            if (streamEventChunk.getSize() != 0) {
+                StreamEvent[] events = [];
+                streamEventChunk.resetToFront();
+                while (streamEventChunk.hasNext()) {
+                    StreamEvent streamEvent = getStreamEvent(streamEventChunk.next());
+                    events[events.length()] = streamEvent;
                 }
-            }
-            () => {
-                //do nothing
+                nextProcessFuncPointer.call(events);
             }
         }
     }
 
     public function invokeProcess() returns error? {
-        StreamEvent timerEvent = new((""timer"", {}), ""TIMER"", time:currentTime().time);
+        map<anydata> data = {};
+        StreamEvent timerEvent = new((""timer"", data), ""TIMER"", time:currentTime().time);
         StreamEvent[] timerEventWrapper = [];
         timerEventWrapper[0] = timerEvent;
         self.process(timerEventWrapper);
         if (!self.timerQueue.isEmpty()) {
-            task:Timer timer = check trap <task:Timer>self.timerQueue.removeFirst();
+            task:Timer timer = <task:Timer>self.timerQueue.removeFirst();
             _ = timer.stop();
         }
         return ();
@@ -250,30 +229,24 @@ public type TimeWindow object {
 
     public function getCandidateEvents(
                         StreamEvent originEvent,
-                        (function (map<any> e1Data, map<any> e2Data) returns boolean)? conditionFunc,
+                        (function (map<anydata> e1Data, map<anydata> e2Data) returns boolean)? conditionFunc,
                         boolean isLHSTrigger = true)
                         returns (StreamEvent?, StreamEvent?)[] {
         (StreamEvent?, StreamEvent?)[] events = [];
         int i = 0;
         foreach e in self.expiredEventQueue.asArray() {
-            match e {
-                StreamEvent s => {
-                    StreamEvent lshEvent = (isLHSTrigger) ? originEvent : s;
-                    StreamEvent rhsEvent = (isLHSTrigger) ? s : originEvent;
-                    match (conditionFunc) {
-                        function (map<any> e1Data, map<any> e2Data) returns boolean conditionCheckFunc => {
-                            if (conditionCheckFunc(lshEvent.data, rhsEvent.data)) {
-                                events[i] = (lshEvent, rhsEvent);
-                                i += 1;
-                            }
-                        }
-                        () => {
-                            events[i] = (lshEvent, rhsEvent);
-                            i += 1;
-                        }
+            if (e is StreamEvent) {
+                StreamEvent lshEvent = (isLHSTrigger) ? originEvent : e;
+                StreamEvent rhsEvent = (isLHSTrigger) ? e : originEvent;
+
+                if (conditionFunc is function (map<anydata> e1Data, map<anydata> e2Data) returns boolean) {
+                    if (conditionFunc.call(lshEvent.data, rhsEvent.data)) {
+                        events[i] = (lshEvent, rhsEvent);
+                        i += 1;
                     }
-                }
-                any a => {
+                } else if (conditionFunc is ()) {
+                    events[i] = (lshEvent, rhsEvent);
+                    i += 1;
                 }
             }",Add improved streams bal files and tests based on updated grammar,"""Refactor window objects to use type narrowing and simplify match expressions""","The commit message should be:

""Update Ballerina streams to use anydata instead of any for map keys""

This commit message accurately reflects the changes made in the code, which involve replacing `any` with `anydata` in various places to ensure type safety and consistency with Ballerina's type system.","This commit updates the Ballerina code in the `stdlib/streams/src/main/ballerina/streams/windows.bal` file. The changes include:

1. Modifying the `getCandidateEvents` function signature in the `Window` type to use `map<anydata>` instead of `map<any>` for the `e1Data` and `e2Data` parameters of the `conditionFunc` function.
2. Updating the constructor of the `LengthWindow` type to use the `__init` function name and assigning the `nextProcessPointer` and `windowParameters` fields directly.
3. Simplifying the code in the `process` function of the `LengthWindow` type by removing unnecessary match cases and using an `if` statement to check the type of the removed item from the linked list.
4. Simplifying the code in the `getCandidateEvents` function of the `LengthWindow` type by removing unnecessary match cases and using `if` statements to check the type of the `conditionFunc` parameter and the items in the linked list.
5. Updating the constructor of the `TimeWindow` type to use the `__init` function name and assigning the `nextProcessPointer` and `windowParameters` fields directly.
6. Simplifying the code in the `process` function of the `TimeWindow` type by removing unnecessary match cases and using an `if` statement to check the type of the items in the `streamEventChunk`.
7. Simplifying the code in the `getCandidateEvents` function of the `TimeWindow` type by removing unnecessary match cases and using `if` statements to check the type of the `conditionFunc` parameter and the items in the `expiredEventQueue`.

Overall, the changes seem to be focused on simplifying the code and using more idiomatic Ballerina constructs. However, the commit message does not provide any context or explanation for these changes.","""Refactor window functions, improve type handling, and replace match statements with type checks, reducing redundant code.""",Model 1
"diff --git a/gdx/src/com/badlogic/gdx/graphics/g2d/tiled/TileAtlas.java b/gdx/src/com/badlogic/gdx/graphics/g2d/tiled/TileAtlas.java
index b5e0647a4..fa32922ea 100644
--- a/gdx/src/com/badlogic/gdx/graphics/g2d/tiled/TileAtlas.java
+++ b/gdx/src/com/badlogic/gdx/graphics/g2d/tiled/TileAtlas.java
@@ -121,4 +121,15 @@ public class TileAtlas implements Disposable {
 
 		return child;
 	}
+
+	/**
+	 * Flips all regions in the atlas on the specified axis.
+	 * @param x - if <code>true</code> region is flipped on the <b>x</b> axis 
+	 * @param y - if <code>true</code> region is flipped on the <b>y</b> axis 
+	 */
+	public void flipRegions(boolean x, boolean y) {
+		for (TextureRegion region : regionsMap.values()) {
+			region.flip(x, y);
+		}
+	}
 }",Added flipRegions method .,"""Added method to flip all regions in a TileAtlas""",Added method to flip all regions in the atlas on specified axis.,"This commit adds a new method `flipRegions(boolean x, boolean y)` to the `TileAtlas` class in the `com.badlogic.gdx.graphics.g2d.tiled` package. This method takes two boolean parameters `x` and `y` and flips all regions in the atlas on the specified axis. The method iterates through all the regions in the `regionsMap` and calls the `flip(x, y)` method on each region. The commit also includes a corresponding Javadoc comment for the new method.",Added flipRegions method to TileAtlas for flipping regions on the x and y axis.,Model 2
"diff --git a/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/FeatureImpl.java b/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/FeatureImpl.java
index bf67d27d02d..ce7a943bc65 100644
--- a/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/FeatureImpl.java
+++ b/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/FeatureImpl.java
@@ -46,6 +46,7 @@ import java.util.function.Predicate;
 import java.util.stream.Collectors;
 
 import com.oracle.svm.hosted.code.CEntryPointData;
+import com.oracle.svm.hosted.code.CompileQueue;
 import org.graalvm.collections.Pair;
 import org.graalvm.compiler.debug.DebugContext;
 import org.graalvm.nativeimage.hosted.Feature;
@@ -563,9 +564,16 @@ public class FeatureImpl {
     }
 
     public static class AfterCompilationAccessImpl extends CompilationAccessImpl implements Feature.AfterCompilationAccess {
+        private Collection<CompileQueue.CompileTask> compilationTasks;
+
         AfterCompilationAccessImpl(FeatureHandler featureHandler, ImageClassLoader imageClassLoader, AnalysisUniverse aUniverse, HostedUniverse hUniverse, HostedMetaAccess hMetaAccess,
-                        NativeImageHeap heap, DebugContext debugContext) {
+                                   Collection<CompileQueue.CompileTask> compilationTasks, NativeImageHeap heap, DebugContext debugContext) {
             super(featureHandler, imageClassLoader, aUniverse, hUniverse, hMetaAccess, heap, debugContext);
+            this.compilationTasks = compilationTasks;
+        }
+
+        public Collection<CompileQueue.CompileTask> getCompilationTasks() {
+            return compilationTasks;
         }
     }
 
diff --git a/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/NativeImageGenerator.java b/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/NativeImageGenerator.java
index d8d8428251e..2face1e80e4 100644
--- a/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/NativeImageGenerator.java
+++ b/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/NativeImageGenerator.java
@@ -613,7 +613,7 @@ public class NativeImageGenerator {
                 codeCache.layoutConstants();
                 codeCache.layoutMethods(debug, imageName, bigbang, compilationExecutor);
 
-                AfterCompilationAccessImpl config = new AfterCompilationAccessImpl(featureHandler, loader, aUniverse, hUniverse, hMetaAccess, heap, debug);
+                AfterCompilationAccessImpl config = new AfterCompilationAccessImpl(featureHandler, loader, aUniverse, hUniverse, hMetaAccess, compileQueue.getCompilationTasks(), heap, debug);
                 featureHandler.forEachFeature(feature -> feature.afterCompilation(config));
             }
             CodeCacheProvider codeCacheProvider = runtime.getRuntimeConfig().getBackendForNormalMethod().getProviders().getCodeCache();
diff --git a/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/code/CompileQueue.java b/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/code/CompileQueue.java
index f9099678535..814f3a7e141 100644
--- a/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/code/CompileQueue.java
+++ b/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/code/CompileQueue.java
@@ -28,6 +28,7 @@ import java.lang.annotation.Annotation;
 import java.lang.reflect.Modifier;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collection;
 import java.util.Collections;
 import java.util.Comparator;
 import java.util.HashMap;
@@ -391,6 +392,10 @@ public class CompileQueue {
         return phaseSuite;
     }
 
+    public Collection<CompileTask> getCompilationTasks() {
+        return compilations.values();
+    }
+
     private void printMethodHistogram() {
         long sizeAllMethods = 0;
         long sizeDeoptMethods = 0;",Expose compilation tasks in the afterCompilation handler .,"""Added compilation tasks to AfterCompilationAccessImpl and exposed them through NativeImageGenerator""","""Added support for compile queue tasks in AfterCompilationAccessImpl and NativeImageGenerator""","""Add compilation tasks to AfterCompilationAccessImpl and expose them via getCompilationTasks()""

This commit introduces the following changes:

1. In `FeatureImpl.java`, a new field `compilationTasks` is added to `AfterCompilationAccessImpl` class. The constructor is updated to accept this new field, and a getter method `getCompilationTasks()` is added.

2. In `NativeImageGenerator.java`, the `AfterCompilationAccessImpl` object is now created with the `compileQueue.getCompilationTasks()` as an argument.

3. In `CompileQueue.java`, a new method `getCompilationTasks()` is added to return the compilations.

These changes seem to be related to managing and accessing compilation tasks in the native image generation process.",Add access to compile tasks in AfterCompilationAccessImpl and expose compilation tasks collection in CompileQueue.,Model 4
"diff --git a/test/org/apache/tomcat/util/http/TestParametersPerformance.java b/test/org/apache/tomcat/util/http/TestParametersPerformance.java
new file mode 100644
index 0000000000..9b6d4acb8a
--- /dev/null
+++ b/test/org/apache/tomcat/util/http/TestParametersPerformance.java
@@ -0,0 +1,133 @@
+/*
+ *  Licensed to the Apache Software Foundation (ASF) under one or more
+ *  contributor license agreements.  See the NOTICE file distributed with
+ *  this work for additional information regarding copyright ownership.
+ *  The ASF licenses this file to You under the Apache License, Version 2.0
+ *  (the ""License""); you may not use this file except in compliance with
+ *  the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing, software
+ *  distributed under the License is distributed on an ""AS IS"" BASIS,
+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+package org.apache.tomcat.util.http;
+
+import java.io.UnsupportedEncodingException;
+import java.nio.charset.Charset;
+import java.util.logging.Level;
+import java.util.logging.LogManager;
+
+import static org.junit.Assert.assertEquals;
+import org.junit.Test;
+
+import org.apache.tomcat.util.buf.B2CConverter;
+
+public class TestParametersPerformance {
+
+    @Test
+    public void testProcessParametersByteArrayIntInt() {
+        LogManager.getLogManager().getLogger("""").setLevel(Level.OFF);
+        doTestProcessParametersMultiple(""foo"".getBytes());
+    }
+
+    private void doTestProcessParametersMultiple(byte[] input) {
+        System.out.println(doTestProcessParameters(input, 10000));
+        System.out.println(doTestProcessParameters(input, 20000));
+        System.out.println(doTestProcessParameters(input, 40000));
+        System.out.println(doTestProcessParameters(input, 80000));
+        System.out.println(doTestProcessParameters(input, 160000));
+        System.out.println(doTestProcessParameters(input, 320000));
+        System.out.println(doTestProcessParameters(input, 640000));
+        System.out.println(doTestProcessParameters(input, 1280000));
+    }
+
+    private long doTestProcessParameters(byte[] input, int size) {
+        assertEquals(input.length, 3);
+
+        Parameters p = new Parameters();
+
+        byte[] params = createParams(input, size);
+        //byte[] input = createParams(8);
+        p.setEncoding(""ISO-8859-1"");
+        long start = System.nanoTime();
+        p.processParameters(params, 0, params.length);
+        return System.nanoTime() - start;
+    }
+
+    private byte[] createParams(byte[] input, int len) {
+        byte[] result = new byte[len * 4 - 1];
+
+        for (int i = 0; i < len; i++) {
+            result[i * 4] = input[0];
+            result[i * 4 + 1] = input[1];
+            result[i * 4 + 2] = input[2];
+            if (i < len -1) {
+                result[i * 4 + 3] = 38;
+            }
+        }
+        return result;
+    }
+
+    @Test
+    public void testCreateString() throws UnsupportedEncodingException {
+        B2CConverter.getCharset(""ISO-8859-1"");
+        doCreateStringMultiple(""foo"");
+    }
+
+    private void doCreateStringMultiple(String input) {
+        System.out.println(doCreateString(input, 10, true));
+        System.out.println(doCreateString(input, 100, true));
+        System.out.println(doCreateString(input, 1000, true));
+        System.out.println(doCreateString(input, 10000, true));
+        System.out.println(doCreateString(input, 100000, true));
+        System.out.println(doCreateString(input, 1000000, true));
+        System.out.println(doCreateString(input, 2000000, true));
+        //System.out.println(doCreateString(input, 4000000, true));
+        //System.out.println(doCreateString(input, 8000000, true));
+        System.out.println(doCreateString(input, 10, false));
+        System.out.println(doCreateString(input, 100, false));
+        System.out.println(doCreateString(input, 1000, false));
+        System.out.println(doCreateString(input, 10000, false));
+        System.out.println(doCreateString(input, 100000, false));
+        System.out.println(doCreateString(input, 1000000, false));
+        System.out.println(doCreateString(input, 2000000, false));
+        //System.out.println(doCreateString(input, 4000000, false));
+        //System.out.println(doCreateString(input, 8000000, false));
+    }
+
+    private long doCreateString(String input, int size,
+            boolean defensiveCopyWorkAround) {
+        int loops = 10000;
+        byte[] inputBytes = input.getBytes();
+        byte[] bytes = new byte[size];
+        int inputLength = inputBytes.length;
+
+        System.arraycopy(inputBytes, 0, bytes, 0, inputLength);
+
+        String[] result = new String[loops];
+        Charset charset = null;
+        try {
+            charset = B2CConverter.getCharset(""ISO-8859-1"");
+        } catch (UnsupportedEncodingException e) {
+            // TODO Auto-generated catch block
+            e.printStackTrace();
+        }
+
+        long start = System.nanoTime();
+        for (int i = 0; i < loops; i++) {
+            if (defensiveCopyWorkAround) {
+                byte[] tmp = new byte[inputLength];
+                System.arraycopy(bytes, 0, tmp, 0, inputLength);
+                result[i] = new String(tmp, 0, inputLength, charset);
+            } else {
+                result[i] = new String(bytes, 0, inputLength, charset);
+            }
+        }
+
+        return System.nanoTime() - start;
+    }
+}",Add some tests used to help track down performance issues . . git - svn - id : https : / / svn . apache . org / repos / asf / tomcat / trunk @ 1190383 13f79535 - 47bb - 0310 - 9956 - ffa450edef68,"""Added test class TestParametersPerformance to measure performance of Parameters class""","Added performance test for Parameters class and B2CConverter class.

This commit message is concise and accurately describes the changes made in the commit. It mentions the specific classes that are being tested for performance, which is useful for understanding the context of the changes.","""Add TestParametersPerformance.java""

The file TestParametersPerformance.java has been added with a complete code for a JUnit test class. The class contains several test methods for testing the performance of processing parameters and creating strings in the org.apache.tomcat.util.http package. The class uses the Apache License, Version 2.0.","""Add performance tests for processing parameters and creating strings in Tomcat HTTP utility.""",Model 4
"diff --git a/core/pom.xml b/core/pom.xml
index f90b7d7e8e..da843c813f 100644
--- a/core/pom.xml
+++ b/core/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.jvnet.hudson.main</groupId>
     <artifactId>pom</artifactId>
-    <version>1.110-SNAPSHOT</version>
+    <version>1.110</version>
     <relativePath>../pom.xml</relativePath>
   </parent>
   
diff --git a/jnlp-agent/pom.xml b/jnlp-agent/pom.xml
index 0f4e841c7a..bab6fdce6c 100644
--- a/jnlp-agent/pom.xml
+++ b/jnlp-agent/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.jvnet.hudson.main</groupId>
     <artifactId>pom</artifactId>
-    <version>1.110-SNAPSHOT</version>
+    <version>1.110</version>
     <relativePath>../pom.xml</relativePath>
   </parent>
   
diff --git a/maven-agent/pom.xml b/maven-agent/pom.xml
index a0680767dc..0cb093b1e0 100644
--- a/maven-agent/pom.xml
+++ b/maven-agent/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.jvnet.hudson.main</groupId>
     <artifactId>pom</artifactId>
-    <version>1.110-SNAPSHOT</version>
+    <version>1.110</version>
     <relativePath>../pom.xml</relativePath>
   </parent>
   
diff --git a/maven-interceptor/pom.xml b/maven-interceptor/pom.xml
index cab7beef52..ecc99e5c0b 100644
--- a/maven-interceptor/pom.xml
+++ b/maven-interceptor/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.jvnet.hudson.main</groupId>
     <artifactId>pom</artifactId>
-    <version>1.110-SNAPSHOT</version>
+    <version>1.110</version>
     <relativePath>../pom.xml</relativePath>
   </parent>
   
diff --git a/pom.xml b/pom.xml
index 129e310307..032f399853 100644
--- a/pom.xml
+++ b/pom.xml
@@ -9,7 +9,7 @@
   
   <groupId>org.jvnet.hudson.main</groupId>
   <artifactId>pom</artifactId>
-  <version>1.110-SNAPSHOT</version>
+  <version>1.110</version>
   <packaging>pom</packaging>
   
   <name>Hudson main module</name>
@@ -28,6 +28,7 @@
     <connection>scm:cvs:pserver:guest@cvs.dev.java.net:/cvs:hudson/hudson/main</connection>
     <developerConnection>scm:cvs:pserver:kohsuke@cvs.dev.java.net:/cvs:hudson/hudson/main</developerConnection>
     <url>https://hudson.dev.java.net/source/browse/hudson/hudson/main</url>
+    <tag>hudson-1_110</tag>
   </scm>
   
   <build>
diff --git a/remoting/pom.xml b/remoting/pom.xml
index 1bf847a2ba..9adc742c2e 100644
--- a/remoting/pom.xml
+++ b/remoting/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.jvnet.hudson.main</groupId>
     <artifactId>pom</artifactId>
-    <version>1.110-SNAPSHOT</version>
+    <version>1.110</version>
     <relativePath>../pom.xml</relativePath>
   </parent>
   
diff --git a/war/pom.xml b/war/pom.xml
index a0f7a0053e..816f686976 100644
--- a/war/pom.xml
+++ b/war/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.jvnet.hudson.main</groupId>
     <artifactId>pom</artifactId>
-    <version>1.110-SNAPSHOT</version>
+    <version>1.110</version>
     <relativePath>../pom.xml</relativePath>
   </parent>",prepare release hudson - 1_110 .,"""Release Hudson 1.110: Update version numbers from 1.110-SNAPSHOT to 1.110 and add release tag""",Bump Hudson main module version to 1.110 from 1.110-SNAPSHOT.,"""Updating parent version from 1.110-SNAPSHOT to 1.110 in various pom.xml files and adding tag hudson-1_110 in pom.xml""","""Update all modules to version 1.110, changing from 1.110-SNAPSHOT and adding SCM tag in parent POM.""",Model 1
"diff --git a/hotspot/.hgtags b/hotspot/.hgtags
index b9ee766f1a..3f843994e7 100644
--- a/hotspot/.hgtags
+++ b/hotspot/.hgtags
@@ -1014,3 +1014,4 @@ cdfe7ec6f29293d7c2f64239518e8947733ad85c jdk8u152-b12
 3dd92151df1b3b7c21756f241b49607024b6fe5a jdk8u152-b13
 0a9d8db98fc5f0302da6520ba329f41baa092ae0 jdk8u152-b14
 c1bf165d3b27e864a9f8eec5bb0c1e746a972ad5 jdk8u152-b15
+98b4b0661837817cc39047000e1a7efa6015af7c jdk8u152-b16",Added tag jdk8u152 - b16 for changeset eade057fd8d0,"""Added tag jdk8u152-b16""","""Update .hgtags to include jdk8u152-b16""","Based on the diff you provided, it seems like a new line has been added to the .hgtags file in the hotspot directory. The new line is:

`98b4b0661837817cc39047000e1a7efa6015af7c jdk8u152-b16`

This line represents a new commit with the commit hash `98b4b0661837817cc39047000e1a7efa6015af7c` and the tag `jdk8u152-b16`. However, the diff does not provide any information about the changes made in this commit.

If you want to create a commit message, you might need more context about what changes were made in this commit. A commit message typically includes a summary of the changes and a more detailed description if necessary.

If you want to see the changes made in this commit, you can use the command `git show 98b4b0661837817cc39047000e1a7efa6015af7c` (or the shorter `git show jdk8u152-b16`, if the tag is unique) in a terminal. This will show you the changes made in this commit, which you can use to write an appropriate commit message.",Added new tag `jdk8u152-b16` to the `.hgtags` file.,Model 4
"diff --git a/CHANGELOG.md b/CHANGELOG.md
index 1a5f08962a..ae38b20a7a 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -1,7 +1,8 @@
 3.5.0 (in progress)
 ================
 * [#446](https://github.com/oshi/oshi/pull/446): Add getChildProcesses to OperatingSystem. - [@jsimomaa](https://github.com/jsimomaa)
-* [#447](https://github.com/oshi/oshi/pull/447): Added context switches and interrupts (linux/windows) - [@jpbempel](https://github.com/jpbempel).
+* [#447](https://github.com/oshi/oshi/pull/447), [#471](https://github.com/oshi/oshi/pull/471): Added context switches and interrupts - [@jpbempel](https://github.com/jpbempel), [@dbwiddis](https://github.com/dbwiddis).
+* Updated to JNA 4.5.1
 * Your contribution here.
 
 3.4.5 (4/11/18)
diff --git a/oshi-core/pom.xml b/oshi-core/pom.xml
index f93a30de69..9b504939b8 100644
--- a/oshi-core/pom.xml
+++ b/oshi-core/pom.xml
@@ -45,7 +45,7 @@
 		<dependency>
 			<groupId>net.java.dev.jna</groupId>
 			<artifactId>jna-platform</artifactId>
-			<version>4.5.0</version>
+			<version>4.5.1</version>
 		</dependency>
 		<dependency>
 			<groupId>org.threeten</groupId>
diff --git a/oshi-core/src/main/java/oshi/hardware/CentralProcessor.java b/oshi-core/src/main/java/oshi/hardware/CentralProcessor.java
index ecb4617288..3d95b486fc 100644
--- a/oshi-core/src/main/java/oshi/hardware/CentralProcessor.java
+++ b/oshi-core/src/main/java/oshi/hardware/CentralProcessor.java
@@ -69,7 +69,8 @@ public interface CentralProcessor extends Serializable {
          */
         SOFTIRQ(6),
         /**
-         * Time which the hypervisor dedicated for other guests in the system. Only supported on Linux.
+         * Time which the hypervisor dedicated for other guests in the system.
+         * Only supported on Linux.
          */
         STEAL(7);
 
@@ -239,19 +240,19 @@ public interface CentralProcessor extends Serializable {
      * Get System-wide CPU Load tick counters. Returns an array with seven
      * elements representing either clock ticks or milliseconds (platform
      * dependent) spent in User (0), Nice (1), System (2), Idle (3), IOwait (4),
-     * Hardware interrupts (IRQ) (5), Software interrupts/DPC (SoftIRQ) (6), or Steal (7)
-     * states. Use {@link TickType#getIndex()} to retrieve the appropriate
-     * index. By measuring the difference between ticks across a time interval,
-     * CPU load over that interval may be calculated.
+     * Hardware interrupts (IRQ) (5), Software interrupts/DPC (SoftIRQ) (6), or
+     * Steal (7) states. Use {@link TickType#getIndex()} to retrieve the
+     * appropriate index. By measuring the difference between ticks across a
+     * time interval, CPU load over that interval may be calculated.
      *
      * Nice and IOWait information is not available on Windows, and IOwait and
      * IRQ information is not available on macOS, so these ticks will always be
      * zero.
      *
      * To calculate overall Idle time using this method, include both Idle and
-     * IOWait ticks. Similarly, IRQ, SoftIRQ, and Steal ticks should be added to the
-     * System value to get the total. System ticks also include time executing
-     * other virtual hosts (steal).
+     * IOWait ticks. Similarly, IRQ, SoftIRQ, and Steal ticks should be added to
+     * the System value to get the total. System ticks also include time
+     * executing other virtual hosts (steal).
      *
      * @return An array of 7 long values representing time spent in User, Nice,
      *         System, Idle, IOwait, IRQ, SoftIRQ, and Steal states.
@@ -317,10 +318,9 @@ public interface CentralProcessor extends Serializable {
      * than 1 second. If less than one second has elapsed since the last call of
      * this method, it will return a calculation based on the tick counts and
      * times of the previous two calls. If at least a second has elapsed, it
-     * will return the average CPU load for the interval and update the
-     * ""last called"" times. This method is intended to be used for periodic
-     * polling (iterating over all processors) at intervals of 1 second or
-     * longer.
+     * will return the average CPU load for the interval and update the ""last
+     * called"" times. This method is intended to be used for periodic polling
+     * (iterating over all processors) at intervals of 1 second or longer.
      *
      * @return array of CPU load between 0 and 1 (100%) for each logical
      *         processor
@@ -332,23 +332,23 @@ public interface CentralProcessor extends Serializable {
      * with {@link #getLogicalProcessorCount()} arrays, each containing seven
      * elements representing either clock ticks or milliseconds (platform
      * dependent) spent in User (0), Nice (1), System (2), Idle (3), IOwait (4),
-     * Hardware interrupts (IRQ) (5), Software interrupts/DPC (SoftIRQ) (6), or Steal (7)
-     * states. Use {@link TickType#getIndex()} to retrieve the appropriate
-     * index. By measuring the difference between ticks across a time interval,
-     * CPU load over that interval may be calculated.
+     * Hardware interrupts (IRQ) (5), Software interrupts/DPC (SoftIRQ) (6), or
+     * Steal (7) states. Use {@link TickType#getIndex()} to retrieve the
+     * appropriate index. By measuring the difference between ticks across a
+     * time interval, CPU load over that interval may be calculated.
      *
      * Nice and IOwait per processor information is not available on Windows,
      * and IOwait and IRQ information is not available on macOS, so these ticks
      * will always be zero.
      *
      * To calculate overall Idle time using this method, include both Idle and
-     * IOWait ticks. Similarly, IRQ, SoftIRQ and Steal ticks should be added to the
-     * System value to get the total. System ticks also include time executing
-     * other virtual hosts (steal).
+     * IOWait ticks. Similarly, IRQ, SoftIRQ and Steal ticks should be added to
+     * the System value to get the total. System ticks also include time
+     * executing other virtual hosts (steal).
      *
      * @return A 2D array of logicalProcessorCount x 7 long values representing
-     *         time spent in User, Nice, System, Idle, IOwait, IRQ, SoftIRQ, and Steal
-     *         states.
+     *         time spent in User, Nice, System, Idle, IOwait, IRQ, SoftIRQ, and
+     *         Steal states.
      */
     long[][] getProcessorCpuLoadTicks();
 
@@ -390,13 +390,15 @@ public interface CentralProcessor extends Serializable {
     int getPhysicalProcessorCount();
 
     /**
-     *  Get the number of context switches happened
+     * Get the number of context switches which have occurred
+     * 
      * @return The number of context switches
      */
     long getContextSwitches();
 
     /**
-     * Get the number of interrupts happened
+     * Get the number of interrupts which have occurred
+     * 
      * @return The number of interrupts
      */
     long getInterrupts();
diff --git a/oshi-core/src/main/java/oshi/hardware/platform/mac/MacCentralProcessor.java b/oshi-core/src/main/java/oshi/hardware/platform/mac/MacCentralProcessor.java
index 2a9710bbb5..cfa0703ffd 100644
--- a/oshi-core/src/main/java/oshi/hardware/platform/mac/MacCentralProcessor.java
+++ b/oshi-core/src/main/java/oshi/hardware/platform/mac/MacCentralProcessor.java
@@ -28,6 +28,7 @@ import com.sun.jna.ptr.PointerByReference;
 
 import oshi.hardware.common.AbstractCentralProcessor;
 import oshi.jna.platform.mac.SystemB;
+import oshi.jna.platform.mac.SystemB.VMMeter;
 import oshi.jna.platform.unix.CLibrary.Timeval;
 import oshi.util.ExecutingCommand;
 import oshi.util.FormatUtil;
@@ -194,7 +195,14 @@ public class MacCentralProcessor extends AbstractCentralProcessor {
      */
     @Override
     public long getContextSwitches() {
-        return -1;
+        int machPort = SystemB.INSTANCE.mach_host_self();
+        VMMeter vmstats = new VMMeter();
+        if (0 != SystemB.INSTANCE.host_statistics(machPort, SystemB.HOST_VM_INFO, vmstats,
+                new IntByReference(vmstats.size()))) {
+            LOG.error(""Failed to update vmstats. Error code: "" + Native.getLastError());
+            return -1;
+        }
+        return ParseUtil.unsignedIntToLong(vmstats.v_swtch);
     }
 
     /**
@@ -202,6 +210,13 @@ public class MacCentralProcessor extends AbstractCentralProcessor {
      */
     @Override
     public long getInterrupts() {
-        return -1;
+        int machPort = SystemB.INSTANCE.mach_host_self();
+        VMMeter vmstats = new VMMeter();
+        if (0 != SystemB.INSTANCE.host_statistics(machPort, SystemB.HOST_VM_INFO, vmstats,
+                new IntByReference(vmstats.size()))) {
+            LOG.error(""Failed to update vmstats. Error code: "" + Native.getLastError());
+            return -1;
+        }
+        return ParseUtil.unsignedIntToLong(vmstats.v_intr);
     }
 }
diff --git a/oshi-core/src/main/java/oshi/hardware/platform/unix/freebsd/FreeBsdCentralProcessor.java b/oshi-core/src/main/java/oshi/hardware/platform/unix/freebsd/FreeBsdCentralProcessor.java
index 33cfe01256..4c5346f389 100644
--- a/oshi-core/src/main/java/oshi/hardware/platform/unix/freebsd/FreeBsdCentralProcessor.java
+++ b/oshi-core/src/main/java/oshi/hardware/platform/unix/freebsd/FreeBsdCentralProcessor.java
@@ -264,7 +264,13 @@ public class FreeBsdCentralProcessor extends AbstractCentralProcessor {
      */
     @Override
     public long getContextSwitches() {
-        return -1;
+        String name = ""vm.stats.sys.v_swtch"";
+        IntByReference size = new IntByReference(Libc.INT_SIZE);
+        Pointer p = new Memory(size.getValue());
+        if (0 != Libc.INSTANCE.sysctlbyname(name, p, size, null, 0)) {
+            return -1;
+        }
+        return ParseUtil.unsignedIntToLong(p.getInt(0));
     }
 
     /**
@@ -272,6 +278,12 @@ public class FreeBsdCentralProcessor extends AbstractCentralProcessor {
      */
     @Override
     public long getInterrupts() {
-        return -1;
+        String name = ""vm.stats.sys.v_intr"";
+        IntByReference size = new IntByReference(Libc.INT_SIZE);
+        Pointer p = new Memory(size.getValue());
+        if (0 != Libc.INSTANCE.sysctlbyname(name, p, size, null, 0)) {
+            return -1;
+        }
+        return ParseUtil.unsignedIntToLong(p.getInt(0));
     }
 }
diff --git a/oshi-core/src/main/java/oshi/hardware/platform/unix/solaris/SolarisCentralProcessor.java b/oshi-core/src/main/java/oshi/hardware/platform/unix/solaris/SolarisCentralProcessor.java
index 20ea2923b1..702e1ae622 100644
--- a/oshi-core/src/main/java/oshi/hardware/platform/unix/solaris/SolarisCentralProcessor.java
+++ b/oshi-core/src/main/java/oshi/hardware/platform/unix/solaris/SolarisCentralProcessor.java
@@ -206,7 +206,12 @@ public class SolarisCentralProcessor extends AbstractCentralProcessor {
      */
     @Override
     public long getContextSwitches() {
-        return -1;
+        long swtch = 0;
+        List<String> kstat = ExecutingCommand.runNative(""kstat -p cpu_stat:::/pswitch\\\\|inv_swtch/"");
+        for (String s : kstat) {
+            swtch += ParseUtil.parseLastLong(s, 0L);
+        }
+        return swtch > 0 ? swtch : -1L;
     }
 
     /**
@@ -214,6 +219,11 @@ public class SolarisCentralProcessor extends AbstractCentralProcessor {
      */
     @Override
     public long getInterrupts() {
-        return -1;
+        long intr = 0;
+        List<String> kstat = ExecutingCommand.runNative(""kstat -p cpu_stat:::/intr/"");
+        for (String s : kstat) {
+            intr += ParseUtil.parseLastLong(s, 0L);
+        }
+        return intr > 0 ? intr : -1L;
     }
 }
diff --git a/oshi-core/src/main/java/oshi/jna/platform/mac/SystemB.java b/oshi-core/src/main/java/oshi/jna/platform/mac/SystemB.java
index f0facbe1a2..10e748bc7c 100644
--- a/oshi-core/src/main/java/oshi/jna/platform/mac/SystemB.java
+++ b/oshi-core/src/main/java/oshi/jna/platform/mac/SystemB.java
@@ -135,6 +135,65 @@ public interface SystemB extends CLibrary, com.sun.jna.platform.mac.SystemB {
         }
     }
 
+    class VMMeter extends Structure {
+        /*
+         * General system activity.
+         */
+        public int v_swtch; /* context switches */
+        public int v_trap; /* calls to trap */
+        public int v_syscall; /* calls to syscall() */
+        public int v_intr; /* device interrupts */
+        public int v_soft; /* software interrupts */
+        public int v_faults; /* total faults taken */
+        /*
+         * Virtual memory activity.
+         */
+        public int v_lookups; /* object cache lookups */
+        public int v_hits; /* object cache hits */
+        public int v_vm_faults; /* number of address memory faults */
+        public int v_cow_faults; /* number of copy-on-writes */
+        public int v_swpin; /* swapins */
+        public int v_swpout; /* swapouts */
+        public int v_pswpin; /* pages swapped in */
+        public int v_pswpout; /* pages swapped out */
+        public int v_pageins; /* number of pageins */
+        public int v_pageouts; /* number of pageouts */
+        public int v_pgpgin; /* pages paged in */
+        public int v_pgpgout; /* pages paged out */
+        public int v_intrans; /* intransit blocking page faults */
+        public int v_reactivated; /*
+                                   * number of pages reactivated from free list
+                                   */
+        public int v_rev; /* revolutions of the hand */
+        public int v_scan; /* scans in page out daemon */
+        public int v_dfree; /* pages freed by daemon */
+        public int v_pfree; /* pages freed by exiting processes */
+        public int v_zfod; /* pages zero filled on demand */
+        public int v_nzfod; /* number of zfod's created */
+        /*
+         * Distribution of page usages.
+         */
+        public int v_page_size; /* page size in bytes */
+        public int v_kernel_pages; /* number of pages in use by kernel */
+        public int v_free_target; /* number of pages desired free */
+        public int v_free_min; /* minimum number of pages desired free */
+        public int v_free_count; /* number of pages free */
+        public int v_wire_count; /* number of pages wired down */
+        public int v_active_count; /* number of pages active */
+        public int v_inactive_target; /* number of pages desired inactive */
+        public int v_inactive_count; /* number of pages inactive */
+
+        @Override
+        protected List<String> getFieldOrder() {
+            return Arrays.asList(new String[] { ""v_swtch"", ""v_trap"", ""v_syscall"", ""v_intr"", ""v_soft"", ""v_faults"",
+                    ""v_lookups"", ""v_hits"", ""v_vm_faults"", ""v_cow_faults"", ""v_swpin"", ""v_swpout"", ""v_pswpin"",
+                    ""v_pswpout"", ""v_pageins"", ""v_pageouts"", ""v_pgpgin"", ""v_pgpgout"", ""v_intrans"", ""v_reactivated"",
+                    ""v_rev"", ""v_scan"", ""v_dfree"", ""v_pfree"", ""v_zfod"", ""v_nzfod"", ""v_page_size"", ""v_kernel_pages"",
+                    ""v_free_target"", ""v_free_min"", ""v_free_count"", ""v_wire_count"", ""v_active_count"",
+                    ""v_inactive_target"", ""v_inactive_count"" });
+        }
+    }
+
     class RUsageInfoV2 extends Structure {
         public byte[] ri_uuid = new byte[16];
         public long ri_user_time;
diff --git a/oshi-core/src/main/java/oshi/util/ParseUtil.java b/oshi-core/src/main/java/oshi/util/ParseUtil.java
index 01eceff145..4a5db9abaa 100644
--- a/oshi-core/src/main/java/oshi/util/ParseUtil.java
+++ b/oshi-core/src/main/java/oshi/util/ParseUtil.java
@@ -139,6 +139,24 @@ public class ParseUtil {
         }
     }
 
+    /**
+     * Parse the last element of a space-delimited string to a value
+     *
+     * @param s
+     *            The string to parse
+     * @param li
+     *            Default long integer if not parsable
+     * @return value or the given default if not parsable
+     */
+    public static long parseLastLong(String s, long li) {
+        try {
+            return Long.parseLong(parseLastString(s));
+        } catch (NumberFormatException e) {
+            LOG.trace(DEFAULT_LOG_MSG, s, e);
+            return li;
+        }
+    }
+
     /**
      * Parse the last element of a space-delimited string to a string
      *
@@ -548,5 +566,4 @@ public class ParseUtil {
         buffer.append(original.substring(currIndex));
         return buffer.toString();
     }
-
 }
diff --git a/oshi-core/src/test/java/oshi/hardware/CentralProcessorTest.java b/oshi-core/src/test/java/oshi/hardware/CentralProcessorTest.java
index ff27124ad7..bfcad08517 100644
--- a/oshi-core/src/test/java/oshi/hardware/CentralProcessorTest.java
+++ b/oshi-core/src/test/java/oshi/hardware/CentralProcessorTest.java
@@ -100,10 +100,7 @@ public class CentralProcessorTest {
         assertNotNull(p.getSystemSerialNumber());
         assertTrue(p.getLogicalProcessorCount() >= p.getPhysicalProcessorCount());
         assertTrue(p.getPhysicalProcessorCount() > 0);
-
-        if (Platform.isLinux() || Platform.isWindows()) {
-            assertTrue(p.getContextSwitches() >= 0);
-            assertTrue(p.getInterrupts() >= 0);
-        }
+        assertTrue(p.getContextSwitches() >= 0);
+        assertTrue(p.getInterrupts() >= 0);
     }
 }
diff --git a/oshi-core/src/test/java/oshi/util/ParseUtilTest.java b/oshi-core/src/test/java/oshi/util/ParseUtilTest.java
index 944944d39a..2d5539a6f2 100644
--- a/oshi-core/src/test/java/oshi/util/ParseUtilTest.java
+++ b/oshi-core/src/test/java/oshi/util/ParseUtilTest.java
@@ -55,6 +55,12 @@ public class ParseUtilTest {
         assertEquals(-1, ParseUtil.parseLastInt(""foo : bar"", -1));
         assertEquals(1, ParseUtil.parseLastInt(""foo : 1"", 0));
         assertEquals(2, ParseUtil.parseLastInt(""foo"", 2));
+        assertEquals(3, ParseUtil.parseLastInt(""max_int plus one is 2147483648"", 3));
+
+        assertEquals(-1L, ParseUtil.parseLastLong(""foo : bar"", -1L));
+        assertEquals(1L, ParseUtil.parseLastLong(""foo : 1"", 0L));
+        assertEquals(2L, ParseUtil.parseLastLong(""foo"", 2L));
+        assertEquals(2147483648L, ParseUtil.parseLastLong(""max_int plus one is 2147483648"", 3L));
     }
 
     /**
diff --git a/oshi-json/src/main/java/oshi/json/hardware/CentralProcessor.java b/oshi-json/src/main/java/oshi/json/hardware/CentralProcessor.java
index 14c2980515..f58dea1aa1 100644
--- a/oshi-json/src/main/java/oshi/json/hardware/CentralProcessor.java
+++ b/oshi-json/src/main/java/oshi/json/hardware/CentralProcessor.java
@@ -259,10 +259,9 @@ public interface CentralProcessor extends OshiJsonObject {
      * than 1 second. If less than one second has elapsed since the last call of
      * this method, it will return a calculation based on the tick counts and
      * times of the previous two calls. If at least a second has elapsed, it
-     * will return the average CPU load for the interval and update the
-     * ""last called"" times. This method is intended to be used for periodic
-     * polling (iterating over all processors) at intervals of 1 second or
-     * longer.
+     * will return the average CPU load for the interval and update the ""last
+     * called"" times. This method is intended to be used for periodic polling
+     * (iterating over all processors) at intervals of 1 second or longer.
      *
      * @return array of CPU load between 0 and 1 (100%) for each logical
      *         processor
@@ -337,13 +336,15 @@ public interface CentralProcessor extends OshiJsonObject {
     int getPhysicalProcessorCount();
 
     /**
-     *  Get the number of context switches happened
+     * Get the number of context switches which have occurred
+     * 
      * @return The number of context switches
      */
     long getContextSwitches();
 
     /**
-     * Get the number of interrupts happened
+     * Get the number of interrupts which have occurred
+     * 
      * @return The number of interrupts
      */
     long getInterrupts();
diff --git a/oshi-json/src/test/java/oshi/json/hardware/CentralProcessorTest.java b/oshi-json/src/test/java/oshi/json/hardware/CentralProcessorTest.java
index 38d6c2667b..655553559e 100644
--- a/oshi-json/src/test/java/oshi/json/hardware/CentralProcessorTest.java
+++ b/oshi-json/src/test/java/oshi/json/hardware/CentralProcessorTest.java
@@ -100,10 +100,7 @@ public class CentralProcessorTest {
         assertNotNull(p.getSystemSerialNumber());
         assertTrue(p.getLogicalProcessorCount() >= p.getPhysicalProcessorCount());
         assertTrue(p.getPhysicalProcessorCount() > 0);
-
-        if (Platform.isLinux() || Platform.isWindows()) {
-            assertTrue(p.getContextSwitches() >= 0);
-            assertTrue(p.getInterrupts() >= 0);
-        }
+        assertTrue(p.getContextSwitches() >= 0);
+        assertTrue(p.getInterrupts() >= 0);
     }
 }
diff --git a/oshi-json/src/test/resources/oshi.json.properties b/oshi-json/src/test/resources/oshi.json.properties
index 3d9d673c0c..634ee24b06 100644
--- a/oshi-json/src/test/resources/oshi.json.properties
+++ b/oshi-json/src/test/resources/oshi.json.properties
@@ -141,6 +141,8 @@
 #    hardware.processor.processorCpuLoadBetweenTicks     = false
 #    hardware.processor.processorCpuLoadTicks            = false
 #    hardware.processor.systemUptime                     = false
+#    hardware.processor.contextSwitches                  = false
+#    hardware.processor.interrupts                       = false
 #  hardware.memory                                       = false
 #    hardware.memory.available                           = false
 #    hardware.memory.total                               = false","Implement context switches and interrupts on macOS , FreeBSD , Solaris ( <issue_id> ) .","""Added context switches and interrupts for macOS, FreeBSD, and Solaris, and updated JNA to 4.5.1""","""Added context switches and interrupts for Linux, Windows, and macOS, and updated JNA version to 4.5.1""","This commit updates OSHI to version 3.5.0 and includes the following changes:

* Adds support for retrieving child processes in the OperatingSystem class (#446)
* Adds support for context switches and interrupts on Linux and Windows (#447, #471)
* Updates JNA dependency to version 4.5.1

The changes to the code include modifications to the CHANGELOG.md, pom.xml, and various Java files. The specific changes include adding new methods to the CentralProcessor interface and implementing them in the platform-specific classes, as well as updating the JNA dependency in the pom.xml file.

This commit also includes a change to the MacCentralProcessor class to use the host\_statistics() function from the SystemB library instead of the sysctlbyname() function from the Libc library to retrieve context switch and interrupt counts. This change was made to fix an issue where the previous implementation was not working correctly on macOS.

Finally, this commit includes a change to the ParseUtil class to add a new method for parsing the last element of a space-delimited string to a long value. This method is used in the implementation of the getContextSwitches() and getInterrupts() methods in the CentralProcessor interface.","""Add support for context switches and interrupts on Mac, FreeBSD, and Solaris. Updated to JNA 4.5.1. Various documentation and test updates.""",Model 4
diff,Human Written,Model 1,Model 2,Model 3,Model 4,Choice
"diff --git a/release.gradle b/release.gradle
index ab3472c..c1d8557 100644
--- a/release.gradle
+++ b/release.gradle
@@ -15,8 +15,8 @@ task commitRelease(type: Exec) {
 task createGithubRelease(type: Exec) {
     def versionName = getVersionName()
     def jsonData = JsonOutput.toJson([
-            tag_name: ""v$versionName"",
-            name    : ""v$versionName"",
+            tag_name: ""$versionName"",
+            name    : ""$versionName"",
             draft   : true])
     commandLine ""curl"", ""--data"", jsonData, ""-u"", ""amlcurran:"" + System.getenv('GITHUB_TOKEN'), ""https://api.github.com/repos/amlcurran/ShowcaseView/releases""
 }","Remove \"" v \"" from release and tag name","""Remove 'v' prefix from GitHub release tag and name""","""Remove version prefix from GitHub release name and tag""","Update tag_name and name in createGithubRelease task

The changes in the code are:

- The `tag_name` and `name` in the `jsonData` object no longer have a ""v"" prefix for the version name.

Here is the updated code for the `createGithubRelease` task:

```groovy
task createGithubRelease(type: Exec) {
    def versionName = getVersionName()
    def jsonData = JsonOutput.toJson([
        tag_name: ""$versionName"",
        name    : ""$versionName"",
        draft   : true])
    commandLine ""curl"", ""--data"", jsonData, ""-u"", ""amlcurran:"" + System.getenv('GITHUB_TOKEN'), ""https://api.github.com/repos/amlcurran/ShowcaseView/releases""
}
```

This change will affect how the version is displayed on the GitHub release page. The ""v"" prefix will no longer be automatically added, so if you want to include it, you will need to update the `getVersionName()` function to return the version name with the prefix.",Simplified tag and release name by removing 'v' prefix in createGithubRelease task within release.gradle.,Model 4
"diff --git a/distro/sql-script/upgrade/db2_engine_7.7_patch_7.7.4_to_7.7.5.sql b/distro/sql-script/upgrade/db2_engine_7.7_patch_7.7.4_to_7.7.5.sql
new file mode 100644
index 0000000000..404dd4378f
--- /dev/null
+++ b/distro/sql-script/upgrade/db2_engine_7.7_patch_7.7.4_to_7.7.5.sql
@@ -0,0 +1,14 @@
+-- insert indices for history cleanup - https://app.camunda.com/jira/browse/CAM-8184 --
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
\ No newline at end of file
diff --git a/distro/sql-script/upgrade/h2_engine_7.7_patch_7.7.4_to_7.7.5.sql b/distro/sql-script/upgrade/h2_engine_7.7_patch_7.7.4_to_7.7.5.sql
new file mode 100644
index 0000000000..404dd4378f
--- /dev/null
+++ b/distro/sql-script/upgrade/h2_engine_7.7_patch_7.7.4_to_7.7.5.sql
@@ -0,0 +1,14 @@
+-- insert indices for history cleanup - https://app.camunda.com/jira/browse/CAM-8184 --
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
\ No newline at end of file
diff --git a/distro/sql-script/upgrade/mariadb_engine_7.7_patch_7.7.4_to_7.7.5.sql b/distro/sql-script/upgrade/mariadb_engine_7.7_patch_7.7.4_to_7.7.5.sql
new file mode 100644
index 0000000000..404dd4378f
--- /dev/null
+++ b/distro/sql-script/upgrade/mariadb_engine_7.7_patch_7.7.4_to_7.7.5.sql
@@ -0,0 +1,14 @@
+-- insert indices for history cleanup - https://app.camunda.com/jira/browse/CAM-8184 --
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
\ No newline at end of file
diff --git a/distro/sql-script/upgrade/mssql_engine_7.7_patch_7.7.4_to_7.7.5.sql b/distro/sql-script/upgrade/mssql_engine_7.7_patch_7.7.4_to_7.7.5.sql
new file mode 100644
index 0000000000..404dd4378f
--- /dev/null
+++ b/distro/sql-script/upgrade/mssql_engine_7.7_patch_7.7.4_to_7.7.5.sql
@@ -0,0 +1,14 @@
+-- insert indices for history cleanup - https://app.camunda.com/jira/browse/CAM-8184 --
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
\ No newline at end of file
diff --git a/distro/sql-script/upgrade/mysql_engine_7.7_patch_7.7.4_to_7.7.5.sql b/distro/sql-script/upgrade/mysql_engine_7.7_patch_7.7.4_to_7.7.5.sql
new file mode 100644
index 0000000000..404dd4378f
--- /dev/null
+++ b/distro/sql-script/upgrade/mysql_engine_7.7_patch_7.7.4_to_7.7.5.sql
@@ -0,0 +1,14 @@
+-- insert indices for history cleanup - https://app.camunda.com/jira/browse/CAM-8184 --
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
\ No newline at end of file
diff --git a/distro/sql-script/upgrade/oracle_engine_7.7_patch_7.7.4_to_7.7.5.sql b/distro/sql-script/upgrade/oracle_engine_7.7_patch_7.7.4_to_7.7.5.sql
new file mode 100644
index 0000000000..404dd4378f
--- /dev/null
+++ b/distro/sql-script/upgrade/oracle_engine_7.7_patch_7.7.4_to_7.7.5.sql
@@ -0,0 +1,14 @@
+-- insert indices for history cleanup - https://app.camunda.com/jira/browse/CAM-8184 --
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
\ No newline at end of file
diff --git a/distro/sql-script/upgrade/postgres_engine_7.7_patch_7.7.4_to_7.7.5.sql b/distro/sql-script/upgrade/postgres_engine_7.7_patch_7.7.4_to_7.7.5.sql
new file mode 100644
index 0000000000..404dd4378f
--- /dev/null
+++ b/distro/sql-script/upgrade/postgres_engine_7.7_patch_7.7.4_to_7.7.5.sql
@@ -0,0 +1,14 @@
+-- insert indices for history cleanup - https://app.camunda.com/jira/browse/CAM-8184 --
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
\ No newline at end of file
diff --git a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.db2.create.history.sql b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.db2.create.history.sql
index d0b6cf3a6b..3fc5f04530 100644
--- a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.db2.create.history.sql
+++ b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.db2.create.history.sql
@@ -292,6 +292,8 @@ create index ACT_IDX_HI_ACT_INST_PROC_DEF_KEY on ACT_HI_ACTINST(PROC_DEF_KEY_);
 
 create index ACT_IDX_HI_TASK_INST_TENANT_ID on ACT_HI_TASKINST(TENANT_ID_);
 create index ACT_IDX_HI_TASK_INST_PROC_DEF_KEY on ACT_HI_TASKINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
 
 create index ACT_IDX_HI_DETAIL_PROC_INST on ACT_HI_DETAIL(PROC_INST_ID_);
 create index ACT_IDX_HI_DETAIL_ACT_INST on ACT_HI_DETAIL(ACT_INST_ID_);
@@ -302,33 +304,44 @@ create index ACT_IDX_HI_DETAIL_NAME on ACT_HI_DETAIL(NAME_);
 create index ACT_IDX_HI_DETAIL_TASK_ID on ACT_HI_DETAIL(TASK_ID_);
 create index ACT_IDX_HI_DETAIL_TENANT_ID on ACT_HI_DETAIL(TENANT_ID_);
 create index ACT_IDX_HI_DETAIL_PROC_DEF_KEY on ACT_HI_DETAIL(PROC_DEF_KEY_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_IDENT_LNK_USER on ACT_HI_IDENTITYLINK(USER_ID_);
 create index ACT_IDX_HI_IDENT_LNK_GROUP on ACT_HI_IDENTITYLINK(GROUP_ID_);
 create index ACT_IDX_HI_IDENT_LNK_TENANT_ID on ACT_HI_IDENTITYLINK(TENANT_ID_);
 create index ACT_IDX_HI_IDENT_LNK_PROC_DEF_KEY on ACT_HI_IDENTITYLINK(PROC_DEF_KEY_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
 
 create index ACT_IDX_HI_PROCVAR_PROC_INST on ACT_HI_VARINST(PROC_INST_ID_);
 create index ACT_IDX_HI_PROCVAR_NAME_TYPE on ACT_HI_VARINST(NAME_, VAR_TYPE_);
 create index ACT_IDX_HI_CASEVAR_CASE_INST on ACT_HI_VARINST(CASE_INST_ID_);
 create index ACT_IDX_HI_VAR_INST_TENANT_ID on ACT_HI_VARINST(TENANT_ID_);
 create index ACT_IDX_HI_VAR_INST_PROC_DEF_KEY on ACT_HI_VARINST(PROC_DEF_KEY_);
-
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_INCIDENT_TENANT_ID on ACT_HI_INCIDENT(TENANT_ID_);
 create index ACT_IDX_HI_INCIDENT_PROC_DEF_KEY on ACT_HI_INCIDENT(PROC_DEF_KEY_);
-
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
 
 create index ACT_IDX_HI_JOB_LOG_PROCINST on ACT_HI_JOB_LOG(PROCESS_INSTANCE_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROCDEF on ACT_HI_JOB_LOG(PROCESS_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_TENANT_ID on ACT_HI_JOB_LOG(TENANT_ID_);
 create index ACT_IDX_HI_JOB_LOG_JOB_DEF_ID on ACT_HI_JOB_LOG(JOB_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROC_DEF_KEY on ACT_HI_JOB_LOG(PROCESS_DEF_KEY_);
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
 
 create index ACT_HI_EXT_TASK_LOG_PROCINST on ACT_HI_EXT_TASK_LOG(PROC_INST_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROCDEF on ACT_HI_EXT_TASK_LOG(PROC_DEF_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROC_DEF_KEY on ACT_HI_EXT_TASK_LOG(PROC_DEF_KEY_);
 create index ACT_HI_EXT_TASK_LOG_TENANT_ID on ACT_HI_EXT_TASK_LOG(TENANT_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
 
 create index ACT_IDX_HI_OP_LOG_PROCINST on ACT_HI_OP_LOG(PROC_INST_ID_);
 create index ACT_IDX_HI_OP_LOG_PROCDEF on ACT_HI_OP_LOG(PROC_DEF_ID_);
+
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
\ No newline at end of file
diff --git a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.h2.create.history.sql b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.h2.create.history.sql
index 598235780e..128177edfc 100644
--- a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.h2.create.history.sql
+++ b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.h2.create.history.sql
@@ -297,35 +297,49 @@ create index ACT_IDX_HI_DETAIL_NAME on ACT_HI_DETAIL(NAME_);
 create index ACT_IDX_HI_DETAIL_TASK_ID on ACT_HI_DETAIL(TASK_ID_);
 create index ACT_IDX_HI_DETAIL_TENANT_ID on ACT_HI_DETAIL(TENANT_ID_);
 create index ACT_IDX_HI_DETAIL_PROC_DEF_KEY on ACT_HI_DETAIL(PROC_DEF_KEY_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_IDENT_LNK_USER on ACT_HI_IDENTITYLINK(USER_ID_);
 create index ACT_IDX_HI_IDENT_LNK_TENANT_ID on ACT_HI_IDENTITYLINK(TENANT_ID_);
 create index ACT_IDX_HI_IDENT_LNK_GROUP on ACT_HI_IDENTITYLINK(GROUP_ID_);
 create index ACT_IDX_HI_IDENT_LNK_PROC_DEF_KEY on ACT_HI_IDENTITYLINK(PROC_DEF_KEY_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
 
 create index ACT_IDX_HI_TASK_INST_TENANT_ID on ACT_HI_TASKINST(TENANT_ID_);
 create index ACT_IDX_HI_TASK_INST_PROC_DEF_KEY on ACT_HI_TASKINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
 
 create index ACT_IDX_HI_PROCVAR_PROC_INST on ACT_HI_VARINST(PROC_INST_ID_);
 create index ACT_IDX_HI_PROCVAR_NAME_TYPE on ACT_HI_VARINST(NAME_, VAR_TYPE_);
 create index ACT_IDX_HI_CASEVAR_CASE_INST on ACT_HI_VARINST(CASE_INST_ID_);
 create index ACT_IDX_HI_VAR_INST_TENANT_ID on ACT_HI_VARINST(TENANT_ID_);
 create index ACT_IDX_HI_VAR_INST_PROC_DEF_KEY on ACT_HI_VARINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_INCIDENT_TENANT_ID on ACT_HI_INCIDENT(TENANT_ID_);
 create index ACT_IDX_HI_INCIDENT_PROC_DEF_KEY on ACT_HI_INCIDENT(PROC_DEF_KEY_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
 
 create index ACT_IDX_HI_JOB_LOG_PROCINST on ACT_HI_JOB_LOG(PROCESS_INSTANCE_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROCDEF on ACT_HI_JOB_LOG(PROCESS_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_TENANT_ID on ACT_HI_JOB_LOG(TENANT_ID_);
 create index ACT_IDX_HI_JOB_LOG_JOB_DEF_ID on ACT_HI_JOB_LOG(JOB_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROC_DEF_KEY on ACT_HI_JOB_LOG(PROCESS_DEF_KEY_);
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
 
 create index ACT_HI_EXT_TASK_LOG_PROCINST on ACT_HI_EXT_TASK_LOG(PROC_INST_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROCDEF on ACT_HI_EXT_TASK_LOG(PROC_DEF_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROC_DEF_KEY on ACT_HI_EXT_TASK_LOG(PROC_DEF_KEY_);
 create index ACT_HI_EXT_TASK_LOG_TENANT_ID on ACT_HI_EXT_TASK_LOG(TENANT_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
 
 create index ACT_IDX_HI_OP_LOG_PROCINST on ACT_HI_OP_LOG(PROC_INST_ID_);
 create index ACT_IDX_HI_OP_LOG_PROCDEF on ACT_HI_OP_LOG(PROC_DEF_ID_);
 
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
diff --git a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mariadb.create.history.sql b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mariadb.create.history.sql
index 1a9060608e..fd806fea63 100644
--- a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mariadb.create.history.sql
+++ b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mariadb.create.history.sql
@@ -290,6 +290,8 @@ create index ACT_IDX_HI_ACT_INST_PROC_DEF_KEY on ACT_HI_ACTINST(PROC_DEF_KEY_);
 
 create index ACT_IDX_HI_TASK_INST_TENANT_ID on ACT_HI_TASKINST(TENANT_ID_);
 create index ACT_IDX_HI_TASK_INST_PROC_DEF_KEY on ACT_HI_TASKINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
 
 create index ACT_IDX_HI_DETAIL_PROC_INST on ACT_HI_DETAIL(PROC_INST_ID_);
 create index ACT_IDX_HI_DETAIL_ACT_INST on ACT_HI_DETAIL(ACT_INST_ID_);
@@ -300,31 +302,44 @@ create index ACT_IDX_HI_DETAIL_NAME on ACT_HI_DETAIL(NAME_);
 create index ACT_IDX_HI_DETAIL_TASK_ID on ACT_HI_DETAIL(TASK_ID_);
 create index ACT_IDX_HI_DETAIL_TENANT_ID on ACT_HI_DETAIL(TENANT_ID_);
 create index ACT_IDX_HI_DETAIL_PROC_DEF_KEY on ACT_HI_DETAIL(PROC_DEF_KEY_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_IDENT_LNK_USER on ACT_HI_IDENTITYLINK(USER_ID_);
 create index ACT_IDX_HI_IDENT_LNK_GROUP on ACT_HI_IDENTITYLINK(GROUP_ID_);
 create index ACT_IDX_HI_IDENT_LNK_TENANT_ID on ACT_HI_IDENTITYLINK(TENANT_ID_);
 create index ACT_IDX_HI_IDENT_LNK_PROC_DEF_KEY on ACT_HI_IDENTITYLINK(PROC_DEF_KEY_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
 
 create index ACT_IDX_HI_PROCVAR_PROC_INST on ACT_HI_VARINST(PROC_INST_ID_);
 create index ACT_IDX_HI_PROCVAR_NAME_TYPE on ACT_HI_VARINST(NAME_, VAR_TYPE_);
 create index ACT_IDX_HI_CASEVAR_CASE_INST on ACT_HI_VARINST(CASE_INST_ID_);
 create index ACT_IDX_HI_VAR_INST_TENANT_ID on ACT_HI_VARINST(TENANT_ID_);
 create index ACT_IDX_HI_VAR_INST_PROC_DEF_KEY on ACT_HI_VARINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_INCIDENT_TENANT_ID on ACT_HI_INCIDENT(TENANT_ID_);
 create index ACT_IDX_HI_INCIDENT_PROC_DEF_KEY on ACT_HI_INCIDENT(PROC_DEF_KEY_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
 
 create index ACT_IDX_HI_JOB_LOG_PROCINST on ACT_HI_JOB_LOG(PROCESS_INSTANCE_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROCDEF on ACT_HI_JOB_LOG(PROCESS_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_TENANT_ID on ACT_HI_JOB_LOG(TENANT_ID_);
 create index ACT_IDX_HI_JOB_LOG_JOB_DEF_ID on ACT_HI_JOB_LOG(JOB_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROC_DEF_KEY on ACT_HI_JOB_LOG(PROCESS_DEF_KEY_);
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
 
 create index ACT_HI_EXT_TASK_LOG_PROCINST on ACT_HI_EXT_TASK_LOG(PROC_INST_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROCDEF on ACT_HI_EXT_TASK_LOG(PROC_DEF_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROC_DEF_KEY on ACT_HI_EXT_TASK_LOG(PROC_DEF_KEY_);
 create index ACT_HI_EXT_TASK_LOG_TENANT_ID on ACT_HI_EXT_TASK_LOG(TENANT_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
 
 create index ACT_IDX_HI_OP_LOG_PROCINST on ACT_HI_OP_LOG(PROC_INST_ID_);
 create index ACT_IDX_HI_OP_LOG_PROCDEF on ACT_HI_OP_LOG(PROC_DEF_ID_);
+
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
diff --git a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mssql.create.history.sql b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mssql.create.history.sql
index 0e698d9b66..24fb9882c3 100644
--- a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mssql.create.history.sql
+++ b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mssql.create.history.sql
@@ -289,11 +289,14 @@ create index ACT_IDX_HI_ACT_INST_PROC_DEF_KEY on ACT_HI_ACTINST(PROC_DEF_KEY_);
 
 create index ACT_IDX_HI_TASK_INST_TENANT_ID on ACT_HI_TASKINST(TENANT_ID_);
 create index ACT_IDX_HI_TASK_INST_PROC_DEF_KEY on ACT_HI_TASKINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
 
 create index ACT_IDX_HI_IDENT_LNK_USER on ACT_HI_IDENTITYLINK(USER_ID_);
 create index ACT_IDX_HI_IDENT_LNK_GROUP on ACT_HI_IDENTITYLINK(GROUP_ID_);
 create index ACT_IDX_HI_IDENT_LNK_TENANT_ID on ACT_HI_IDENTITYLINK(TENANT_ID_);
 create index ACT_IDX_HI_IDENT_LNK_PROC_DEF_KEY on ACT_HI_IDENTITYLINK(PROC_DEF_KEY_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
 
 create index ACT_IDX_HI_DETAIL_PROC_INST on ACT_HI_DETAIL(PROC_INST_ID_);
 create index ACT_IDX_HI_DETAIL_ACT_INST on ACT_HI_DETAIL(ACT_INST_ID_);
@@ -304,26 +307,38 @@ create index ACT_IDX_HI_DETAIL_NAME on ACT_HI_DETAIL(NAME_);
 create index ACT_IDX_HI_DETAIL_TASK_ID on ACT_HI_DETAIL(TASK_ID_);
 create index ACT_IDX_HI_DETAIL_TENANT_ID on ACT_HI_DETAIL(TENANT_ID_);
 create index ACT_IDX_HI_DETAIL_PROC_DEF_KEY on ACT_HI_DETAIL(PROC_DEF_KEY_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_PROCVAR_PROC_INST on ACT_HI_VARINST(PROC_INST_ID_);
 create index ACT_IDX_HI_PROCVAR_NAME_TYPE on ACT_HI_VARINST(NAME_, VAR_TYPE_);
 create index ACT_IDX_HI_CASEVAR_CASE_INST on ACT_HI_VARINST(CASE_INST_ID_);
 create index ACT_IDX_HI_VAR_INST_TENANT_ID on ACT_HI_VARINST(TENANT_ID_);
 create index ACT_IDX_HI_VAR_INST_PROC_DEF_KEY on ACT_HI_VARINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_INCIDENT_TENANT_ID on ACT_HI_INCIDENT(TENANT_ID_);
 create index ACT_IDX_HI_INCIDENT_PROC_DEF_KEY on ACT_HI_INCIDENT(PROC_DEF_KEY_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
 
 create index ACT_IDX_HI_JOB_LOG_PROCINST on ACT_HI_JOB_LOG(PROCESS_INSTANCE_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROCDEF on ACT_HI_JOB_LOG(PROCESS_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_TENANT_ID on ACT_HI_JOB_LOG(TENANT_ID_);
 create index ACT_IDX_HI_JOB_LOG_JOB_DEF_ID on ACT_HI_JOB_LOG(JOB_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROC_DEF_KEY on ACT_HI_JOB_LOG(PROCESS_DEF_KEY_);
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
 
 create index ACT_HI_EXT_TASK_LOG_PROCINST on ACT_HI_EXT_TASK_LOG(PROC_INST_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROCDEF on ACT_HI_EXT_TASK_LOG(PROC_DEF_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROC_DEF_KEY on ACT_HI_EXT_TASK_LOG(PROC_DEF_KEY_);
 create index ACT_HI_EXT_TASK_LOG_TENANT_ID on ACT_HI_EXT_TASK_LOG(TENANT_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
 
 create index ACT_IDX_HI_OP_LOG_PROCINST on ACT_HI_OP_LOG(PROC_INST_ID_);
 create index ACT_IDX_HI_OP_LOG_PROCDEF on ACT_HI_OP_LOG(PROC_DEF_ID_);
+
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
diff --git a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mysql.create.history.sql b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mysql.create.history.sql
index 791a6eff3e..c48fecd387 100644
--- a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mysql.create.history.sql
+++ b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.mysql.create.history.sql
@@ -292,6 +292,8 @@ create index ACT_IDX_HI_ACT_INST_PROC_DEF_KEY on ACT_HI_ACTINST(PROC_DEF_KEY_);
 
 create index ACT_IDX_HI_TASK_INST_TENANT_ID on ACT_HI_TASKINST(TENANT_ID_);
 create index ACT_IDX_HI_TASK_INST_PROC_DEF_KEY on ACT_HI_TASKINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
 
 create index ACT_IDX_HI_DETAIL_PROC_INST on ACT_HI_DETAIL(PROC_INST_ID_);
 create index ACT_IDX_HI_DETAIL_ACT_INST on ACT_HI_DETAIL(ACT_INST_ID_);
@@ -302,32 +304,44 @@ create index ACT_IDX_HI_DETAIL_NAME on ACT_HI_DETAIL(NAME_);
 create index ACT_IDX_HI_DETAIL_TASK_ID on ACT_HI_DETAIL(TASK_ID_);
 create index ACT_IDX_HI_DETAIL_TENANT_ID on ACT_HI_DETAIL(TENANT_ID_);
 create index ACT_IDX_HI_DETAIL_PROC_DEF_KEY on ACT_HI_DETAIL(PROC_DEF_KEY_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_IDENT_LNK_USER on ACT_HI_IDENTITYLINK(USER_ID_);
 create index ACT_IDX_HI_IDENT_LNK_GROUP on ACT_HI_IDENTITYLINK(GROUP_ID_);
 create index ACT_IDX_HI_IDENT_LNK_TENANT_ID on ACT_HI_IDENTITYLINK(TENANT_ID_);
 create index ACT_IDX_HI_IDENT_LNK_PROC_DEF_KEY on ACT_HI_IDENTITYLINK(PROC_DEF_KEY_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
 
 create index ACT_IDX_HI_PROCVAR_PROC_INST on ACT_HI_VARINST(PROC_INST_ID_);
 create index ACT_IDX_HI_PROCVAR_NAME_TYPE on ACT_HI_VARINST(NAME_, VAR_TYPE_);
 create index ACT_IDX_HI_CASEVAR_CASE_INST on ACT_HI_VARINST(CASE_INST_ID_);
 create index ACT_IDX_HI_VAR_INST_TENANT_ID on ACT_HI_VARINST(TENANT_ID_);
 create index ACT_IDX_HI_VAR_INST_PROC_DEF_KEY on ACT_HI_VARINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_INCIDENT_TENANT_ID on ACT_HI_INCIDENT(TENANT_ID_);
 create index ACT_IDX_HI_INCIDENT_PROC_DEF_KEY on ACT_HI_INCIDENT(PROC_DEF_KEY_);
-
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
 
 create index ACT_IDX_HI_JOB_LOG_PROCINST on ACT_HI_JOB_LOG(PROCESS_INSTANCE_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROCDEF on ACT_HI_JOB_LOG(PROCESS_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_TENANT_ID on ACT_HI_JOB_LOG(TENANT_ID_);
 create index ACT_IDX_HI_JOB_LOG_JOB_DEF_ID on ACT_HI_JOB_LOG(JOB_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROC_DEF_KEY on ACT_HI_JOB_LOG(PROCESS_DEF_KEY_);
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
 
 create index ACT_HI_EXT_TASK_LOG_PROCINST on ACT_HI_EXT_TASK_LOG(PROC_INST_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROCDEF on ACT_HI_EXT_TASK_LOG(PROC_DEF_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROC_DEF_KEY on ACT_HI_EXT_TASK_LOG(PROC_DEF_KEY_);
 create index ACT_HI_EXT_TASK_LOG_TENANT_ID on ACT_HI_EXT_TASK_LOG(TENANT_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
 
 create index ACT_IDX_HI_OP_LOG_PROCINST on ACT_HI_OP_LOG(PROC_INST_ID_);
 create index ACT_IDX_HI_OP_LOG_PROCDEF on ACT_HI_OP_LOG(PROC_DEF_ID_);
+
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
+
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
diff --git a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.oracle.create.history.sql b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.oracle.create.history.sql
index 640173763c..76169cc873 100644
--- a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.oracle.create.history.sql
+++ b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.oracle.create.history.sql
@@ -290,6 +290,8 @@ create index ACT_IDX_HI_ACT_INST_PROC_KEY on ACT_HI_ACTINST(PROC_DEF_KEY_);
 
 create index ACT_IDX_HI_TASK_INST_TENANT_ID on ACT_HI_TASKINST(TENANT_ID_, 0);
 create index ACT_IDX_HI_TASK_INST_PROC_KEY on ACT_HI_TASKINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
 
 create index ACT_IDX_HI_DETAIL_PROC_INST on ACT_HI_DETAIL(PROC_INST_ID_);
 create index ACT_IDX_HI_DETAIL_ACT_INST on ACT_HI_DETAIL(ACT_INST_ID_);
@@ -300,31 +302,44 @@ create index ACT_IDX_HI_DETAIL_NAME on ACT_HI_DETAIL(NAME_);
 create index ACT_IDX_HI_DETAIL_TASK_ID on ACT_HI_DETAIL(TASK_ID_);
 create index ACT_IDX_HI_DETAIL_TENANT_ID on ACT_HI_DETAIL(TENANT_ID_, 0);
 create index ACT_IDX_HI_DETAIL_PROC_KEY on ACT_HI_DETAIL(PROC_DEF_KEY_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_IDENT_LNK_USER on ACT_HI_IDENTITYLINK(USER_ID_);
 create index ACT_IDX_HI_IDENT_LNK_GROUP on ACT_HI_IDENTITYLINK(GROUP_ID_);
 create index ACT_IDX_HI_IDENT_LNK_TENANT_ID on ACT_HI_IDENTITYLINK(TENANT_ID_, 0);
 create index ACT_IDX_HI_IDENT_LNK_PROC_KEY on ACT_HI_IDENTITYLINK(PROC_DEF_KEY_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
 
 create index ACT_IDX_HI_PROCVAR_PROC_INST on ACT_HI_VARINST(PROC_INST_ID_);
 create index ACT_IDX_HI_PROCVAR_NAME_TYPE on ACT_HI_VARINST(NAME_, VAR_TYPE_);
 create index ACT_IDX_HI_CASEVAR_CASE_INST on ACT_HI_VARINST(CASE_INST_ID_);
 create index ACT_IDX_HI_VAR_INST_TENANT_ID on ACT_HI_VARINST(TENANT_ID_, 0);
 create index ACT_IDX_HI_VAR_INST_PROC_KEY on ACT_HI_VARINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_VARINST_BYTEAR on ACT_HI_VARINST(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_INCIDENT_TENANT_ID on ACT_HI_INCIDENT(TENANT_ID_, 0);
 create index ACT_IDX_HI_INCIDENT_PROC_KEY on ACT_HI_INCIDENT(PROC_DEF_KEY_);
+create index ACT_IDX_HI_INCIDENT_PROCINST on ACT_HI_INCIDENT(PROC_INST_ID_);
 
 create index ACT_IDX_HI_JOB_LOG_PROCINST on ACT_HI_JOB_LOG(PROCESS_INSTANCE_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROCDEF on ACT_HI_JOB_LOG(PROCESS_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_TENANT_ID on ACT_HI_JOB_LOG(TENANT_ID_, 0);
 create index ACT_IDX_HI_JOB_LOG_JOB_DEF_ID on ACT_HI_JOB_LOG(JOB_DEF_ID_);
 create index ACT_IDX_HI_JOB_LOG_PROC_KEY on ACT_HI_JOB_LOG(PROCESS_DEF_KEY_);
+create index ACT_IDX_HI_JOB_LOG_EX_STACK on ACT_HI_JOB_LOG(JOB_EXCEPTION_STACK_ID_);
 
 create index ACT_HI_EXT_TASK_LOG_PROCINST on ACT_HI_EXT_TASK_LOG(PROC_INST_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROCDEF on ACT_HI_EXT_TASK_LOG(PROC_DEF_ID_);
 create index ACT_HI_EXT_TASK_LOG_PROC_KEY on ACT_HI_EXT_TASK_LOG(PROC_DEF_KEY_);
 create index ACT_HI_EXT_TASK_LOG_TENANT_ID on ACT_HI_EXT_TASK_LOG(TENANT_ID_);
+create index ACT_IDX_HI_EXT_TASK_LOG_ERROR_DET on ACT_HI_EXT_TASK_LOG(ERROR_DETAILS_ID_);
 
 create index ACT_IDX_HI_OP_LOG_PROCINST on ACT_HI_OP_LOG(PROC_INST_ID_);
 create index ACT_IDX_HI_OP_LOG_PROCDEF on ACT_HI_OP_LOG(PROC_DEF_ID_);
+
+create index ACT_IDX_HI_COMMENT_TASK on ACT_HI_COMMENT(TASK_ID_);
+create index ACT_IDX_HI_COMMENT_PROCINST on ACT_HI_COMMENT(PROC_INST_ID_);
+
+create index ACT_IDX_HI_ATTACHMENT_CONTENT on ACT_HI_ATTACHMENT(CONTENT_ID_);
+create index ACT_IDX_HI_ATTACHMENT_PROCINST on ACT_HI_ATTACHMENT(PROC_INST_ID_);
+create index ACT_IDX_HI_ATTACHMENT_TASK on ACT_HI_ATTACHMENT(TASK_ID_);
diff --git a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.postgres.create.history.sql b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.postgres.create.history.sql
index 865f1cae79..ff57a31286 100644
--- a/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.postgres.create.history.sql
+++ b/engine/src/main/resources/org/camunda/bpm/engine/db/create/activiti.postgres.create.history.sql
@@ -290,6 +290,8 @@ create index ACT_IDX_HI_ACT_INST_PROC_DEF_KEY on ACT_HI_ACTINST(PROC_DEF_KEY_);
 
 create index ACT_IDX_HI_TASK_INST_TENANT_ID on ACT_HI_TASKINST(TENANT_ID_);
 create index ACT_IDX_HI_TASK_INST_PROC_DEF_KEY on ACT_HI_TASKINST(PROC_DEF_KEY_);
+create index ACT_IDX_HI_TASKINST_PROCINST on ACT_HI_TASKINST(PROC_INST_ID_);
+create index ACT_IDX_HI_TASKINST_ID_PROCINST on ACT_HI_TASKINST(ID_,PROC_INST_ID_);
 
 create index ACT_IDX_HI_DETAIL_PROC_INST on ACT_HI_DETAIL(PROC_INST_ID_);
 create index ACT_IDX_HI_DETAIL_ACT_INST on ACT_HI_DETAIL(ACT_INST_ID_);
@@ -300,32 +302,44 @@ create index ACT_IDX_HI_DETAIL_NAME on ACT_HI_DETAIL(NAME_);
 create index ACT_IDX_HI_DETAIL_TASK_ID on ACT_HI_DETAIL(TASK_ID_);
 create index ACT_IDX_HI_DETAIL_TENANT_ID on ACT_HI_DETAIL(TENANT_ID_);
 create index ACT_IDX_HI_DETAIL_PROC_DEF_KEY on ACT_HI_DETAIL(PROC_DEF_KEY_);
+create index ACT_IDX_HI_DETAIL_BYTEAR on ACT_HI_DETAIL(BYTEARRAY_ID_);
 
 create index ACT_IDX_HI_IDENT_LNK_USER on ACT_HI_IDENTITYLINK(USER_ID_);
 create index ACT_IDX_HI_IDENT_LNK_GROUP on ACT_HI_IDENTITYLINK(GROUP_ID_);
 create index ACT_IDX_HI_IDENT_LNK_TENANT_ID on ACT_HI_IDENTITYLINK(TENANT_ID_);
 create index ACT_IDX_HI_IDENT_LNK_PROC_DEF_KEY on ACT_HI_IDENTITYLINK(PROC_DEF_KEY_);
+create index ACT_IDX_HI_IDENTITYLINK_TASK on ACT_HI_IDENTITYLINK(TASK_ID_);
 
 create index ACT_IDX_HI_PROCVAR_PROC_INST",add indices to improve performance of history cleanup .,"""Added indices for history cleanup (CAM-8184)""","""Added missing indices for history cleanup across various database engines""","""Adding indices for history cleanup - CAM-8184""

This commit appears to add new indices to several tables in the database schema used by Camunda BPM. The indices are added to tables such as ACT\_HI\_JOB\_LOG, ACT\_HI\_VARINST, ACT\_HI\_DETAIL, ACT\_HI\_EXT\_TASK\_LOG, ACT\_HI\_COMMENT, ACT\_HI\_ATTACHMENT, ACT\_HI\_TASKINST, and ACT\_HI\_IDENTITYLINK. The indices are added to columns such as JOB\_EXCEPTION\_STACK\_ID\_, BYTEARRAY\_ID\_, ERROR\_DETAILS\_ID\_, TASK\_ID\_, PROC\_INST\_ID\_, ID\_PROCINST, CONTENT\_ID\_, and PROC\_INST\_ID\_. The purpose of these indices is to optimize the performance of history cleanup, as indicated by the commit message and the Jira ticket CAM-8184.",Added indices for history cleanup in various database scripts to enhance performance as per CAM-8184.,Model 1
"diff --git a/src/cpp/session/modules/SessionReticulate.R b/src/cpp/session/modules/SessionReticulate.R
index 3dfad2adb5..4fbd2c44d4 100644
--- a/src/cpp/session/modules/SessionReticulate.R
+++ b/src/cpp/session/modules/SessionReticulate.R
@@ -521,15 +521,14 @@ options(reticulate.repl.teardown   = .rs.reticulate.replTeardown)
 {
    inspect <- reticulate::import(""inspect"", convert = TRUE)
    
-   # if this is a class object (has an __init__ method), then
-   # get methods from that
-   init <- reticulate::py_get_attr(object, ""__init__"", silent = TRUE)
-   if (!inherits(init, ""python.builtin.NoneType"")) {
+   if (inspect$isclass(object)) {
+      # for class objects, use the arguments of the __init__ method
+      init <- reticulate::py_get_attr(object, ""__init__"", silent = TRUE)
       arguments <- tryCatch(inspect$getargspec(init)$args, error = identity)
       if (inherits(arguments, ""error""))
          return(.rs.python.emptyCompletions())
-      arguments <- setdiff(arguments, ""self"")
    } else {
+      # assume that this is a callable, and ask for the arg spec
       arguments <- tryCatch(inspect$getargspec(object)$args, error = identity)
       if (inherits(arguments, ""error""))
          return(.rs.python.emptyCompletions())",fix up argument completion,"""Improve Python object inspection in reticulate module""","""Improve handling of Python class objects and callables in SessionReticulate""","""Update completion logic for Python objects in reticulate: use inspect.isclass to check if an object is a class, and handle arguments for both class objects and callable objects.""",Update Python object inspection to differentiate class objects from callables.,Model 2
"diff --git a/requery-processor/src/main/java/io/requery/processor/AttributeMember.java b/requery-processor/src/main/java/io/requery/processor/AttributeMember.java
index fa0fd54..2c32116 100644
--- a/requery-processor/src/main/java/io/requery/processor/AttributeMember.java
+++ b/requery-processor/src/main/java/io/requery/processor/AttributeMember.java
@@ -46,7 +46,6 @@ import io.requery.meta.MapAttributeBuilder;
 import io.requery.meta.ResultAttributeBuilder;
 import io.requery.meta.SetAttributeBuilder;
 import io.requery.query.Order;
-import io.requery.sql.Keyword;
 
 import javax.annotation.processing.ProcessingEnvironment;
 import javax.lang.model.SourceVersion;
@@ -184,7 +183,7 @@ class AttributeMember extends BaseProcessableElement<Element> implements Attribu
                     isIterable = Mirrors.isInstance(types, element, Iterable.class);
                 }
                 isMap = Mirrors.isInstance(types, element, Map.class);
-                if (isMap) {
+                if (isMap && cardinality != null) {
                     builderClass = MapAttributeBuilder.class;
                 }
                 isOptional = Mirrors.isInstance(types, element, Optional.class);
diff --git a/requery-processor/src/main/java/io/requery/processor/EntityGenerator.java b/requery-processor/src/main/java/io/requery/processor/EntityGenerator.java
index b5c017a..48d9808 100644
--- a/requery-processor/src/main/java/io/requery/processor/EntityGenerator.java
+++ b/requery-processor/src/main/java/io/requery/processor/EntityGenerator.java
@@ -629,7 +629,7 @@ class EntityGenerator implements SourceGenerator {
             builder.add(""\nnew $T($S, $T.class, $T.class)\n"",
                 builderName, attribute.name(), ClassName.get(collectionElement), name);
 
-        } else if (attribute.isMap()) {
+        } else if (attribute.isMap() && attribute.cardinality() != null) {
             List<TypeMirror> parameters = Mirrors.listGenericTypeArguments(typeMirror);
             // key type
             TypeName keyName = TypeName.get(parameters.get(0));",Resolve <issue_id> Don \' t use map attribute builder for non relational map,"""Fix map attribute handling to require cardinality""","""Refine attribute processing for maps with cardinality constraints""","""Fixed attribute member generation for maps with null cardinality and updated map attribute handling in entity generator""

This commit appears to have made two changes to the code:

1. In the `AttributeMember` class, it added a check for `cardinality != null` before setting the `builderClass` to `MapAttributeBuilder.class` when `isMap` is true. This prevents a `NullPointerException` when the cardinality is null.
2. In the `EntityGenerator` class, it added a similar check for `cardinality != null` before checking if the attribute is a map. This ensures that the map attribute is only handled when the cardinality is not null.

These changes seem to be related to fixing issues with generating code for map attributes when the cardinality is null.",Ensure `isMap` considers cardinality in `AttributeMember` and `EntityGenerator`.,Model 2
"diff --git a/server/webapp/WEB-INF/applicationContext-acegi-security.xml b/server/webapp/WEB-INF/applicationContext-acegi-security.xml
index 002dae3bbf..ae3e662fbe 100644
--- a/server/webapp/WEB-INF/applicationContext-acegi-security.xml
+++ b/server/webapp/WEB-INF/applicationContext-acegi-security.xml
@@ -272,6 +272,7 @@
                 /api/admin/plugin_info/**=ROLE_SUPERVISOR, ROLE_GROUP_SUPERVISOR
                 /api/admin/agents=ROLE_SUPERVISOR
                 /api/elastic/profiles/**=ROLE_SUPERVISOR, ROLE_GROUP_SUPERVISOR
+                /admin/elastic_profiles/**=ROLE_SUPERVISOR, ROLE_GROUP_SUPERVISOR
                 /api/admin/templates/**=ROLE_SUPERVISOR
                 /api/admin/**=ROLE_SUPERVISOR
                 /api/config-repository.git/**=ROLE_SUPERVISOR
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/javascripts/lib/string-plus.js b/server/webapp/WEB-INF/rails.new/app/assets/javascripts/lib/string-plus.js
index 6e56d644ad..c6b610092d 100644
--- a/server/webapp/WEB-INF/rails.new/app/assets/javascripts/lib/string-plus.js
+++ b/server/webapp/WEB-INF/rails.new/app/assets/javascripts/lib/string-plus.js
@@ -79,6 +79,14 @@ define(['string', 'lodash', 'mithril'], function (s, _, m) {
 
       return s4() + s4() + '-' + s4() + '-' + s4() + '-' +
         s4() + '-' + s4() + s4() + s4();
+    },
+
+    terminateWithPeriod: function (str) {
+      if (s.endsWith(str, '.')) {
+        return str;
+      } else {
+        return `${str}.`;
+      }
     }
   };
 
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/helpers/form_helper.js.msx b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/helpers/form_helper.js.msx
index b6f38ad61e..542542be5a 100644
--- a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/helpers/form_helper.js.msx
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/helpers/form_helper.js.msx
@@ -57,7 +57,7 @@ define(['mithril', 'jquery', 'lodash', 'string-plus', 'models/model_mixins', 'es
 
         return (
           <div class={compactClasses(args, 'columns', 'medium-' + size, 'large-' + largeSize, end)}
-            {...args}>
+               {...args}>
             {children}
           </div>
         );
@@ -77,7 +77,7 @@ define(['mithril', 'jquery', 'lodash', 'string-plus', 'models/model_mixins', 'es
       },
 
       view: function (ctrl, args) {
-        var model = deleteKeyAndReturnValue(args, 'model'),
+        var model       = deleteKeyAndReturnValue(args, 'model'),
           attrName    = deleteKeyAndReturnValue(args, 'attrName'),
           type        = deleteKeyAndReturnValue(args, 'type', 'text'),
           placeholder = deleteKeyAndReturnValue(args, 'placeholder', ''),
@@ -367,7 +367,7 @@ define(['mithril', 'jquery', 'lodash', 'string-plus', 'models/model_mixins', 'es
 
       view: function (ctrl, args, children) {
         var tabs = (
-          <ul class={_.compact(['tabs', args.isVertical ? 'vertical': undefined]).join(' ')}>
+          <ul class={_.compact(['tabs', args.isVertical ? 'vertical' : undefined]).join(' ')}>
             {_.map(args.tabTitles, function (tabTitle, tabIndex) {
 
               var tabTitleElem;
@@ -395,7 +395,7 @@ define(['mithril', 'jquery', 'lodash', 'string-plus', 'models/model_mixins', 'es
 
         var tabsContent = (
           <div
-            class={_.compact([args.isVertical ? 'vertical': undefined, 'tabs-content', 'tabs-content-container', ctrl.prefixedClass('tabs-content-container')]).join(' ')}>
+            class={_.compact([args.isVertical ? 'vertical' : undefined, 'tabs-content', 'tabs-content-container', ctrl.prefixedClass('tabs-content-container')]).join(' ')}>
             {_.map(_.flatten(children), function (child, tabIndex) {
 
               var renderedChild;
@@ -604,33 +604,28 @@ define(['mithril', 'jquery', 'lodash', 'string-plus', 'models/model_mixins', 'es
       }
     },
 
+    callout: {
+      view: function (ctrl, args, children) {
+        var type = deleteKeyAndReturnValue(args, 'type');
+        return (<div class={'callout ' + type} {...args}>{children}</div>);
+      }
+    },
+
     alert: {
       view: function (ctrl, args, children) {
-        return (
-          <div>
-            <span class=""callout alert"">{children}</span>
-          </div>
-        );
+        return (<f.callout type=""alert"" {...args}>{children}</f.callout>);
       }
     },
 
     warning: {
       view: function (ctrl, args, children) {
-        return (
-          <div class='warning callout'>
-            <p>{children}</p>
-          </div>
-        );
+        return (<f.callout type=""warning"" {...args}>{children}</f.callout>);
       }
     },
 
     info: {
       view: function (ctrl, args, children) {
-        return (
-          <div class='info callout'>
-            <p>{children}</p>
-          </div>
-        );
+        return (<f.callout type=""info"" {...args}>{children}</f.callout>);
       }
     },
 
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/helpers/mrequest.js b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/helpers/mrequest.js
index 96713de62f..d73b73a21a 100644
--- a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/helpers/mrequest.js
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/helpers/mrequest.js
@@ -14,10 +14,14 @@
  * limitations under the License.
  */
 
-define([], function () {
+define(['jquery'], function ($) {
   var setHeaders = function (xhr, version) {
     xhr.setRequestHeader(""Content-Type"", ""application/json"");
     xhr.setRequestHeader(""Accept"", ""application/vnd.go.cd."" + version + ""+json"");
+    var csrfToken = $('meta[name=csrf-token]').attr('content');
+    if (csrfToken) {
+      xhr.setRequestHeader('X-CSRF-Token', csrfToken);
+    }
   };
 
   return {
@@ -34,6 +38,14 @@ define([], function () {
       v4: function (xhr) {
         setHeaders(xhr, 'v4');
       }
+    },
+
+    unwrapErrorExtractMessage: function (data) {
+      if (data.message) {
+        return data.message;
+      } else {
+        return ""There was an unknown error performing the operation"";
+      }
     }
   };
 });
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/elastic_profiles/elastic_profiles.js b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/elastic_profiles/elastic_profiles.js
new file mode 100644
index 0000000000..3d5294c94a
--- /dev/null
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/elastic_profiles/elastic_profiles.js
@@ -0,0 +1,135 @@
+/*
+ * Copyright 2016 ThoughtWorks, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+define([
+  'mithril', 'lodash', 'string-plus', 'models/model_mixins', 'models/shared/plugin_configurations', 'helpers/mrequest', 'js-routes', 'models/validatable_mixin'
+], function (m, _, s, Mixins, PluginConfigurations, mrequest, Routes, Validatable) {
+
+  var unwrapMessageOrProfile = function (data, xhr) {
+    if (xhr.status === 422) {
+      return new ElasticProfiles.Profile.fromJSON(data.data);
+    } else {
+      return mrequest.unwrapErrorExtractMessage(data, xhr);
+    }
+  };
+
+  var ElasticProfiles = function (data) {
+    Mixins.HasMany.call(this, {
+      factory:    ElasticProfiles.Profile.create,
+      as:         'Profile',
+      collection: data,
+      uniqueOn:   'id'
+    });
+  };
+
+  ElasticProfiles.all = function () {
+    return m.request({
+      method:        ""GET"",
+      url:           Routes.apiv1ElasticProfilesPath(),
+      config:        mrequest.xhrConfig.v1,
+      unwrapSuccess: function (data) {
+        return ElasticProfiles.fromJSON(data['_embedded']['profiles']);
+      },
+      unwrapError:   mrequest.unwrapErrorExtractMessage
+    });
+  };
+
+  ElasticProfiles.Profile = function (data) {
+    this.id         = m.prop(s.defaultToIfBlank(data.id, ''));
+    this.pluginId   = m.prop(s.defaultToIfBlank(data.pluginId, ''));
+    this.properties = s.collectionToJSON(m.prop(s.defaultToIfBlank(data.properties, new PluginConfigurations())));
+    this.parent     = Mixins.GetterSetter();
+    this.etag       = Mixins.GetterSetter();
+
+    Validatable.call(this, data);
+
+    this.validatePresenceOf('id');
+    this.validatePresenceOf('pluginId');
+
+    this.update = function () {
+      var profile = this;
+      return m.request({
+        method:      'PUT',
+        url:         Routes.apiv1ElasticProfilePath(this.id()),
+        config:      function (xhr) {
+          mrequest.xhrConfig.v1(xhr);
+          xhr.setRequestHeader('If-Match', profile.etag());
+        },
+        data:        JSON.parse(JSON.stringify(profile, s.snakeCaser)),
+        unwrapError: unwrapMessageOrProfile
+      });
+    };
+
+    this.delete = function () {
+      return m.request({
+        method:        ""DELETE"",
+        url:           Routes.apiv1ElasticProfilePath(this.id()),
+        config:        mrequest.xhrConfig.v1,
+        unwrapSuccess: function (data, xhr) {
+          if (xhr.status === 200) {
+            return data.message;
+          }
+        },
+        unwrapError:   mrequest.unwrapErrorExtractMessage
+      });
+    };
+
+    this.create = function () {
+      return m.request({
+        method:      'POST',
+        url:         Routes.apiv1ElasticProfilesPath(),
+        config:      mrequest.xhrConfig.v1,
+        data:        JSON.parse(JSON.stringify(this, s.snakeCaser)),
+        unwrapError: unwrapMessageOrProfile
+      });
+    };
+  };
+
+  ElasticProfiles.Profile.get = function (id) {
+    return m.request({
+      method:        'GET',
+      url:           Routes.apiv1ElasticProfilePath(id),
+      config:        mrequest.xhrConfig.v1,
+      unwrapSuccess: function (data, xhr) {
+        var profile = ElasticProfiles.Profile.fromJSON(data);
+        profile.etag(xhr.getResponseHeader('ETag'));
+        return profile;
+      },
+      unwrapError:   mrequest.unwrapErrorExtractMessage
+    });
+  };
+
+  ElasticProfiles.Profile.create = function (data) {
+    return new ElasticProfiles.Profile(data);
+  };
+
+  ElasticProfiles.Profile.fromJSON = function (data) {
+    return new ElasticProfiles.Profile({
+      id:         data.id,
+      pluginId:   data.plugin_id,
+      errors:     data.errors,
+      properties: PluginConfigurations.fromJSON(data.properties)
+    });
+  };
+
+  Mixins.fromJSONCollection({
+    parentType: ElasticProfiles,
+    childType:  ElasticProfiles.Profile,
+    via:        'addProfile'
+  });
+
+  return ElasticProfiles;
+});
\ No newline at end of file
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/errors.js b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/errors.js
index 7899c1715b..e5f833f219 100644
--- a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/errors.js
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/errors.js
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 
-define(['mithril', 'lodash'], function (m, _) {
+define(['mithril', 'lodash', 'string-plus'], function (m, _, s) {
   var Errors = function (errors) {
     errors = errors || {};
 
@@ -40,9 +40,7 @@ define(['mithril', 'lodash'], function (m, _) {
     };
 
     this.errorsForDisplay = function (attrName) {
-      return _.map(errors[attrName] || [], function (message) {
-        return message + ""."";
-      }).join("" "");
+      return _.map(errors[attrName] || [], s.terminateWithPeriod).join("" "");
     };
   };
 
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/pipeline_configs/plugin_infos.js b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/pipeline_configs/plugin_infos.js
index 7b0b822eb6..7788bab31b 100644
--- a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/pipeline_configs/plugin_infos.js
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/pipeline_configs/plugin_infos.js
@@ -14,17 +14,17 @@
  * limitations under the License.
  */
 
-define(['mithril', 'lodash', 'string-plus', 'helpers/mrequest', 'js-routes'], function (m, _, s, mrequest, Routes) {
+define(['mithril', 'lodash', 'string-plus', 'helpers/mrequest', 'models/shared/image', 'js-routes'], function (m, _, s, mrequest, Image, Routes) {
   var PluginInfos = m.prop([]);
 
-  PluginInfos.init = function () {
+  PluginInfos.init = function (type) {
     var unwrap = function (response) {
       return response._embedded.plugin_info;
     };
 
     return m.request({
       method:        'GET',
-      url:           Routes.apiv1AdminPluginInfoIndexPath(),
+      url:           Routes.apiv1AdminPluginInfoIndexPath({'type': type}),
       background:    true,
       config:        mrequest.xhrConfig.v1,
       unwrapSuccess: unwrap,
@@ -55,17 +55,22 @@ define(['mithril', 'lodash', 'string-plus', 'helpers/mrequest', 'js-routes'], fu
     this.version        = m.prop(data.version);
     this.type           = m.prop(data.type);
     this.configurations = data.pluggable_instance_settings ?
-                            m.prop(s.defaultToIfBlank(data.pluggable_instance_settings.configurations, {})) :
-                            m.prop({});
+      m.prop(s.defaultToIfBlank(data.pluggable_instance_settings.configurations, {})) :
+      m.prop({});
     this.viewTemplate   = m.prop(s.defaultToIfBlank(view(data.pluggable_instance_settings).template, ''));
+
+    if (data.image) {
+      this.image = m.prop(new Image(data.image.content_type, data.image.data));
+    }
   };
 
   PluginInfos.PluginInfo.byId = function (id) {
     return m.request({
-      method: 'GET',
-      url:    Routes.apiv1AdminPluginInfoPath({id: id}),
-      config: mrequest.xhrConfig.v1,
-      type:   PluginInfos.PluginInfo
+      method:      'GET',
+      url:         Routes.apiv1AdminPluginInfoPath({id: id}),
+      config:      mrequest.xhrConfig.v1,
+      type:        PluginInfos.PluginInfo,
+      unwrapError: mrequest.unwrapErrorExtractMessage
     });
   };
 
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/shared/image.js b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/shared/image.js
new file mode 100644
index 0000000000..bd5352bfeb
--- /dev/null
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/models/shared/image.js
@@ -0,0 +1,28 @@
+/*
+ * Copyright 2016 ThoughtWorks, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+define(['mithril'], function (m) {
+  var Image = function (contentType, data) {
+    this.contentType = m.prop(contentType);
+    this.data        = m.prop(data);
+
+    this.toDataURI = function () {
+      return ""data:"" + this.contentType() + "";base64,"" + this.data();
+    };
+  };
+
+  return Image;
+});
\ No newline at end of file
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/single_page_apps/elastic_profiles.js b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/single_page_apps/elastic_profiles.js
new file mode 100644
index 0000000000..172c5e7610
--- /dev/null
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/single_page_apps/elastic_profiles.js
@@ -0,0 +1,33 @@
+/*
+ * Copyright 2016 ThoughtWorks, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+require([
+  'jquery', 'mithril',
+  'js-routes',
+  'views/elastic_profiles/elastic_profiles_widget',
+  'models/pipeline_configs/plugin_infos',
+  'foundation.util.mediaQuery', 'foundation.dropdownMenu', 'foundation.responsiveToggle', 'foundation.dropdown'
+], function ($, m, JsRoutes,
+             ElasticProfilesWidget, PluginInfos) {
+
+  $(function () {
+    $(document).foundation();
+
+    m.sync([PluginInfos.init('elastic-agent')]).then(function () {
+      m.mount($(""#elastic-profiles"").get(0), ElasticProfilesWidget);
+    });
+  });
+});
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/agents/agents_widget.js.msx b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/agents/agents_widget.js.msx
index 59db732710..24721bde39 100644
--- a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/agents/agents_widget.js.msx
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/agents/agents_widget.js.msx
@@ -233,7 +233,7 @@ define([
 
       return (
         <div onclick={ctrl.hideDropDownsAndMessage.bind(ctrl)}>
-          <div class=""agent-header-panel"">
+          <div class=""header-panel"">
             <ButtonRowWidget isAnyAgentSelected={ ctrl.isAnyAgentSelected.bind(ctrl) }
                              dropdown={args.vm.dropdown}
                              selectedAgents={ ctrl.selectedAgents.bind(ctrl) }
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/agents/button_row_widget.js.msx b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/agents/button_row_widget.js.msx
index dcb460a581..6114d1f486 100644
--- a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/agents/button_row_widget.js.msx
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/agents/button_row_widget.js.msx
@@ -56,34 +56,30 @@ define(['mithril', 'lodash',
             </f.column>
 
             <f.column size={7}>
-              <ul class=""button-group agent-button-group"">
+              <ul class=""button-group header-panel-button-group"">
                 <li>
-                  <f.button class=""button""
-                            onclick={args.onDelete}
+                  <f.button onclick={args.onDelete}
                             disabled={!args.isAnyAgentSelected()}>
                     Delete
                   </f.button>
                 </li>
 
                 <li>
-                  <f.button class=""button""
-                            onclick={args.onDisable}
+                  <f.button onclick={args.onDisable}
                             disabled={!args.isAnyAgentSelected()}>
                     Disable
                   </f.button>
                 </li>
 
                 <li>
-                  <f.button class=""button""
-                            onclick={args.onEnable}
+                  <f.button onclick={args.onEnable}
                             disabled={!args.isAnyAgentSelected()}>
                     Enable
                   </f.button>
                 </li>
 
                 <li class={ ctrl.dropdownClass('resource') }>
-                  <f.button class=""button""
-                            onclick={ctrl.resourcesButtonClicked}
+                  <f.button onclick={ctrl.resourcesButtonClicked}
                             disabled={!args.isAnyAgentSelected()}>
                     Resources
                   </f.button>
@@ -95,8 +91,7 @@ define(['mithril', 'lodash',
                 </li>
 
                 <li class={ctrl.dropdownClass('environment')}>
-                  <f.button class=""button""
-                            onclick={ctrl.environmentsButtonClicked}
+                  <f.button onclick={ctrl.environmentsButtonClicked}
                             disabled={!args.isAnyAgentSelected()}>
                     Environments
                   </f.button>
diff --git a/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/elastic_profiles/elastic_profile_modal_body.js.msx b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/elastic_profiles/elastic_profile_modal_body.js.msx
new file mode 100644
index 0000000000..61f7594ef4
--- /dev/null
+++ b/server/webapp/WEB-INF/rails.new/app/assets/new_javascripts/views/elastic_profiles/elastic_profile_modal_body.js.msx
@@ -0,0 +1,120 @@
+/*
+ * Copyright 2016 ThoughtWorks, Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+define([
+  ""mithril"", 'lodash', 'jquery', 'helpers/form_helper', 'models/pipeline_configs/plugin_infos', 'models/elastic_profiles/elastic_profiles',
+  'views/shared/angular_plugin'
+], function (m, _, $, f, PluginInfos, ElasticProfiles, AngularPlugin) {
+
+  var autoComplete = function (model, attrName, selectCb) {
+    return function (elem, isInitialized) {
+      if (isInitialized) {
+        return;
+      }
+
+      var $inputElem = $($(elem).find(`input[data-prop-name='${attrName}']`));
+      var values     = _.map(PluginInfos(), function (pi) {
+        return pi.id();
+      });
+
+      $inputElem.textcomplete([
+        {
+          match:   /([^\s].*)$/,
+          index:   1, // use the second match in the regex to extract the search term
+          search:  function (term, callback) {
+            term = term.toLowerCase();
+            callback($.map(values, function (word) {
+              return",Add a page to manage elastic agent profiles,"""Added elastic profiles feature, including security configuration, JavaScript models, and views""","""Added Elastic Profiles feature and security updates""","This commit contains several changes to the JavaScript code in a web application using Mithril.js and jQuery. Here's a summary of the changes:

1. In `applicationContext-acegi-security.xml`, added a new security rule for the URL pattern `/admin/elastic_profiles/**` requiring the roles `ROLE_SUPERVISOR` and `ROLE_GROUP_SUPERVISOR`.

2. In `string-plus.js`, added a new `terminateWithPeriod` function to ensure a string ends with a period.

3. In `form_helper.js.msx`, updated the class attribute in the `<div>` element inside the `columns` function to properly use the `compact` function from lodash to join class names. Also, added a new `callout` component.

4. In `mrequest.js`, added a new function `unwrapErrorExtractMessage` to extract the error message from a response data object. Also, added code to set the 'X-CSRF-Token' header in the `setHeaders` function if a CSRF token is found in the meta tag of the HTML.

5. In `errors.js`, updated the `errorsForDisplay` function to use the new `terminateWithPeriod` function from `string-plus.js`.

6. In `plugin_infos.js`, updated the `init` function to accept a `type` parameter and pass it to the API endpoint when fetching plugin info. Also, added an `Image` property to the `PluginInfos.PluginInfo` object if an image is present in the plugin info data.

7. Added a new `image.js` file to define an `Image` model with a `toDataURI` function.

8. Added a new `elastic_profiles.js` file to handle Elastic Profiles functionality.

9. Added a new `elastic_profiles_widget.js.msx` file to define the UI for the Elastic Profiles widget.

10. In `agents_widget.js.msx`, updated the class attribute of a `<div>` element to remove the 'agent-' prefix from the 'agent-header-panel' class name.

11. In `button_row_widget.js.msx`, updated the class attribute of a `<ul>` element to remove the 'agent-' prefix from the 'agent-button-group' class name.

12. Added a new `elastic_profile_modal_body.js.msx` file to define the UI for the Elastic Profile modal body.

The commit message could be: ""Add Elastic Profiles functionality, update form helper, and various other changes and fixes.""","### Commit Message

""Add CSRF Token, Elastic Profile Management, UI Enhancements, and Error Handling Improvements""",Model 4
"diff --git a/build/qa/pmd-ruleset.xml b/build/qa/pmd-ruleset.xml
index 3947e8fe7b..edba7d484e 100644
--- a/build/qa/pmd-ruleset.xml
+++ b/build/qa/pmd-ruleset.xml
@@ -85,6 +85,12 @@ under the License.
     <rule ref=""category/java/errorprone.xml/UnnecessaryConversionTemporary"" />
     <rule ref=""category/java/errorprone.xml/UnusedNullCheckInEquals"" />
     <rule ref=""category/java/errorprone.xml/UselessOperationOnImmutable"" />
+    <rule ref=""category/java/errorprone.xml/CloseResource"" >
+        <properties>
+            <!-- When calling the store to close, PMD wants the full prefix before the call to the method to match, so let's try to use common var names for store ... -->
+            <property name=""closeTargets"" value=""releaseConnection,store.releaseConnection,closeQuietly,closeConnection,closeSafe,store.closeSafe,dataStore.closeSafe,getDataStore().closeSafe,close,closeResultSet,closeStmt,closeFinally,JDBCUtils.close""/>
+        </properties>
+    </rule>
 
     <rule ref=""category/java/multithreading.xml/AvoidThreadGroup"" />
     <rule ref=""category/java/multithreading.xml/DontCallThreadRun"" />",Adding checks for unclosed sql closeables,"""Added CloseResource rule to PMD ruleset with custom closeTargets""",Added PMD rule to enforce closing resources and improved configuration for better matching.,"""Added custom configuration for CloseResource rule in PMD ruleset XML""

Explanation: The diff shows that a new rule has been added to the PMD ruleset XML file, specifically the ""CloseResource"" rule under the ""errorprone"" category. Additionally, some properties have been set for this rule to customize its behavior, specifically the ""closeTargets"" property. Therefore, the commit message should reflect that the CloseResource rule has been added and customized in the PMD ruleset XML file.",Add CloseResource rule to detect unclosed resources and specify common close method names in PMD ruleset.,Model 4
"diff --git a/community/cypher/src/main/java/org/neo4j/cypher/javacompat/ExecutionResult.java b/community/cypher/src/main/java/org/neo4j/cypher/javacompat/ExecutionResult.java
index 9ff0e6d3eb6..e87d50727c2 100644
--- a/community/cypher/src/main/java/org/neo4j/cypher/javacompat/ExecutionResult.java
+++ b/community/cypher/src/main/java/org/neo4j/cypher/javacompat/ExecutionResult.java
@@ -54,7 +54,8 @@ public class ExecutionResult implements Iterable<Map<String,Object>>
     }
 
     /**
-     * Provides result objects from a single column of the result set.
+     * Provides result objects from a single column of the result set. This method is best used for
+     * single column results.
      *
      * @param n exact name of the column, as it appeared in the original query
      * @param <T> desired type cast for the result objects",Added javadoc,"""Added note to ExecutionResult's column method to recommend its use for single column results""","""Added documentation to ExecutionResult#column() method to clarify its usage for single column results.""","This commit adds a comment to the `columnAs` method in the `ExecutionResult` class of the `org.neo4j.cypher.javacompat` package in the Neo4j community Cypher project. The comment recommends using the method for single column results and provides a brief description of the method's functionality.

The added comment is:
```python
+     * Provides result objects from a single column of the result set. This method is best used for
+     * single column results.
```
The commit message could be: ""Added recommendation to use ExecutionResult.columnAs method for single column results and provided brief description of method functionality.""","""Updated `columnAs` method documentation to specify its optimal use for single column results.""",Model 4
"diff --git a/DaoTest/src/de/greenrobot/daotest/query/QueryThreadLocalTest.java b/DaoTest/src/de/greenrobot/daotest/query/QueryThreadLocalTest.java
index 614a42a..a44fb2d 100644
--- a/DaoTest/src/de/greenrobot/daotest/query/QueryThreadLocalTest.java
+++ b/DaoTest/src/de/greenrobot/daotest/query/QueryThreadLocalTest.java
@@ -17,12 +17,15 @@
  */
 package de.greenrobot.daotest.query;
 
+import de.greenrobot.dao.DaoException;
 import de.greenrobot.dao.Query;
+import de.greenrobot.dao.QueryBuilder;
 import de.greenrobot.daotest.TestEntity;
 import de.greenrobot.daotest.TestEntityDao.Properties;
 import de.greenrobot.daotest.entity.TestEntityTestBase;
 
 public class QueryThreadLocalTest extends TestEntityTestBase {
+    private Query<TestEntity> queryFromOtherThread;
 
     public void testGetForCurrentThread_SameInstance() {
         Query<TestEntity> query = dao.queryBuilder().build();
@@ -41,5 +44,81 @@ public class QueryThreadLocalTest extends TestEntityTestBase {
         assertEquals(value, (int) entityFor1.getSimpleInteger());
     }
 
-    // TODO more tests
+    public void testGetForCurrentThread_TwoThreads() throws InterruptedException {
+        insert(3);
+        createQueryFromOtherThread();
+        Query<TestEntity> query = queryFromOtherThread.forCurrentThread();
+        assertNotSame(queryFromOtherThread, query);
+        query.setLimit(10);
+        query.setOffset(0);
+        assertEquals(getSimpleInteger(1), (int) query.uniqueOrThrow().getSimpleInteger());
+        int expected = getSimpleInteger(2);
+        query.setParameter(0, expected);
+        assertEquals(expected, (int) query.list().get(0).getSimpleInteger());
+        assertEquals(expected, (int) query.listLazy().get(0).getSimpleInteger());
+        assertEquals(expected, (int) query.listLazyUncached().get(0).getSimpleInteger());
+        assertEquals(expected, (int) query.unique().getSimpleInteger());
+        assertEquals(expected, (int) query.uniqueOrThrow().getSimpleInteger());
+    }
+
+    public void testThrowOutsideOwnerThread() throws InterruptedException {
+        createQueryFromOtherThread();
+        try {
+            queryFromOtherThread.list();
+            fail(""Did not throw"");
+        } catch (DaoException expected) {
+        }
+        try {
+            queryFromOtherThread.listIterator();
+            fail(""Did not throw"");
+        } catch (DaoException expected) {
+        }
+        try {
+            queryFromOtherThread.listLazyUncached();
+            fail(""Did not throw"");
+        } catch (DaoException expected) {
+        }
+        try {
+            queryFromOtherThread.setLimit(2);
+            fail(""Did not throw"");
+        } catch (DaoException expected) {
+        }
+        try {
+            queryFromOtherThread.setOffset(2);
+            fail(""Did not throw"");
+        } catch (DaoException expected) {
+        }
+        try {
+            queryFromOtherThread.setParameter(0, 42);
+            fail(""Did not throw"");
+        } catch (DaoException expected) {
+        }
+        try {
+            queryFromOtherThread.unique();
+            fail(""Did not throw"");
+        } catch (DaoException expected) {
+        }
+        try {
+            queryFromOtherThread.uniqueOrThrow();
+            fail(""Did not throw"");
+        } catch (DaoException expected) {
+        }
+    }
+
+    private void createQueryFromOtherThread() throws InterruptedException {
+        Thread thread = new Thread() {
+
+            @Override
+            public void run() {
+                QueryBuilder<TestEntity> builder = dao.queryBuilder();
+                builder.where(Properties.SimpleInteger.eq(getSimpleInteger(1)));
+                builder.limit(10).offset(20);
+                queryFromOtherThread = builder.build();
+            }
+        };
+        thread.start();
+        thread.join();
+",Added second thread tests to QueryThreadLocalTest,"""Added tests for QueryThreadLocal behavior in multi-threaded environment""","""Added tests for thread safety of Query instances""","""Added more tests to QueryThreadLocalTest and imported necessary classes""

Here's a breakdown of the changes:

1. Imported new classes: `de.greenrobot.dao.DaoException` and `de.greenrobot.dao.QueryBuilder`.

2. Added a new instance variable `private Query<TestEntity> queryFromOtherThread;`.

3. Added two new test methods: `testGetForCurrentThread_TwoThreads()` and `testThrowOutsideOwnerThread()`. These methods test the behavior of the `Query` class when used with multiple threads.

4. Added a new utility method `createQueryFromOtherThread()` which is used by the new test methods to create a `Query` instance in a separate thread.

5. Added a TODO comment in the original version of the code, indicating that more tests were planned. This comment has been removed in the new version, as the planned tests have been added.","""Added tests for Query handling across threads, ensuring expected exceptions are thrown and proper query results retrieved.""",Model 1
"diff --git a/pom.xml b/pom.xml
index 02c54eecc14..667113fbce8 100644
--- a/pom.xml
+++ b/pom.xml
@@ -1183,7 +1183,7 @@
         <equinox.osgi.version>3.10.2.v20150203-1939</equinox.osgi.version>
         <equinox.osgi.services.version>3.4.0.v20140312-2051</equinox.osgi.services.version>
         <carbon.kernel.version>5.1.0</carbon.kernel.version>
-        <transport.http.version>6.0.81</transport.http.version>
+        <transport.http.version>6.0.84</transport.http.version>
         <carbon.messaging.version>2.3.7</carbon.messaging.version>
         <carbon.deployment.version>5.0.0</carbon.deployment.version>
         <carbon.config.version>2.1.2</carbon.config.version>",Bump the transport version,"""Update transport.http.version to 6.0.84""","""Updated transport.http.version to 6.0.84""","""Updating transport.http.version from 6.0.81 to 6.0.84""",Updated `transport.http.version` from 6.0.81 to 6.0.84 in pom.xml to ensure compatibility and security patches.,Model 1
"diff --git a/querydsl-hibernate-search/src/main/java/com/mysema/query/search/LuceneQuery.java b/querydsl-hibernate-search/src/main/java/com/mysema/query/search/LuceneQuery.java
index 3f319d48f..f7651a422 100644
--- a/querydsl-hibernate-search/src/main/java/com/mysema/query/search/LuceneQuery.java
+++ b/querydsl-hibernate-search/src/main/java/com/mysema/query/search/LuceneQuery.java
@@ -11,7 +11,6 @@ import com.mysema.query.QueryModifiers;
 import com.mysema.query.SimpleProjectable;
 import com.mysema.query.SimpleQuery;
 import com.mysema.query.support.QueryMixin;
-import com.mysema.query.support.SimpleQueryAdapter;
 import com.mysema.query.types.OrderSpecifier;
 import com.mysema.query.types.expr.EBoolean;
 import com.mysema.query.types.path.Path;",organized imports,"""Remove unused import of SimpleQueryAdapter in LuceneQuery.java""","""Remove unused import from LuceneQuery.java""","""Remove import of SimpleQueryAdapter in LuceneQuery.java""",Remove unnecessary import SimpleQueryAdapter from LuceneQuery.java in querydsl-hibernate-search.,Model 4
"diff --git a/src/gwt/acesupport/acemixins/token_tooltip.js b/src/gwt/acesupport/acemixins/token_tooltip.js
new file mode 100644
index 0000000000..f77a3fe9ec
--- /dev/null
+++ b/src/gwt/acesupport/acemixins/token_tooltip.js
@@ -0,0 +1,155 @@
+/* ***** BEGIN LICENSE BLOCK *****
+ * Distributed under the BSD license:
+ *
+ * Copyright (c) 2010, Ajax.org B.V.
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Ajax.org B.V. nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS"" AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL AJAX.ORG B.V. BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * ***** END LICENSE BLOCK ***** */
+
+define(""ace/token_tooltip"", [""require"", ""exports"", ""module""], function(require, exports, module) {
+
+var dom = require(""ace/lib/dom"");
+var oop = require(""ace/lib/oop"");
+var event = require(""ace/lib/event"");
+var Range = require(""ace/range"").Range;
+var Tooltip = require(""ace/tooltip"").Tooltip;
+
+function TokenTooltip (editor) {
+    if (editor.tokenTooltip)
+        return;
+    Tooltip.call(this, editor.container);
+    editor.tokenTooltip = this;
+    this.editor = editor;
+
+    this.update = this.update.bind(this);
+    this.onMouseMove = this.onMouseMove.bind(this);
+    this.onMouseOut = this.onMouseOut.bind(this);
+    event.addListener(editor.renderer.scroller, ""mousemove"", this.onMouseMove);
+    event.addListener(editor.renderer.content, ""mouseout"", this.onMouseOut);
+}
+
+oop.inherits(TokenTooltip, Tooltip);
+
+(function(){
+    this.token = {};
+    this.range = new Range();
+    
+    this.update = function() {
+        this.$timer = null;
+        
+        var r = this.editor.renderer;
+        if (this.lastT - (r.timeStamp || 0) > 1000) {
+            r.rect = null;
+            r.timeStamp = this.lastT;
+            this.maxHeight = window.innerHeight;
+            this.maxWidth = window.innerWidth;
+        }
+
+        var canvasPos = r.rect || (r.rect = r.scroller.getBoundingClientRect());
+        var offset = (this.x + r.scrollLeft - canvasPos.left - r.$padding) / r.characterWidth;
+        var row = Math.floor((this.y + r.scrollTop - canvasPos.top) / r.lineHeight);
+        var col = Math.round(offset);
+
+        var screenPos = {row: row, column: col, side: offset - col > 0 ? 1 : -1};
+        var session = this.editor.session;
+        var docPos = session.screenToDocumentPosition(screenPos.row, screenPos.column);
+        var token = session.getTokenAt(docPos.row, docPos.column);
+
+        if (!token && !session.getLine(docPos.row)) {
+            token = {
+                type: """",
+                value: """",
+                state: session.bgTokenizer.getState(0)
+            };
+        }
+        if (!token) {
+            session.removeMarker(this.marker);
+            this.hide();
+            return;
+        }
+
+        var tokenText = token.type;
+        if (token.state)
+            tokenText += ""|"" + token.state;
+        if (token.merge)
+            tokenText += ""\n  merge"";
+        if (token.stateTransitions)
+            tokenText += ""\n  "" + token.stateTransitions.join(""\n  "");
+
+        if (this.tokenText != tokenText) {
+            this.setText(tokenText);
+            this.width = this.getWidth();
+            this.height = this.getHeight();
+            this.tokenText = tokenText;
+        }
+
+        this.show(null, this.x, this.y);
+
+        this.token = token;
+        session.removeMarker(this.marker);
+        this.range = new Range(docPos.row, token.start, docPos.row, token.start + token.value.length);
+        this.marker = session.addMarker(this.range, ""ace_bracket"", ""text"");
+    };
+    
+    this.onMouseMove = function(e) {
+        this.x = e.clientX;
+        this.y = e.clientY;
+        if (this.isOpen) {
+            this.lastT = e.timeStamp;
+            this.setPosition(this.x, this.y);
+        }
+        if (!this.$timer)
+            this.$timer = setTimeout(this.update, 100);
+    };
+
+    this.onMouseOut = function(e) {
+        if (e && e.currentTarget.contains(e.relatedTarget))
+            return;
+        this.hide();
+        this.editor.session.removeMarker(this.marker);
+        this.$timer = clearTimeout(this.$timer);
+    };
+
+    this.setPosition = function(x, y) {
+        if (x + 10 + this.width > this.maxWidth)
+            x = window.innerWidth - this.width - 10;
+        if (y > window.innerHeight * 0.75 || y + 20 + this.height > this.maxHeight)
+            y = y - this.height - 30;
+
+        Tooltip.prototype.setPosition.call(this, x + 10, y + 20);
+    };
+
+    this.destroy = function() {
+        this.onMouseOut();
+        event.removeListener(this.editor.renderer.scroller, ""mousemove"", this.onMouseMove);
+        event.removeListener(this.editor.renderer.content, ""mouseout"", this.onMouseOut);
+        delete this.editor.tokenTooltip;
+    };
+
+}).call(TokenTooltip.prototype);
+
+exports.TokenTooltip = TokenTooltip;
+
+});
diff --git a/src/gwt/src/org/rstudio/studio/client/workbench/commands/Commands.cmd.xml b/src/gwt/src/org/rstudio/studio/client/workbench/commands/Commands.cmd.xml
index 0207d524cc..9b6f5e46fc 100644
--- a/src/gwt/src/org/rstudio/studio/client/workbench/commands/Commands.cmd.xml
+++ b/src/gwt/src/org/rstudio/studio/client/workbench/commands/Commands.cmd.xml
@@ -425,6 +425,8 @@ well as menu structures (for main menu and popup menus).
             <cmd refid=""updateCredentials""/>
             <cmd refid=""diagnosticsReport""/>
             <separator/>
+            <cmd refid=""toggleEditorTokenInfo""/>
+            <separator/>
             <cmd refid=""debugDumpContents""/>
             <cmd refid=""debugImportDump""/>
             <cmd refid=""raiseException""/>
@@ -2518,5 +2520,9 @@ well as menu structures (for main menu and popup menus).
         desc=""Connect or disconnect accounts""
         visible=""false""
         rebindable=""false""/>
+        
+   <cmd id=""toggleEditorTokenInfo""
+        menuLabel=""Toggle Editor Token Information""
+        rebindable=""false""/>
 
 </commands>
diff --git a/src/gwt/src/org/rstudio/studio/client/workbench/commands/Commands.java b/src/gwt/src/org/rstudio/studio/client/workbench/commands/Commands.java
index 67cb2db8b1..d0959ad5ad 100644
--- a/src/gwt/src/org/rstudio/studio/client/workbench/commands/Commands.java
+++ b/src/gwt/src/org/rstudio/studio/client/workbench/commands/Commands.java
@@ -437,6 +437,7 @@ public abstract class
    public abstract AppCommand layoutConsoleOnRight();
    public abstract AppCommand paneLayout();
    public abstract AppCommand maximizeConsole();
+   public abstract AppCommand toggleEditorTokenInfo();
    
    public static final String KEYBINDINGS_PATH =
          ""~/.R/keybindings/rstudio_commands.json"";
diff --git a/src/gwt/src/org/rstudio/studio/client/workbench/views/source/Source.java b/src/gwt/src/org/rstudio/studio/client/workbench/views/source/Source.java
index e2c54c2487..025f46f211 100644
--- a/src/gwt/src/org/rstudio/studio/client/workbench/views/source/Source.java
+++ b/src/gwt/src/org/rstudio/studio/client/workbench/views/source/Source.java
@@ -940,7 +940,6 @@ public class Source implements InsertSourceHandler,
             });
    }
    
-
    @Handler
    public void onNewSourceDoc()
    {
diff --git a/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/AceEditor.java b/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/AceEditor.java
index 96c09613b3..35a589bc9d 100644
--- a/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/AceEditor.java
+++ b/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/AceEditor.java
@@ -2799,6 +2799,20 @@ public class AceEditor implements DocDisplay,
       return snippets_.onInsertSnippet();
    }
    
+   public void toggleTokenInfo()
+   {
+      toggleTokenInfo(widget_.getEditor());
+   }
+   
+   private static final native void toggleTokenInfo(AceEditorNative editor) /*-{
+      if (editor.tokenTooltip && editor.tokenTooltip.destroy) {
+         editor.tokenTooltip.destroy();
+      } else {
+         var TokenTooltip = $wnd.require(""ace/token_tooltip"").TokenTooltip;
+         editor.tokenTooltip = new TokenTooltip(editor);
+      }
+   }-*/;
+   
    private static final int DEBUG_CONTEXT_LINES = 2;
    private final HandlerManager handlers_ = new HandlerManager(this);
    private final AceEditorWidget widget_;
diff --git a/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/DocDisplay.java b/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/DocDisplay.java
index 0d9fba5daf..13dc4a1176 100644
--- a/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/DocDisplay.java
+++ b/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/DocDisplay.java
@@ -345,4 +345,6 @@ public interface DocDisplay extends HasValueChangeHandlers<Void>,
    
    void goToLineStart();
    void goToLineEnd();
+   
+   void toggleTokenInfo();
 }
diff --git a/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/TextEditingTarget.java b/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/TextEditingTarget.java
index c509ca2afc..6b376ac6bf 100644
--- a/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/TextEditingTarget.java
+++ b/src/gwt/src/org/rstudio/studio/client/workbench/views/source/editors/text/TextEditingTarget.java
@@ -5013,6 +5013,12 @@ public class TextEditingTarget implements
       }
    }
    
+   @Handler
+   void onToggleEditorTokenInfo()
+   {
+      docDisplay_.toggleTokenInfo();
+   }
+   
    boolean useScopeTreeFolding()
    {
       return docDisplay_.hasScopeTree();",add ( debug ) command to show toke information,"""Added token tooltip feature to AceEditor""",Added token information tooltip to Ace editor and corresponding menu item.,"""Added token tooltip functionality to AceEditor in RStudio""

This commit adds a new feature to the AceEditor in RStudio, which displays token information when the mouse hovers over a token in the editor. The feature is implemented using the `ace/token_tooltip` module, which is a dependency of AceEditor.

The `TokenTooltip` class is defined in the `token_tooltip.js` file, and it extends the `Tooltip` class from the `ace/tooltip` module. The `TokenTooltip` class listens for `mousemove` events on the editor's renderer, and updates the tooltip's position and content based on the current mouse position. It also listens for `mouseout` events to hide the tooltip when the mouse leaves the editor's content area.

The `TokenTooltip` class is used by the `AceEditor` class in the `AceEditor.java` file. The `toggleTokenInfo()` method is added to the `AceEditor` class, which toggles the token tooltip functionality on or off. When the method is called, it checks if the `tokenTooltip` property is already defined on the editor's `AceEditorNative` object. If it is, the `destroy()` method is called on the `tokenTooltip` object to remove it. If it is not, a new `TokenTooltip` object is created and assigned to the `tokenTooltip` property.

The `toggleTokenInfo()` method is also added to the `DocDisplay` interface in the `DocDisplay.java` file, which is implemented by the `AceEditor` class. This allows other classes that depend on the `DocDisplay` interface to toggle the token tooltip functionality.

Finally, the `Commands.java` and `Commands.cmd.xml` files are updated to add a new command for toggling the token tooltip functionality. The command is added to the ""Tools"" menu, and is assigned the keyboard shortcut ""Ctrl+Alt+T"".","Introduce token tooltips in Ace editor, adding toggle command and integrating with existing command structure.",Model 2
"diff --git a/src/main/java/org/tron/core/capsule/AccountCapsule.java b/src/main/java/org/tron/core/capsule/AccountCapsule.java
index 623998d0b..0348d4ed2 100644
--- a/src/main/java/org/tron/core/capsule/AccountCapsule.java
+++ b/src/main/java/org/tron/core/capsule/AccountCapsule.java
@@ -329,6 +329,14 @@ public class AccountCapsule implements ProtoCapsule<Account>, Comparable<Account
     return getInstance().getFrozenList();
   }
 
+  public int getFrozenSupplyCount() {
+    return getInstance().getFrozenSupplyCount();
+  }
+
+  public List<Frozen> getFrozenSupplyList() {
+    return getInstance().getFrozenSupplyList();
+  }
+
   public long getFrozenBalance() {
     List<Frozen> frozenList = getFrozenList();
     final long[] frozenBalance = {0};",add supply interface in AccountCapsule,"""Added methods to retrieve frozen supply count and list in AccountCapsule""","Added methods to retrieve frozen supply information

This commit message is concise and accurately describes the changes made in the commit. It mentions the addition of new methods to retrieve frozen supply information, which is in line with the changes shown in the diff.","""Added getFrozenSupplyCount and getFrozenSupplyList methods to AccountCapsule class""

This commit message describes the change made in the code snippet provided, where two new methods `getFrozenSupplyCount()` and `getFrozenSupplyList()` have been added to the `AccountCapsule` class.",Added methods to retrieve frozen supply count and list in AccountCapsule.,Model 4
"diff --git a/engine/src/main/java/org/terasology/rendering/assets/mesh/ObjMeshFormat.java b/engine/src/main/java/org/terasology/rendering/assets/mesh/ObjMeshFormat.java
index 1c35cdc89..bc33b2283 100644
--- a/engine/src/main/java/org/terasology/rendering/assets/mesh/ObjMeshFormat.java
+++ b/engine/src/main/java/org/terasology/rendering/assets/mesh/ObjMeshFormat.java
@@ -69,10 +69,10 @@ public MeshData load(ResourceUrn urn, List<AssetDataFile> inputs) throws IOExcep
             if (data.getVertices() == null) {
                 throw new IOException(""No vertices define"");
             }
-            //if (data.getNormals() == null || data.getNormals().size() != data.getVertices().size()) {
-            //    throw new IOException(""The number of normals does not match the number of vertices."");
-            //}
-            if (data.getTexCoord0() == null || data.getTexCoord0().size() / 2 != data.getVertices().size() / 3) {
+            if (!data.getNormals().isEmpty() && data.getNormals().size() != data.getVertices().size()) {
+                throw new IOException(""The number of normals does not match the number of vertices."");
+            }
+            if (!data.getTexCoord0().isEmpty() && data.getTexCoord0().size() / 2 != data.getVertices().size() / 3) {
                 throw new IOException(""The number of tex coords does not match the number of vertices."");
             }
 ",Allow obj meshes without texture coords .,"""Relax OBJ mesh format validation to allow missing normals and tex coords""","""Fixed vertex data validation in ObjMeshFormat to check for missing normals and incorrect tex coord count.""","""Updated ObjMeshFormat to allow meshes without normals or texture coordinates""

This commit removes the requirement for normals and texture coordinates to be present in the OBJ mesh data. It also checks if the size of the normals or texture coordinates array matches the size of the vertices array only if they are not empty. This allows for the loading of OBJ meshes that do not have normals or texture coordinates defined.","""Validate normals and texture coordinates only if they are present in ObjMeshFormat.java, fixed validation logic.""",Model 1
"diff --git a/src/net/java/sip/communicator/impl/callhistory/CallRecordImpl.java b/src/net/java/sip/communicator/impl/callhistory/CallRecordImpl.java
index 4fb410ad3..c52728a86 100644
--- a/src/net/java/sip/communicator/impl/callhistory/CallRecordImpl.java
+++ b/src/net/java/sip/communicator/impl/callhistory/CallRecordImpl.java
@@ -53,7 +53,7 @@ public Call getSourceCall()
 
     /**
      * Set the time when the call finishes
-     * If some participant has no end Time set we set it also
+     * If some peer has no end Time set we set it also
      * @param endTime Date
      */
     public void setEndTime(Date endTime)
diff --git a/src/net/java/sip/communicator/impl/gui/main/call/CallManager.java b/src/net/java/sip/communicator/impl/gui/main/call/CallManager.java
index e4b98ba32..ccde718cc 100644
--- a/src/net/java/sip/communicator/impl/gui/main/call/CallManager.java
+++ b/src/net/java/sip/communicator/impl/gui/main/call/CallManager.java
@@ -280,7 +280,7 @@ public void run()
 
 
     /**
-     * Answers all call participants in the given call.
+     * Answers all call peers in the given call.
      */
     private static class AnswerCallThread
         extends Thread
@@ -295,22 +295,22 @@ public AnswerCallThread(Call call)
         public void run()
         {
             ProtocolProviderService pps = call.getProtocolProvider();
-            Iterator<CallPeer> participants = call.getCallPeers();
+            Iterator<CallPeer> peers = call.getCallPeers();
 
-            while (participants.hasNext())
+            while (peers.hasNext())
             {
-                CallPeer participant = participants.next();
+                CallPeer peer = peers.next();
                 OperationSetBasicTelephony telephony =
                     (OperationSetBasicTelephony) pps
                         .getOperationSet(OperationSetBasicTelephony.class);
 
                 try
                 {
-                    telephony.answerCallPeer(participant);
+                    telephony.answerCallPeer(peer);
                 }
                 catch (OperationFailedException e)
                 {
-                    logger.error(""Could not answer to : "" + participant
+                    logger.error(""Could not answer to : "" + peer
                         + "" caused by the following exception: "" + e);
                 }
             }
@@ -318,7 +318,7 @@ public void run()
     }
 
     /**
-     * Hangups all call participants in the given call.
+     * Hangups all call peers in the given call.
      */
     private static class HangupCallThread
         extends Thread
@@ -333,11 +333,11 @@ public HangupCallThread(Call call)
         public void run()
         {
             ProtocolProviderService pps = call.getProtocolProvider();
-            Iterator<CallPeer> participants = call.getCallPeers();
+            Iterator<CallPeer> peers = call.getCallPeers();
 
-            while (participants.hasNext())
+            while (peers.hasNext())
             {
-                CallPeer participant = participants.next();
+                CallPeer participant = peers.next();
                 OperationSetBasicTelephony telephony =
                     (OperationSetBasicTelephony) pps
                         .getOperationSet(OperationSetBasicTelephony.class);
diff --git a/src/net/java/sip/communicator/impl/gui/main/call/ReceivedCallDialog.java b/src/net/java/sip/communicator/impl/gui/main/call/ReceivedCallDialog.java
index b14c8cc9a..0dbb05f78 100644
--- a/src/net/java/sip/communicator/impl/gui/main/call/ReceivedCallDialog.java
+++ b/src/net/java/sip/communicator/impl/gui/main/call/ReceivedCallDialog.java
@@ -121,41 +121,40 @@ private void initComponents()
      */
     private void initCallLabel(JLabel callLabel)
     {
-        Iterator<CallPeer> participantsIter
-            = incomingCall.getCallPeers();
+        Iterator<CallPeer> peersIter = incomingCall.getCallPeers();
 
-        boolean hasMoreParticipants = false;
+        boolean hasMorePeers = false;
         String text = """";
 
         ImageIcon imageIcon =
             ImageUtils.getScaledRoundedIcon(ImageLoader
                 .getImage(ImageLoader.DEFAULT_USER_PHOTO), 40, 45);
 
-        while (participantsIter.hasNext())
+        while (peersIter.hasNext())
         {
-            CallPeer participant = participantsIter.next();
+            CallPeer peer = peersIter.next();
 
-            // More participants.
-            if (participantsIter.hasNext())
+            // More peers.
+            if (peersIter.hasNext())
             {
                 text = callLabel.getText()
-                    + participant.getDisplayName() + "", "";
+                    + peer.getDisplayName() + "", "";
 
-                hasMoreParticipants = true;
+                hasMorePeers = true;
             }
-            // Only one participant.
+            // Only one peer.
             else
             {
                 text = callLabel.getText()
-                    + participant.getDisplayName()
+                    + peer.getDisplayName()
                     + "" ""
                     + GuiActivator.getResources().getI18NString(""service.gui.IS_CALLING"");
 
-                imageIcon = getParticipantImage(participant);
+                imageIcon = getPeerImage(peer);
             }
         }
 
-        if (hasMoreParticipants)
+        if (hasMorePeers)
             text += GuiActivator.getResources()
                 .getI18NString(""service.gui.ARE_CALLING"");
 
@@ -186,21 +185,21 @@ else if (buttonName.equals(HANGUP_BUTTON))
     }
 
     /**
-     * Returns the participant image.
+     * Returns the peer image.
      *
-     * @param participant The call participant, for which we're returning an
+     * @param peer The call peer, for which we're returning an
      * image.
-     * @return the participant image.
+     * @return the peer image.
      */
-    private ImageIcon getParticipantImage(CallPeer participant)
+    private ImageIcon getPeerImage(CallPeer peer)
     {
      ",Renames occurrences of callParticipant to callPeer so that it would better reflect our new Call architecture that also includes conferencing and ConferenceMembers,"""Replace 'participant' with 'peer' in call-related classes for consistency""","""Consistent use of 'peer' terminology in call history and call management.""","""Updated terminology from 'participant' to 'peer' in CallRecordImpl, CallManager, and ReceivedCallDialog""","""Refactor: Replaced 'participant' with 'peer' for consistency in naming throughout the call management classes.""",Model 2
"diff --git a/do-release.sh b/do-release.sh
index f276238301..d1efe7f60d 100755
--- a/do-release.sh
+++ b/do-release.sh
@@ -113,7 +113,10 @@ echo
 echo ""Updated stats in release notes:""
 echo ""$STATS""
 echo
+echo ""Please verify docs/pages/release_notes.md""
 echo
+echo ""Press enter to continue...""
+read
 
 # install bundles needed for rendering release notes
 bundle install --with=release_notes_preprocessing --path vendor/bundle",Add a verify step in do - release . sh,"""Add confirmation step before rendering release notes""","""Added verification step for release notes and added prompt to continue""","Added prompts to verify release notes and press enter to continue in do-release.sh

This commit adds two echo statements and a read statement in the do-release.sh script. The first echo statement prompts the user to verify the release notes located in docs/pages/release\_notes.md. The second echo statement asks the user to press enter to continue. The read statement pauses the script execution until the user presses enter.

Additionally, there is a comment indicating that the script installs bundles needed for rendering release notes using the command ""bundle install --with=release\_notes\_preprocessing --path vendor/bundle"". This comment was already present in the original file and was not added in this commit.",Add release notes verification and prompt before continuing the release script process.,Model 3
"diff --git a/src/main/java/hex/FrameTask.java b/src/main/java/hex/FrameTask.java
index a7b161c7e..f6e459b47 100644
--- a/src/main/java/hex/FrameTask.java
+++ b/src/main/java/hex/FrameTask.java
@@ -23,6 +23,8 @@ public abstract class FrameTask<T extends FrameTask<T>> extends MRTask2<T>{
   protected float _useFraction = 1.0f;
   protected boolean _shuffle = false;
 
+  protected boolean skipMissing() { return true; }
+
   public FrameTask(Key jobKey, DataInfo dinfo) {
     this(jobKey,dinfo,null);
   }
@@ -556,10 +558,11 @@ public abstract class FrameTask<T extends FrameTask<T>> extends MRTask2<T>{
         final long lr = r + chunks[0]._start;
         if ((_dinfo._nfolds > 0 && (lr % _dinfo._nfolds) == _dinfo._foldId)
                 || (skip_rng != null && skip_rng.nextFloat() > _useFraction))continue;
-        for(Chunk c:chunks)if(c.isNA0(r))continue OUTER; // skip rows with NAs!
+        for(Chunk c:chunks)if(skipMissing() && c.isNA0(r))continue OUTER; // skip rows with NAs!
         ++num_processed_rows;
         int i = 0, ncats = 0;
         for(; i < _dinfo._cats; ++i){
+          assert(!chunks[i].isNA0(r));
           int c = (int)chunks[i].at80(r);
           if(_dinfo._catLvls != null){ // some levels are ignored?
             c = Arrays.binarySearch(_dinfo._catLvls[i],c);
@@ -572,13 +575,14 @@ public abstract class FrameTask<T extends FrameTask<T>> extends MRTask2<T>{
         }
         final int n = chunks.length-_dinfo._responses;
         for(;i < n;++i){
-          double d = chunks[i].at0(r);
+          double d = chunks[i].at0(r); //can be NA if skipMissing() == false
           if(_dinfo._normMul != null) d = (d - _dinfo._normSub[i-_dinfo._cats])*_dinfo._normMul[i-_dinfo._cats];
           nums[i-_dinfo._cats] = d;
         }
         for(i = 0; i < _dinfo._responses; ++i) {
           response[i] = chunks[chunks.length-_dinfo._responses + i].at0(r);
           if (_dinfo._normRespMul != null) response[i] = (response[i] - _dinfo._normRespSub[i])*_dinfo._normRespMul[i];
+          if(Double.isNaN(response[i]))continue OUTER; // skip rows without a valid response (no supervised training possible)
         }
         long seed = offset + rrr*(end-start) + r;
         if (outputs != null && outputs.length > 0)
diff --git a/src/main/java/hex/deeplearning/DeepLearningTask.java b/src/main/java/hex/deeplearning/DeepLearningTask.java
index 992003d6a..230c93319 100644
--- a/src/main/java/hex/deeplearning/DeepLearningTask.java
+++ b/src/main/java/hex/deeplearning/DeepLearningTask.java
@@ -19,6 +19,8 @@ public class DeepLearningTask extends FrameTask<DeepLearningTask> {
 
   int _chunk_node_count = 1;
 
+  @Override protected boolean skipMissing() { return false; }
+
   public DeepLearningTask(hex.deeplearning.DeepLearningModel.DeepLearningModelInfo input, float fraction){this(input,fraction,null);}
   private DeepLearningTask(hex.deeplearning.DeepLearningModel.DeepLearningModelInfo input, float fraction, H2OCountedCompleter cmp){
     super(input.get_params().self(),input.data_info(),cmp);
@@ -167,8 +169,13 @@ public class DeepLearningTask extends FrameTask<DeepLearningTask> {
           if (training) {
             for (int i = 1; i < neurons.length - 1; i++)
               Arrays.fill(neurons[i]._e.raw(), 0);
-            assert ((double) (int) responses[0] == responses[0]);
-            final int target_label = (int) responses[0];
+            int target_label;
+            if (Double.isNaN(responses[0])) { //missing response
+              target_label = Neurons.missing_int_value;
+            } else {
+              assert ((double) (int) responses[0] == responses[0]); //classification -> integer labels expected
+              target_label = (int) responses[0];
+            }
             ((Neurons.Softmax) neurons[neurons.length - 1]).bprop(target_label);
           }
         } else {
@@ -176,7 +183,12 @@ public class DeepLearningTask extends FrameTask<DeepLearningTask> {
           if (training) {
             for (int i = 1; i < neurons.length - 1; i++)
               Arrays.fill(neurons[i]._e.raw(), 0);
-            final float target_value = (float) responses[0];
+            float target_value;
+            if (Double.isNaN(responses[0])) { //missing response
+              target_value = Neurons.missing_real_value;
+            } else {
+              target_value = (float) responses[0];
+            }
             ((Neurons.Linear) neurons[neurons.length - 1]).bprop(target_value);
           }
         }
diff --git a/src/main/java/hex/deeplearning/Neurons.java b/src/main/java/hex/deeplearning/Neurons.java
index 4050c6967..3eee80643 100644
--- a/src/main/java/hex/deeplearning/Neurons.java
+++ b/src/main/java/hex/deeplearning/Neurons.java
@@ -5,7 +5,6 @@ import hex.deeplearning.DeepLearning.Loss;
 import water.Iced;
 import water.MemoryManager;
 import water.api.Request.API;
-import water.util.Log;
 import water.util.Utils;
 
 import java.util.Arrays;
@@ -89,16 +88,8 @@ public abstract class Neurons {
 
   public DenseVector _avg_a;
 
-//  /**
-//   * We need a way to encode a missing value in the neural net forward/back-propagation scheme.
-//   * For simplicity and performance, we simply use the largest values to encode a missing value.
-//   * If we run into exactly one of those values with regular neural net updates, then we're very
-//   * likely also running into overflow problems, which will trigger a NaN somewhere, which will be
-//   * caught and lead to automatic job cancellation.
-//   */
-//  public static final int missing_int_value = Integer.MAX_VALUE; //encode missing label or target
-//  public static final double missing_double_value = Double.MAX_VALUE; //encode missing input
-
+  public static final int missing_int_value = Integer.MAX_VALUE; //encode missing label
+  public static final Float missing_real_value = Float.NaN; //encode missing regression target
 
   /**
    * Helper to check sanity of Neuron layers
@@ -928,7 +919,7 @@ public abstract class Neurons {
      * @param target actual class label
      */
     protected void bprop(int target) {
-//      if (target == missing_int_value) return; //ignore missing response values
+      assert (target != missing_int_value); // no correction of weights/biases for missing label
       float m = momentum();
       float r = _minfo.adaDelta() ? 0 : rate(_minfo.get_processed_total()) * (1f - m);
       float g; //partial derivative dE/dy * dy/dnet
@@ -966,7 +957,7 @@ public abstract class Neurons {
      * @param target floating-point target value
      */
     protected void bprop(float target) {
-//      if (target == missing_double_value) return;
+      assert (target != missing_real_value);
       if (params.loss != Loss.MeanSquare) throw new UnsupportedOperationException(""Regression is only implemented for MeanSquare error."");
       final int row = 0;
       // Computing partial derivative: dE/dnet = dE/dy * dy/dnet = dE/dy * 1",Add support for missing values in DL ( via mean imputation ) .,"""Handle missing values in FrameTask and DeepLearningTask""","""Added skipMissing() method to FrameTask and DeepLearningTask, and updated handling of missing values in Neurons and DeepLearningTask.""","The commit message should be:

""Added method to skip missing values in FrameTask and handling for missing responses in DeepLearningTask and Neurons. Also added assertions to check for missing values in DeepLearningTask and Neurons.""

This commit introduces a new method `skipMissing()` in the `FrameTask` class to allow subclasses to decide whether to skip rows with missing values or not. It also adds handling for missing responses in the `DeepLearningTask` and `Neurons` classes. Furthermore, assertions are added to check for missing values in these classes to ensure that the code behaves as expected.","The commit message is:

""Add handling for missing values in FrameTask and DeepLearningTask, including skip logic and missing value encodings.""",Model 2
"diff --git a/devtools/gradle/src/functionalTest/java/io/quarkus/gradle/devmode/DotEnvQuarkusDevModeConfigurationTest.java b/devtools/gradle/src/functionalTest/java/io/quarkus/gradle/devmode/DotEnvQuarkusDevModeConfigurationTest.java
new file mode 100644
index 00000000000..5a23dcb26bb
--- /dev/null
+++ b/devtools/gradle/src/functionalTest/java/io/quarkus/gradle/devmode/DotEnvQuarkusDevModeConfigurationTest.java
@@ -0,0 +1,15 @@
+package io.quarkus.gradle.devmode;
+
+import static org.assertj.core.api.Assertions.assertThat;
+
+public class DotEnvQuarkusDevModeConfigurationTest extends QuarkusDevGradleTestBase {
+    @Override
+    protected String projectDirectoryName() {
+        return ""dotenv-config-java-module"";
+    }
+
+    @Override
+    protected void testDevMode() throws Exception {
+        assertThat(getHttpResponse(""/hello"")).contains(""hey"");
+    }
+}
diff --git a/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/.env b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/.env
new file mode 100644
index 00000000000..c1f759725f0
--- /dev/null
+++ b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/.env
@@ -0,0 +1 @@
+GREETING_MESSAGE=hey
diff --git a/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/build.gradle b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/build.gradle
new file mode 100644
index 00000000000..183d880b88a
--- /dev/null
+++ b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/build.gradle
@@ -0,0 +1,33 @@
+plugins {
+    id 'java'
+    id 'io.quarkus'
+}
+
+repositories {
+     mavenLocal()
+     mavenCentral()
+}
+
+dependencies {
+    implementation enforcedPlatform(""${quarkusPlatformGroupId}:${quarkusPlatformArtifactId}:${quarkusPlatformVersion}"")
+    implementation 'io.quarkus:quarkus-resteasy'
+
+    testImplementation 'io.quarkus:quarkus-junit5'
+    testImplementation 'io.rest-assured:rest-assured'
+}
+
+group 'org.acme'
+version '1.0.0-SNAPSHOT'
+
+compileJava {
+    options.encoding = 'UTF-8'
+    options.compilerArgs << '-parameters'
+}
+
+compileTestJava {
+    options.encoding = 'UTF-8'
+}
+
+quarkusDev {
+    workingDir = System.getProperty(""java.io.tmpdir"")
+}
diff --git a/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/gradle.properties b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/gradle.properties
new file mode 100644
index 00000000000..ec2b6ef199c
--- /dev/null
+++ b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/gradle.properties
@@ -0,0 +1,2 @@
+quarkusPlatformArtifactId=quarkus-bom
+quarkusPlatformGroupId=io.quarkus
diff --git a/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/settings.gradle b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/settings.gradle
new file mode 100644
index 00000000000..554eb4c4098
--- /dev/null
+++ b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/settings.gradle
@@ -0,0 +1,11 @@
+pluginManagement {
+    repositories {
+        mavenLocal()
+        mavenCentral()
+        gradlePluginPortal()
+    }
+    plugins {
+      id 'io.quarkus' version ""${quarkusPluginVersion}""
+    }
+}
+rootProject.name='code-with-quarkus'
diff --git a/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/src/main/java/org/acme/GreetingResource.java b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/src/main/java/org/acme/GreetingResource.java
new file mode 100644
index 00000000000..6ac027d26dc
--- /dev/null
+++ b/devtools/gradle/src/functionalTest/resources/dotenv-config-java-module/src/main/java/org/acme/GreetingResource.java
@@ -0,0 +1,21 @@
+package org.acme;
+
+import javax.ws.rs.GET;
+import javax.ws.rs.Path;
+import javax.ws.rs.Produces;
+import javax.ws.rs.core.MediaType;
+
+import org.eclipse.microprofile.config.inject.ConfigProperty;
+
+@Path(""/hello"")
+public class GreetingResource {
+
+    @ConfigProperty(name = ""greeting.message"")
+    String message;
+
+    @GET
+    @Produces(MediaType.TEXT_PLAIN)
+    public String hello() {
+        return message;
+    }
+}",Add test to ensure that . env works in Gradle .,"""Add functional test for Quarkus dev mode with .env configuration""","""Add test for Quarkus Dev Mode configuration with .env file""","""Add functional test for dotenv configuration in Quarkus dev mode""

This commit appears to add a new functional test class `DotEnvQuarkusDevModeConfigurationTest` for testing the dotenv configuration in Quarkus dev mode using Gradle. It also includes a new Gradle project in the `dotenv-config-java-module` directory with an `.env` file containing a single key-value pair for testing. The `build.gradle` file sets up the project with the necessary dependencies and configurations for Quarkus, and the `GreetingResource` class uses the `@ConfigProperty` annotation to inject the value from the `.env` file. The test case in `DotEnvQuarkusDevModeConfigurationTest` verifies that the injected value is correctly used by the application in dev mode.",Add dotenv configuration test for Quarkus Gradle dev mode with GreetingResource endpoint using environment variable.,Model 3
"diff --git a/frontend/server/src/test/resources/inference_open_api.json b/frontend/server/src/test/resources/inference_open_api.json
index e0b601d2..702af168 100644
--- a/frontend/server/src/test/resources/inference_open_api.json
+++ b/frontend/server/src/test/resources/inference_open_api.json
@@ -125,7 +125,7 @@
         }
       }
     },
-    ""/predictions/{model_name}"": {
+    ""/predictions/{model_name}[/{model_version}]"": {
       ""post"": {
         ""description"": ""Predictions entry point for each model. Use OPTIONS method to get detailed model API input and output description."",
         ""operationId"": ""predictions"",
diff --git a/frontend/server/src/test/resources/management_open_api.json b/frontend/server/src/test/resources/management_open_api.json
index 79ff026d..7848c2e9 100644
--- a/frontend/server/src/test/resources/management_open_api.json
+++ b/frontend/server/src/test/resources/management_open_api.json
@@ -448,9 +448,9 @@
         }
       }
     },
-    ""/models/{model_name}"": {
+    ""/models/{model_name}[/{model_version}]"": {
       ""get"": {
-        ""description"": ""Provides detailed information about the specified model."",
+        ""description"": ""Provides detailed information about the specified version of a model. If no version is specified, returns the details of default version. If \""all\"" is specified as version, returns the details about all the versions of the model."",
         ""operationId"": ""describeModel"",
         ""parameters"": [
           {
@@ -461,6 +461,15 @@
             ""schema"": {
               ""type"": ""string""
             }
+          },
+          {
+            ""in"": ""path"",
+            ""name"": ""model_version"",
+            ""description"": ""Version of model to describe."",
+            ""required"": true,
+            ""schema"": {
+              ""type"": ""string""
+            }
           }
         ],
         ""responses"": {
@@ -607,7 +616,7 @@
         }
       },
       ""put"": {
-        ""description"": ""Configure number of workers for a model, This is a asynchronous call by default. Caller need to call describeModel check if the model workers has been changed."",
+        ""description"": ""Configure number of workers for a specified version of a model. If no version is specified, this applies to the default version of the model. This is a asynchronous call by default. Caller need to call describeModel check if the model workers has been changed."",
         ""operationId"": ""setAutoScale"",
         ""parameters"": [
           {
@@ -619,6 +628,15 @@
               ""type"": ""string""
             }
           },
+          {
+            ""in"": ""path"",
+            ""name"": ""model_version"",
+            ""description"": ""Version of model to describe."",
+            ""required"": true,
+            ""schema"": {
+              ""type"": ""string""
+            }
+          },
           {
             ""in"": ""query"",
             ""name"": ""min_worker"",
@@ -818,7 +836,7 @@
         }
       },
       ""delete"": {
-        ""description"": ""Unregister a model from TorchServe. This is an asynchronous call by default. Caller can call listModels to confirm if all the works has be terminated."",
+        ""description"": ""Unregister the specified version of a model from TorchServe. If no version is specified, TorchServe tries to unregister the default version of the model and unregisters it if it is the only version available. This is an asynchronous call by default. Caller can call listModels to confirm if all the works has be terminated."",
         ""operationId"": ""unregisterModel"",
         ""parameters"": [
           {
@@ -830,6 +848,15 @@
               ""type"": ""string""
             }
           },
+          {
+            ""in"": ""path"",
+            ""name"": ""model_version"",
+            ""description"": ""Version of model to unregister."",
+            ""required"": true,
+            ""schema"": {
+              ""type"": ""string""
+            }
+          },
           {
             ""in"": ""query"",
             ""name"": ""synchronous"",
@@ -919,6 +946,35 @@
               }
             }
           },
+          ""400"": {
+            ""description"": ""Model version not found"",
+            ""content"": {
+              ""application/json"": {
+                ""schema"": {
+                  ""type"": ""object"",
+                  ""required"": [
+                    ""code"",
+                    ""type"",
+                    ""message""
+                  ],
+                  ""properties"": {
+                    ""code"": {
+                      ""type"": ""integer"",
+                      ""description"": ""Error code.""
+                    },
+                    ""type"": {
+                      ""type"": ""string"",
+                      ""description"": ""Error type.""
+                    },
+                    ""message"": {
+                      ""type"": ""string"",
+                      ""description"": ""Error message.""
+                    }
+                  }
+                }
+              }
+            }
+          },
           ""408"": {
             ""description"": ""Request Timeout Error"",
             ""content"": {
@@ -979,6 +1035,111 @@
           }
         }
       }
+    },
+    ""/models/{model_name}/{model_version}/set-default"": {
+      ""put"": {
+        ""description"": ""Set default version of a model"",
+        ""operationId"": ""setDefault"",
+        ""parameters"": [
+          {
+         ",updated expected output for UTs,"""Added model versioning support to OpenAPI definitions""

This commit message accurately reflects the changes made in the diff, which include adding model versioning support to various API endpoints in the OpenAPI definitions.","Added support for model versions in OpenAPI definitions

This commit message is concise and accurately describes the changes made in the commit. It mentions the key feature added, which is support for model versions in the OpenAPI definitions.","""Update OpenAPI specifications for model versioning:
- Add model version parameter to the /predictions/{model_name} endpoint in inference_open_api.json
- Add model version parameter to various endpoints in management_open_api.json
- Update descriptions and responses to reflect changes due to model versioning""

Explanation:
The changes made in this commit primarily involve adding a new parameter ""model_version"" to several endpoints in both inference_open_api.json and management_open_api.json. The descriptions and responses have also been updated to reflect the changes brought about by the introduction of model versioning. For instance, the description for the /models/{model_name} GET request has been modified to include version-specific details. Similarly, the descriptions for other endpoints like /models/{model_name} PUT and DELETE requests have been updated to reflect the changes due to model versioning. Additionally, new response codes and their descriptions have been introduced where necessary.","""Add model version handling and detailed descriptions for API endpoints in inference_open_api.json and management_open_api.json.""",Model 3
"diff --git a/README b/README
index b5db6e3c6..34a82e0b3 100644
--- a/README
+++ b/README
@@ -15,7 +15,7 @@ Atmosphere is also availaible as part of the following framework:
 * Akka, event-driven, scalable and fault-tolerant architectures for the JVM
 * Google Widget Toolkit (GWT)
 
-Browse our super easy Rest based PubSub sample and read on what is Atmosphere exactly.
+Atmosphere ship with a JQuery Plug In that can be used with any Comet or WebSocket Framework:
 
     http://is.gd/bJXhH
 ",Improve documentation,"""Update README to mention Atmosphere's JQuery Plug In""","""Update README to mention Atmosphere's JQuery Plug In""","""Updated README: Added information about Atmosphere's JQuery Plug In""","Updated README to mention the jQuery plugin for use with Comet or WebSocket Frameworks, replacing Rest-based PubSub sample reference.",Model 2
"diff --git a/README.txt b/README.txt
index c9977efb7c7..9ff5e59e856 100644
--- a/README.txt
+++ b/README.txt
@@ -433,6 +433,9 @@ web.xml of source.war file and change them (see note1) appropriately.
   - The file 'body_include' can be created under DATA_ROOT.
     The contents of this file will be inserted above the footer of the web
     application's ""Home"" page.
+  - The file 'error_forbidden_include' can be created under DATA_ROOT.
+    The contents of this file will be displayed as the error page when
+    the user is forbidden to see a particular project with HTTP 403 code.
 
 
 5.4.3 - Path Descriptions (optional)
diff --git a/src/org/opensolaris/opengrok/configuration/Configuration.java b/src/org/opensolaris/opengrok/configuration/Configuration.java
index e2d4619b757..0ec1c4d34be 100644
--- a/src/org/opensolaris/opengrok/configuration/Configuration.java
+++ b/src/org/opensolaris/opengrok/configuration/Configuration.java
@@ -1014,6 +1014,30 @@ public final class Configuration {
         return body;
     }
 
+    /**
+     * The name of the file relative to the <var>DATA_ROOT</var>, which should
+     * be included into the error page handling access forbidden errors - HTTP
+     * code 403 Forbidden.
+     */
+    public static final String E_FORBIDDEN_INCLUDE_FILE = ""error_forbidden_include"";
+
+    private transient String eforbidden_content = null;
+
+    /**
+     * Get the contents of the page for forbidden error page (403 Forbidden)
+     * include file.
+     *
+     * @return an empty string if it could not be read successfully, the
+     * contents of the file otherwise.
+     * @see Configuration#E_FORBIDDEN_INCLUDE_FILE
+     */
+    public String getForbiddenIncludeFileContent() {
+        if (eforbidden_content == null) {
+            eforbidden_content = getFileContent(new File(getDataRoot(), E_FORBIDDEN_INCLUDE_FILE));
+        }
+        return eforbidden_content;
+    }
+
     /**
      * Get the eftar file, which contains definition tags.
      *
diff --git a/web/WEB-INF/web.xml b/web/WEB-INF/web.xml
index d5249d94005..a9f9e0f75f4 100644
--- a/web/WEB-INF/web.xml
+++ b/web/WEB-INF/web.xml
@@ -127,6 +127,15 @@
 <param-name>keepgenerated</param-name><param-value>true</param-value>
 </init-param>
   </servlet>
+  <servlet>
+      <display-name>Forbidden error handler</display-name>
+      <servlet-name>eforbidden</servlet-name>
+      <jsp-file>/eforbidden.jsp</jsp-file>
+      <init-param>
+          <param-name>keepgenerated</param-name>
+          <param-value>true</param-value>
+      </init-param>
+  </servlet>
   <servlet-mapping>
     <servlet-name>search</servlet-name>
     <url-pattern>/search</url-pattern>		<!-- SEARCH_P -->
@@ -179,6 +188,10 @@
     <servlet-name>enoent</servlet-name>
     <url-pattern>/enoent</url-pattern>		<!-- NOT_FOUND -->
   </servlet-mapping>
+  <servlet-mapping>
+      <servlet-name>eforbidden</servlet-name>
+      <url-pattern>/eforbidden</url-pattern>		<!-- FORBIDDEN -->
+  </servlet-mapping>
   <error-page>
     <error-code>404</error-code>
     <location>/enoent</location>
@@ -187,8 +200,12 @@
     <error-code>500</error-code>
     <location>/error</location>
   </error-page>
+  <error-page>
+      <error-code>403</error-code>
+      <location>/eforbidden</location>
+  </error-page>
   <jsp-config>
-    <jsp-property-group>
+      <jsp-property-group>
       <url-pattern>*.jsp</url-pattern>
       <trim-directive-whitespaces>true</trim-directive-whitespaces>
     </jsp-property-group>
diff --git a/web/eforbidden.jsp b/web/eforbidden.jsp
new file mode 100644
index 00000000000..3d4121ab9a7
--- /dev/null
+++ b/web/eforbidden.jsp
@@ -0,0 +1,30 @@
+<%--
+CDDL HEADER START
+
+The contents of this file are subject to the terms of the
+Common Development and Distribution License (the ""License"").
+You may not use this file except in compliance with the License.
+
+See LICENSE.txt included in this distribution for the specific
+language governing permissions and limitations under the License.
+
+When distributing Covered Code, include this CDDL HEADER in each
+file and include the License file at LICENSE.txt.
+If applicable, add the following below this CDDL HEADER, with the
+fields enclosed by brackets ""[]"" replaced with your own identifying
+information: Portions Copyright [yyyy] [name of copyright owner]
+
+CDDL HEADER END
+
+Copyright (c) 2017, Oracle and/or its affiliates. All rights reserved.
+--%><%@page  session=""false"" isErrorPage=""true"" import=""
+             org.opensolaris.opengrok.web.PageConfig""
+%><%
+    /* ---------------------- eforbidden.jspf start --------------------- */
+    {
+%>
+<%= PageConfig.get(request).getEnv().getConfiguration().getForbiddenIncludeFileContent()%>
+<%
+    }
+    /* ---------------------- eforbidden.jspf end --------------------- */
+%>",let the user to customize the 403 error page ( <issue_id> ) .,"""Added support for custom 403 Forbidden error page""","""Added support for custom forbidden error page with HTTP 403 code""","The commit message could be:

""Added support for custom error page for forbidden access (HTTP 403)

Changes include:
- Updated README.txt to include instructions for creating the error_forbidden_include file
- Added a new constant E_FORBIDDEN_INCLUDE_FILE and a new method getForbiddenIncludeFileContent() in Configuration.java
- Added a new servlet for handling forbidden errors in web.xml
- Created a new JSP file eforbidden.jsp to display the custom error message""",Add error handling for HTTP 403 forbidden in the web application with customizable error page include file.,Model 2
"diff --git a/README.md b/README.md
index ae0690ae3..dbb0e562d 100644
--- a/README.md
+++ b/README.md
@@ -8,6 +8,11 @@ This is the official repository of AntennaPod, a podcast manager for Android.
 </a>
 [AntennaPod on fdroid.org](http://f-droid.org/repository/browse/?fdcategory=Multimedia&fdid=de.danoeh.antennapod&fdpage=1)
 
+## Feedback
+You can use the [AntennaPod Google Group](https://groups.google.com/forum/#!forum/antennapod) for discussions about the app.
+
+Bug reports and feature requests can be submitted [here](https://github.com/danieloeh/AntennaPod/issues/new) (please read the [instructions](https://github.com/danieloeh/AntennaPod/blob/master/CONTRIBUTING.md) on how to report a bug and how to submit a feature request first!).
+
 ## License
 
 AntennaPod is licensed under the MIT License. You can find the license text in the LICENSE file.",Added feedback section,"""Add feedback section to README with links to Google Group and issue tracker""","""Added feedback section to README.md with information on discussion forum, bug reports, and feature requests.""","The commit message should be:

 Add feedback section to README.md

 This commit message describes the change made in the README.md file, which is the addition of a new section about feedback. It provides a brief summary of the changes made in the commit.","""Add feedback section with links to Google Group for discussions and GitHub issues for bug reports and feature requests.""",Model 4
"diff --git a/SwitchButton/library/src/main/java/com/kyleduo/switchbutton/SwitchButton.java b/SwitchButton/library/src/main/java/com/kyleduo/switchbutton/SwitchButton.java
index 64f589a..6f30abe 100644
--- a/SwitchButton/library/src/main/java/com/kyleduo/switchbutton/SwitchButton.java
+++ b/SwitchButton/library/src/main/java/com/kyleduo/switchbutton/SwitchButton.java
@@ -13,6 +13,9 @@ import android.graphics.RectF;
 import android.graphics.drawable.Drawable;
 import android.graphics.drawable.StateListDrawable;
 import android.support.v4.content.ContextCompat;
+import android.text.Layout;
+import android.text.StaticLayout;
+import android.text.TextPaint;
 import android.util.AttributeSet;
 import android.view.MotionEvent;
 import android.view.SoundEffectConstants;
@@ -52,7 +55,7 @@ public class SwitchButton extends CompoundButton {
 
 	private int mCurrThumbColor, mCurrBackColor, mNextBackColor;
 	private Drawable mCurrentBackDrawable, mNextBackDrawable;
-	private RectF mThumbRectF, mBackRectF, mSafeRectF;
+	private RectF mThumbRectF, mBackRectF, mSafeRectF, mTextOnRectF, mTextOffRectF;
 	private Paint mPaint;
 	// whether using Drawable for thumb or back
 	private boolean mIsThumbUseDrawable, mIsBackUseDrawable;
@@ -66,6 +69,11 @@ public class SwitchButton extends CompoundButton {
 	private int mTouchSlop;
 	private int mClickTimeout;
 	private Paint mRectPaint;
+	private String mTextOn;
+	private String mTextOff;
+	private TextPaint mTextPaint;
+	private Layout mOnLayout;
+	private Layout mOffLayout;
 
 	public SwitchButton(Context context, AttributeSet attrs, int defStyle) {
 		super(context, attrs, defStyle);
@@ -91,11 +99,15 @@ public class SwitchButton extends CompoundButton {
 		mRectPaint.setStyle(Paint.Style.STROKE);
 		mRectPaint.setStrokeWidth(getResources().getDisplayMetrics().density);
 
+		mTextPaint = getPaint();
+
 		mThumbRectF = new RectF();
 		mBackRectF = new RectF();
 		mSafeRectF = new RectF();
 		mThumbSizeF = new PointF();
 		mThumbMargin = new RectF();
+		mTextOnRectF = new RectF();
+		mTextOffRectF = new RectF();
 
 		mProcessAnimator = ObjectAnimator.ofFloat(this, ""process"", 0, 0).setDuration(DEFAULT_ANIMATION_DURATION);
 		mProcessAnimator.setInterpolator(new AccelerateDecelerateInterpolator());
@@ -122,6 +134,8 @@ public class SwitchButton extends CompoundButton {
 		int animationDuration = DEFAULT_ANIMATION_DURATION;
 		boolean fadeBack = true;
 		int tintColor = Integer.MIN_VALUE;
+		String textOn = null;
+		String textOff = null;
 
 		TypedArray ta = attrs == null ? null : getContext().obtainStyledAttributes(attrs, R.styleable.SwitchButton);
 		if (ta != null) {
@@ -142,9 +156,15 @@ public class SwitchButton extends CompoundButton {
 			animationDuration = ta.getInteger(R.styleable.SwitchButton_kswAnimationDuration, animationDuration);
 			fadeBack = ta.getBoolean(R.styleable.SwitchButton_kswFadeBack, true);
 			tintColor = ta.getColor(R.styleable.SwitchButton_kswTintColor, tintColor);
+			textOn = ta.getString(R.styleable.SwitchButton_kswTextOn);
+			textOff = ta.getString(R.styleable.SwitchButton_kswTextOff);
 			ta.recycle();
 		}
 
+		// text
+		mTextOn = textOn;
+		mTextOff = textOff;
+
 		// thumb drawable and color
 		mThumbDrawable = thumbDrawable;
 		mThumbColor = thumbColor;
@@ -195,8 +215,19 @@ public class SwitchButton extends CompoundButton {
 		}
 	}
 
+
+	private Layout makeLayout(CharSequence text) {
+		return new StaticLayout(text, mTextPaint, (int) Math.ceil(Layout.getDesiredWidth(text, mTextPaint)), Layout.Alignment.ALIGN_NORMAL, 1.f, 0, false);
+	}
+
 	@Override
 	protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) {
+		if (mOnLayout == null) {
+            mOnLayout = makeLayout(mTextOn == null ? """" : mTextOn);
+        }
+        if (mOffLayout == null) {
+            mOffLayout = makeLayout(mTextOff == null ? """" : mTextOff);
+        }
 		setMeasuredDimension(measureWidth(widthMeasureSpec), measureHeight(heightMeasureSpec));
 	}
 
@@ -279,6 +310,14 @@ public class SwitchButton extends CompoundButton {
 		if (mBackDrawable != null) {
 			mBackDrawable.setBounds((int) mBackRectF.left, (int) mBackRectF.top, (int) mBackRectF.right, (int) mBackRectF.bottom);
 		}
+
+		float marginOnX = Math.max(0, (mBackRectF.width() - mThumbRectF.width() - mOnLayout.getWidth()) / 2);
+		float marginOnY = Math.max(0, (mBackRectF.height() - mOnLayout.getHeight()) / 2);
+		mTextOnRectF.set(mBackRectF.left + marginOnX, mBackRectF.top + marginOnY, mBackRectF.right - mThumbRectF.width() - marginOnX, mBackRectF.bottom - marginOnY);
+
+		float marginOffX = Math.max(0, (mBackRectF.width() - mThumbRectF.width() - mOffLayout.getWidth()) / 2);
+		float marginOffY = Math.max(0, (mBackRectF.height() - mOffLayout.getHeight()) / 2);
+		mTextOffRectF.set(mBackRectF.left + mThumbRectF.width() + marginOffX, mBackRectF.top + marginOffY, mBackRectF.right - marginOffX, mBackRectF.bottom - marginOffY);
 	}
 
 	@Override
@@ -324,6 +363,14 @@ public class SwitchButton extends CompoundButton {
 			}
 		}
 
+		// text
+		Layout switchText = isChecked() ? mOnLayout : mOffLayout;
+		RectF textRectF = isChecked() ? mTextOnRectF : mTextOffRectF;
+		canvas.save();
+		canvas.translate(textRectF.left, textRectF.top);
+		switchText.draw(canvas);
+		canvas.restore();
+
 		// thumb
 		mPresentThumbRectF.set(mThumbRectF);
 		mPresentThumbRectF.offset(mProcess * mSafeRectF.width(), 0);
@@ -340,6 +387,8 @@ public class SwitchButton extends CompoundButton {
 			canvas.drawRect(mBackRectF, mRectPaint);
 			mRectPaint.setColor(Color.parseColor(""#0000FF""));
 			canvas.drawRect(mPresentThumbRectF, mRectPaint);
+			mRectPaint.setColor(Color.parseColor(""#00CC00""));
+			canvas.drawRect(isChecked() ? mTextOnRectF : mTextOffRectF, mRectPaint);
 		}
 	}
 
diff --git a/SwitchButton/library/src/main/res/values/attrs.xml b/SwitchButton/library/src/main/res/values/attrs.xml
index 8dcc647..b8af9b9 100644
--- a/SwitchButton/library/src/main/res/values/attrs.xml
+++ b/SwitchButton/library/src/main/res/values/attrs.xml
@@ -19,6 +19,8 @@
 		<attr name=""kswBackMeasureRatio"" format=""float""/>
 		<attr name=""kswAnimationDuration"" format=""integer""/>
 		<attr name=""kswTintColor"" format=""color|reference""/>
+		<attr name=""kswTextOn"" format=""string""/>
+		<attr name=""kswTextOff"" format=""string""/>
 	</declare-styleable>
 
 </resources>
\ No newline at end of file",Adding \' kswTextOn \' and \' kswTextOff \' attributes,"""Added support for displaying text on the switch button""","Added text on/off support to SwitchButton

This commit message is concise and accurately describes the changes made in the commit. It mentions the key feature added, which is the support for text on/off in the SwitchButton.","This commit adds text support to the SwitchButton library. It includes the following changes:

1. Added new attributes `kswTextOn` and `kswTextOff` in `attrs.xml` to set the text for the on and off states of the switch button.
2. Added new instance variables `mTextOn`, `mTextOff`, `mTextPaint`, `mOnLayout`, `mOffLayout`, `mTextOnRectF`, and `mTextOffRectF` in `SwitchButton.java` to handle the text drawing.
3. Updated the `SwitchButton` constructor to initialize the `TextPaint` object and added code to retrieve the values of `kswTextOn` and `kswTextOff` attributes.
4. Added a new method `makeLayout` in `SwitchButton.java` to create a `Layout` object for the text.
5. Updated the `onMeasure` method in `SwitchButton.java` to create the `Layout` objects for the on and off text.
6. Updated the `onDraw` method in `SwitchButton.java` to draw the text using the `Layout.draw` method.
7. Added a new `RectF` object `mTextOnRectF` and `mTextOffRectF` in `SwitchButton.java` to define the bounds for drawing the text.
8. Updated the `onSizeChanged` method in `SwitchButton.java` to set the bounds for the `mTextOnRectF` and `mTextOffRectF` objects.
9. Added some debug code in `onDraw` method to draw a rectangle around the text bounds.

Overall, this commit adds support for displaying text on the switch button, which can be customized using the `kswTextOn` and `kswTextOff` attributes.","""Add text display functionality with attributes `kswTextOn` and `kswTextOff` to `SwitchButton` component.""",Model 1
"diff --git a/searchlib/src/vespa/searchlib/transactionlog/domain.cpp b/searchlib/src/vespa/searchlib/transactionlog/domain.cpp
index 6d251a2a30e..fdee9dc1a24 100644
--- a/searchlib/src/vespa/searchlib/transactionlog/domain.cpp
+++ b/searchlib/src/vespa/searchlib/transactionlog/domain.cpp
@@ -341,7 +341,6 @@ Domain::startCommit(DoneCallback onDone) {
     vespalib::MonitorGuard guard(_currentChunkMonitor);
     if ( !_currentChunk->empty() ) {
         auto completed = grabCurrentChunk(guard);
-        assert(completed);
         completed->setCommitDoneCallback(std::move(onDone));
         CommitResult result(completed->createCommitResult());
         commitChunk(std::move(completed), guard);
@@ -355,9 +354,7 @@ Domain::commitIfFull(const vespalib::MonitorGuard &guard) {
     if (_currentChunk->sizeBytes() > _config.getChunkSizeLimit()) {
         auto completed = std::move(_currentChunk);
         _currentChunk = std::make_unique<CommitChunk>(_config.getChunkSizeLimit(), completed->stealCallbacks());
-        if (completed) {
-            commitChunk(std::move(completed), guard);
-        }
+        commitChunk(std::move(completed), guard);
     }
 }
 
@@ -369,20 +366,18 @@ Domain::grabCurrentChunk(const vespalib::MonitorGuard & guard) {
     return chunk;
 }
 
-bool
+void
 Domain::commitChunk(std::unique_ptr<CommitChunk> chunk, const vespalib::MonitorGuard & chunkOrderGuard) {
     assert(chunkOrderGuard.monitors(_currentChunkMonitor));
-    if ( ! chunk->getPacket().empty()) {
-        _singleCommitter->execute( makeLambdaTask([this, chunk = std::move(chunk)]() mutable {
-            doCommit(std::move(chunk));
-        }));
-        return true;
-    }
-    return false;
+    _singleCommitter->execute( makeLambdaTask([this, chunk = std::move(chunk)]() mutable {
+        doCommit(std::move(chunk));
+    }));
 }
 
 void
 Domain::doCommit(std::unique_ptr<CommitChunk> chunk) {
+    if (chunk->empty()) return;
+
     const Packet & packet = chunk->getPacket();
     vespalib::nbostream_longlivedbuf is(packet.getHandle().data(), packet.getHandle().size());
     Packet::Entry entry;
diff --git a/searchlib/src/vespa/searchlib/transactionlog/domain.h b/searchlib/src/vespa/searchlib/transactionlog/domain.h
index 5bd11ea2bdf..041ec27cf23 100644
--- a/searchlib/src/vespa/searchlib/transactionlog/domain.h
+++ b/searchlib/src/vespa/searchlib/transactionlog/domain.h
@@ -59,7 +59,7 @@ private:
     void commitIfFull(const vespalib::MonitorGuard & guard);
 
     std::unique_ptr<CommitChunk> grabCurrentChunk(const vespalib::MonitorGuard & guard);
-    bool commitChunk(std::unique_ptr<CommitChunk> chunk, const vespalib::MonitorGuard & chunkOrderGuard);
+    void commitChunk(std::unique_ptr<CommitChunk> chunk, const vespalib::MonitorGuard & chunkOrderGuard);
     void doCommit(std::unique_ptr<CommitChunk> chunk);
     SerialNum begin(const vespalib::LockGuard & guard) const;
     SerialNum end(const vespalib::LockGuard & guard) const;",Remove unnecessary guard and move check for emptiness inside doCommit to ensure ordering also of empty chunks .,"""Remove unnecessary checks and return values in Domain::commitChunk and related methods""","The commit message should be:

""Remove unnecessary assertions and improve code readability in Domain class""

Or, if you want to be more concise:

""Improve Domain class code readability""

However, a more descriptive commit message would be:

""Remove unnecessary assertions and simplify logic in Domain::commitChunk method""

This commit message accurately describes the changes made in the commit, which include removing unnecessary assertions and simplifying the logic in the `commitChunk` method.","""Remove unnecessary assert and return statement in Domain::commitChunk()""

Explanation:

* The assert statement in Domain::startCommit() has been removed.
* The return statement in Domain::commitChunk() has been changed from `bool` to `void`.
* The conditional statement checking if `completed` is not null before calling `commitChunk()` in Domain::commitIfFull() has been removed.
* An early return statement has been added in Domain::doCommit() if `chunk` is empty.

These changes simplify the code by removing unnecessary checks and return statements.",Refactor commitChunk to return void and remove unnecessary checks for empty chunks.,Model 4
"diff --git a/core/src/main/java/fi/iki/elonen/NanoHTTPD.java b/core/src/main/java/fi/iki/elonen/NanoHTTPD.java
index 3279a92..780c588 100644
--- a/core/src/main/java/fi/iki/elonen/NanoHTTPD.java
+++ b/core/src/main/java/fi/iki/elonen/NanoHTTPD.java
@@ -468,11 +468,15 @@ public abstract class NanoHTTPD {
         }
     }
 
-    private static final String CHARSET_REGEX = ""[ |\t]*(charset)[ |\t]*=[ |\t]*['|\""]?([^\""^'^;]*)['|\""]?"";
+    private static final String CONTENT_REGEX = ""[ |\t]*([^/^ ^;^,]+/[^ ^;^,]+)"";
+
+    private static final Pattern MIME_PATTERN = Pattern.compile(CONTENT_REGEX, Pattern.CASE_INSENSITIVE);
+
+    private static final String CHARSET_REGEX = ""[ |\t]*(charset)[ |\t]*=[ |\t]*['|\""]?([^\""^'^;^,]*)['|\""]?"";
 
     private static final Pattern CHARSET_PATTERN = Pattern.compile(CHARSET_REGEX, Pattern.CASE_INSENSITIVE);
 
-    private static final String BOUNDARY_REGEX = ""[ |\t]*(boundary)[ |\t]*=[ |\t]*['|\""]?([^\""^'^;]*)['|\""]?"";
+    private static final String BOUNDARY_REGEX = ""[ |\t]*(boundary)[ |\t]*=[ |\t]*['|\""]?([^\""^'^;^,]*)['|\""]?"";
 
     private static final Pattern BOUNDARY_PATTERN = Pattern.compile(BOUNDARY_REGEX, Pattern.CASE_INSENSITIVE);
 
@@ -625,7 +629,7 @@ public abstract class NanoHTTPD {
                     NanoHTTPD.LOG.log(Level.FINE, ""no protocol version specified, strange. Assuming HTTP/1.1."");
                 }
                 String line = in.readLine();
-                while (line != null && line.trim().length() > 0) {
+                while (line != null && !line.trim().isEmpty()) {
                     int p = line.indexOf(':');
                     if (p >= 0) {
                         headers.put(line.substring(0, p).trim().toLowerCase(Locale.US), line.substring(p + 1).trim());
@@ -1041,28 +1045,23 @@ public abstract class NanoHTTPD {
                 // in data section, too, read it:
                 if (Method.POST.equals(this.method)) {
                     String contentType = """";
+                    String encoding = ""UTF-8"";
                     String contentTypeHeader = this.headers.get(""content-type"");
-
-                    StringTokenizer st = null;
                     if (contentTypeHeader != null) {
-                        st = new StringTokenizer(contentTypeHeader, "",; "");
-                        if (st.hasMoreTokens()) {
-                            contentType = st.nextToken();
-                        }
+                        contentType = getDetailFromContentHeader(contentTypeHeader, MIME_PATTERN, """", 1);
+                        encoding = getDetailFromContentHeader(contentTypeHeader, CHARSET_PATTERN, ""US-ASCII"", 2);
                     }
-
                     if (""multipart/form-data"".equalsIgnoreCase(contentType)) {
-                        // Handle multipart/form-data
-                        if (!st.hasMoreTokens()) {
+                        String boundary = getDetailFromContentHeader(contentTypeHeader, BOUNDARY_PATTERN, null, 2);
+                        if (boundary == null) {
                             throw new ResponseException(Response.Status.BAD_REQUEST,
                                     ""BAD REQUEST: Content type is multipart/form-data but boundary missing. Usage: GET /example/file.html"");
                         }
-                        decodeMultipartFormData(getAttributeFromContentHeader(contentTypeHeader, BOUNDARY_PATTERN, null), //
-                                getAttributeFromContentHeader(contentTypeHeader, CHARSET_PATTERN, ""US-ASCII""), fbuf, this.parms, files);
+                        decodeMultipartFormData(boundary, encoding, fbuf, this.parms, files);
                     } else {
                         byte[] postBytes = new byte[fbuf.remaining()];
                         fbuf.get(postBytes);
-                        String postLine = new String(postBytes).trim();
+                        String postLine = new String(postBytes, encoding).trim();
                         // Handle application/x-www-form-urlencoded
                         if (""application/x-www-form-urlencoded"".equalsIgnoreCase(contentType)) {
                             decodeParms(postLine, this.parms);
@@ -1081,9 +1080,9 @@ public abstract class NanoHTTPD {
             }
         }
 
-        private String getAttributeFromContentHeader(String contentTypeHeader, Pattern pattern, String defaultValue) {
+        private String getDetailFromContentHeader(String contentTypeHeader, Pattern pattern, String defaultValue, int group) {
             Matcher",encoding and contenty type handling <issue_id>,"""Refactor NanoHTTPD to improve content type and boundary parsing""","""Improved HTTP header parsing and content type handling""","""Update regex patterns and add method to extract details from content header in NanoHTTPD""

Explanation:
The commit involves the following changes in the `NanoHTTPD.java` file:

1. Adding a new constant `CONTENT_REGEX` to store the regular expression pattern for content type.
2. Creating a new `Pattern` object, `MIME_PATTERN`, using the `CONTENT_REGEX` pattern.
3. Modifying the `CHARSET_REGEX` pattern to exclude semicolons and commas in the charset value.
4. Modifying the `BOUNDARY_REGEX` pattern to exclude semicolons and commas in the boundary value.
5. Replacing the usage of `StringTokenizer` with the new `getDetailFromContentHeader()` method to extract content type and charset encoding from the content type header.
6. Adding a new method `getDetailFromContentHeader()` to extract specific details (like content type, charset, and boundary) from the content type header using the provided `Pattern` and group number.

The main purpose of the commit is to improve the way content type and related details are extracted from the request headers. The changes make the code more robust and maintainable by using a more specific and flexible method to handle different content types and their associated properties.","Refactor content header parsing logic, improve charset and boundary regex, handle content-type and encoding details more robustly.",Model 3
"diff --git a/tools/src/main/java/com/orientechnologies/orient/console/OConsoleDatabaseApp.java b/tools/src/main/java/com/orientechnologies/orient/console/OConsoleDatabaseApp.java
index ed5babe4ec..6239596b40 100755
--- a/tools/src/main/java/com/orientechnologies/orient/console/OConsoleDatabaseApp.java
+++ b/tools/src/main/java/com/orientechnologies/orient/console/OConsoleDatabaseApp.java
@@ -153,6 +153,10 @@ public class OConsoleDatabaseApp extends OrientConsole implements OCommandOutput
 
     OGlobalConfiguration.STORAGE_KEEP_OPEN.setValue(false);
 
+    // DISABLE THE NETWORK AND STORAGE TIMEOUTS
+    OGlobalConfiguration.STORAGE_LOCK_TIMEOUT.setValue(0);
+    OGlobalConfiguration.NETWORK_LOCK_TIMEOUT.setValue(0);
+
     properties.put(""limit"", ""20"");
     properties.put(""debug"", ""false"");
     properties.put(""maxBinaryDisplay"", ""160"");",removed timeout against remote connections,"""Disable network and storage timeouts in OConsoleDatabaseApp""","""Disable network and storage timeouts in OConsoleDatabaseApp""","""Disable network and storage timeouts in OConsoleDatabaseApp configuration""

Explanation:
The diff shows that two lines of code have been added to the class `OConsoleDatabaseApp`. These lines set the values of `OGlobalConfiguration.STORAGE_LOCK_TIMEOUT` and `OGlobalConfiguration.NETWORK_LOCK_TIMEOUT` to 0. These configurations are used to disable network and storage timeouts respectively. Therefore, the commit message should reflect this change.",Disable network and storage timeouts in OConsoleDatabaseApp by setting STORAGE_LOCK_TIMEOUT and NETWORK_LOCK_TIMEOUT to 0.,Model 4
"diff --git a/jre_emul/Classes/java/util/HashMap.h b/jre_emul/Classes/java/util/HashMap.h
index 5feb0f775..8dae5d82a 100644
--- a/jre_emul/Classes/java/util/HashMap.h
+++ b/jre_emul/Classes/java/util/HashMap.h
@@ -7,16 +7,22 @@
 //
 
 #import <Foundation/Foundation.h>
+#import ""java/io/Serializable.h""
+#import ""java/util/AbstractMap.h""
 #import ""java/util/Map.h""
 
 @class JavaUtilHashMap_Entry;
 
-// An implementation for the java.util.Map protocol, using a
-// NSMutableDictionary delegate. Its constructors are defined by HashMap, so
-// that this class can potentially be a drop-in replacement.
-@interface JavaUtilHashMap : NSObject < JavaUtilMap, NSMutableCopying > {
- @private
-  NSMutableDictionary *dictionary_;
+// An implementation for the java.util.Map protocol, based on the java harmony
+// implementation.
+@interface JavaUtilHashMap : JavaUtilAbstractMap < JavaUtilMap, NSCopying, JavaIoSerializable > {
+ @public
+  int elementCount_;
+  JavaUtilHashMap_Entry **elementData_;
+  int elementDataLength_;
+  int modCount_;
+  float loadFactor_;
+  int threshold_;
 }
 
 - (id)initWithInt:(int)capacity;
diff --git a/jre_emul/Classes/java/util/HashMap.m b/jre_emul/Classes/java/util/HashMap.m
index 522b7ce83..47fb04254 100644
--- a/jre_emul/Classes/java/util/HashMap.m
+++ b/jre_emul/Classes/java/util/HashMap.m
@@ -2,533 +2,692 @@
 //  HashMap.m
 //  JreEmulation
 //
-//  Created by Tom Ball on 1/27/12.
+//  Created by Keith Stanger on 10/19/12.
 //  Copyright 2012 Google, Inc. All rights reserved.
 //
 
+#import ""java/lang/CloneNotSupportedException.h""
 #import ""java/lang/IllegalArgumentException.h""
 #import ""java/lang/IllegalStateException.h""
 #import ""java/lang/NullPointerException.h""
+#import ""java/util/Collection.h""
+#import ""java/util/ConcurrentModificationException.h""
 #import ""java/util/HashMap_PackagePrivate.h""
+#import ""java/util/Iterator.h""
 #import ""java/util/Map.h""
-#import ""IOSList.h""
-#import ""IOSSet.h""
-#import ""JreEmulation.h""
-#import <CoreFoundation/CFDictionary.h>
+#import ""java/util/NoSuchElementException.h""
+#import ""java/util/Set.h""
 
 @implementation JavaUtilHashMap
 
-#define JavaUtilHashMap_DEFAULT_SIZE 16
+@synthesize elementCount = elementCount_;
+@synthesize elementData = elementData_;
+@synthesize elementDataLength = elementDataLength_;
+@synthesize modCount = modCount_;
+@synthesize loadFactor = loadFactor_;
+@synthesize threshold = threshold_;
 
-@synthesize dictionary = dictionary_;
-
-// Private initializer.
-// We need this with a unique name to avoid clashing with subclasses.
-- (id)initJavaUtilHashMapWithCapacity:(int)capacity {
-  if (capacity < 0) {
-    id exception = [[JavaLangIllegalArgumentException alloc] init];
-#if ! __has_feature(objc_arc)
-    [exception autorelease];
-#endif
-    @throw exception;
-  }
-  self = [super init];
-  if (self) {
-    dictionary_ = (ARCBRIDGE_TRANSFER NSMutableDictionary *)
-    CFDictionaryCreateMutable(NULL, capacity,
-        &kCFTypeDictionaryKeyCallBacks, &kCFTypeDictionaryValueCallBacks);
-  }
-  return self;
-}
 
 - (id)init {
-  return [self initWithInt:JavaUtilHashMap_DEFAULT_SIZE];
+  return [self initJavaUtilHashMapWithInt:JavaUtilHashMap_DEFAULT_SIZE
+                                withFloat:JavaUtilHashMap_DEFAULT_LOAD_FACTOR];
 }
 
 - (id)initWithInt:(int)capacity {
-  return [self initJavaUtilHashMapWithCapacity:capacity];
+  return [self initJavaUtilHashMapWithInt:capacity withFloat:JavaUtilHashMap_DEFAULT_LOAD_FACTOR];
 }
 
-- (id)initWithInt:(int)capacity withFloat:(float)loadFactor {
-  if (loadFactor <= 0) {
-    id exception = [[JavaLangIllegalArgumentException alloc] init];
-#if ! __has_feature(objc_arc)
-    [exception autorelease];
-#endif
-    @throw exception;
++ (int)calculateCapacityWithInt:(int)x {
+  if (x >= 1 << 30) {
+    return 1 << 30;
+  }
+  if (x == 0) {
+    return 16;
   }
-  return [self initJavaUtilHashMapWithCapacity:capacity];
+  x = x - 1;
+  x |= x >> 1;
+  x |= x >> 2;
+  x |= x >> 4;
+  x |= x >> 8;
+  x |= x >> 16;
+  return x + 1;
 }
 
-- (id)initWithJavaUtilMap:(id<JavaUtilMap>)map {
-  if (!map) {
-    id exception = [[JavaLangNullPointerException alloc] init];
-#if ! __has_feature(objc_arc)
-    [exception autorelease];
-#endif
-    @throw exception;
-  }
-  int size = [map size];
-  self = [self initJavaUtilHashMapWithCapacity:size];
-  if (self) {
-    if ([map isMemberOfClass:[JavaUtilHashMap class]]) {
-      JavaUtilHashMap *other = (JavaUtilHashMap *) map;
-#if ! __has_feature(objc_arc)
-      [dictionary_ release];
-#endif
-      dictionary_ = (ARCBRIDGE_TRANSFER NSMutableDictionary *)
-          CFDictionaryCreateMutable(NULL, size,
-          &kCFTypeDictionaryKeyCallBacks, &kCFTypeDictionaryValueCallBacks);
-      for(id key in [other->dictionary_ allKeys]) {
-        CFDictionarySetValue((ARCBRIDGE CFMutableDictionaryRef) dictionary_,
-            (ARCBRIDGE void *) key,
-            (ARCBRIDGE void *) [other->dictionary_ objectForKey:key]);
-      }
-    } else {
-      [self putAllImpl:map];
+- (id)initJavaUtilHashMapWithInt:(int)capacity
+                       withFloat:(float)loadFactor {
+  if ((self = [super init])) {
+    modCount_ = 0;
+    if (capacity >= 0 && loadFactor > 0) {
+      capacity = [JavaUtilHashMap calculateCapacityWithInt:capacity];
+      elementCount_ = 0;
+      free(elementData_);
+      elementData_ = (JavaUtilHashMap_Entry **) calloc(capacity, sizeof(JavaUtilHashMap_Entry *));
+      elementDataLength_ = capacity;
+      self.loadFactor = loadFactor;
+      [self computeThreshold];
+    }
+    else {
+      @throw [[[JavaLangIllegalArgumentException alloc] init] autorelease];
     }
   }
   return self;
 }
 
-#pragma mark -
+- (id)initWithInt:(int)capacity
+        withFloat:(float)loadFactor {
+  return [self initJavaUtilHashMapWithInt:capacity withFloat:loadFactor];
+}
+
+- (id)initWithJavaUtilMap:(id<JavaUtilMap>)map {
+  if ((self = [self initJavaUtilHashMapWithInt:
+      [JavaUtilHashMap calculateCapacityWithInt:[((id<JavaUtilMap>) NIL_CHK(map)) size]]
+      withFloat:JavaUtilHashMap_DEFAULT_LOAD_FACTOR])) {
+    [self putAllImplWithJavaUtilMap:map];
+  }
+  return self;
+}
 
 - (void)clear {
-  [dictionary_ removeAllObjects];
+  if (elementCount_ > 0) {
+    elementCount_ = 0;
+    for (int i = 0; i < elementDataLength_; i++) {
+      JavaUtilHashMap_Entry *entry = elementData_[i];
+      elementData_[i] = nil;
+      while (entry != nil) {
+        JavaUtilHashMap_Entry *next = entry->next_;
+        [entry release];
+        entry = next;
+      }
+    }
+    modCount_++;
+  }
 }
 
-id nullify(id object) {
-  return object == [NSNull null] ? nil : object;
+- (void)copyAllPropertiesTo:(id)copy {
+  [super copyAllPropertiesTo:copy];
+  JavaUtilHashMap *typedCopy = (JavaUtilHashMap *) copy;
+  typedCopy.modCount = modCount_;
+  typedCopy.loadFactor = loadFactor_;
+  typedCopy.threshold = threshold_;
 }
 
-id denullify(id object) {
-  return object == nil ? [NSNull null] : object;
+- (id)clone {
+  @try {
+    JavaUtilHashMap *map = (JavaUtilHashMap *) [super clone];
+    map.elementCount = 0;
+    map.elementData =
+        (JavaUtilHashMap_Entry **) calloc(elementDataLength_, sizeof(JavaUtilHashMap_Entry *));
+    map.elementDataLength = elementDataLength_;
+    [map putAllWithJavaUtilMap:self];
+    return map;
+  }
+  @catch (JavaLangCloneNotSupportedException *e) {
+    return nil;
+  }
+}
+
+- (void)computeThreshold {
+  threshold_ = (int) (elementDataLength_ * loadFactor_);
 }
 
 - (BOOL)containsKeyWithId:(id)key {
-  return [dictionary_ objectForKey:denullify(key)] != nil;
+  JavaUtilHashMap_Entry *m = [self getEntryWithId:key];
+  return m != nil;
 }
 
 - (BOOL)containsValueWithId:(id)value {
-  NSArray *keys = [dictionary_ allKeysForObject:denullify(value)];
-  return [keys count] > 0;
+  if (value != nil) {
+    for (int i = 0; i < elementDataLength_; i++) {
+      JavaUtilHashMap_Entry *entry = elementData_[i];
+      while (entry != nil) {
+        if ([JavaUtilHashMap areEqualValuesWithId:value withId:entry->value_]) {
+          return YES;
+        }
+        entry = entry->next_;
+      }
+    }
+  }
+  else {
+    for (int i = 0; i < elementDataLength_; i++) {
+      JavaUtilHashMap_Entry *entry = elementData_[i];
+      while (entry != nil) {
+        if (entry->value_ == nil) {
+          return YES;
+        }
+        entry = entry->next_;
+      }
+    }
+  }
+  return NO;
 }
 
 - (id<JavaUtilSet>)entrySet {
-  id result = [[JavaUtilHashMap_EntrySet alloc] initWithJavaUtilHashMap:self];
-#if ! __has_feature(objc_arc)
-  [result autorelease];
-#endif
-  return result;
+  return [[[JavaUtilHashMap_HashMapEntrySet alloc] initWithJavaUtilHashMap:self] autorelease];
 }
 
 - (id)getWithId:(id)key {
-  id result = [dictionary_ objectForKey:denullify(key)];
-  return nullify(result);
+  JavaUtilHashMap_Entry *m = [self getEntryWithId:key];
+  if (m != nil) {
+    return m.value;
+  }
+  return nil;
 }
 
-- (NSUInteger)hash {
-  return [dictionary_ hash];
+- (JavaUtilHashMap_Entry *)getEntryWithId:(id)key {
+  JavaUtilHashMap_Entry *m;
+  if (key == nil) {
+    m = [self findNullKeyEntry];
+  }
+  else {
+    int hash_ = [JavaUtilHashMap computeHashCodeWithId:key];
+    int index = hash_ & (elementDataLength_ - 1);
+    m = [self findNonNullKeyEntryWithId:key withInt:index withInt:hash_];
+  }
+  return m;
 }
 
-- (BOOL)isEmpty {
-  return [dictionary_ count] == 0;
+- (JavaUtilHashMap_Entry *)findNonNullKeyEntryWithId:(id)key
+                                             withInt:(int)index
+                                             withInt:(int)keyHash {
+  JavaUtilHashMap_Entry *m = elementData_[index];
+  while (m != nil
+      && (m->origKeyHash_ != keyHash || ![JavaUtilHashMap areEqualKeysWithId:key withId:m->key_])) {
+    m = m->next_;
+  }
+  return m;
 }
 
-- (BOOL)isEqual:(id)object {
-  if ([object isKindOfClass:[JavaUtilHashMap class]]) {
-    JavaUtilHashMap *other = (JavaUtilHashMap *) object;
-    BOOL foo = [dictionary_ isEqualToDictionary:other->dictionary_];
-    return foo;
-  }
-  return NO;
+- (JavaUtilHashMap_Entry *)findNullKeyEntry {
+  JavaUtilHashMap_Entry *m = elementData_[0];
+  while (m != nil && m->key_ != nil) m = m->next_;
+  return m;
+}
+
+- (BOOL)isEmpty {
+  return elementCount_ == 0;
 }
 
 - (id<JavaUtilSet>)keySet {
-  id result = [[JavaUtilHashMap_KeySet alloc] initWithJavaUtilHashMap:self];
-#if ! __has_feature(objc_arc)
-  [result autorelease];
-#endif
-  return result;
+  if (keySet__ == nil) {
+    keySet__ = [[JavaUtilHashMap_KeySet alloc] initWithJavaUtilHashMap:self];
+  }
+  return keySet__;
 }
 
 - (id)putWithId:(id)key
          withId:(id)value {
-  key = denullify(key);
-  value = denullify(value);
-  id previous = [dictionary_ objectForKey:key];
-
-#if ! __has_feature(objc_arc)
-  [[previous retain] autorelease];
-#endif
+  return [self putImplWithId:key withId:value];
+}
+
+- (id)putImplWithId:(id)key
+             withId:(id)value {
+  JavaUtilHashMap_Entry *entry;
+  if (key == nil) {
+    entry = [self findNullKeyEntry];
+    if (entry == nil) {
+      modCount_++;
+      entry = [self createHashedEntryWithId:nil withInt:0 withInt:0];
+      if (++elementCount_ > threshold_) {
+        [self rehash];
+      }
+    }
+  }
+  else {
+    int hash_ = [JavaUtilHashMap computeHashCodeWithId:key];
+    int index = hash_ & (elementDataLength_ - 1);
+    entry = [self findNonNullKeyEntryWithId:key withInt:index withInt:hash_];
+    if (entry == nil) {
+      modCount_++;
+      entry = [self createHashedEntryWithId:key withInt:index withInt:hash_];
+      if (++elementCount_ > threshold_) {
+        [self rehash];
+      }
+    }
+  }
+  id result = [entry->value_ autorelease];
+  entry->value_ = [value retain];
+  return result;
+}
 
-  // Use a CFDictionary function so the key is retained rather than copied,
-  // as HashMap keys can't be required to be cloneable.
-  CFDictionarySetValue((ARCBRIDGE CFMutableDictionaryRef) dictionary_,
-                       (ARCBRIDGE void *) key, (ARCBRIDGE void *) value);
-  return nullify(previous);
+- (JavaUtilHashMap_Entry *)createHashedEntryWithId:(id)key
+                                           withInt:(int)index
+                                           withInt:(int)hash_ {
+  JavaUtilHashMap_Entry *entry = [[JavaUtilHashMap_Entry alloc] initWithId:key withInt:hash_];
+  entry->next_ = elementData_[index];
+  elementData_[index] = entry;
+  return entry;
 }
 
 - (void)putAllWithJavaUtilMap:(id<JavaUtilMap>)map {
-  if (![map isEmpty]) {
-    [self putAllImpl:map];
+  if (![((id<JavaUtilMap>) NIL_CHK(map)) isEmpty]) {
+    [self putAllImplWithJavaUtilMap:map];
   }
 }
 
-- (void)putAllImpl:(id<JavaUtilMap>)map {
-  id<JavaUtilSet> entrySet = [map entrySet];
-  id<JavaUtilIterator> iterator = [entrySet iterator];
-
-  // Throw NPE if null iterator, but only if there's something to iterate.
-  if (!iterator) {
-    id exception = [[JavaLangNullPointerException alloc] init];
-#if ! __has_feature(objc_arc)
-    [exception autorelease];
-#endif
-    @throw exception;
+- (void)putAllImplWithJavaUtilMap:(id<JavaUtilMap>)map {
+  int capacity = elementCount_ + [((id<JavaUtilMap>) NIL_CHK(map)) size];
+  if (capacity > threshold_) {
+    [self rehashWithInt:capacity];
   }
+  {
+    id<JavaLangIterable> array__ = (id<JavaLangIterable>) [((id<JavaUtilMap>) NIL_CHK(map)) entrySet];
+    if (!array__) {
+      @throw [[[JavaLangNullPointerException alloc] init] autorelease];
+    }
+    id<JavaUtilIterator> iter__ = [array__ iterator];
+    while ([iter__ hasNext]) {
+      id<JavaUtilMap_Entry> entry = (id<JavaUtilMap_Entry>) [iter__ next];
+      [self putImplWithId:((id) [((id<JavaUtilMap_Entry>) NIL_CHK(entry)) getKey]) withId:((id) [((id<JavaUtilMap_Entry>) NIL_CHK(entry)) getValue])];
+    }
+  }
+}
 
-  while ([iterator hasNext]) {
-    id entry = [iterator next];
-    [self putWithId:[entry getKey] withId:[entry getValue]];
+- (void)rehashWithInt:(int)capacity {
+  int length = [JavaUtilHashMap calculateCapacityWithInt:(capacity == 0 ? 1 : capacity << 1)];
+  JavaUtilHashMap_Entry **newData = calloc(length, sizeof(JavaUtilHashMap_Entry *));
+  for (int i = 0; i < elementDataLength_; i++) {
+    JavaUtilHashMap_Entry *entry = elementData_[i];
+    elementData_[i] = nil;
+    while (entry != nil) {
+      int index = entry->origKeyHash_ & (length - 1);
+      JavaUtilHashMap_Entry *next = entry->next_;
+      entry->next_ = newData[index];
+      newData[index] = entry;
+      entry = next;
+    }
   }
+  free(elementData_);
+  elementData_ = newData;
+  elementDataLength_ = length;
+  [self computeThreshold];
+}
+
+- (void)rehash {
+  [self rehashWithInt:elementDataLength_];
 }
 
 - (id)removeWithId:(id)key {
-  key = denullify(key);
-  id result = [dictionary_ objectForKey:key];
-  if (result) {
-#if ! __has_feature(objc_arc)
-    [[result retain] autorelease];
-#endif
-    [dictionary_ removeObjectForKey:key];
+  JavaUtilHashMap_Entry *entry = [self removeEntryWithId:key];
+  if (entry != nil) {
+    return entry.value;
+  }
+  return nil;
+}
+
+- (void)removeEntryWithJavaUtilHashMap_Entry:(JavaUtilHashMap_Entry *)entry {
+  int index = entry->origKeyHash_ & (elementDataLength_ - 1);
+  JavaUtilHashMap_Entry *m = elementData_[index];
+  if (m == entry) {
+    elementData_[index] = entry->next_;
+  }
+  else {
+    while (m->next_ != entry) {
+      m = m->next_;
+    }
+    m->next_ = entry->next_;
+  }
+  modCount_++;
+  elementCount_--;
+  [entry autorelease];
+}
+
+- (JavaUtilHashMap_Entry *)removeEntryWithId:(id)key {
+  int index = 0;
+  JavaUtilHashMap_Entry *entry;
+  JavaUtilHashMap_Entry *last = nil;
+  if (key != nil) {
+    int hash_ = [JavaUtilHashMap computeHashCodeWithId:key];
+    index = hash_ & (elementDataLength_ - 1);
+    entry = elementData_[index];
+    while (entry != nil
+        && !(entry->origKeyHash_ == hash_
+            && [JavaUtilHashMap areEqualKeysWithId:key withId:entry->key_])) {
+      last = entry;
+      entry = entry->next_;
+    }
   }
-  return nullify(result);
+  else {
+    entry = elementData_[0];
+    while (entry != nil && entry->key_ != nil) {
+      last = entry;
+      entry = entry->next_;
+    }
+  }
+  if (entry == nil) {
+    return nil;
+  }
+  if (last == nil) {
+    elementData_[index] = entry->next_;
+  } else {
+    last->next_ = entry->next_;
+  }
+  modCount_++;
+  elementCount_--;
+  return [entry autorelease];
 }
 
 - (int)size {
-  return [dictionary_ count];
+  return elementCount_;
 }
 
 - (id<JavaUtilCollection>)values {
-  id result = [[JavaUtilHashMap_Values alloc] initWithJavaUtilHashMap:self];
-#if ! __has_feature(objc_arc)
-  [result autorelease];
-#endif
-  return result;
+  if (valuesCollection_ == nil) {
+    valuesCollection_ = [[JavaUtilHashMap_ValuesCollection alloc] initWithJavaUtilHashMap:self];
+  }
+  return valuesCollection_;
 }
 
-- (JavaUtilHashMap_Entry *)entry:(id)key {
-  key = denullify(key);
-  id value = [dictionary_ objectForKey:key];
-  id result = [[JavaUtilHashMap_Entry alloc] initWithKey:key value:value];
-#if ! __has_feature(objc_arc)
-  [result autorelease];
-#endif
-  return result;
++ (int)computeHashCodeWithId:(id)key {
+  return [NIL_CHK(key) hash];
 }
 
-- (id)mutableCopyWithZone:(NSZone *)zone {
-  JavaUtilHashMap *copy = [[[self class] alloc] initWithJavaUtilMap:self];
-  return copy;
++ (BOOL)areEqualKeysWithId:(id)key1
+                    withId:(id)key2 {
+  return (key1 == key2) || [NIL_CHK(key1) isEqual:key2];
 }
 
-- (id)clone {
-  id result = [self mutableCopy];
-#if ! __has_feature(objc_arc)
-  [result autorelease];
-#endif
-  return result;
++ (BOOL)areEqualValuesWithId:(id)value1
+                      withId:(id)value2 {
+  return (value1 == value2) || [NIL_CHK(value1) isEqual:value2];
 }
 
 - (id)copyWithZone:(NSZone *)zone {
-  return [self mutableCopyWithZone:zone];
+  return [self clone];
 }
 
-- (NSString *)description {
-  // Handle case where a map contains itself (legal, but weird).
-  static BOOL recursing = NO;
-  if (recursing) {
-    return @""(this Map)"";
-  } else {
-    BOOL wasRecursing = recursing;
-    @try {
-      recursing = YES;
-      return [dictionary_ description];
-    }
-    @finally {
-      recursing = wasRecursing;
-    }
-  }
-}
-
-#if ! __has_feature(objc_arc)
 - (void)dealloc {
-  [dictionary_ release];
+  [self clear];
+  free(elementData_);
+  elementData_ = nil;
   [super dealloc];
 }
-#endif
-
-#pragma mark -
 
 @end
 
-@implementation JavaUtilHashMap_Entry
-
-- (id)initWithKey:(id)key value:(id)value {
-  return [super initWithId:key withId:value];
-}
 
-#pragma mark -
-#pragma mark JavaUtilMap_Entry
+@implementation JavaUtilHashMap_Entry
 
-- (id)getKey {
-  return nullify([super key]);
+- (id)initWithId:(id)theKey
+         withInt:(int)hash_ {
+  if ((self = [super initWithId:theKey withId:nil])) {
+    origKeyHash_ = hash_;
+  }
+  return self;
 }
 
-- (id)getValue {
-  return nullify([super value]);
+- (id)initWithId:(id)theKey
+          withId:(id)theValue {
+  if ((self = [super initWithId:theKey withId:theValue])) {
+    origKeyHash_ = (theKey == nil ? 0 : [JavaUtilHashMap computeHashCodeWithId:theKey]);
+  }
+  return self;
 }
 
 @end
 
-@implementation JavaUtilHashMap_KeySet
 
-@synthesize map = map_;
+@implementation JavaUtilHashMap_AbstractMapIterator
 
-- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)map {
+@synthesize position = position_;
+@synthesize expectedModCount = expectedModCount_;
+@synthesize futureEntry = futureEntry_;
+@synthesize currentEntry = currentEntry_;
+@synthesize prevEntry = prevEntry_;
+@synthesize associatedMap = associatedMap_;
+
+
+- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)hm {
   if ((self = [super init])) {
-    map_ = map;
+    position_ = 0;
+    [associatedMap_ autorelease];
+    associatedMap_ = [hm retain];
+    expectedModCount_ = ((JavaUtilHashMap *) NIL_CHK(hm)).modCount;
+    futureEntry_ = nil;
   }
   return self;
 }
 
-- (int)size {
-  return [map_ size];
+- (BOOL)hasNext {
+  if (futureEntry_ != nil) {
+    return YES;
+  }
+  while (position_ < associatedMap_.elementDataLength) {
+    if (associatedMap_.elementData[position_] == nil) {
+      position_++;
+    }
+    else {
+      return YES;
+    }
+  }
+  return NO;
 }
 
-- (void)clear {
-  [map_ clear];
+- (void)checkConcurrentMod {
+  if (expectedModCount_ != ((JavaUtilHashMap *) NIL_CHK(associatedMap_)).modCount) {
+    @throw [[[JavaUtilConcurrentModificationException alloc] init] autorelease];
+  }
 }
 
-- (BOOL)removeWithId:(id)key {
-  if ([map_ containsKeyWithId:key]) {
-    [map_ removeWithId:key];
-    return YES;
+- (void)makeNext {
+  [self checkConcurrentMod];
+  if (![self hasNext]) {
+    @throw [[[JavaUtilNoSuchElementException alloc] init] autorelease];
+  }
+  if (futureEntry_ == nil) {
+    currentEntry_ = associatedMap_.elementData[position_++];
+    futureEntry_ = currentEntry_->next_;
+    prevEntry_ = nil;
+  }
+  else {
+    if (currentEntry_ != nil) {
+      prevEntry_ = currentEntry_;
+    }
+    currentEntry_ = futureEntry_;
+    futureEntry_ = futureEntry_->next_;
   }
-  return NO;
 }
 
-- (BOOL)containsWithId:(id)key {
-  return [map_ containsKeyWithId:key];
+- (void)remove {
+  [self checkConcurrentMod];
+  if (currentEntry_ == nil) {
+    @throw [[[JavaLangIllegalStateException alloc] init] autorelease];
+  }
+  if (prevEntry_ == nil) {
+    int index = currentEntry_->origKeyHash_ & (associatedMap_.elementDataLength - 1);
+    associatedMap_.elementData[index] = associatedMap_.elementData[index]->next_;
+  }
+  else {
+    prevEntry_->next_ = currentEntry_->next_;
+  }
+  [currentEntry_ autorelease];
+  currentEntry_ = nil;
+  expectedModCount_++;
+  associatedMap_.modCount++;
+  associatedMap_.elementCount--;
 }
 
-- (id<JavaUtilIterator>)iterator {
-  NSMutableArray *keyList = [[self.map.dictionary allKeys] mutableCopy];
-#if ! __has_feature(objc_arc)
-  [keyList autorelease];
-#endif
-  IOSIterator *keyIterator = [[IOSIterator alloc] initWithList:keyList];
-#if ! __has_feature(objc_arc)
-  [keyIterator autorelease];
-#endif
-  id iterator =
-      [[JavaUtilHashMap_KeySetIterator alloc]
-       initWithJavaUtilHashMap:self.map withIterator:keyIterator];
-#if ! __has_feature(objc_arc)
-  [iterator autorelease];
-#endif
-  return iterator;
+- (void)dealloc {
+  [associatedMap_ autorelease];
+  [super dealloc];
 }
 
 @end
 
-@implementation JavaUtilHashMap_EntrySet
 
-- (BOOL)removeWithId:(id)object {
-  if ([object conformsToProtocol:@protocol(JavaUtilMap_Entry)]) {
-    id<JavaUtilMap_Entry> entry = (id<JavaUtilMap_Entry>) object;
-    return [super removeWithId:[entry getKey]];
-  }
-  return NO;
+@implementation JavaUtilHashMap_EntryIterator
+
+- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)map {
+  return [super initWithJavaUtilHashMap:map];
 }
 
-- (BOOL)containsWithId:(id)object {
-  if ([object conformsToProtocol:@protocol(JavaUtilMap_Entry)]) {
-    id<JavaUtilMap_Entry>entry = (id<JavaUtilMap_Entry>) object;
-    return [super containsWithId:[entry getKey]];
-  }
-  return NO;
+- (id<JavaUtilMap_Entry>)next {
+  [self makeNext];
+  return currentEntry_;
 }
 
-- (id<JavaUtilIterator>)iterator {
-  NSMutableArray *keyList = [[self.map.dictionary allKeys] mutableCopy];
-#if ! __has_feature(objc_arc)
-  [keyList autorelease];
-#endif
-  IOSIterator *keyIterator = [[IOSIterator alloc] initWithList:keyList];
-#if ! __has_feature(objc_arc)
-  [keyIterator autorelease];
-#endif
-  id iterator =
-      [[JavaUtilHashMap_EntrySetIterator alloc]
-       initWithJavaUtilHashMap:self.map withIterator:keyIterator];
-#if ! __has_feature(objc_arc)
-  [iterator autorelease];
-#endif
-  return iterator;
+@end
+
+
+@implementation JavaUtilHashMap_KeyIterator
+
+- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)map {
+  return [super initWithJavaUtilHashMap:map];
+}
+
+- (id)next {
+  [self makeNext];
+  return ((JavaUtilHashMap_Entry *) NIL_CHK(currentEntry_)).key;
+}
+
+@end
+
+
+@implementation JavaUtilHashMap_ValueIterator
+
+- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)map {
+  return [super initWithJavaUtilHashMap:map];
+}
+
+- (id)next {
+  [self makeNext];
+  return ((JavaUtilHashMap_Entry *) NIL_CHK(currentEntry_)).value;
 }
 
 @end
 
-@implementation JavaUtilHashMap_KeySetIterator
 
-@synthesize map = map_;
-@synthesize iterator = iterator_;
+@implementation JavaUtilHashMap_HashMapEntrySet
 
-- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)map
-                 withIterator:(IOSIterator *)iterator {
+- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)hm {
   if ((self = [super init])) {
-    map_ = map;
-    iterator_ = iterator;
-    lastKey_ = nil;
+    [associatedMap_ autorelease];
+    associatedMap_ = [hm retain];
   }
   return self;
 }
 
-- (BOOL)hasNext {
-  return [iterator_ hasNext];
+- (JavaUtilHashMap *)hashMap {
+  return associatedMap_;
 }
 
-- (id)next {
-  lastKey_ = [iterator_ next];
-  return lastKey_;
+- (int)size {
+  return ((JavaUtilHashMap *) NIL_CHK(associatedMap_)).elementCount;
 }
 
-- (void)remove {
-  if (!lastKey_) {
-    id exception = [[JavaLangIllegalStateException alloc] init];
-#if ! __has_feature(objc_arc)
-    [exception autorelease];
-#endif
-    @throw exception;
+- (void)clear {
+  [((JavaUtilHashMap *) NIL_CHK(associatedMap_)) clear];
+}
+
+- (BOOL)removeWithId:(id)object {
+  if ([object conformsToProtocol: @protocol(JavaUtilMap_Entry)]) {
+    id<JavaUtilMap_Entry> oEntry = (id<JavaUtilMap_Entry>) object;
+    JavaUtilHashMap_Entry *entry = [associatedMap_ getEntryWithId:[oEntry getKey]];
+    if ([JavaUtilHashMap_HashMapEntrySet valuesEqWithJavaUtilHashMap_Entry:entry
+                                                     withJavaUtilMap_Entry:oEntry]) {
+      [associatedMap_ removeEntryWithJavaUtilHashMap_Entry:entry];
+      return YES;
+    }
   }
-  [map_ removeWithId:lastKey_];
-  lastKey_ = nil;
+  return NO;
 }
 
-- (NSString *)description {
-  return [iterator_ description];
+- (BOOL)containsWithId:(id)object {
+  if ([object conformsToProtocol: @protocol(JavaUtilMap_Entry)]) {
+    id<JavaUtilMap_Entry> oEntry = (id<JavaUtilMap_Entry>) object;
+    JavaUtilHashMap_Entry *entry = [associatedMap_ getEntryWithId:[oEntry getKey]];
+    return [JavaUtilHashMap_HashMapEntrySet valuesEqWithJavaUtilHashMap_Entry:entry
+                                                        withJavaUtilMap_Entry:oEntry];
+  }
+  return NO;
 }
 
-@end
++ (BOOL)valuesEqWithJavaUtilHashMap_Entry:(JavaUtilHashMap_Entry *)entry
+                    withJavaUtilMap_Entry:(id<JavaUtilMap_Entry>)oEntry {
+  return (entry != nil)
+      && ((entry->value_ == nil) ? ([oEntry getValue] == nil)
+          : ([JavaUtilHashMap areEqualValuesWithId:entry->value_ withId:[oEntry getValue]]));
+}
 
-@implementation JavaUtilHashMap_EntrySetIterator
+- (id<JavaUtilIterator>)iterator {
+  return [[[JavaUtilHashMap_EntryIterator alloc] initWithJavaUtilHashMap:associatedMap_] autorelease];
+}
 
-- (id)next {
-  id key = [self.iterator next];
-  id value = [self.map getWithId:key];
-  id result = [[JavaUtilHashMap_Entry alloc] initWithKey:key value:value];
-#if ! __has_feature(objc_arc)
-  [result autorelease];
-#endif
-  return result;
+- (void)dealloc {
+  [associatedMap_ autorelease];
+  [super dealloc];
 }
 
 @end
 
-@implementation JavaUtilHashMap_Values
 
-@synthesize map = map_;
+@implementation JavaUtilHashMap_KeySet
 
-- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)map {
-  if ((self = [super init])) {
-    map_ = map;
-  }
-  return self;
+- (BOOL)containsWithId:(id)object {
+  return [outer_ containsKeyWithId:object];
 }
 
 - (int)size {
-  return [map_ size];
+  return [outer_ size];
 }
 
 - (void)clear {
-  [map_ clear];
+  [outer_ clear];
 }
 
-- (BOOL)containsWithId:(id)object {
-  return [map_ containsValueWithId:object];
+- (BOOL)removeWithId:(id)key {
+  JavaUtilHashMap_Entry *entry = [outer_ removeEntryWithId:key];
+  return entry != nil;
 }
 
 - (id<JavaUtilIterator>)iterator {
-  NSMutableArray *valueList = [[self.map.dictionary allValues] mutableCopy];
-#if ! __has_feature(objc_arc)
-  [valueList autorelease];
-#endif
-  IOSIterator *valueIterator = [[IOSIterator alloc] initWithList:valueList];
-#if ! __has_feature(objc_arc)
-  [valueIterator autorelease];
-#endif
-  id iterator = [[JavaUtilHashMap_ValuesIterator alloc]
-                 initWithJavaUtilHashMap:self.map withIterator:valueIterator];
-#if ! __has_feature(objc_arc)
-  [iterator autorelease];
-#endif
-  return iterator;
-}
-
-- (BOOL)removeWithId:(id)value {
-  if ([map_ containsValueWithId:value]) {
-    for (id key in [map_.dictionary allKeysForObject:value]) {
-      [map_ removeWithId:key];
-      return YES;
-    }
+  return [[[JavaUtilHashMap_KeyIterator alloc] initWithJavaUtilHashMap:outer_] autorelease];
+}
+
+- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)outer {
+  if ((self = [super init])) {
+    [outer_ autorelease];
+    outer_ = [outer retain];
   }
-  return NO;
+  return self;
+}
+
+- (void)dealloc {
+  [outer_ autorelease];
+  [super dealloc];
 }
 
 @end
 
-@implementation JavaUtilHashMap_ValuesIterator
 
-@synthesize map = map_;
+@implementation JavaUtilHashMap_ValuesCollection
 
-- (id)initWithJavaUtilHashMap:(JavaUtilHashMap *)map
-                 withIterator:(IOSIterator *)iterator {
-  if ((self = [super init])) {
-    map_ = map;
-    iterator_ = iterator;
-    lastValue_ = nil;
-  }
-  return self;
+- (BOOL)containsWithId:(id)object {
+  return [outer_ containsValueWithId:object];
 }
 
-- (BOOL)hasNext {
-  return [iterator_ hasNext];
+- (int)size {
+  return [outer_ size];
 }
 
-- (id)next {
-  lastValue_ = [iterator_ next];
-  return lastValue_;
+- (void)clear {
+  [outer_ clear];
",Rewrite HashMap and LinkedHashMap based on translated apache harmony versions . . Change on 2012 / 11 / 08 by kstanger @ kstanger .,"""Refactor JavaUtilHashMap to use a custom implementation instead of NSMutableDictionary""","Based on the provided diff, the commit message should be:

""Update HashMap implementation to use Java Harmony implementation""

This commit message accurately reflects the changes made in the diff, which include updating the HashMap implementation to use the Java Harmony implementation instead of the previous NSMutableDictionary-based implementation.","The commit message should be:

""Refactor HashMap implementation to be based on Java Harmony""

Explanation:
The changes in the diff show a significant refactoring of the HashMap implementation in the JreEmulation project. The new implementation appears to be based on the Java Harmony project, which is an open-source implementation of the Java Class Library.

The changes include the addition of new instance variables, such as `elementCount_`, `elementData_`, `elementDataLength_`, `modCount_`, `loadFactor_`, and `threshold_`, which are used to manage the internal state of the HashMap. The implementation also appears to use a linked list data structure to handle collisions in the hash table, which is a common technique for implementing hash maps.

Overall, the changes suggest a significant refactoring of the HashMap implementation to improve its performance and compatibility with the Java standard library.","Refactored `JavaUtilHashMap` to replace `NSMutableDictionary` with custom implementation based on Java's HashMap, including entry handling and rehashing.",Model 1
"diff --git a/spring-boot-project/spring-boot-docs/src/main/asciidoc/appendix-application-properties.adoc b/spring-boot-project/spring-boot-docs/src/main/asciidoc/appendix-application-properties.adoc
index 4833f5652b..c43771b1f8 100644
--- a/spring-boot-project/spring-boot-docs/src/main/asciidoc/appendix-application-properties.adoc
+++ b/spring-boot-project/spring-boot-docs/src/main/asciidoc/appendix-application-properties.adoc
@@ -14,66 +14,96 @@ Also, you can define your own properties.
 
 
 
-== Core properties
-
+[[common-application-properties-core]]
+== Core properties [[core-properties]]
 include::{generated-resources-root}/config-docs/core.adoc[]
 
-== Cache properties
 
+
+[[common-application-properties-cache]]
+== Cache properties [[cache-properties]]
 include::{generated-resources-root}/config-docs/cache.adoc[]
 
-== Mail properties
 
+
+[[common-application-properties-mail]]
+== Mail properties [[mail-properties]]
 include::{generated-resources-root}/config-docs/mail.adoc[]
 
-== JSON properties
 
+
+[[common-application-properties-json]]
+== JSON properties [[json-properties]]
 include::{generated-resources-root}/config-docs/json.adoc[]
 
-== Data properties
 
+
+[[common-application-properties-data]]
+== Data properties [[data-properties]]
 include::{generated-resources-root}/config-docs/data.adoc[]
 
-== Transaction properties
 
+
+[[common-application-properties-transaction]]
+== Transaction properties [[transaction-properties]]
 include::{generated-resources-root}/config-docs/transaction.adoc[]
 
-== Data migration properties
 
+
+[[common-application-properties-data-migration]]
+== Data migration properties [[data-migration-properties]]
 include::{generated-resources-root}/config-docs/data-migration.adoc[]
 
-== Integration properties
 
+
+[[common-application-properties-integration]]
+== Integration properties [[integration-properties]]
 include::{generated-resources-root}/config-docs/integration.adoc[]
 
-== Web properties
 
+
+[[common-application-properties-web]]
+== Web properties [[web-properties]]
 include::{generated-resources-root}/config-docs/web.adoc[]
 
-== Templating properties
 
+
+[[common-application-properties-templating]]
+== Templating properties [[templating-properties]]
 include::{generated-resources-root}/config-docs/templating.adoc[]
 
-== Server properties
 
+
+[[common-application-properties-server]]
+== Server properties [[server-properties]]
 include::{generated-resources-root}/config-docs/server.adoc[]
 
-== Security properties
 
+
+[[common-application-properties-security]]
+== Security properties [[security-properties]]
 include::{generated-resources-root}/config-docs/security.adoc[]
 
-== RSocket properties
 
+
+[[common-application-properties-rsocket]]
+== RSocket properties [[rsocket-properties]]
 include::{generated-resources-root}/config-docs/rsocket.adoc[]
 
-== Actuator properties
 
+
+[[common-application-properties-actuator]]
+== Actuator properties [[actuator-properties]]
 include::{generated-resources-root}/config-docs/actuator.adoc[]
 
-== Devtools properties
 
+
+[[common-application-properties-devtools]]
+== Devtools properties [[devtools-properties]]
 include::{generated-resources-root}/config-docs/devtools.adoc[]
 
-== Testing properties
 
+
+[[common-application-properties-testing]]
+== Testing properties [[testing-properties]]
 include::{generated-resources-root}/config-docs/testing.adoc[]
diff --git a/spring-boot-project/spring-boot-docs/src/main/asciidoc/spring-boot-features.adoc b/spring-boot-project/spring-boot-docs/src/main/asciidoc/spring-boot-features.adoc
index 18988385b9..51d3b72fc2 100644
--- a/spring-boot-project/spring-boot-docs/src/main/asciidoc/spring-boot-features.adoc
+++ b/spring-boot-project/spring-boot-docs/src/main/asciidoc/spring-boot-features.adoc
@@ -2346,6 +2346,10 @@ If you have this problem, you can reorder the classpath in the IDE to place the
 By default, Spring Boot provides an `/error` mapping that handles all errors in a sensible way, and it is registered as a ""`global`"" error page in the servlet container.
 For machine clients, it produces a JSON response with details of the error, the HTTP status, and the exception message.
 For browser clients, there is a ""`whitelabel`"" error view that renders the same data in HTML format (to customize it, add a `View` that resolves to `error`).
+
+There are a number of `server.error` properties that can be set if you want to customize the default error handling behavior.
+See the <<appendix-application-properties.adoc#common-application-properties-server, ""`Server Properties`"">> section of the Appendix.  
+
 To replace the default behavior completely, you can implement `ErrorController` and register a bean definition of that type or add a bean of type `ErrorAttributes` to use the existing mechanism but replace the contents.
 
 TIP: The `BasicErrorController` can be used as a base class for a custom `ErrorController`.",Add link to appendix from error handling .,"""Added anchor links to application properties sections and referenced server properties in error handling documentation""","""Refactor application properties documentation to improve organization and readability""","""Update appendix-application-properties.adoc and spring-boot-features.adoc""

The changes made in the first file (appendix-application-properties.adoc) involve adding anchor links to the headings of different sections. The format for these anchor links is `[[common-application-properties-<section-name>]]`. For example, `[[common-application-properties-core]]` is added before the ""Core properties"" section.

In the second file (spring-boot-features.adoc), a paragraph is added at the end of a section, and a link is included in this paragraph that points to a specific section in the first file. The link is created using the format `<<appendix-application-properties.adoc#common-application-properties-<section-name>, ""`<Section-Name>`"">>`. For example, `<<appendix-application-properties.adoc#common-application-properties-server, ""`Server Properties`"">>` is used to link to the ""Server Properties"" section in the first file.",Add section links to server properties in appendix and error handling in Spring Boot docs.,Model 2
"diff --git a/assembly/pom.xml b/assembly/pom.xml
index cd81a376b9..76cd48ce81 100644
--- a/assembly/pom.xml
+++ b/assembly/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-parent</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <groupId>org.tachyonproject</groupId>
   <artifactId>tachyon-assemblies</artifactId>
diff --git a/clients/client/pom.xml b/clients/client/pom.xml
index e5edd61807..f1a3fd58ce 100644
--- a/clients/client/pom.xml
+++ b/clients/client/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-clients</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <groupId>org.tachyonproject</groupId>
   <artifactId>tachyon-client</artifactId>
diff --git a/clients/pom.xml b/clients/pom.xml
index 4b6c5e20fe..c44d36f5ef 100644
--- a/clients/pom.xml
+++ b/clients/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-parent</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-clients</artifactId>
   <packaging>pom</packaging>
diff --git a/clients/unshaded/pom.xml b/clients/unshaded/pom.xml
index d98d2b689d..7a90c025b6 100644
--- a/clients/unshaded/pom.xml
+++ b/clients/unshaded/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-clients</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-client-unshaded</artifactId>
   <packaging>jar</packaging>
diff --git a/common/pom.xml b/common/pom.xml
index 75ecfedf8f..1d2e885e2a 100644
--- a/common/pom.xml
+++ b/common/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-parent</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-common</artifactId>
   <packaging>jar</packaging>
diff --git a/examples/pom.xml b/examples/pom.xml
index ecb63530cc..c6019674d6 100644
--- a/examples/pom.xml
+++ b/examples/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-parent</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-examples</artifactId>
   <packaging>jar</packaging>
diff --git a/integration-tests/pom.xml b/integration-tests/pom.xml
index fc3440f351..0b2806b4b3 100644
--- a/integration-tests/pom.xml
+++ b/integration-tests/pom.xml
@@ -1,9 +1,11 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-parent</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-integration-tests</artifactId>
   <packaging>jar</packaging>
@@ -214,7 +216,7 @@
             <groupId>org.apache.maven.plugins</groupId>
             <artifactId>maven-compiler-plugin</artifactId>
             <configuration>
-              <testExcludes combine.self=""override"" />
+              <testExcludes combine.self=""override""/>
             </configuration>
           </plugin>
         </plugins>
diff --git a/minicluster/pom.xml b/minicluster/pom.xml
index 53825dc888..465342d8ae 100644
--- a/minicluster/pom.xml
+++ b/minicluster/pom.xml
@@ -1,8 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <parent>
     <artifactId>tachyon-parent</artifactId>
     <groupId>org.tachyonproject</groupId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <modelVersion>4.0.0</modelVersion>
 
diff --git a/pom.xml b/pom.xml
index 99f01e6a65..26309fabf6 100644
--- a/pom.xml
+++ b/pom.xml
@@ -2,7 +2,7 @@
   <modelVersion>4.0.0</modelVersion>
   <groupId>org.tachyonproject</groupId>
   <artifactId>tachyon-parent</artifactId>
-  <version>0.7.1-SNAPSHOT</version>
+  <version>0.7.0-SNAPSHOT</version>
   <packaging>pom</packaging>
   <name>Tachyon Parent</name>
   <description>Parent POM of Tachyon project: a Reliable Memory Centric Distributed Storage System</description>
diff --git a/servers/pom.xml b/servers/pom.xml
index 39d06b0c45..d875ff9ce2 100644
--- a/servers/pom.xml
+++ b/servers/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-parent</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-servers</artifactId>
   <packaging>jar</packaging>
diff --git a/shell/pom.xml b/shell/pom.xml
index 8992588abf..ae9dcd50c0 100644
--- a/shell/pom.xml
+++ b/shell/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-parent</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-shell</artifactId>
   <packaging>jar</packaging>
diff --git a/underfs/glusterfs/pom.xml b/underfs/glusterfs/pom.xml
index fd0a59e4f8..5d21326147 100644
--- a/underfs/glusterfs/pom.xml
+++ b/underfs/glusterfs/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-underfs</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-underfs-glusterfs</artifactId>
   <name>Tachyon Under File System - Gluster FS</name>
diff --git a/underfs/hdfs/pom.xml b/underfs/hdfs/pom.xml
index b8fa76e907..d3788a7709 100644
--- a/underfs/hdfs/pom.xml
+++ b/underfs/hdfs/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-underfs</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-underfs-hdfs</artifactId>
   <name>Tachyon Under File System - HDFS</name>
diff --git a/underfs/local/pom.xml b/underfs/local/pom.xml
index ac867dfd92..62d2298512 100644
--- a/underfs/local/pom.xml
+++ b/underfs/local/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-underfs</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-underfs-local</artifactId>
   <name>Tachyon Under File System - Local FS</name>
diff --git a/underfs/pom.xml b/underfs/pom.xml
index 91381959cd..795b192577 100644
--- a/underfs/pom.xml
+++ b/underfs/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-parent</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-underfs</artifactId>
   <packaging>pom</packaging>
diff --git a/underfs/s3/pom.xml b/underfs/s3/pom.xml
index 4f18103a13..08c3c03552 100644
--- a/underfs/s3/pom.xml
+++ b/underfs/s3/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-underfs</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-underfs-s3</artifactId>
   <name>Tachyon Under File System - S3</name>
diff --git a/underfs/swift/pom.xml b/underfs/swift/pom.xml
index a1834e9d08..4283f2b395 100644
--- a/underfs/swift/pom.xml
+++ b/underfs/swift/pom.xml
@@ -1,9 +1,10 @@
-<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
   <modelVersion>4.0.0</modelVersion>
   <parent>
     <groupId>org.tachyonproject</groupId>
     <artifactId>tachyon-underfs</artifactId>
-    <version>0.7.1-SNAPSHOT</version>
+    <version>0.7.0-SNAPSHOT</version>
   </parent>
   <artifactId>tachyon-underfs-swift</artifactId>
   <name>Tachyon Under File System - Swift</name>",Revert release plugin changes .,Downgrade Tachyon version from 0.7.1-SNAPSHOT to 0.7.0-SNAPSHOT,Bump Tachyon version to 0.7.0-SNAPSHOT in various pom.xml files.,"""Downgrading Tachyon version from 0.7.1-SNAPSHOT to 0.7.0-SNAPSHOT""

This commit involves changing the version of Tachyon from 0.7.1-SNAPSHOT to 0.7.0-SNAPSHOT in multiple pom.xml files throughout the project. It seems like the project is downgrading the version of Tachyon used.","""Revert version from 0.7.1-SNAPSHOT to 0.7.0-SNAPSHOT across multiple POM files""",Model 1
"diff --git a/crepecake/build.gradle b/crepecake/build.gradle
index 6c62c19c..3b4dbb05 100644
--- a/crepecake/build.gradle
+++ b/crepecake/build.gradle
@@ -15,6 +15,7 @@ repositories {
 
 dependencies {
     compile gradleApi()
+    compile 'com.google.http-client:google-http-client:1.23.0'
     compile 'org.apache.commons:commons-compress:1.15'
     compile 'com.google.guava:guava:23.5-jre'
     compile 'com.fasterxml.jackson.core:jackson-databind:2.9.2'
diff --git a/crepecake/src/main/java/com/google/cloud/tools/crepecake/blob/InputStreamBlob.java b/crepecake/src/main/java/com/google/cloud/tools/crepecake/blob/InputStreamBlob.java
index cb9c21fd..363f7f75 100644
--- a/crepecake/src/main/java/com/google/cloud/tools/crepecake/blob/InputStreamBlob.java
+++ b/crepecake/src/main/java/com/google/cloud/tools/crepecake/blob/InputStreamBlob.java
@@ -45,6 +45,8 @@ class InputStreamBlob implements Blob {
 
   @Override
   public BlobDescriptor writeTo(OutputStream outputStream) throws IOException {
-    return writeFromInputStream(inputStream, outputStream);
+    try (InputStream inputStream = this.inputStream) {
+      return writeFromInputStream(inputStream, outputStream);
+    }
   }
 }
diff --git a/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/BlobHttpContent.java b/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/BlobHttpContent.java
new file mode 100644
index 00000000..94d0f179
--- /dev/null
+++ b/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/BlobHttpContent.java
@@ -0,0 +1,54 @@
+/*
+ * Copyright 2017 Google Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License""); you may not
+ * use this file except in compliance with the License. You may obtain a copy of
+ * the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+
+package com.google.cloud.tools.crepecake.http;
+
+import com.google.api.client.http.HttpContent;
+import com.google.cloud.tools.crepecake.blob.Blob;
+import java.io.IOException;
+import java.io.OutputStream;
+
+/** {@link Blob}-backed {@link HttpContent}. */
+class BlobHttpContent implements HttpContent {
+
+  private final Blob blob;
+
+  BlobHttpContent(Blob blob) {
+    this.blob = blob;
+  }
+
+  @Override
+  public long getLength() throws IOException {
+    // Returns negative value for unknown length.
+    return -1;
+  }
+
+  @Override
+  public String getType() {
+    // TODO: This should return the actual Content-Type.
+    return null;
+  }
+
+  @Override
+  public boolean retrySupported() {
+    return false;
+  }
+
+  @Override
+  public void writeTo(OutputStream outputStream) throws IOException {
+    blob.writeTo(outputStream);
+  }
+}
diff --git a/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Connection.java b/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Connection.java
new file mode 100644
index 00000000..a61e322a
--- /dev/null
+++ b/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Connection.java
@@ -0,0 +1,99 @@
+/*
+ * Copyright 2017 Google Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License""); you may not
+ * use this file except in compliance with the License. You may obtain a copy of
+ * the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+
+package com.google.cloud.tools.crepecake.http;
+
+import com.google.api.client.http.GenericUrl;
+import com.google.api.client.http.HttpMethods;
+import com.google.api.client.http.HttpRequestFactory;
+import com.google.api.client.http.HttpResponse;
+import com.google.api.client.http.javanet.NetHttpTransport;
+import com.google.common.annotations.VisibleForTesting;
+import java.io.Closeable;
+import java.io.IOException;
+import java.net.URL;
+
+/**
+ * Sends an HTTP {@link Request} and stores the {@link Response}.
+ *
+ * <p>Example usage:
+ *
+ * <pre>{@code
+ * try (Connection connection = new Connection(url)) {
+ *   Response response = connection.get(request);
+ *   // ... process the response
+ * }
+ * }</pre>
+ */
+public class Connection implements Closeable {
+
+  private static final HttpRequestFactory HTTP_REQUEST_FACTORY =
+      new NetHttpTransport().createRequestFactory();
+
+  private final HttpRequestFactory requestFactory;
+
+  private HttpResponse httpResponse;
+
+  /** The URL to send the request to. */
+  private GenericUrl url;
+
+  /**
+   * Make sure to wrap with a try-with-resource to ensure that the connection is closed after usage.
+   */
+  public Connection(URL url) throws IOException {
+    this(url, HTTP_REQUEST_FACTORY);
+  }
+
+  @VisibleForTesting
+  Connection(URL url, HttpRequestFactory requestFactory) {
+    this.url = new GenericUrl(url);
+    this.requestFactory = requestFactory;
+  }
+
+  @Override
+  public void close() throws IOException {
+    if (httpResponse == null) {
+      return;
+    }
+
+    httpResponse.disconnect();
+  }
+
+  /** Sends the request with method GET. */
+  public Response get(Request request) throws IOException {
+    return send(HttpMethods.GET, request);
+  }
+
+  /** Sends the request with method POST. */
+  public Response post(Request request) throws IOException {
+    return send(HttpMethods.POST, request);
+  }
+
+  /** Sends the request with method PUT. */
+  public Response put(Request request) throws IOException {
+    return send(HttpMethods.PUT, request);
+  }
+
+  /** Sends the request. */
+  private Response send(String httpMethod, Request request) throws IOException {
+    httpResponse =
+        requestFactory
+            .buildRequest(httpMethod, url, request.getHttpContent())
+            .setHeaders(request.getHeaders())
+            .execute();
+    return new Response(httpResponse);
+  }
+}
diff --git a/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Request.java b/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Request.java
new file mode 100644
index 00000000..6e17a0ec
--- /dev/null
+++ b/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Request.java
@@ -0,0 +1,51 @@
+/*
+ * Copyright 2017 Google Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License""); you may not
+ * use this file except in compliance with the License. You may obtain a copy of
+ * the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+
+package com.google.cloud.tools.crepecake.http;
+
+import com.google.api.client.http.HttpHeaders;
+import com.google.cloud.tools.crepecake.blob.Blob;
+import javax.annotation.Nullable;
+
+/** Holds an HTTP request. */
+public class Request {
+
+  /** The HTTP request headers. */
+  private final HttpHeaders headers = new HttpHeaders();
+
+  /** The HTTP request body. */
+  @Nullable private BlobHttpContent body;
+
+  public HttpHeaders getHeaders() {
+    return headers;
+  }
+
+  @Nullable
+  public BlobHttpContent getHttpContent() {
+    return body;
+  }
+
+  /** Sets the {@code Content-Type} header. */
+  public Request setContentType(String contentType) {
+    headers.setContentType(contentType);
+    return this;
+  }
+
+  public Request setBody(Blob body) {
+    this.body = new BlobHttpContent(body);
+    return this;
+  }
+}
diff --git a/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Response.java b/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Response.java
new file mode 100644
index 00000000..ecd00d87
--- /dev/null
+++ b/crepecake/src/main/java/com/google/cloud/tools/crepecake/http/Response.java
@@ -0,0 +1,48 @@
+/*
+ * Copyright 2017 Google Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License""); you may not
+ * use this file except in compliance with the License. You may obtain a copy of
+ * the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+
+package com.google.cloud.tools.crepecake.http;
+
+import com.google.api.client.http.HttpResponse;
+import com.google.cloud.tools.crepecake.blob.Blob;
+import com.google.cloud.tools.crepecake.blob.Blobs;
+import java.io.IOException;
+import java.util.List;
+
+/** Holds an HTTP response. */
+public class Response {
+
+  private final HttpResponse httpResponse;
+
+  Response(HttpResponse httpResponse) {
+    this.httpResponse = httpResponse;
+  }
+
+  /** Gets the HTTP status code of the response. */
+  public int getStatusCode() {
+    return httpResponse.getStatusCode();
+  }
+
+  /** Gets a header in the response. */
+  public List<String> getHeader(String headerName) {
+    return httpResponse.getHeaders().getHeaderStringValues(headerName);
+  }
+
+  /** Gets the HTTP response body as a {@link Blob}. */
+  public Blob getBody() throws IOException {
+    return Blobs.from(httpResponse.getContent());
+  }
+}
diff --git a/crepecake/src/test/java/com/google/cloud/tools/crepecake/blob/BlobTest.java b/crepecake/src/test/java/com/google/cloud/tools/crepecake/blob/BlobTest.java
index 359029da..90599990 100644
--- a/crepecake/src/test/java/com/google/cloud/tools/crepecake/blob/BlobTest.java
+++ b/crepecake/src/test/java/com/google/cloud/tools/crepecake/blob/BlobTest.java
@@ -38,33 +38,33 @@ public class BlobTest {
 
   @Test
   public void testEmpty() throws IOException, DigestException {
-    verifyBlobStreamWriteTo("""", Blobs.empty());
+    verifyBlobWriteTo("""", Blobs.empty());
   }
 
   @Test
   public void testFromInputStream() throws IOException, DigestException {
     String expected = ""crepecake"";
     InputStream inputStream = new ByteArrayInputStream(expected.getBytes(Charsets.UTF_8));
-    verifyBlobStreamWriteTo(expected, Blobs.from(inputStream));
+    verifyBlobWriteTo(expected, Blobs.from(inputStream));
   }
 
   @Test
   public void testFromFile() throws IOException, DigestException, URISyntaxException {
     File fileA = new File(Resources.getResource(""fileA"").toURI());
     String expected = new String(Files.readAllBytes(fileA.toPath()), Charsets.UTF_8);
-    verifyBlobStreamWriteTo(expected, Blobs.from(fileA));
+    verifyBlobWriteTo(expected, Blobs.from(fileA));
   }
 
   @Test
   public void testFromString_hashing() throws IOException, DigestException {
     String expected = ""crepecake"";
-    verifyBlobStreamWriteTo(expected, Blobs.from(expected, true));
+    verifyBlobWriteTo(expected, Blobs.from(expected, true));
   }
 
   @Test
   public void testFromString_noHashing() throws IOException, DigestException {
     String expected = ""crepecake"";
-    verifyBlobStreamWriteTo(expected, Blobs.from(expected, false));
+    verifyBlobWriteTo(expected, Blobs.from(expected, false));
   }
 
   @Test
@@ -73,12 +73,11 @@ public class BlobTest {
 
     BlobWriter writer = outputStream -> outputStream.write(expected.getBytes(Charsets.UTF_8));
 
-    verifyBlobStreamWriteTo(expected, Blobs.from(writer));
+    verifyBlobWriteTo(expected, Blobs.from(writer));
   }
 
   /** Checks that the {@link Blob} streams the expected string. */
-  private void verifyBlobStreamWriteTo(String expected, Blob blob)
-      throws IOException, DigestException {
+  private void verifyBlobWriteTo(String expected, Blob blob) throws IOException, DigestException {
     OutputStream outputStream = new ByteArrayOutputStream();
     BlobDescriptor blobDescriptor = blob.writeTo(outputStream);
 
diff --git a/crepecake/src/test/java/com/google/cloud/tools/crepecake/http/ConnectionTest.java b/crepecake/src/test/java/com/google/cloud/tools/crepecake/http/ConnectionTest.java
new file mode 100644
index 00000000..87c27042
--- /dev/null
+++ b/crepecake/src/test/java/com/google/cloud/tools/crepecake/http/ConnectionTest.java
@@ -0,0 +1,112 @@
+/*
+ * Copyright 2017 Google Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License""); you may not
+ * use this file except in compliance with the License. You may obtain a copy of
+ * the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+
+package com.google.cloud.tools.crepecake.http;
+
+import com.google.api.client.http.GenericUrl;
+import com.google.api.client.http.HttpHeaders;
+import com.google.api.client.http.HttpMethods;
+import com.google.api.client.http.HttpRequest;
+import com.google.api.client.http.HttpRequestFactory;
+import com.google.api.client.http.HttpResponse;
+import com.google.cloud.tools.crepecake.blob.Blob;
+import com.google.cloud.tools.crepecake.blob.Blobs;
+import com.google.common.base.Charsets;
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.ArgumentCaptor;
+import org.mockito.Mock;
+import org.mockito.Mockito;
+import org.mockito.junit.MockitoJUnitRunner;
+
+/** Tests for {@link Connection}. */
+@RunWith(MockitoJUnitRunner.class)
+public class ConnectionTest {
+
+  @Mock private HttpRequestFactory mockHttpRequestFactory;
+  @Mock private HttpRequest mockHttpRequest;
+  @Mock private HttpResponse mockHttpResponse;
+
+  private final ArgumentCaptor<HttpHeaders> httpHeadersArgumentCaptor =
+      ArgumentCaptor.forClass(HttpHeaders.class);
+  private final ArgumentCaptor<BlobHttpContent> blobHttpContentArgumentCaptor =
+      ArgumentCaptor.forClass(BlobHttpContent.class);
+
+  private final GenericUrl fakeUrl = new GenericUrl(""http://crepecake/fake/url"");
+  private final Request fakeRequest = new Request();
+
+  @Before
+  public void setUpMocksAndFakes() throws IOException {
+    Blob fakeBlob = Blobs.from(""crepecake"", false);
+    fakeRequest.setBody(fakeBlob);
+    fakeRequest.setContentType(""fake.content.type"");
+
+    Mockito.when(
+            mockHttpRequestFactory.buildRequest(
+                Mockito.any(String.class), Mockito.eq(fakeUrl), Mockito.any(BlobHttpContent.class)))
+        .thenReturn(mockHttpRequest);
+
+    Mockito.when(mockHttpRequest.setHeaders(Mockito.any(HttpHeaders.class)))
+        .thenReturn(mockHttpRequest);
+    Mockito.when(mockHttpRequest.execute()).thenReturn(mockHttpResponse);
+  }
+
+  @Test
+  public void testGet() throws IOException {
+    testSend(HttpMethods.GET, Connection::get);
+  }
+
+  @Test
+  public void testPost() throws IOException {
+    testSend(HttpMethods.POST, Connection::post);
+  }
+
+  @Test
+  public void testPut() throws IOException {
+    testSend(HttpMethods.PUT, Connection::put);
+  }
+
+  @FunctionalInterface
+  private interface SendFunction {
+
+    Response send(Connection connection, Request request) throws IOException;
+  }
+
+  private void testSend(String httpMethod, SendFunction sendFunction) throws IOException {
+    try (Connection connection = new Connection(fakeUrl.toURL(), mockHttpRequestFactory)) {
+      sendFunction.send(connection, fakeRequest);
+    }
+
+    Mockito.verify(mockHttpRequest).setHeaders(httpHeadersArgumentCaptor.capture());
+    Mockito.verify(mockHttpResponse).disconnect();
+
+    Assert.assertEquals(""fake.content.type"", httpHeadersArgumentCaptor.getValue().getContentType());
+
+    Mockito.verify(mockHttpRequestFactory)
+        .buildRequest(
+            Mockito.eq(httpMethod), Mockito.eq(fakeUrl), blobHttpContentArgumentCaptor.capture());
+
+    ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();
+    blobHttpContentArgumentCaptor.getValue().writeTo(byteArrayOutputStream);
+
+    Assert.assertEquals(
+        ""crepecake"", new String(byteArrayOutputStream.toByteArray(), Charsets.UTF_8));
+  }
+}
diff --git a/crepecake/src/test/java/com/google/cloud/tools/crepecake/http/ResponseTest.java b/crepecake/src/test/java/com/google/cloud/tools/crepecake/http/ResponseTest.java
new file mode 100644
index 00000000..d7fd0782
--- /dev/null
+++ b/crepecake/src/test/java/com/google/cloud/tools/crepecake/http/ResponseTest.java
@@ -0,0 +1,55 @@
+/*
+ * Copyright 2017 Google Inc.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License""); you may not
+ * use this file except in compliance with the License. You may obtain a copy of
+ * the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations under
+ * the License.
+ */
+
+package com.google.cloud.tools.crepecake.http;
+
+import com.google.api.client.http.HttpResponse;
+import com.google.cloud.tools.crepecake.blob.Blob;
+import com.google.common.base.Charsets;
+import java.io.ByteArrayInputStream;
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import org.junit.Assert;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mock;
+import org.mockito.Mockito;
+import org.mockito.junit.MockitoJUnitRunner;
+
+/** Tests for {@link Response}. */
+@RunWith(MockitoJUnitRunner.class)
+public class ResponseTest {
+
+  @Mock private HttpResponse httpResponseMock;
+
+  @Test
+  public void testGetContent() throws IOException {
+    String expectedResponse = ""crepecake\nis\ngood!"";
+    ByteArrayInputStream responseInputStream =
+        new ByteArrayInputStream(expectedResponse.getBytes(Charsets.UTF_8));
+
+    Mockito.when(httpResponseMock.getContent()).thenReturn(responseInputStream);
+
+    Response response = new Response(httpResponseMock);
+    Blob responseStream = response.getBody();
+
+    ByteArrayOutputStream responseOutputStream = new ByteArrayOutputStream();
+    responseStream.writeTo(responseOutputStream);
+
+    Assert.assertEquals(
+        expectedResponse, new String(responseOutputStream.toByteArray(), Charsets.UTF_8));
+  }
+}
diff --git a/crepecake/src/test/resources/mockito-extensions/org.mockito.plugins.MockMaker b/crepecake/src/test/resources/mockito-extensions/org.mockito.plugins.MockMaker
new file mode 100644
index 00000000..1f0955d4
--- /dev/null
+++ b/crepecake/src/test/resources/mockito-extensions/org.mockito.plugins.MockMaker
@@ -0,0 +1 @@
+mock-maker-inline",Adds HTTP request utilities .,"""Added HTTP client functionality and tests""","Added HTTP client functionality to crepecake

This commit message is concise and accurately describes the changes made in the commit. It mentions the addition of HTTP client functionality, which is the main focus of the changes.","""Added Google HTTP client library and related code changes""

The commit adds the Google HTTP client library as a dependency in the build.gradle file and includes several new Java classes related to HTTP requests and responses in the crepecake/src/main/java/com/google/cloud/tools/crepecake/http/ directory. There is also a change to the InputStreamBlob class to properly close the input stream after use.","Added HTTP request handling using google-http-client, included new BlobHttpContent, Connection, Request, and Response classes, and corresponding unit tests.",Model 3
"diff --git a/components/camel-http/src/main/java/org/apache/camel/component/http/HttpComponent.java b/components/camel-http/src/main/java/org/apache/camel/component/http/HttpComponent.java
index d1de0457021..b8b2b028d11 100644
--- a/components/camel-http/src/main/java/org/apache/camel/component/http/HttpComponent.java
+++ b/components/camel-http/src/main/java/org/apache/camel/component/http/HttpComponent.java
@@ -397,7 +397,7 @@ public class HttpComponent extends HttpCommonComponent implements RestProducerFa
         if (localConnectionsPerRoute > 0) {
             answer.setDefaultMaxPerRoute(localConnectionsPerRoute);
         }
-        LOG.info(""Created ClientConnectionManager {}"", answer);
+        LOG.debug(""Created ClientConnectionManager {}"", answer);
 
         return answer;
     }",create connection manager method logs in debug mode .,"""Downgrade log level for ClientConnectionManager creation from INFO to DEBUG""","""Log level for ClientConnectionManager creation changed to DEBUG""","""Change log level from INFO to DEBUG for creating ClientConnectionManager in HttpComponent.java""",Changed log level from info to debug for ClientConnectionManager creation in HttpComponent.,Model 1
"diff --git a/management/src/main/java/io/micronaut/management/endpoint/info/InfoAggregator.java b/management/src/main/java/io/micronaut/management/endpoint/info/InfoAggregator.java
index ab2dc2d822..b2ec2cf328 100644
--- a/management/src/main/java/io/micronaut/management/endpoint/info/InfoAggregator.java
+++ b/management/src/main/java/io/micronaut/management/endpoint/info/InfoAggregator.java
@@ -15,9 +15,6 @@
  */
 package io.micronaut.management.endpoint.info;
 
-import io.micronaut.context.env.Environment;
-import io.micronaut.context.env.PropertySource;
-import io.micronaut.management.endpoint.Endpoint;
 import org.reactivestreams.Publisher;
 
 /**
@@ -27,7 +24,6 @@ import org.reactivestreams.Publisher;
  * @author Zachary Klein
  * @since 1.0
  */
-@Endpoint(""info"")
 public interface InfoAggregator<T> {
 
     /**
diff --git a/management/src/main/java/io/micronaut/management/endpoint/info/InfoEndpoint.java b/management/src/main/java/io/micronaut/management/endpoint/info/InfoEndpoint.java
index 74a6cdb599..f8af9fede9 100644
--- a/management/src/main/java/io/micronaut/management/endpoint/info/InfoEndpoint.java
+++ b/management/src/main/java/io/micronaut/management/endpoint/info/InfoEndpoint.java
@@ -27,10 +27,9 @@ import org.reactivestreams.Publisher;
  * @author Zachary Klein
  * @since 1.0
  */
-@Endpoint(""info"")
+@Endpoint(InfoEndpoint.NAME)
 public class InfoEndpoint {
 
-
     public static final String NAME = ""info"";
     public static final String PREFIX = EndpointConfiguration.PREFIX + ""."" + NAME;
 ",Remove endpoint annotation added where it shouldnt be,"""Remove duplicate @Endpoint annotation from InfoAggregator and standardize endpoint name in InfoEndpoint""","The commit message should be: 

""Remove unnecessary imports and annotations from InfoAggregator and InfoEndpoint""","""Remove @Endpoint annotation from InfoAggregator and add it to InfoEndpoint with constant name""

Explanation:
The diff shows that the `@Endpoint(""info"")` annotation has been removed from the `InfoAggregator` interface and added to the `InfoEndpoint` class with the constant name `InfoEndpoint.NAME`. Additionally, an unused import statement `import io.micronaut.management.endpoint.Endpoint;` has been removed from the `InfoAggregator` interface.",Refactor: Specify `InfoEndpoint.NAME` in `@Endpoint` annotation and clean up imports and `@Endpoint` annotation from `InfoAggregator`.,Model 2
"diff --git a/modules/core/src/main/java/org/apache/ignite/internal/processors/cache/transactions/TxDeadlockDetection.java b/modules/core/src/main/java/org/apache/ignite/internal/processors/cache/transactions/TxDeadlockDetection.java
index a904e5b6fe..576dec74d7 100644
--- a/modules/core/src/main/java/org/apache/ignite/internal/processors/cache/transactions/TxDeadlockDetection.java
+++ b/modules/core/src/main/java/org/apache/ignite/internal/processors/cache/transactions/TxDeadlockDetection.java
@@ -52,7 +52,7 @@ import static org.apache.ignite.internal.processors.cache.transactions.IgniteTxM
  */
 public class TxDeadlockDetection {
     /** Deadlock detection maximum iterations. */
-    private static final int DEADLOCK_TIMEOUT = getInteger(IGNITE_TX_DEADLOCK_DETECTION_TIMEOUT, 60000);
+    private static int deadLockTimeout = getInteger(IGNITE_TX_DEADLOCK_DETECTION_TIMEOUT, 60000);
 
     /** Sequence. */
     private static final AtomicLong SEQ = new AtomicLong();
@@ -229,7 +229,7 @@ public class TxDeadlockDetection {
             this.topVer = topVer;
             this.keys = keys;
 
-            if (DEADLOCK_TIMEOUT > 0) {
+            if (deadLockTimeout > 0) {
                 timeoutObj = new DeadlockTimeoutObject();
 
                 cctx.time().addTimeoutObject(timeoutObj);
@@ -555,7 +555,7 @@ public class TxDeadlockDetection {
              * Default constructor.
              */
             DeadlockTimeoutObject() {
-                super(DEADLOCK_TIMEOUT);
+                super(deadLockTimeout);
             }
 
             /** {@inheritDoc} */
@@ -564,7 +564,7 @@ public class TxDeadlockDetection {
 
                 IgniteLogger log = cctx.kernalContext().log(this.getClass());
 
-                U.warn(log, ""Deadlock detection was timed out [timeout="" + DEADLOCK_TIMEOUT + "", fut="" + this + ']');
+                U.warn(log, ""Deadlock detection was timed out [timeout="" + deadLockTimeout + "", fut="" + this + ']');
 
                 onDone();
             }
diff --git a/modules/core/src/test/java/org/apache/ignite/internal/processors/cache/transactions/TxDeadlockDetectionNoHangsTest.java b/modules/core/src/test/java/org/apache/ignite/internal/processors/cache/transactions/TxDeadlockDetectionNoHangsTest.java
index 27a07993d5..7a7651b6b5 100644
--- a/modules/core/src/test/java/org/apache/ignite/internal/processors/cache/transactions/TxDeadlockDetectionNoHangsTest.java
+++ b/modules/core/src/test/java/org/apache/ignite/internal/processors/cache/transactions/TxDeadlockDetectionNoHangsTest.java
@@ -89,12 +89,12 @@ public class TxDeadlockDetectionNoHangsTest extends GridCommonAbstractTest {
     @Override protected void beforeTestsStarted() throws Exception {
         super.beforeTestsStarted();
 
-        GridTestUtils.setFieldValue(null, TxDeadlockDetection.class, ""DEADLOCK_TIMEOUT"", (int)(getTestTimeout() * 2));
+        GridTestUtils.setFieldValue(TxDeadlockDetection.class, ""deadLockTimeout"", (int)(getTestTimeout() * 2));
     }
 
     /** {@inheritDoc} */
     @Override protected void afterTestsStopped() throws Exception {
-        GridTestUtils.setFieldValue(null, TxDeadlockDetection.class, ""DEADLOCK_TIMEOUT"",
+        GridTestUtils.setFieldValue(TxDeadlockDetection.class, ""deadLockTimeout"",
             getInteger(IGNITE_TX_DEADLOCK_DETECTION_TIMEOUT, 60000));
     }
 
@@ -113,14 +113,14 @@ public class TxDeadlockDetectionNoHangsTest extends GridCommonAbstractTest {
         doTest(PESSIMISTIC);
 
         try {
-            GridTestUtils.setFieldValue(null, IgniteTxManager.class, ""DEADLOCK_MAX_ITERS"", 0);
+            GridTestUtils.setFieldValue(IgniteTxManager.class, ""DEADLOCK_MAX_ITERS"", 0);
 
             assertFalse(grid(0).context().cache().context().tm().deadlockDetectionEnabled());
 
             doTest(PESSIMISTIC);
         }
         finally {
-            GridTestUtils.setFieldValue(null, IgniteTxManager.class, ""DEADLOCK_MAX_ITERS"",
+            GridTestUtils.setFieldValue(IgniteTxManager.class, ""DEADLOCK_MAX_ITERS"",
                 IgniteSystemProperties.getInteger(IGNITE_TX_DEADLOCK_DETECTION_MAX_ITERS, 1000));
         }
     }
@@ -135,14 +135,14 @@ public class TxDeadlockDetectionNoHangsTest extends GridCommonAbstractTest {
         doTest(OPTIMISTIC);
 
         try {
-            GridTestUtils.setFieldValue(null, IgniteTxManager.class, ""DEADLOCK_MAX_ITERS"", 0);
+            GridTestUtils.setFieldValue(IgniteTxManager.class, ""DEADLOCK_MAX_ITERS"", 0);
 
             assertFalse(grid(0).context().cache().context().tm().deadlockDetectionEnabled());
 
             doTest(OPTIMISTIC);
         }
         finally {
-            GridTestUtils.setFieldValue(null, IgniteTxManager.class, ""DEADLOCK_MAX_ITERS"",
+            GridTestUtils.setFieldValue(IgniteTxManager.class, ""DEADLOCK_MAX_ITERS"",
                 IgniteSystemProperties.getInteger(IGNITE_TX_DEADLOCK_DETECTION_MAX_ITERS, 1000));
         }
     }
diff --git a/modules/core/src/test/java/org/apache/ignite/testframework/GridTestUtils.java b/modules/core/src/test/java/org/apache/ignite/testframework/GridTestUtils.java
index f7993226b6..608c52aa4c 100644
--- a/modules/core/src/test/java/org/apache/ignite/testframework/GridTestUtils.java
+++ b/modules/core/src/test/java/org/apache/ignite/testframework/GridTestUtils.java
@@ -34,10 +34,8 @@ import java.net.InetAddress;
 import java.net.MulticastSocket;
 import java.net.ServerSocket;
 import java.nio.file.attribute.PosixFilePermission;
-import java.security.AccessController;
 import java.security.GeneralSecurityException;
 import java.security.KeyStore;
-import java.security.PrivilegedAction;
 import java.sql.Connection;
 import java.sql.DriverManager;
 import java.sql.SQLException;
@@ -1621,27 +1619,6 @@ public final class GridTestUtils {
         return field.get(obj);
     }
 
-    /**
-     * Change static final fields.
-     * @param field Need to be changed.
-     * @param newVal New value.
-     * @throws Exception If failed.
-     */
-    public static void setFieldValue(Field field, Object newVal) throws Exception {
-        field.setAccessible(true);
-        Field modifiersField = Field.class.getDeclaredField(""modifiers"");
-
-        AccessController.doPrivileged(new PrivilegedAction() {
-            @Override public Object run() {
-                modifiersField.setAccessible(true);
-                return null;
-            }
-        });
-
-        modifiersField.setInt(field, field.getModifiers() & ~Modifier.FINAL);
-        field.set(null, newVal);
-    }
-
     /**
      * Get inner class by its name from the enclosing class.
      *
@@ -1674,6 +1651,18 @@ public final class GridTestUtils {
 
             Field field = cls.getDeclaredField(fieldName);
 
+            boolean isFinal = (field.getModifiers() & Modifier.FINAL) != 0;
+
+            boolean isStatic = (field.getModifiers() & Modifier.STATIC) != 0;
+
+            /**
+             * http://java.sun.com/docs/books/jls/third_edition/html/memory.html#17.5.3
+             * If a final field is initialized to a compile-time constant in the field declaration,
+             *   changes to the final field may not be observed.
+             */
+            if (isFinal && isStatic)
+                throw new IgniteException(""Modification of static final field through reflection."");
+
             boolean accessible = field.isAccessible();
 
             if (!accessible)
@@ -1708,6 +1697,16 @@ public final class GridTestUtils {
 
             boolean isFinal = (field.getModifiers() & Modifier.FINAL) != 0;
 
+            boolean isStatic = (field.getModifiers() & Modifier.STATIC) != 0;
+
+            /**
+             * http://java.sun.com/docs/books/jls/third_edition/html/memory.html#17.5.3
+             * If a final field is initialized to a compile-time constant in the field declaration,
+             *   changes to the final field may not be observed.
+             */
+            if (isFinal && isStatic)
+                throw new IgniteException(""Modification of static final field through reflection."");
+
             if (isFinal) {
                 Field modifiersField = Field.class.getDeclaredField(""modifiers"");
 
diff --git a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/twostep/AbstractReducer.java b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/twostep/AbstractReducer.java
index dfb23d736a..3b08fe1d0b 100644
--- a/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/twostep/AbstractReducer.java
+++ b/modules/indexing/src/main/java/org/apache/ignite/internal/processors/query/h2/twostep/AbstractReducer.java
@@ -54,16 +54,16 @@ public abstract class AbstractReducer implements Reducer {
     static final int MAX_FETCH_SIZE = getInteger(IGNITE_SQL_MERGE_TABLE_MAX_SIZE, 10_000);
 
     /** */
-    static final int PREFETCH_SIZE = getInteger(IGNITE_SQL_MERGE_TABLE_PREFETCH_SIZE, 1024);
+    static int prefetchSize = getInteger(IGNITE_SQL_MERGE_TABLE_PREFETCH_SIZE, 1024);
 
     static {
-        if (!U.isPow2(PREFETCH_SIZE)) {
-            throw new IllegalArgumentException(IGNITE_SQL_MERGE_TABLE_PREFETCH_SIZE + "" ("" + PREFETCH_SIZE +
+        if (!U.isPow2(prefetchSize)) {
+            throw new IllegalArgumentException(IGNITE_SQL_MERGE_TABLE_PREFETCH_SIZE + "" ("" + prefetchSize +
                 "") must be positive and a power of 2."");
         }
 
-        if (PREFETCH_SIZE >= MAX_FETCH_SIZE) {
-            throw new IllegalArgumentException(IGNITE_SQL_MERGE_TABLE_PREFETCH_SIZE + "" ("" + PREFETCH_SIZE +
+        if (prefetchSize >= MAX_FETCH_SIZE) {
+            throw new IllegalArgumentException(IGNITE_SQL_MERGE_TABLE_PREFETCH_SIZE + "" ("" + prefetchSize +
                 "") must be less than "" + IGNITE_SQL_MERGE_TABLE_MAX_SIZE + "" ("" + MAX_FETCH_SIZE + "")."");
         }
     }
@@ -102,7 +102,7 @@ public abstract class AbstractReducer implements Reducer {
     AbstractReducer(GridKernalContext ctx) {
         this.ctx = ctx;
 
-        fetched = new ReduceBlockList<>(PREFETCH_SIZE);
+        fetched = new ReduceBlockList<>(prefetchSize);
     }
 
     /** {@inheritDoc} */
@@ -191,7 +191,7 @@ public abstract class AbstractReducer implements Reducer {
      * @param evictedBlock Evicted block.
      */
     protected void onBlockEvict(@NotNull List<Row> evictedBlock) {
-        assert evictedBlock.size() == PREFETCH_SIZE;
+        assert evictedBlock.size() == prefetchSize;
 
         // Remember the last row (it will be max row) from the evicted block.
         lastEvictedRow = requireNonNull(last(evictedBlock));
diff --git a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/IgniteSqlSplitterSelfTest.java b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/IgniteSqlSplitterSelfTest.java
index 92e0739a06..15dd2e1323 100644
--- a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/IgniteSqlSplitterSelfTest.java
+++ b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/IgniteSqlSplitterSelfTest.java
@@ -567,7 +567,7 @@ public class IgniteSqlSplitterSelfTest extends AbstractIndexingCommonTest {
             Integer.class, Value.class));
 
         try {
-            GridTestUtils.setFieldValue(null, AbstractReducer.class, ""PREFETCH_SIZE"", 8);
+            GridTestUtils.setFieldValue(AbstractReducer.class, ""prefetchSize"", 8);
 
             Random rnd = new GridRandom();
 
@@ -617,7 +617,7 @@ public class IgniteSqlSplitterSelfTest extends AbstractIndexingCommonTest {
             }
         }
         finally {
-            GridTestUtils.setFieldValue(null, AbstractReducer.class, ""PREFETCH_SIZE"", 1024);
+            GridTestUtils.setFieldValue(AbstractReducer.class, ""prefetchSize"", 1024);
 
             c.destroy();
         }
diff --git a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/h2/twostep/RetryCauseMessageSelfTest.java b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/h2/twostep/RetryCauseMessageSelfTest.java
index 62f5f32d57..a1f670e57f 100644
--- a/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/h2/twostep/RetryCauseMessageSelfTest.java
+++ b/modules/indexing/src/test/java/org/apache/ignite/internal/processors/query/h2/twostep/RetryCauseMessageSelfTest.java
@@ -96,7 +96,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
     public void testSynthCacheWasNotFoundMessage() {
         GridMapQueryExecutor mapQryExec = GridTestUtils.getFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"");
 
-        GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"",
+        GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"",
             new MockGridMapQueryExecutor() {
                 @Override public void onQueryRequest(ClusterNode node, GridH2QueryRequest qryReq)
                     throws IgniteCheckedException {
@@ -121,7 +121,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
             return;
         }
         finally {
-            GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"", mapQryExec);
+            GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"", mapQryExec);
         }
         fail();
     }
@@ -135,7 +135,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
 
         final ConcurrentMap<PartitionReservationKey, GridReservable> reservations = reservations(h2Idx);
 
-        GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"",
+        GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"",
             new MockGridMapQueryExecutor() {
                 @Override public void onQueryRequest(ClusterNode node, GridH2QueryRequest qryReq)
                     throws IgniteCheckedException {
@@ -166,7 +166,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
             return;
         }
         finally {
-            GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"", mapQryExec);
+            GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"", mapQryExec);
         }
         fail();
     }
@@ -181,7 +181,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
 
         final GridKernalContext ctx = GridTestUtils.getFieldValue(mapQryExec, GridMapQueryExecutor.class, ""ctx"");
 
-        GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"",
+        GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"",
             new MockGridMapQueryExecutor() {
                 @Override public void onQueryRequest(ClusterNode node, GridH2QueryRequest qryReq) throws IgniteCheckedException {
                     GridCacheContext<?, ?> cctx = ctx.cache().context().cacheContext(qryReq.caches().get(0));
@@ -211,7 +211,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
             return;
         }
         finally {
-            GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"", mapQryExec);
+            GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"", mapQryExec);
         }
         fail();
     }
@@ -225,7 +225,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
 
         final GridKernalContext ctx = GridTestUtils.getFieldValue(mapQryExec, GridMapQueryExecutor.class, ""ctx"");
 
-        GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"",
+        GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"",
             new MockGridMapQueryExecutor() {
                 @Override public void onQueryRequest(ClusterNode node, GridH2QueryRequest qryReq)
                     throws IgniteCheckedException {
@@ -256,7 +256,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
             return;
         }
         finally {
-            GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"", mapQryExec);
+            GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"", mapQryExec);
         }
         fail();
     }
@@ -270,7 +270,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
 
         final ConcurrentMap<PartitionReservationKey, GridReservable> reservations = reservations(h2Idx);
 
-        GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"",
+        GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"",
             new MockGridMapQueryExecutor() {
                 @Override public void onQueryRequest(ClusterNode node, GridH2QueryRequest qryReq)
                     throws IgniteCheckedException {
@@ -300,7 +300,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
             return;
         }
         finally {
-            GridTestUtils.setFieldValue(h2Idx, IgniteH2Indexing.class, ""mapQryExec"", mapQryExec);
+            GridTestUtils.setFieldValue(h2Idx, ""mapQryExec"", mapQryExec);
         }
         fail();
     }
@@ -316,7 +316,7 @@ public class RetryCauseMessageSelfTest extends AbstractIndexingCommonTest {
         final IgniteLogger logger = GridTestUtils.getFieldValue(rdcQryExec, GridReduceQueryExecutor.class, ""log"");
         final GridKernalContext ctx = GridTestUtils.getFieldValue(rdcQryExec, GridReduceQueryExecutor.class, ""ctx"");
 
-        GridTestUtils.setFieldValue(rdcQryExec, GridReduceQueryExecutor.class, ""mapper"",
+        GridTestUtils.setFieldValue(rdcQryExec, ""mapper"",
             new ReducePartitionMapper(ctx, logger) {
                 @Override public ReducePartitionMapResult nodesForPartitions(List<Integer> cacheIds,
             ",IGNITE - 13039 Get rid of possibility to change final static fields - Fixes <issue_id> . . Signed - off - by : Alexey Goncharuk < alexey . goncharuk @ gmail . com >,"""Fixed issues with modifying static final fields through reflection and updated related test cases""","The commit message should be:

""Refactor static final fields to be non-final and mutable.""","This commit changes the way the `DEADLOCK_TIMEOUT` and `deadLockTimeout` variables are accessed and modified in the `TxDeadlockDetection` class.

Previously, `DEADLOCK_TIMEOUT` was a static final field that was accessed and modified directly. Now, `deadLockTimeout` is a static non-final field that is accessed and modified using getter and setter methods.

Additionally, the `DeadlockTimeoutObject` constructor has been updated to use the new `deadLockTimeout` field instead of `DEADLOCK_TIMEOUT`.

The `TxDeadlockDetectionNoHangsTest` class has also been updated to use the new getter and setter methods for `deadLockTimeout`.

Finally, the `GridTestUtils` class has been updated to throw an exception when attempting to modify a static final field through reflection. This is due to the fact that changes to static final fields may not be observed if they are initialized to a compile-time constant in the field declaration.","Refactor code to remove static final fields, replace direct static field access with instance methods, and simplify reflection utility in GridTestUtils.",Model 1
"diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/Partitioning.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/Partitioning.java
index d7b6854725..681f94dd6b 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/Partitioning.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/Partitioning.java
@@ -16,6 +16,8 @@ package com.facebook.presto.sql.planner;
 import com.facebook.presto.Session;
 import com.facebook.presto.metadata.Metadata;
 import com.facebook.presto.spi.predicate.NullableValue;
+import com.facebook.presto.sql.tree.Expression;
+import com.facebook.presto.sql.tree.SymbolReference;
 import com.fasterxml.jackson.annotation.JsonCreator;
 import com.fasterxml.jackson.annotation.JsonProperty;
 import com.google.common.collect.ImmutableList;
@@ -32,6 +34,7 @@ import java.util.function.Function;
 
 import static com.google.common.base.MoreObjects.toStringHelper;
 import static com.google.common.base.Preconditions.checkArgument;
+import static com.google.common.base.Verify.verify;
 import static com.google.common.collect.ImmutableList.toImmutableList;
 import static com.google.common.collect.ImmutableSet.toImmutableSet;
 import static java.util.Objects.requireNonNull;
@@ -51,7 +54,15 @@ public final class Partitioning
     public static Partitioning create(PartitioningHandle handle, List<Symbol> columns)
     {
         return new Partitioning(handle, columns.stream()
-                .map(ArgumentBinding::columnBinding)
+                .map(Symbol::toSymbolReference)
+                .map(ArgumentBinding::expressionBinding)
+                .collect(toImmutableList()));
+    }
+
+    public static Partitioning createWithExpressions(PartitioningHandle handle, List<Expression> expressions)
+    {
+        return new Partitioning(handle, expressions.stream()
+                .map(ArgumentBinding::expressionBinding)
                 .collect(toImmutableList()));
     }
 
@@ -160,13 +171,20 @@ public final class Partitioning
 
     public boolean isPartitionedOn(Collection<Symbol> columns, Set<Symbol> knownConstants)
     {
-        // partitioned on (k_1, k_2, ..., k_n) => partitioned on (k_1, k_2, ..., k_n, k_n+1, ...)
-        // can safely ignore all constant columns when comparing partition properties
-        return arguments.stream()
-                .filter(ArgumentBinding::isVariable)
-                .map(ArgumentBinding::getColumn)
-                .filter(symbol -> !knownConstants.contains(symbol))
-                .allMatch(columns::contains);
+        for (ArgumentBinding argument : arguments) {
+            // partitioned on (k_1, k_2, ..., k_n) => partitioned on (k_1, k_2, ..., k_n, k_n+1, ...)
+            // can safely ignore all constant columns when comparing partition properties
+            if (argument.isConstant()) {
+                continue;
+            }
+            if (!argument.isVariable()) {
+                return false;
+            }
+            if (!knownConstants.contains(argument.getColumn()) && !columns.contains(argument.getColumn())) {
+                return false;
+            }
+        }
+        return true;
     }
 
     public boolean isEffectivelySinglePartition(Set<Symbol> knownConstants)
@@ -194,11 +212,11 @@ public final class Partitioning
                 .collect(toImmutableList()));
     }
 
-    public Optional<Partitioning> translate(Function<Symbol, Optional<Symbol>> translator, Function<Symbol, Optional<NullableValue>> constants)
+    public Optional<Partitioning> translate(Translator translator)
     {
         ImmutableList.Builder<ArgumentBinding> newArguments = ImmutableList.builder();
         for (ArgumentBinding argument : arguments) {
-            Optional<ArgumentBinding> newArgument = argument.translate(translator, constants);
+            Optional<ArgumentBinding> newArgument = argument.translate(translator);
             if (!newArgument.isPresent()) {
                 return Optional.empty();
             }
@@ -242,25 +260,43 @@ public final class Partitioning
                 .toString();
     }
 
+    @Immutable
+    public static final class Translator
+    {
+        private final Function<Symbol, Optional<Symbol>> columnTranslator;
+        private final Function<Symbol, Optional<NullableValue>> constantTranslator;
+        private final Function<Expression, Optional<Symbol>> expressionTranslator;
+
+        public Translator(
+                Function<Symbol, Optional<Symbol>> columnTranslator,
+                Function<Symbol, Optional<NullableValue>> constantTranslator,
+                Function<Expression, Optional<Symbol>> expressionTranslator)
+        {
+            this.columnTranslator = requireNonNull(columnTranslator, ""columnTranslator is null"");
+            this.constantTranslator = requireNonNull(constantTranslator, ""constantTranslator is null"");
+            this.expressionTranslator = requireNonNull(expressionTranslator, ""expressionTranslator is null"");
+        }
+    }
+
     @Immutable
     public static final class ArgumentBinding
     {
-        private final Symbol column;
+        private final Expression expression;
         private final NullableValue constant;
 
         @JsonCreator
         public ArgumentBinding(
-                @JsonProperty(""column"") Symbol column,
+                @JsonProperty(""expression"") Expression expression,
                 @JsonProperty(""constant"") NullableValue constant)
         {
-            this.column = column;
+            this.expression = expression;
             this.constant = constant;
-            checkArgument((column == null) != (constant == null), ""Either column or constant must be set"");
+            checkArgument((expression == null) != (constant == null), ""Either expression or constant must be set"");
         }
 
-        public static ArgumentBinding columnBinding(Symbol column)
+        public static ArgumentBinding expressionBinding(Expression expression)
         {
-            return new ArgumentBinding(requireNonNull(column, ""column is null""), null);
+            return new ArgumentBinding(requireNonNull(expression, ""expression is null""), null);
         }
 
         public static ArgumentBinding constantBinding(NullableValue constant)
@@ -275,13 +311,19 @@ public final class Partitioning
 
         public boolean isVariable()
         {
-            return column != null;
+            return expression instanceof SymbolReference;
         }
 
-        @JsonProperty
         public Symbol getColumn()
         {
-            return column;
+            verify(expression instanceof SymbolReference, ""Expect the expression to be a SymbolReference"");
+            return Symbol.from(expression);
+        }
+
+        @JsonProperty
+        public Expression getExpression()
+        {
+            return expression;
         }
 
         @JsonProperty
@@ -295,25 +337,31 @@ public final class Partitioning
             if (isConstant()) {
                 return this;
             }
-            return columnBinding(translator.apply(column));
+            return expressionBinding(translator.apply(Symbol.from(expression)).toSymbolReference());
         }
 
-        public Optional<ArgumentBinding> translate(Function<Symbol, Optional<Symbol>> translator, Function<Symbol, Optional<NullableValue>> constants)
+        public Optional<ArgumentBinding> translate(Translator translator)
         {
             if (isConstant()) {
                 return Optional.of(this);
             }
 
-            Optional<ArgumentBinding> newColumn = translator.apply(column)
-                    .map(ArgumentBinding::columnBinding);
+            if (!isVariable()) {
+                return translator.expressionTranslator.apply(expression)
+                        .map(Symbol::toSymbolReference)
+                        .map(ArgumentBinding::expressionBinding);
+            }
+
+            Optional<ArgumentBinding> newColumn = translator.columnTranslator.apply(Symbol.from(expression))
+                    .map(Symbol::toSymbolReference)
+                    .map(ArgumentBinding::expressionBinding);
             if (newColumn.isPresent()) {
                 return newColumn;
             }
-
             // As a last resort, check for a constant mapping for the symbol
             // Note: this MUST be last because we want to favor the symbol representation
             // as it makes further optimizations possible.
-            return constants.apply(column)
+            return translator.constantTranslator.apply(Symbol.from(expression))
                     .map(ArgumentBinding::constantBinding);
         }
 
@@ -323,7 +371,8 @@ public final class Partitioning
             if (constant != null) {
                 return constant.toString();
             }
-            return ""\"""" + column + ""\"""";
+
+            return expression.toString();
         }
 
         @Override
@@ -336,14 +385,14 @@ public final class Partitioning
                 return false;
             }
             ArgumentBinding that = (ArgumentBinding) o;
-            return Objects.equals(column, that.column) &&
+            return Objects.equals(expression, that.expression) &&
                     Objects.equals(constant, that.constant);
         }
 
         @Override
         public int hashCode()
         {
-            return Objects.hash(column, constant);
+            return Objects.hash(expression, constant);
         }
     }
 }
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/ActualProperties.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/ActualProperties.java
index 762d8c6868..7747914b71 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/ActualProperties.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/ActualProperties.java
@@ -21,6 +21,7 @@ import com.facebook.presto.spi.predicate.NullableValue;
 import com.facebook.presto.sql.planner.Partitioning;
 import com.facebook.presto.sql.planner.PartitioningHandle;
 import com.facebook.presto.sql.planner.Symbol;
+import com.facebook.presto.sql.tree.Expression;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.ImmutableSet;
@@ -153,17 +154,21 @@ public class ActualProperties
 
     public ActualProperties translate(Function<Symbol, Optional<Symbol>> translator)
     {
-        Map<Symbol, NullableValue> translatedConstants = new HashMap<>();
-        for (Map.Entry<Symbol, NullableValue> entry : constants.entrySet()) {
-            Optional<Symbol> translatedKey = translator.apply(entry.getKey());
-            if (translatedKey.isPresent()) {
-                translatedConstants.put(translatedKey.get(), entry.getValue());
-            }
-        }
         return builder()
-                .global(global.translate(translator, symbol -> Optional.ofNullable(constants.get(symbol))))
+                .global(global.translate(new Partitioning.Translator(translator, symbol -> Optional.ofNullable(constants.get(symbol)), expression -> Optional.empty())))
                 .local(LocalProperties.translate(localProperties, translator))
-                .constants(translatedConstants)
+                .constants(translateConstants(translator))
+                .build();
+    }
+
+    public ActualProperties translate(
+            Function<Symbol, Optional<Symbol>> translator,
+            Function<Expression, Optional<Symbol>> expressionTranslator)
+    {
+        return builder()
+                .global(global.translate(new Partitioning.Translator(translator, symbol -> Optional.ofNullable(constants.get(symbol)), expressionTranslator)))
+                .local(LocalProperties.translate(localProperties, translator))
+                .constants(translateConstants(translator))
                 .build();
     }
 
@@ -199,6 +204,18 @@ public class ActualProperties
         return new Builder(properties.global, properties.localProperties, properties.constants);
     }
 
+    private Map<Symbol, NullableValue> translateConstants(Function<Symbol, Optional<Symbol>> translator)
+    {
+        Map<Symbol, NullableValue> translatedConstants = new HashMap<>();
+        for (Map.Entry<Symbol, NullableValue> entry : constants.entrySet()) {
+            Optional<Symbol> translatedKey = translator.apply(entry.getKey());
+            if (translatedKey.isPresent()) {
+                translatedConstants.put(translatedKey.get(), entry.getValue());
+            }
+        }
+        return translatedConstants;
+    }
+
     public static class Builder
     {
         private Global global;
@@ -448,11 +465,11 @@ public class ActualProperties
             return (!streamPartitioning.isPresent() || streamPartitioning.get().isRepartitionEffective(keys, constants)) && !nullsAndAnyReplicated;
         }
 
-        private Global translate(Function<Symbol, Optional<Symbol>> translator, Function<Symbol, Optional<NullableValue>> constants)
+        private Global translate(Partitioning.Translator translator)
         {
             return new Global(
-                    nodePartitioning.flatMap(partitioning -> partitioning.translate(translator, constants)),
-                    streamPartitioning.flatMap(partitioning -> partitioning.translate(translator, constants)),
+                    nodePartitioning.flatMap(partitioning -> partitioning.translate(translator)),
+                    streamPartitioning.flatMap(partitioning -> partitioning.translate(translator)),
                     nullsAndAnyReplicated);
         }
 
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PreferredProperties.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PreferredProperties.java
index 7089a11370..d89aa005c9 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PreferredProperties.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PreferredProperties.java
@@ -391,7 +391,7 @@ class PreferredProperties
                 return Optional.of(new PartitioningProperties(newPartitioningColumns, Optional.empty(), nullsAndAnyReplicated));
             }
 
-            Optional<Partitioning> newPartitioning = partitioning.get().translate(translator, symbol -> Optional.empty());
+            Optional<Partitioning> newPartitioning = partitioning.get().translate(new Partitioning.Translator(translator, symbol -> Optional.empty(), coalesceSymbols -> Optional.empty()));
             if (!newPartitioning.isPresent()) {
                 return Optional.empty();
             }
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PropertyDerivations.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PropertyDerivations.java
index 66fc8bf9da..23964ab9c5 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PropertyDerivations.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PropertyDerivations.java
@@ -31,6 +31,7 @@ import com.facebook.presto.sql.planner.DomainTranslator;
 import com.facebook.presto.sql.planner.ExpressionInterpreter;
 import com.facebook.presto.sql.planner.NoOpSymbolResolver;
 import com.facebook.presto.sql.planner.OrderingScheme;
+import com.facebook.presto.sql.planner.Partitioning;
 import com.facebook.presto.sql.planner.Symbol;
 import com.facebook.presto.sql.planner.TypeProvider;
 import com.facebook.presto.sql.planner.optimizations.ActualProperties.Global;
@@ -67,6 +68,7 @@ import com.facebook.presto.sql.planner.plan.TopNRowNumberNode;
 import com.facebook.presto.sql.planner.plan.UnnestNode;
 import com.facebook.presto.sql.planner.plan.ValuesNode;
 import com.facebook.presto.sql.planner.plan.WindowNode;
+import com.facebook.presto.sql.tree.CoalesceExpression;
 import com.facebook.presto.sql.tree.Expression;
 import com.facebook.presto.sql.tree.NodeRef;
 import com.facebook.presto.sql.tree.SymbolReference;
@@ -422,8 +424,22 @@ public class PropertyDerivations
                             .unordered(unordered)
                             .build();
                 case FULL:
-                    // We can't say anything about the partitioning scheme because any partition of
-                    // a hash-partitioned join can produce nulls in case of a lack of matches
+                    if (probeProperties.getNodePartitioning().isPresent()) {
+                        Partitioning nodePartitioning = probeProperties.getNodePartitioning().get();
+                        ImmutableList.Builder<Expression> coalesceExpressions = ImmutableList.builder();
+                        for (Symbol column : nodePartitioning.getColumns()) {
+                            for (JoinNode.EquiJoinClause equality : node.getCriteria()) {
+                                if (equality.getLeft().equals(column) || equality.getRight().equals(column)) {
+                                    coalesceExpressions.add(new CoalesceExpression(ImmutableList.of(equality.getLeft().toSymbolReference(), equality.getRight().toSymbolReference())));
+                                }
+                            }
+                        }
+
+                        return ActualProperties.builder()
+                                .global(partitionedOn(Partitioning.createWithExpressions(nodePartitioning.getHandle(), coalesceExpressions.build()), Optional.empty()))
+                                .unordered(unordered)
+                                .build();
+                    }
                     return ActualProperties.builder()
                             .global(probeProperties.isSingleNode() ? singleStreamPartition() : arbitraryPartition())
                             .unordered(unordered)
@@ -606,7 +622,7 @@ public class PropertyDerivations
 
             Map<Symbol, Symbol> identities = computeIdentityTranslations(node.getAssignments().getMap());
 
-            ActualProperties translatedProperties = properties.translate(column -> Optional.ofNullable(identities.get(column)));
+            ActualProperties translatedProperties = properties.translate(column -> Optional.ofNullable(identities.get(column)), expression -> rewriteExpression(node.getAssignments().getMap(), expression));
 
             // Extract additional constants
             Map<Symbol, NullableValue> constants = new HashMap<>();
@@ -824,4 +840,28 @@ public class PropertyDerivations
 
         return Optional.empty();
     }
+
+    public static Optional<Symbol> rewriteExpression(Map<Symbol, Expression> assignments, Expression expression)
+    {
+        checkArgument(expression instanceof CoalesceExpression, ""The rewrite can only handle CoalesceExpression"");
+        // We are using the property that the result of coalesce from full outer join keys would not be null despite of the order
+        // of the arguments. Thus we extract and compare the symbols of the CoalesceExpression as a set rather than compare the
+        // CoalesceExpression directly.
+        for (Map.Entry<Symbol, Expression> entry : assignments.entrySet()) {
+            if (entry.getValue() instanceof CoalesceExpression) {
+                Set<Symbol> symbolsInAssignment = ((CoalesceExpression) entry.getValue()).getOperands().stream()
+                        .filter(SymbolReference.class::isInstance)
+                        .map(Symbol::from)
+                        .collect(toImmutableSet());
+                Set<Symbol> symbolInExpression = ((CoalesceExpression) expression).getOperands().stream()
+                        .filter(SymbolReference.class::isInstance)
+                        .map(Symbol::from)
+                        .collect(toImmutableSet());
+                if (symbolsInAssignment.containsAll(symbolInExpression)) {
+                    return Optional.of(entry.getKey());
+                }
+            }
+        }
+        return Optional.empty();
+    }
 }
diff --git a/presto-main/src/main/java/com/facebook/presto/util/GraphvizPrinter.java b/presto-main/src/main/java/com/facebook/presto/util/GraphvizPrinter.java
index e18789afeb..f9135dcff2 100644
--- a/presto-main/src/main/java/com/facebook/presto/util/GraphvizPrinter.java
+++ b/presto-main/src/main/java/com/facebook/presto/util/GraphvizPrinter.java
@@ -309,7 +309,8 @@ public final class GraphvizPrinter
         public Void visitExchange(ExchangeNode node, Void context)
         {
             List<ArgumentBinding> symbols = node.getOutputSymbols().stream()
-         ",Propagate partition properties for full outer join .,"""Refactor Partitioning to use Expressions instead of Symbols""","According to the diff, the commit message should be:

""Refactor Partitioning to use Expression instead of Symbol and add Translator for translating Partitioning""","The commit message could be: ""Refactor Partitioning to support expressions and update ActualProperties, PreferredProperties, and PropertyDerivations accordingly.""

This commit refactors the Partitioning class to support expressions, not just symbols. It also updates the ActualProperties, PreferredProperties, and PropertyDerivations classes to work with this new Partitioning class. The changes include new methods for translating expressions and constants, and updating the partitioning schemes to handle expressions. Additionally, it adds a new class, Partitioning.Translator, to encapsulate the translation of symbols, constants, and expressions.","""Refactored Partitioning to support expressions, added comprehensive translation capabilities, and enhanced join handling.""",Model 1
"diff --git a/configserver/src/main/java/com/yahoo/vespa/config/server/ApplicationRepository.java b/configserver/src/main/java/com/yahoo/vespa/config/server/ApplicationRepository.java
index a8b4844ca43..585a1a67f4d 100644
--- a/configserver/src/main/java/com/yahoo/vespa/config/server/ApplicationRepository.java
+++ b/configserver/src/main/java/com/yahoo/vespa/config/server/ApplicationRepository.java
@@ -36,6 +36,7 @@ import com.yahoo.vespa.config.server.configchange.RestartActions;
 import com.yahoo.vespa.config.server.deploy.DeployHandlerLogger;
 import com.yahoo.vespa.config.server.deploy.Deployment;
 import com.yahoo.vespa.config.server.http.CompressedApplicationInputStream;
+import com.yahoo.vespa.config.server.http.LogRetriever;
 import com.yahoo.vespa.config.server.http.SimpleHttpFetcher;
 import com.yahoo.vespa.config.server.http.v2.PrepareResult;
 import com.yahoo.vespa.config.server.provision.HostProvisionerProvider;
@@ -50,6 +51,7 @@ import com.yahoo.vespa.config.server.session.SilentDeployLogger;
 import com.yahoo.vespa.config.server.tenant.Rotations;
 import com.yahoo.vespa.config.server.tenant.Tenant;
 import com.yahoo.vespa.config.server.tenant.TenantRepository;
+import com.yahoo.vespa.model.VespaModel;
 
 import java.io.File;
 import java.io.IOException;
@@ -477,6 +479,13 @@ public class ApplicationRepository implements com.yahoo.config.provision.Deploye
         return convergeChecker.servicesToCheck(getApplication(applicationId), uri, timeout);
     }
 
+    // ---------------- Logs ----------------------------------------------------------------
+
+    public HttpResponse getLogs(ApplicationId applicationId) {
+        String logServerHostName = getLogServerHostname(applicationId);
+        return LogRetriever.getLogs(logServerHostName);
+    }
+
     // ---------------- Session operations ----------------------------------------------------------------
 
     /**
@@ -690,6 +699,13 @@ public class ApplicationRepository implements com.yahoo.config.provision.Deploye
         }
     }
 
+    private String getLogServerHostname(ApplicationId applicationId) {
+        Application application = getApplication(applicationId);
+        VespaModel model = (VespaModel) application.getModel();
+        String logServerHostname = model.getAdmin().getLogserver().getHostName();
+        return logServerHostname;
+    }
+
     /** Returns version to use when deploying application in given environment */
     static Version decideVersion(ApplicationId application, Environment environment, Version targetVersion, boolean bootstrap) {
         if (environment.isManuallyDeployed() &&
diff --git a/configserver/src/main/java/com/yahoo/vespa/config/server/http/LogRetriever.java b/configserver/src/main/java/com/yahoo/vespa/config/server/http/LogRetriever.java
new file mode 100644
index 00000000000..f4952b5b9fc
--- /dev/null
+++ b/configserver/src/main/java/com/yahoo/vespa/config/server/http/LogRetriever.java
@@ -0,0 +1,41 @@
+package com.yahoo.vespa.config.server.http;
+
+import com.yahoo.container.jdisc.HttpResponse;
+import org.apache.http.client.methods.HttpGet;
+import org.apache.http.impl.client.CloseableHttpClient;
+import org.apache.http.impl.client.HttpClientBuilder;
+import org.apache.http.util.EntityUtils;
+
+import java.io.IOException;
+import java.io.OutputStream;
+import java.util.logging.Level;
+import java.util.logging.Logger;
+
+
+public class LogRetriever {
+
+    private final static Logger log = Logger.getLogger(LogRetriever.class.getName());
+
+    public static HttpResponse getLogs(String logServerHostname) {
+        HttpGet get = new HttpGet(logServerHostname);
+        try (CloseableHttpClient httpClient = HttpClientBuilder.create().build()) {
+            org.apache.http.HttpResponse response = httpClient.execute(get);
+            String responseBody = EntityUtils.toString(response.getEntity(), ""UTF-8"");
+            return new HttpResponse(response.getStatusLine().getStatusCode()) {
+                @Override
+                public void render(OutputStream outputStream) throws IOException {
+                    if (response.getEntity() != null ) outputStream.write(responseBody.getBytes());
+                }
+            };
+        } catch (IOException e) {
+            log.log(Level.WARNING, ""Failed to retrieve logs from log server"", e);
+            return new HttpResponse(404) {
+                @Override
+                public void render(OutputStream outputStream) throws IOException {
+                    outputStream.write(e.toString().getBytes());
+                }
+            };
+        }
+
+    }
+}
diff --git a/configserver/src/main/java/com/yahoo/vespa/config/server/http/v2/ApplicationHandler.java b/configserver/src/main/java/com/yahoo/vespa/config/server/http/v2/ApplicationHandler.java
index 2004ab95144..b65cb370f93 100644
--- a/configserver/src/main/java/com/yahoo/vespa/config/server/http/v2/ApplicationHandler.java
+++ b/configserver/src/main/java/com/yahoo/vespa/config/server/http/v2/ApplicationHandler.java
@@ -96,6 +96,10 @@ public class ApplicationHandler extends HttpHandler {
             return applicationRepository.filedistributionStatus(applicationId, timeout);
         }
 
+        if (isLogRequest(request)) {
+            return applicationRepository.getLogs(applicationId);
+        }
+
         return new GetApplicationResponse(Response.Status.OK, applicationRepository.getApplicationGeneration(applicationId));
     }
 
@@ -140,7 +144,13 @@ public class ApplicationHandler extends HttpHandler {
                 ""http://*/application/v2/tenant/*/application/*/environment/*/region/*/instance/*/serviceconverge/*"",
                 ""http://*/application/v2/tenant/*/application/*/environment/*/region/*/instance/*/clustercontroller/*/status/*"",
                 ""http://*/application/v2/tenant/*/application/*/environment/*/region/*/instance/*"",
-                ""http://*/application/v2/tenant/*/application/*"");
+                ""http://*/application/v2/tenant/*/application/*"",
+                ""http://*/application/v2/tenant/*/application/*/logs"");
+    }
+
+    private static boolean isLogRequest(HttpRequest request) {
+        return getBindingMatch(request).groupCount() == 4 &&
+                request.getUri().getPath().endsWith(""/logs"");
     }
 
     private static boolean isServiceConvergeListRequest(HttpRequest request) {
diff --git a/configserver/src/main/resources/configserver-app/services.xml b/configserver/src/main/resources/configserver-app/services.xml
index 8a99869e69a..60dd7b0cea2 100644
--- a/configserver/src/main/resources/configserver-app/services.xml
+++ b/configserver/src/main/resources/configserver-app/services.xml
@@ -147,6 +147,8 @@
       <binding>https://*/application/v2/tenant/*/application/*/environment/*/region/*/instance/*</binding>
       <binding>http://*/application/v2/tenant/*/application/*</binding>
       <binding>https://*/application/v2/tenant/*/application/*</binding>
+      <binding>http://*/application/v2/tenant/*/application/*/logs</binding>
+      <binding>https://*/application/v2/tenant/*/application/*/logs</binding>
     </handler>
     <handler id='com.yahoo.vespa.config.server.http.v2.HttpGetConfigHandler' bundle='configserver'>
       <binding>http://*/config/v2/tenant/*/application/*/*</binding>
diff --git a/configserver/src/test/java/com/yahoo/vespa/config/server/http/LogRetrieverTest.java b/configserver/src/test/java/com/yahoo/vespa/config/server/http/LogRetrieverTest.java
new file mode 100644
index 00000000000..2c3622e3dac
--- /dev/null
+++ b/configserver/src/test/java/com/yahoo/vespa/config/server/http/LogRetrieverTest.java
@@ -0,0 +1,46 @@
+package com.yahoo.vespa.config.server.http;
+
+import com.github.tomakehurst.wiremock.junit.WireMockRule;
+import com.yahoo.container.jdisc.HttpResponse;
+import org.junit.Rule;
+import org.junit.Test;
+
+
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+
+import static com.github.tomakehurst.wiremock.client.WireMock.aResponse;
+import static com.github.tomakehurst.wiremock.client.WireMock.get;
+import static com.github.tomakehurst.wiremock.client.WireMock.okJson;
+import static com.github.tomakehurst.wiremock.client.WireMock.stubFor;
+import static com.github.tomakehurst.wiremock.client.WireMock.urlEqualTo;
+import static com.github.tomakehurst.wiremock.core.WireMockConfiguration.options;
+import static org.junit.Assert.assertEquals;
+
+public class LogRetrieverTest {
+
+    private String logServerHostName = ""http://localhost:8080/"";
+    @Rule
+    public final WireMockRule wireMock = new WireMockRule(options().port(8080), true);
+
+    @Test
+    public void testThatLogHandlerPropagatesResponseBody() throws IOException {
+        String expectedBody = ""{logs-json}"";
+        stubFor(get(urlEqualTo(""/"")).willReturn(okJson(expectedBody)));
+        HttpResponse response = LogRetriever.getLogs(logServerHostName);
+        ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();
+        response.render(byteArrayOutputStream);
+        assertEquals(expectedBody, byteArrayOutputStream.toString());
+        assertEquals(200, response.getStatus());
+    }
+
+    @Test
+    public void testThatNotFoundLogServerReturns404() throws IOException {
+        stubFor(get(urlEqualTo(""/"")).willReturn(aResponse().withStatus(200)));
+        HttpResponse response = LogRetriever.getLogs(""http://wrong-host:8080/"");
+        assertEquals(404, response.getStatus());
+    }
+
+
+
+}
\ No newline at end of file
diff --git a/container-core/src/main/java/com/yahoo/container/handler/LogHandler.java b/container-core/src/main/java/com/yahoo/container/handler/LogHandler.java
new file mode 100644
index 00000000000..474d7d7321a
--- /dev/null
+++ b/container-core/src/main/java/com/yahoo/container/handler/LogHandler.java
@@ -0,0 +1,31 @@
+package com.yahoo.container.handler;
+
+import com.fasterxml.jackson.core.JsonFactory;
+import com.google.inject.Inject;
+import com.yahoo.container.jdisc.HttpRequest;
+import com.yahoo.container.jdisc.HttpResponse;
+import com.yahoo.container.jdisc.ThreadedHttpRequestHandler;
+import java.io.IOException;
+import java.io.OutputStream;
+import java.util.concurrent.Executor;
+
+public class LogHandler extends ThreadedHttpRequestHandler {
+
+    private static final String LOG_DIRECTORY = ""/home/y/logs/vespa/"";
+
+    @Inject
+    public LogHandler(Executor executor) {
+        super(executor);
+    }
+
+    @Override
+    public HttpResponse handle(HttpRequest request) {
+
+        return new HttpResponse(200) {
+            @Override
+            public void render(OutputStream outputStream) throws IOException {
+                LogReader.writeToOutputStream(LOG_DIRECTORY, outputStream);
+            }
+        };
+    }
+}
diff --git a/container-core/src/main/java/com/yahoo/container/handler/LogReader.java b/container-core/src/main/java/com/yahoo/container/handler/LogReader.java
new file mode 100644
index 00000000000..e35ea748c0e
--- /dev/null
+++ b/container-core/src/main/java/com/yahoo/container/handler/LogReader.java
@@ -0,0 +1,44 @@
+package com.yahoo.container.handler;
+
+import com.fasterxml.jackson.core.JsonFactory;
+import com.fasterxml.jackson.core.JsonGenerator;
+import org.apache.commons.codec.binary.Base64;
+import org.json.JSONException;
+import org.json.JSONObject;
+
+import javax.xml.bind.DatatypeConverter;
+import java.io.ByteArrayOutputStream;
+import java.io.File;
+import java.io.IOException;
+import java.io.OutputStream;
+import java.io.OutputStreamWriter;
+import java.nio.file.Files;
+
+public class LogReader {
+
+    protected static void writeToOutputStream(String logDirectory, OutputStream outputStream) throws IOException {
+        OutputStreamWriter outputStreamWriter = new OutputStreamWriter(outputStream);
+        JSONObject json = new JSONObject();
+        File root = new File(logDirectory);
+        try {
+            traverse_folder(root, json);
+        } catch (JSONException e) {
+            outputStreamWriter.write(""Failed to create log JSON"");
+        }
+        outputStreamWriter.write(json.toString());
+        outputStreamWriter.close();
+    }
+
+    private static void traverse_folder(File root, JSONObject json) throws IOException, JSONException {
+        for(File child : root.listFiles()) {
+            JSONObject childJson = new JSONObject();
+            if(child.isFile()) {
+                json.put(child.getName(), DatatypeConverter.printBase64Binary(Files.readAllBytes(child.toPath())));
+            }
+            else {
+                json.put(child.getName(), childJson);
+                traverse_folder(child, childJson);
+            }
+        }
+    }
+}
diff --git a/container-core/src/test/java/com/yahoo/container/handler/LogReaderTest.java b/container-core/src/test/java/com/yahoo/container/handler/LogReaderTest.java
new file mode 100644
index 00000000000..ff6ea74a411
--- /dev/null
+++ b/container-core/src/test/java/com/yahoo/container/handler/LogReaderTest.java
@@ -0,0 +1,36 @@
+package com.yahoo.container.handler;
+
+import org.junit.Before;
+import org.junit.Test;
+
+import java.io.ByteArrayOutputStream;
+
+import static org.junit.Assert.*;
+
+public class LogReaderTest {
+
+    ByteArrayOutputStream outputStream;
+
+    @Before
+    public void setup() {
+        outputStream = new ByteArrayOutputStream();
+    }
+
+    @Test
+    public void testThatFilesAreWrittenCorrectlyToOutputStream() throws Exception{
+        String logDirectory = ""src/test/resources/logfolder/"";
+        LogReader.writeToOutputStream(logDirectory, outputStream);
+        String expected = ""{\""subfolder\"":{\""log2.log\"":\""VGhpcyBpcyBhbm90aGVyIGxvZyBmaWxl\""},\""log1.log\"":\""VGhpcyBpcyBvbmUgbG9nIGZpbGU=\""}"";
+        String actual = new String(outputStream.toByteArray());
+        assertEquals(expected, actual);
+    }
+
+    @Test
+    public void testNothingISWrittenToOutputStreamWithEmptyLogFolder() throws Exception {
+        String logDirectory = ""src/test/resources/emptylogfolder/"";
+        LogReader.writeToOutputStream(logDirectory, outputStream);
+        String expected = ""{}"";
+        String actual = new String(outputStream.toByteArray());
+        assertEquals(expected, actual);
+    }
+}
\ No newline at end of file
diff --git a/container-core/src/test/resources/logfolder/log1.log b/container-core/src/test/resources/logfolder/log1.log
new file mode 100644
index 00000000000..bb85d5a4950
--- /dev/null
+++ b/container-core/src/test/resources/logfolder/log1.log
@@ -0,0 +1 @@
+This is one log file
\ No newline at end of file
diff --git a/container-core/src/test/resources/logfolder/subfolder/log2.log b/container-core/src/test/resources/logfolder/subfolder/log2.log
new file mode 100644
index 00000000000..aee6eaca2e8
--- /dev/null
+++ b/container-core/src/test/resources/logfolder/subfolder/log2.log
@@ -0,0 +1 @@
+This is another log file
\ No newline at end of file
diff --git a/controller-api/src/main/java/com/yahoo/vespa/hosted/controller/api/integration/configserver/ConfigServer.java b/controller-api/src/main/java/com/yahoo/vespa/hosted/controller/api/integration/configserver/ConfigServer.java
index 54e057e4187..eb10c78f891 100644
--- a/controller-api/src/main/java/com/yahoo/vespa/hosted/controller/api/integration/configserver/ConfigServer.java
+++ b/controller-api/src/main/java/com/yahoo/vespa/hosted/controller/api/integration/configserver/ConfigServer.java
@@ -1,6 +1,7 @@
 // Copyright 2018 Yahoo Holdings. Licensed under the terms of the Apache 2.0 license. See LICENSE in the project root.
 package com.yahoo.vespa.hosted.controller.api.integration.configserver;
 
+import com.yahoo.container.jdisc.HttpResponse;
 import com.yahoo.vespa.hosted.controller.api.application.v4.model.DeployOptions;
 import com.yahoo.vespa.hosted.controller.api.application.v4.model.EndpointStatus;
 import com.yahoo.vespa.hosted.controller.api.identifiers.DeploymentId;
@@ -41,6 +42,7 @@ public interface ConfigServer {
 
     Map<?,?> getServiceApiResponse(String tenantName, String applicationName, String instanceName, String environment, String region, String serviceName, String restPath);
 
+    HttpResponse getLogs(DeploymentId deployment);
     /**
      * Set new status on en endpoint in one zone.
      *
diff --git a/controller-server/src/main/java/com/yahoo/vespa/hosted/controller/restapi/application/ApplicationApiHandler.java b/controller-server/src/main/java/com/yahoo/vespa/hosted/controller/restapi/application/ApplicationApiHandler.java
index 22809ac18bf..556d019d440 100644
--- a/controller-server/src/main/java/com/yahoo/vespa/hosted/controller/restapi/application/ApplicationApiHandler.java
+++ b/controller-server/src/main/java/com/yahoo/vespa/hosted/controller/restapi/application/ApplicationApiHandler.java
@@ -169,6 +169,7 @@ public class ApplicationApiHandler extends LoggingRequestHandler {
         if (path.matches(""/application/v4/tenant/{tenant}"")) return tenant(path.get(""tenant""), request);
         if (path.matches(""/application/v4/tenant/{tenant}/application"")) return applications(path.get(""tenant""), request);
         if (path.matches(""/application/v4/tenant/{tenant}/application/{application}"")) return application(path.get(""tenant""), path.get(""application""), request);
+        if (path.matches(""/application/v4/tenant/{tenant}/application/{application}/environment/{environment}/region/{region}/instance/{instance}/logs"")) return logs(path.get(""tenant""), path.get(""application""), path.get(""instance""), path.get(""environment""), path.get(""region""));
         if (path.matches(""/application/v4/tenant/{tenant}/application/{application}/instance/{instance}/job"")) return JobControllerApiHandlerHelper.jobTypeResponse(controller, appIdFromPath(path), request.getUri());
         if (path.matches(""/application/v4/tenant/{tenant}/application/{application}/instance/{instance}/job/{jobtype}"")) return JobControllerApiHandlerHelper.runResponse(controller.jobController().runs(appIdFromPath(path), jobTypeFromPath(path)), request.getUri());
         if (path.matches(""/application/v4/tenant/{tenant}/application/{application}/instance/{instance}/job/{jobtype}/run/{number}"")) return JobControllerApiHandlerHelper.runDetailsResponse(controller.jobController(), runIdFromPath(path), request.getProperty(""after""));
@@ -346,6 +347,14 @@ public class ApplicationApiHandler extends LoggingRequestHandler {
         return new SlimeJsonResponse(slime);
     }
 
+    private HttpResponse logs(String tenantName, String applicationName, String instanceName, String environment, String region) {
+        ApplicationId application = ApplicationId.from(tenantName, applicationName, instanceName);
+        ZoneId zone = ZoneId.from(environment, region);
+        DeploymentId deployment = new DeploymentId(application, zone);
+        return controller.configServer().getLogs(deployment);
+    }
+
+
     private void toSlime(Cursor object, Application application, HttpRequest request) {
         object.setString(""application"", application.id().application().value());
         object.setString(""instance"", application.id().instance().value());
diff --git a/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/integration/ConfigServerMock.java b/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/integration/ConfigServerMock.java
index 458ba49f3e3..bd65465633e 100644
--- a/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/integration/ConfigServerMock.java
+++ b/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/integration/ConfigServerMock.java
@@ -7,6 +7,7 @@ import com.yahoo.component.Version;
 import com.yahoo.config.provision.ApplicationId;
 import com.yahoo.config.provision.HostName;
 import com.yahoo.config.provision.NodeType;
+import com.yahoo.container.jdisc.HttpResponse;
 import com.yahoo.vespa.hosted.controller.api.application.v4.model.DeployOptions;
 import com.yahoo.vespa.hosted.controller.api.application.v4.model.EndpointStatus;
 import com.yahoo.vespa.hosted.controller.api.application.v4.model.configserverbindings.ConfigChangeActions;
@@ -25,7 +26,11 @@ import com.yahoo.vespa.hosted.controller.application.SystemApplication;
 import com.yahoo.vespa.serviceview.bindings.ApplicationView;
 import com.yahoo.vespa.serviceview.bindings.ClusterView;
 import com.yahoo.vespa.serviceview.bindings.ServiceView;
+import org.json.JSONException;
+import org.json.JSONObject;
 
+import java.io.IOException;
+import java.io.OutputStream;
 import java.net.URI;
 import java.util.ArrayList;
 import java.util.Arrays;
@@ -292,6 +297,17 @@ public class ConfigServerMock extends AbstractComponent implements ConfigServer
         return endpoints.getOrDefault(endpoint, result);
     }
 
+    @Override
+    public HttpResponse getLogs(DeploymentId deployment) {
+        return new HttpResponse(200) {
+            @Override
+            public void render(OutputStream outputStream) throws IOException {
+                outputStream.write(""{\""subfolder\"":{\""log2.log\"":\""VGhpcyBpcyBhbm90aGVyIGxvZyBmaWxl\""},\""log1.log\"":\""VGhpcyBpcyBvbmUgbG9nIGZpbGU=\""}"".getBytes());
+            }
+        };
+
+    }
+
     public static class Application {
 
         private final ApplicationId id;
diff --git a/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/restapi/application/ApplicationApiTest.java b/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/restapi/application/ApplicationApiTest.java
index 13092451d4b..03877cca30e 100644
--- a/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/restapi/application/ApplicationApiTest.java
+++ b/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/restapi/application/ApplicationApiTest.java
@@ -330,6 +330,9 @@ public class ApplicationApiTest extends ControllerContainerTest {
                                       .recursive(""true""),
                               new File(""application1-recursive.json""));
 
+        // GET logs
+        tester.assertResponse(request(""/application/v4/tenant/tenant2/application//application1/environment/prod/region/corp-us-east-1/instance/default/logs"", GET).userIdentity(USER_ID), new File(""logs.json""));
+
         // DELETE (cancel) ongoing change
         tester.assertResponse(request(""/application/v4/tenant/tenant1/application/application1/deploying"", DELETE)
                                       .userIdentity(HOSTED_VESPA_OPERATOR),
diff --git a/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/restapi/application/responses/logs.json b/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/restapi/application/responses/logs.json
new file mode 100644
index 00000000000..398a62758ee
--- /dev/null
+++ b/controller-server/src/test/java/com/yahoo/vespa/hosted/controller/restapi/application/responses/logs.json
@@ -0,0 +1,5 @@
+{
+  ""subfolder"": {
+    ""log2.log"":""VGhpcyBpcyBhbm90aGVyIGxvZyBmaWxl""},
+  ""log1.log"":""VGhpcyBpcyBvbmUgbG9nIGZpbGU=""
+}
\ No newline at end of file",Add functionality for retrieving logs,"""Added support for retrieving logs from the log server""","Added support for retrieving logs from a Vespa application.

This commit introduces a new `LogRetriever` class that retrieves logs from a Vespa application by making an HTTP request to the log server. The `ApplicationRepository` class has been updated to include a new method `getLogs` that uses `LogRetriever` to retrieve logs for a given application. The `ApplicationHandler` class has been updated to handle log requests and the `ConfigServer` interface has been updated to include a new method `getLogs` that returns the logs for a given deployment. 

Additionally, a new `LogHandler` class has been added to the container-core module to handle log requests and a new `LogReader` class has been added to read log files and convert them into a JSON format. 

The commit also includes test cases for the new log retrieval functionality.","""Add log retrieval functionality to Vespa Config Server""

This commit adds the following changes:

1. A new `LogRetriever` class is added to the `com.yahoo.vespa.config.server.http` package. This class provides a static method `getLogs` that takes a log server hostname and returns an `HttpResponse` object containing the logs.
2. A new `getLogs` method is added to the `ApplicationRepository` class. This method takes an `ApplicationId` object and returns an `HttpResponse` object containing the logs for that application. It uses the `LogRetriever` class to retrieve the logs.
3. A new `getLogServerHostname` method is added to the `ApplicationRepository` class. This method takes an `ApplicationId` object and returns the log server hostname for that application.
4. The `ApplicationHandler` class is modified to handle log requests. If the request URL matches the pattern `http://*/application/v2/tenant/*/application/*/logs`, the `getLogs` method of the `ApplicationRepository` class is called to retrieve the logs.
5. The `services.xml` file is modified to add bindings for log requests. The bindings are added for both HTTP and HTTPS schemes.
6. A new `LogRetrieverTest` class is added to the test directory. This class contains two tests:
	* `testThatLogHandlerPropagatesResponseBody`: This test verifies that the `LogRetriever` class correctly propagates the response body from the log server. It uses a mock log server to return a test response, and then checks that the `LogRetriever` returns the same response.
	* `testThatNotFoundLogServerReturns404`: This test verifies that the `LogRetriever` returns a 404 status code if the log server cannot be found. It uses a mock log server that returns a 200 status code, but with a different hostname than the one used by the `LogRetriever`. The test checks that the `LogRetriever` returns a 404 status code in this case.

Overall, this commit adds functionality to the Vespa Config Server to retrieve logs for a given application. It uses a new `LogRetriever` class to retrieve the logs from a log server, and adds a new endpoint to the `ApplicationHandler` class to handle log requests. It also includes tests to verify the correct behavior of the `LogRetriever` class.","```
Add log retrieval functionality to ApplicationHandler, including new LogRetriever class and endpoints to fetch logs from deployment environments.
```",Model 3
"diff --git a/jaxp/.hgtags b/jaxp/.hgtags
index b8bde0dc729..7e7e54dfed2 100644
--- a/jaxp/.hgtags
+++ b/jaxp/.hgtags
@@ -187,3 +187,4 @@ af9e8b0f1900b631a8a0fcccff9f1514fe58c808 jdk8-b59
 192d8a244bc36427757866e9fb3a08938c0e674c jdk8-b63
 27ab79568c34abf80958d5fa8c04fd1740d243da jdk8-b64
 5cf3c69a93d6d088a1cdfa28031d4f0f9438c0de jdk8-b65
+e6af1ad464e3d9b1154b9f9ed9a5373b97d129fc jdk8-b66",Added tag jdk8 - b66 for changeset bc221bce9150,"""Added tag for jdk8-b66""","""Update .hgtags to include JDK 8 b66""","Based on the diff you provided, it seems like you are looking for the commit message associated with the commit hash `e6af1ad464e3d9b1154b9f9ed9a5373b97d129fc` for the tag `jdk8-b66`.

However, the diff you provided does not contain any commit messages. It only shows the change in the `.hgtags` file in the JAXP repository, where a new entry for the commit hash `e6af1ad464e3d9b1154b9f9ed9a5373b97d129fc` with the tag `jdk8-b66` was added.

To get the commit message for this commit, you would need to run the following command in the JAXP repository:
```css
git show e6af1ad464e3d9b1154b9f9ed9a5373b97d129fc
```
This command will show you the commit details, including the commit message, author, date, and the changes made in that commit.",Added tag for jdk8-b66 in .hgtags file.,Model 4
"diff --git a/src/site/xdoc/manual/configuration.xml.vm b/src/site/xdoc/manual/configuration.xml.vm
index ca0bceb6b1..d1f485c4e4 100644
--- a/src/site/xdoc/manual/configuration.xml.vm
+++ b/src/site/xdoc/manual/configuration.xml.vm
@@ -424,6 +424,7 @@ public class Bar {
                 <td>Enables diagnostic information while loading plugins.</td>
               </tr>
             </table>
+          <a name=""XML""/>
           <p>
             Log4j can be configured using two XML flavors; concise and strict. The",Add XML anchor to fix documentation link .,"""Added anchor for XML configuration section in manual""","""Added documentation for Log4j XML configuration options""",Added an XML anchor tag in the configuration.xml.vm file.,Added an anchor for XML configuration section in the Log4j configuration documentation.,Model 2
"diff --git a/src/WorldEdit.java b/src/WorldEdit.java
index 0fabd0353..63fb109d8 100644
--- a/src/WorldEdit.java
+++ b/src/WorldEdit.java
@@ -94,6 +94,8 @@ public WorldEdit() {
         commands.put(""/editexpand"", ""<Dir> [Num] - Expands the selection"");
         commands.put(""/editcontract"", ""<Dir> [Num] - Contracts the selection"");
         commands.put(""/unstuck"", ""Go up to the first free spot"");
+        commands.put(""/ascend"", ""Go up one level"");
+        commands.put(""/descend"", ""Go dowm one level"");
     }
 
     /**
@@ -202,6 +204,26 @@ public boolean performCommand(WorldEditPlayer player,
             player.findFreePosition();
             return true;
 
+        // Ascend a level
+        } else if(split[0].equalsIgnoreCase(""/ascend"")) {
+            checkArgs(split, 0, 0, split[0]);
+            if (player.ascendLevel()) {
+                player.print(""Ascended a level."");
+            } else {
+                player.printError(""No free spot above you found."");
+            }
+            return true;
+
+        // Descend a level
+        } else if(split[0].equalsIgnoreCase(""/descend"")) {
+            checkArgs(split, 0, 0, split[0]);
+            if (player.descendLevel()) {
+                player.print(""Descended a level."");
+            } else {
+                player.printError(""No free spot below you found."");
+            }
+            return true;
+
         // Set edit position #1
         } else if (split[0].equalsIgnoreCase(""/editpos1"")) {
             checkArgs(split, 0, 0, split[0]);
diff --git a/src/WorldEditPlayer.java b/src/WorldEditPlayer.java
index 45141d54b..11ffa6b81 100644
--- a/src/WorldEditPlayer.java
+++ b/src/WorldEditPlayer.java
@@ -133,7 +133,7 @@ public void printError(String msg) {
 
     /**
      * Move the player.
-     * 
+     *
      * @param pos
      * @param pitch
      * @param yaw
@@ -148,6 +148,21 @@ public void setPosition(Vector pos, float pitch, float yaw) {
         player.teleportTo(loc);
     }
 
+    /**
+     * Move the player.
+     *
+     * @param pos
+     */
+    public void setPosition(Vector pos) {
+        Location loc = new Location();
+        loc.x = pos.getX();
+        loc.y = pos.getY();
+        loc.z = pos.getZ();
+        loc.rotX = (float)getYaw();
+        loc.rotY = (float)getPitch();
+        player.teleportTo(loc);
+    }
+
     /**
      * Find a position for the player to stand that is not inside a block.
      * Blocks above the player will be iteratively tested until there is
@@ -186,6 +201,73 @@ public void findFreePosition() {
         }
     }
 
+    /**
+     * Go up one level to the next free space above.
+     *
+     * @return true if a spot was found
+     */
+    public boolean ascendLevel() {
+        int x = (int)Math.floor(player.getX());
+        int y = (int)Math.floor(player.getY());
+        int z = (int)Math.floor(player.getZ());
+
+        byte free = 0;
+        byte spots = 0;
+        boolean inFree = false;
+
+        while (y <= 129) {
+            if (etc.getServer().getBlockIdAt(x, y, z) == 0) {
+                free++;
+            } else {
+                free = 0;
+                inFree = false;
+            }
+
+            if (free == 2 && inFree == false) {
+                inFree = true;
+                spots++;
+                if (y >= 129 || spots == 2) {
+                    setPosition(new Vector(x + 0.5, y - 1, z + 0.5));
+                    return true;
+                }
+            }
+
+            y++;
+        }
+
+        return false;
+    }
+
+    /**
+     * Go up one level to the next free space above.
+     *
+     * @return true if a spot was found
+     */
+    public boolean descendLevel() {
+        int x = (int)Math.floor(player.getX());
+        int y = (int)Math.floor(player.getY()) - 1;
+        int z =",Added / ascend and / descend .,"""Added /ascend and /descend commands to move player up or down one level to the next free space""","Added commands ""/ascend"" and ""/descend"" to move up and down one level, and implemented corresponding methods in WorldEditPlayer.","""Added /ascend and /descend commands for WorldEdit""

This commit adds two new commands to the WorldEdit plugin: ""/ascend"" and ""/descend"". These commands allow the player to move up or down one level, respectively, by finding the next free spot above or below them. The ""/ascend"" command moves the player up to the first free spot above them, while the ""/descend"" command moves the player down to the first free spot below them. If no free spot is found, the player is notified with an error message. The code for these commands is added to the WorldEdit.java file, and a new method ""setPosition(Vector pos)"" is added to the WorldEditPlayer.java file to allow the player's position to be changed using a Vector object.",Add ascend and descend level commands for player movement in WorldEdit.,Model 2
"diff --git a/server/src/main/java/org/elasticsearch/search/DefaultSearchContext.java b/server/src/main/java/org/elasticsearch/search/DefaultSearchContext.java
index ebb964bb648..6184b18048b 100644
--- a/server/src/main/java/org/elasticsearch/search/DefaultSearchContext.java
+++ b/server/src/main/java/org/elasticsearch/search/DefaultSearchContext.java
@@ -28,11 +28,9 @@ import org.apache.lucene.search.MatchNoDocsQuery;
 import org.apache.lucene.search.Query;
 import org.elasticsearch.action.search.SearchShardTask;
 import org.elasticsearch.action.search.SearchType;
-import org.elasticsearch.cluster.service.ClusterService;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.lucene.search.Queries;
 import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.IndexSettings;
 import org.elasticsearch.index.cache.bitset.BitsetFilterCache;
@@ -83,9 +81,7 @@ final class DefaultSearchContext extends SearchContext {
     private final SearchShardTarget shardTarget;
     private final LongSupplier relativeTimeSupplier;
     private SearchType searchType;
-    private final BigArrays bigArrays;
     private final IndexShard indexShard;
-    private final ClusterService clusterService;
     private final IndexService indexService;
     private final ContextIndexSearcher searcher;
     private final DfsSearchResult dfsResult;
@@ -146,8 +142,6 @@ final class DefaultSearchContext extends SearchContext {
     DefaultSearchContext(ReaderContext readerContext,
                          ShardSearchRequest request,
                          SearchShardTarget shardTarget,
-                         ClusterService clusterService,
-                         BigArrays bigArrays,
                          LongSupplier relativeTimeSupplier,
                          TimeValue timeout,
                          FetchPhase fetchPhase,
@@ -157,14 +151,11 @@ final class DefaultSearchContext extends SearchContext {
         this.fetchPhase = fetchPhase;
         this.searchType = request.searchType();
         this.shardTarget = shardTarget;
-        // SearchContexts use a BigArrays that can circuit break
-        this.bigArrays = bigArrays.withCircuitBreaking();
         this.dfsResult = new DfsSearchResult(readerContext.id(), shardTarget, request);
         this.queryResult = new QuerySearchResult(readerContext.id(), shardTarget, request);
         this.fetchResult = new FetchSearchResult(readerContext.id(), shardTarget);
         this.indexService = readerContext.indexService();
         this.indexShard = readerContext.indexShard();
-        this.clusterService = clusterService;
 
         Engine.Searcher engineSearcher = readerContext.acquireSearcher(""search"");
         this.searcher = new ContextIndexSearcher(engineSearcher.getIndexReader(), engineSearcher.getSimilarity(),
@@ -457,11 +448,6 @@ final class DefaultSearchContext extends SearchContext {
         return this.indexShard;
     }
 
-    @Override
-    public BigArrays bigArrays() {
-        return bigArrays;
-    }
-
     @Override
     public BitsetFilterCache bitsetFilterCache() {
         return indexService.cache().bitsetFilterCache();
diff --git a/server/src/main/java/org/elasticsearch/search/SearchService.java b/server/src/main/java/org/elasticsearch/search/SearchService.java
index 57f0da88afd..8c416d9b091 100644
--- a/server/src/main/java/org/elasticsearch/search/SearchService.java
+++ b/server/src/main/java/org/elasticsearch/search/SearchService.java
@@ -768,8 +768,8 @@ public class SearchService extends AbstractLifecycleComponent implements IndexEv
         try {
             SearchShardTarget shardTarget = new SearchShardTarget(clusterService.localNode().getId(),
                 reader.indexShard().shardId(), request.getClusterAlias(), OriginalIndices.NONE);
-            searchContext = new DefaultSearchContext(reader, request, shardTarget, clusterService,
-                bigArrays, threadPool::relativeTimeInMillis, timeout, fetchPhase, lowLevelCancellation);
+            searchContext = new DefaultSearchContext(reader, request, shardTarget,
+                threadPool::relativeTimeInMillis, timeout, fetchPhase, lowLevelCancellation);
             // we clone the query shard context here just for rewriting otherwise we
             // might end up with incorrect state since we are using now() or script services
             // during rewrite and normalized / evaluate templates etc.
diff --git a/server/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregationBuilder.java b/server/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregationBuilder.java
index fe516114332..df13bb1d19c 100644
--- a/server/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregationBuilder.java
+++ b/server/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregationBuilder.java
@@ -25,7 +25,6 @@ import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;
 import org.elasticsearch.common.xcontent.ObjectParser;
 import org.elasticsearch.common.xcontent.XContentBuilder;
-import org.elasticsearch.index.query.QueryRewriteContext;
 import org.elasticsearch.search.aggregations.AggregationBuilder;
 import org.elasticsearch.search.aggregations.Aggregator.SubAggCollectionMode;
 import org.elasticsearch.search.aggregations.AggregatorFactories;
@@ -401,11 +400,6 @@ public class TermsAggregationBuilder extends ValuesSourceAggregationBuilder<Term
         return NAME;
     }
 
-    @Override
-    protected AggregationBuilder doRewrite(QueryRewriteContext queryShardContext) throws IOException {
-        return super.doRewrite(queryShardContext);
-    }
-
     @Override
     protected ValuesSourceRegistry.RegistryKey<?> getRegistryKey() {
         return REGISTRY_KEY;
diff --git a/server/src/main/java/org/elasticsearch/search/aggregations/support/AggregationContext.java b/server/src/main/java/org/elasticsearch/search/aggregations/support/AggregationContext.java
index b5008f1e4ad..cc664811315 100644
--- a/server/src/main/java/org/elasticsearch/search/aggregations/support/AggregationContext.java
+++ b/server/src/main/java/org/elasticsearch/search/aggregations/support/AggregationContext.java
@@ -230,6 +230,12 @@ public abstract class AggregationContext {
      */
     public abstract Analyzer getIndexAnalyzer(Function<String, NamedAnalyzer> unindexedFieldAnalyzer);
 
+    /**
+     * Is this request cacheable? Requests that have
+     * non-deterministic queries or scripts aren't cachable.
+     */
+    public abstract boolean isCacheable();
+
     /**
      * Implementation of {@linkplain AggregationContext} for production usage
      * that wraps our ubiquitous {@link QueryShardContext} and anything else
@@ -239,6 +245,7 @@ public abstract class AggregationContext {
      */
     public static class ProductionAggregationContext extends AggregationContext {
         private final QueryShardContext context;
+        private final BigArrays bigArrays;
         private final Query topLevelQuery;
         private final AggregationProfiler profiler;
         private final MultiBucketConsumer multiBucketConsumer;
@@ -277,6 +284,7 @@ public abstract class AggregationContext {
             Supplier<Boolean> isCancelled
         ) {
             this.context = context;
+            this.bigArrays = context.bigArrays().withCircuitBreaking();  // We can break in searches.
             this.topLevelQuery = topLevelQuery;
             this.profiler = profiler;
             this.multiBucketConsumer = multiBucketConsumer;
@@ -343,7 +351,7 @@ public abstract class AggregationContext {
 
         @Override
         public BigArrays bigArrays() {
-            return context.bigArrays();
+            return bigArrays;
         }
 
         @Override
@@ -425,5 +433,10 @@ public abstract class AggregationContext {
         public Analyzer getIndexAnalyzer(Function<String, NamedAnalyzer> unindexedFieldAnalyzer) {
             return context.getIndexAnalyzer(unindexedFieldAnalyzer);
         }
+
+        @Override
+        public boolean isCacheable() {
+            return context.isCacheable();
+        }
     }
 }
diff --git a/server/src/main/java/org/elasticsearch/search/internal/FilteredSearchContext.java b/server/src/main/java/org/elasticsearch/search/internal/FilteredSearchContext.java
index f3c6bcebc92..b4ae043bdb2 100644
--- a/server/src/main/java/org/elasticsearch/search/internal/FilteredSearchContext.java
+++ b/server/src/main/java/org/elasticsearch/search/internal/FilteredSearchContext.java
@@ -25,7 +25,6 @@ import org.apache.lucene.search.Query;
 import org.elasticsearch.action.search.SearchShardTask;
 import org.elasticsearch.action.search.SearchType;
 import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.cache.bitset.BitsetFilterCache;
 import org.elasticsearch.index.query.ParsedQuery;
 import org.elasticsearch.index.query.QueryShardContext;
@@ -200,11 +199,6 @@ public abstract class FilteredSearchContext extends SearchContext {
         return in.indexShard();
     }
 
-    @Override
-    public BigArrays bigArrays() {
-        return in.bigArrays();
-    }
-
     @Override
     public BitsetFilterCache bitsetFilterCache() {
         return in.bitsetFilterCache();
diff --git a/server/src/main/java/org/elasticsearch/search/internal/SearchContext.java b/server/src/main/java/org/elasticsearch/search/internal/SearchContext.java
index 5a299ddfc22..59e9aabb648 100644
--- a/server/src/main/java/org/elasticsearch/search/internal/SearchContext.java
+++ b/server/src/main/java/org/elasticsearch/search/internal/SearchContext.java
@@ -28,7 +28,6 @@ import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.lease.Releasable;
 import org.elasticsearch.common.lease.Releasables;
 import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.cache.bitset.BitsetFilterCache;
 import org.elasticsearch.index.query.ParsedQuery;
 import org.elasticsearch.index.query.QueryShardContext;
@@ -210,8 +209,6 @@ public abstract class SearchContext implements Releasable {
 
     public abstract IndexShard indexShard();
 
-    public abstract BigArrays bigArrays();  // TODO this is only used in aggs land and should be contained
-
     public abstract BitsetFilterCache bitsetFilterCache();
 
     public abstract TimeValue timeout();
diff --git a/server/src/test/java/org/elasticsearch/index/SearchSlowLogTests.java b/server/src/test/java/org/elasticsearch/index/SearchSlowLogTests.java
index f587f867dc5..1378161bf26 100644
--- a/server/src/test/java/org/elasticsearch/index/SearchSlowLogTests.java
+++ b/server/src/test/java/org/elasticsearch/index/SearchSlowLogTests.java
@@ -32,7 +32,6 @@ import org.elasticsearch.common.logging.Loggers;
 import org.elasticsearch.common.logging.MockAppender;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.query.QueryBuilders;
 import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.search.builder.SearchSourceBuilder;
@@ -82,10 +81,9 @@ public class SearchSlowLogTests extends ESSingleNodeTestCase {
     }
 
     protected SearchContext createSearchContext(IndexService indexService, String... groupStats) {
-        BigArrays bigArrays = indexService.getBigArrays();
         final ShardSearchRequest request =
             new ShardSearchRequest(new ShardId(indexService.index(), 0), 0L, null);
-        return new TestSearchContext(bigArrays, indexService) {
+        return new TestSearchContext(indexService) {
             @Override
             public List<String> groupStats() {
                 return Arrays.asList(groupStats);
diff --git a/server/src/test/java/org/elasticsearch/index/shard/SearchOperationListenerTests.java b/server/src/test/java/org/elasticsearch/index/shard/SearchOperationListenerTests.java
index 38292f61cca..2d3c1c7b36c 100644
--- a/server/src/test/java/org/elasticsearch/index/shard/SearchOperationListenerTests.java
+++ b/server/src/test/java/org/elasticsearch/index/shard/SearchOperationListenerTests.java
@@ -18,6 +18,7 @@
  */
 package org.elasticsearch.index.shard;
 
+import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.search.internal.ReaderContext;
 import org.elasticsearch.search.internal.SearchContext;
 import org.elasticsearch.test.ESTestCase;
@@ -139,7 +140,7 @@ public class SearchOperationListenerTests extends ESTestCase {
         Collections.shuffle(indexingOperationListeners, random());
         SearchOperationListener.CompositeListener compositeListener =
             new SearchOperationListener.CompositeListener(indexingOperationListeners, logger);
-        SearchContext ctx = new TestSearchContext(null);
+        SearchContext ctx = new TestSearchContext((QueryShardContext) null);
         compositeListener.onQueryPhase(ctx, timeInNanos.get());
         assertEquals(0, preFetch.get());
         assertEquals(0, preQuery.get());
diff --git a/server/src/test/java/org/elasticsearch/search/DefaultSearchContextTests.java b/server/src/test/java/org/elasticsearch/search/DefaultSearchContextTests.java
index 2f406a50bab..e4384bd344a 100644
--- a/server/src/test/java/org/elasticsearch/search/DefaultSearchContextTests.java
+++ b/server/src/test/java/org/elasticsearch/search/DefaultSearchContextTests.java
@@ -34,9 +34,6 @@ import org.elasticsearch.cluster.metadata.IndexMetadata;
 import org.elasticsearch.common.UUIDs;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.TimeValue;
-import org.elasticsearch.common.util.BigArrays;
-import org.elasticsearch.common.util.MockBigArrays;
-import org.elasticsearch.common.util.MockPageCacheRecycler;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.IndexSettings;
 import org.elasticsearch.index.cache.IndexCache;
@@ -49,7 +46,6 @@ import org.elasticsearch.index.query.ParsedQuery;
 import org.elasticsearch.index.query.QueryShardContext;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.indices.breaker.NoneCircuitBreakerService;
 import org.elasticsearch.search.internal.AliasFilter;
 import org.elasticsearch.search.internal.LegacyReaderContext;
 import org.elasticsearch.search.internal.ReaderContext;
@@ -122,8 +118,6 @@ public class DefaultSearchContextTests extends ESTestCase {
         when(indexService.getIndexSettings()).thenReturn(indexSettings);
         when(mapperService.getIndexSettings()).thenReturn(indexSettings);
 
-        BigArrays bigArrays = new MockBigArrays(new MockPageCacheRecycler(Settings.EMPTY), new NoneCircuitBreakerService());
-
         try (Directory dir = newDirectory();
              RandomIndexWriter w = new RandomIndexWriter(random(), dir)) {
 
@@ -150,7 +144,7 @@ public class DefaultSearchContextTests extends ESTestCase {
             ReaderContext readerWithoutScroll = new ReaderContext(
                 newContextId(), indexService, indexShard, searcherSupplier.get(), randomNonNegativeLong(), false);
             DefaultSearchContext contextWithoutScroll = new DefaultSearchContext(readerWithoutScroll, shardSearchRequest, target, null,
-                bigArrays, null, timeout, null, false);
+                timeout, null, false);
             contextWithoutScroll.from(300);
             contextWithoutScroll.close();
 
@@ -166,7 +160,7 @@ public class DefaultSearchContextTests extends ESTestCase {
             ReaderContext readerContext = new LegacyReaderContext(
                 newContextId(), indexService, indexShard, searcherSupplier.get(), shardSearchRequest, randomNonNegativeLong());
             DefaultSearchContext context1 = new DefaultSearchContext(readerContext, shardSearchRequest, target, null,
-                bigArrays, null, timeout, null, false);
+                timeout, null, false);
             context1.from(300);
             exception = expectThrows(IllegalArgumentException.class, () -> context1.preProcess(false));
             assertThat(exception.getMessage(), equalTo(""Batch size is too large, size must be less than or equal to: [""
@@ -200,7 +194,7 @@ public class DefaultSearchContextTests extends ESTestCase {
                 newContextId(), indexService, indexShard, searcherSupplier.get(), randomNonNegativeLong(), false);
             // rescore is null but sliceBuilder is not null
             DefaultSearchContext context2 = new DefaultSearchContext(readerContext, shardSearchRequest, target,
-                null, bigArrays, null, timeout, null, false);
+                null, timeout, null, false);
 
             SliceBuilder sliceBuilder = mock(SliceBuilder.class);
             int numSlices = maxSlicesPerScroll + randomIntBetween(1, 100);
@@ -217,7 +211,7 @@ public class DefaultSearchContextTests extends ESTestCase {
             when(shardSearchRequest.indexBoost()).thenReturn(AbstractQueryBuilder.DEFAULT_BOOST);
 
             DefaultSearchContext context3 = new DefaultSearchContext(readerContext, shardSearchRequest, target, null,
-                bigArrays, null, timeout, null, false);
+                timeout, null, false);
             ParsedQuery parsedQuery = ParsedQuery.parsedMatchAllQuery();
             context3.sliceBuilder(null).parsedQuery(parsedQuery).preProcess(false);
             assertEquals(context3.query(), context3.buildFilteredQuery(parsedQuery.query()));
@@ -229,7 +223,7 @@ public class DefaultSearchContextTests extends ESTestCase {
             readerContext = new ReaderContext(newContextId(), indexService, indexShard,
                 searcherSupplier.get(), randomNonNegativeLong(), false);
             DefaultSearchContext context4 =
-                new DefaultSearchContext(readerContext, shardSearchRequest, target, null, bigArrays, null, timeout, null, false);
+                new DefaultSearchContext(readerContext, shardSearchRequest, target, null, timeout, null, false);
             context4.sliceBuilder(new SliceBuilder(1,2)).parsedQuery(parsedQuery).preProcess(false);
             Query query1 = context4.query();
             context4.sliceBuilder(new SliceBuilder(0,2)).parsedQuery(parsedQuery).preProcess(false);
@@ -256,8 +250,6 @@ public class DefaultSearchContextTests extends ESTestCase {
 
         IndexService indexService = mock(IndexService.class);
 
-        BigArrays bigArrays = new MockBigArrays(new MockPageCacheRecycler(Settings.EMPTY), new NoneCircuitBreakerService());
-
         try (Directory dir = newDirectory();
              RandomIndexWriter w = new RandomIndexWriter(random(), dir)) {
 
@@ -282,7 +274,7 @@ public class DefaultSearchContextTests extends ESTestCase {
             ReaderContext readerContext = new ReaderContext(
                 newContextId(), indexService, indexShard, searcherSupplier, randomNonNegativeLong(), false);
             DefaultSearchContext context = new DefaultSearchContext(readerContext, shardSearchRequest, target, null,
-                bigArrays, null, timeout, null, false);
+                timeout, null, false);
 
             assertThat(context.searcher().hasCancellations(), is(false));
             context.searcher().addQueryCancellation(() -> {});
diff --git a/server/src/test/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregatorTests.java b/server/src/test/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregatorTests.java
index 0cea28e5f4d..f6e01830700 100644
--- a/server/src/test/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregatorTests.java
+++ b/server/src/test/java/org/elasticsearch/search/aggregations/bucket/BucketsAggregatorTests.java
@@ -32,14 +32,10 @@ import org.elasticsearch.search.aggregations.AggregatorFactories;
 import org.elasticsearch.search.aggregations.AggregatorTestCase;
 import org.elasticsearch.search.aggregations.InternalAggregation;
 import org.elasticsearch.search.aggregations.LeafBucketCollector;
-import org.elasticsearch.search.aggregations.MultiBucketConsumerService.MultiBucketConsumer;
-import org.elasticsearch.search.aggregations.support.AggregationContext.ProductionAggregationContext;
-import org.elasticsearch.search.internal.SearchContext;
+import org.elasticsearch.search.aggregations.support.AggregationContext;
 
 import java.io.IOException;
 
-import static org.mockito.Mockito.mock;
-
 public class BucketsAggregatorTests extends AggregatorTestCase{
 
     public BucketsAggregator buildMergeAggregator() throws IOException{
@@ -53,12 +49,11 @@ public class BucketsAggregatorTests extends AggregatorTestCase{
             try (IndexReader indexReader = DirectoryReader.open(directory)) {
                 IndexSearcher indexSearcher = new IndexSearcher(indexReader);
 
-                SearchContext searchContext = createSearchContext(
+                AggregationContext context = createAggregationContext(
                     indexSearcher,
                     null,
                     new NumberFieldMapper.NumberFieldType(""test"", NumberFieldMapper.NumberType.INTEGER)
                 );
-                ProductionAggregationContext context = new ProductionAggregationContext(searchContext, mock(MultiBucketConsumer.class));
 
                 return new BucketsAggregator(""test"", AggregatorFactories.EMPTY, context, null, null, null) {
                     @Override
diff --git a/server/src/test/java/org/elasticsearch/search/aggregations/bucket/adjacency/AdjacencyMatrixAggregationBuilderTests.java b/server/src/test/java/org/elasticsearch/search/aggregations/bucket/adjacency/AdjacencyMatrixAggregationBuilderTests.java
index 9af7f6cc0c7..304e19636f1 100644
--- a/server/src/test/java/org/elasticsearch/search/aggregations/bucket/adjacency/AdjacencyMatrixAggregationBuilderTests.java
+++ b/server/src/test/java/org/elasticsearch/search/aggregations/bucket/adjacency/AdjacencyMatrixAggregationBuilderTests.java
@@ -22,6 +22,7 @@ package org.elasticsearch.search.aggregations.bucket.adjacency;
 import org.elasticsearch.Version;
 import org.elasticsearch.cluster.metadata.IndexMetadata;
 import org.elasticsearch.common.settings.Settings;
+import org.elasticsearch.common.util.BigArrays;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.IndexSettings;
 import org.elasticsearch.index.query.QueryBuilder;
@@ -62,6 +63,7 @@ public class AdjacencyMatrixAggregationBuilderTests extends ESTestCase {
         IndexSettings indexSettings = new IndexSettings(indexMetadata, Settings.EMPTY);
         when(indexShard.indexSettings()).thenReturn(indexSettings);
         when(queryShardContext.getIndexSettings()).thenReturn(indexSettings);
+        when(queryShardContext.bigArrays()).thenReturn(BigArrays.NON_RECYCLING_INSTANCE);
         when(indexShard.shardId()).thenReturn(new ShardId(new Index(""test"", ""test""), 1));
         SearchContext context = new TestSearchContext(queryShardContext, indexShard);
 
diff --git a/server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java b/server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java
index 740b3271fe9..0dc026ecd42 100644
--- a/server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java
+++ b/server/src/test/java/org/elasticsearch/search/aggregations/bucket/histogram/DateHistogramAggregatorTests.java
@@ -38,8 +38,8 @@ import org.elasticsearch.search.aggregations.Aggregator;
 import org.elasticsearch.search.aggregations.BucketOrder;
 import org.elasticsearch.search.aggregations.bucket.terms.StringTerms;
 import org.elasticsearch.search.aggregations.bucket.terms.TermsAggregationBuilder;
+import org.elasticsearch.search.aggregations.support.AggregationContext;
 import org.elasticsearch.search.aggregations.support.AggregationInspectionHelper;
-import org.elasticsearch.search.internal.SearchContext;
 import org.hamcrest.Matcher;
 
 import java.io.IOException;
@@ -1210,7 +1210,7 @@ public class DateHistogramAggregatorTests extends DateHistogramAggregatorTestCas
                 );
             }
             try (IndexReader reader = indexWriter.getReader()) {
-                SearchContext context = createSearchContext(new IndexSearcher(reader), new MatchAllDocsQuery(), ft);
+                AggregationContext context = createAggregationContext(new IndexSearcher(reader), new MatchAllDocsQuery(), ft);
                 Aggregator agg = createAggregator(builder, context);
                 Matcher<Aggregator> matcher = instanceOf(DateHistogramAggregator.FromDateRange.class);
                 if (usesFromRange == false) {
diff --git a/server/src/test/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregatorTests.java b/server/src/test/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregatorTests.java
index f5697e0153f..c119cc1e484 100644
--- a/server/src/test/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregatorTests.java
+++ b/server/src/test/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregatorTests.java
@@ -88,11 +88,11 @@ import org.elasticsearch.search.aggregations.metrics.InternalTopHits;
 import org.elasticsearch.search.aggregations.metrics.TopHitsAggregationBuilder;
 import org.elasticsearch.search.aggregations.pipeline.BucketScriptPipelineAggregationBuilder;
 import org.elasticsearch.search.aggregations.pipeline.PipelineAggregator.PipelineTree;
+import org.elasticsearch.search.aggregations.support.AggregationContext;
 import org.elasticsearch.search.aggregations.support.AggregationInspectionHelper;
 import org.elasticsearch.search.aggregations.support.CoreValuesSourceType;
 import org.elasticsearch.search.aggregations.support.ValueType;
 import org.elasticsearch.search.aggregations.support.ValuesSourceType;
-import org.elasticsearch.search.internal.SearchContext;
 import org.elasticsearch.search.sort.FieldSortBuilder;
 import org.elasticsearch.search.sort.ScoreSortBuilder;
 import org.elasticsearch.test.geo.RandomGeoGenerator;
@@ -142,7 +142,8 @@ public class TermsAggregatorTests extends AggregatorTestCase {
         return new ScriptService(Settings.EMPTY, engines, ScriptModule.CORE_CONTEXTS);
     }
 
-    protected <A extends Aggregator> A createAggregator(AggregationBuilder aggregationBuilder, SearchContext context) throws IOException {
+    protected <A extends Aggregator> A createAggregator(AggregationBuilder aggregationBuilder, AggregationContext context)
+        throws IOException {
         try {
             if (randomizeAggregatorImpl) {
                 TermsAggregatorFactory.COLLECT_SEGMENT_ORDS = randomBoolean();
@@ -253,7 +254,7 @@ public class TermsAggregatorTests extends AggregatorTestCase {
                             .order(BucketOrder.key(true));
                         MappedFieldType fieldType = new KeywordFieldMapper.KeywordFieldType(""string"");
 
-                        SearchContext context = createSearchContext(indexSearcher, null, fieldType);
+                        AggregationContext context = createAggregationContext(indexSearcher, null, fieldType);
                         TermsAggregator aggregator = createAggregator(aggregationBuilder, context);
                         aggregator.preCollection();
                         indexSearcher.search(new MatchAllDocsQuery(), aggregator);
@@ -322,7 +323,7 @@ public class TermsAggregatorTests extends AggregatorTestCase {
                         .size(12)
                         .order(BucketOrder.key(true));
 
-                    SearchContext context = createSearchContext(indexSearcher, null, fieldType);
+                    AggregationContext context = createAggregationContext(indexSearcher, null, fieldType);
                     TermsAggregator aggregator = createAggregator(aggregationBuilder, context);
                     aggregator.preCollection();
                     indexSearcher.search(new MatchAllDocsQuery(), aggregator);
@@ -357,7 +358,7 @@ public class TermsAggregatorTests extends AggregatorTestCase {
                         .field(""sv_field"")
                         .order(BucketOrder.key(true));
 
-                    context = createSearchContext(indexSearcher, null, fieldType2);
+                    context = createAggregationContext(indexSearcher, null, fieldType2);
                     aggregator = createAggregator(aggregationBuilder, context);
                     aggregator.preCollection();
                     indexSearcher.search(new MatchAllDocsQuery(), aggregator);
@@ -381,7 +382,7 @@ public class TermsAggregatorTests extends AggregatorTestCase {
                         .field(""mv_field"")
                         .order(BucketOrder.key(true));
 
-                    context = createSearchContext(indexSearcher, null, fieldType);
+                    context = createAggregationContext(indexSearcher, null, fieldType);
                     aggregator = createAggregator(aggregationBuilder, context);
                     aggregator.preCollection();
                     indexSearcher.search(new MatchAllDocsQuery(), aggregator);
@@ -410,7 +411,7 @@ public class TermsAggregatorTests extends AggregatorTestCase {
                         .includeExclude(new IncludeExclude(null, ""val00.+""))
                         .field(""mv_field"")
                         .order(BucketOrder.key(true));
-                    context = createSearchContext(indexSearcher, null, fieldType);
+                    context = createAggregationContext(indexSearcher, null, fieldType);
                     aggregator = createAggregator(aggregationBuilder, context);
                     aggregator.preCollection();
                     indexSearcher.search(new MatchAllDocsQuery(), aggregator);
@@ -427,7",Remove BigArrays from SearchContext ( <issue_id> ) .,Remove BigArrays from SearchContext and related classes.,"Remove unused BigArrays instances and circuit breaking from SearchContext

This commit message accurately reflects the changes made in the code. The diff shows that several instances of `BigArrays` were removed, and the circuit breaking functionality was removed from `SearchContext`.","""Remove BigArrays from SearchContext and related changes""

This commit removes the BigArrays field from the SearchContext class and updates related classes accordingly. The changes include:

* Removing the BigArrays field from the DefaultSearchContext and FilteredSearchContext classes.
* Updating the ProductionAggregationContext class to use its own BigArrays instance instead of getting it from the SearchContext.
* Updating the SearchService class to create a new DefaultSearchContext without passing in a BigArrays instance.
* Removing the bigArrays() method from the SearchContext interface.
* Removing the BigArrays field from the TestSearchContext class in the SearchSlowLogTests test class.
* Updating the createSearchContext() method in the SearchSlowLogTests test class to create a new TestSearchContext without passing in a BigArrays instance.
* Updating the createSearchContext() method in the SearchOperationListenerTests test class to create a new TestSearchContext without passing in a BigArrays instance.

The commit also adds a new isCacheable() method to the AggregationContext interface, which is implemented in the ProductionAggregationContext class to return the value of the isCacheable() method from the QueryShardContext instance.","""Remove BigArrays dependency from DefaultSearchContext and improve AggregationContext by adding isCacheable method.""",Model 4
"diff --git a/src/com/google/javascript/jscomp/LintPassConfig.java b/src/com/google/javascript/jscomp/LintPassConfig.java
index a2939a56f..d718bcd10 100644
--- a/src/com/google/javascript/jscomp/LintPassConfig.java
+++ b/src/com/google/javascript/jscomp/LintPassConfig.java
@@ -17,7 +17,6 @@ package com.google.javascript.jscomp;
 
 import com.google.common.collect.ImmutableList;
 import com.google.javascript.jscomp.NodeTraversal.Callback;
-import com.google.javascript.jscomp.lint.CheckArguments;
 import com.google.javascript.jscomp.lint.CheckEmptyStatements;
 import com.google.javascript.jscomp.lint.CheckEnums;
 import com.google.javascript.jscomp.lint.CheckInterfaces;
@@ -79,7 +78,6 @@ class LintPassConfig extends PassConfig.PassConfigDelegate {
           return new CombinedCompilerPass(
               compiler,
               ImmutableList.<Callback>of(
-                  new CheckArguments(compiler),
                   new CheckEmptyStatements(compiler),
                   new CheckEnums(compiler),
                   new CheckInterfaces(compiler),","Remove the ` arguments ` check from the linter for now , until it \' s better documented and gives clearer advice to the user . . - - - - - - - - - - - - - .","""Remove CheckArguments from LintPassConfig""","""Remove unused CheckArguments lint check from LintPassConfig.""","""Remove CheckArguments from LintPassConfig in JavaScript Compiler""",Remove CheckArguments lint rule from LintPassConfig.,Model 3
"diff --git a/curator-framework/src/test/java/org/apache/curator/framework/imps/TestFrameworkBackground.java b/curator-framework/src/test/java/org/apache/curator/framework/imps/TestFrameworkBackground.java
index 8527a148..5aa13537 100644
--- a/curator-framework/src/test/java/org/apache/curator/framework/imps/TestFrameworkBackground.java
+++ b/curator-framework/src/test/java/org/apache/curator/framework/imps/TestFrameworkBackground.java
@@ -34,7 +34,6 @@ import org.testng.annotations.Test;
 import java.util.Arrays;
 import java.util.List;
 import java.util.concurrent.CountDownLatch;
-import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicLong;
 
 public class TestFrameworkBackground extends BaseClassForTests
@@ -127,11 +126,12 @@ public class TestFrameworkBackground extends BaseClassForTests
     @Test
     public void testCuratorCallbackOnError() throws Exception
     {
-
+        Timing timing = new Timing();
         CuratorFramework client = CuratorFrameworkFactory.builder()
             .connectString(server.getConnectString())
-            .sessionTimeoutMs(60000)
-            .retryPolicy(new RetryNTimes(1, 1000)).build();
+            .sessionTimeoutMs(timing.session())
+            .connectionTimeoutMs(timing.connection())
+            .retryPolicy(new RetryOneTime(1000)).build();
         final CountDownLatch latch = new CountDownLatch(1);
         try
         {
@@ -154,7 +154,7 @@ public class TestFrameworkBackground extends BaseClassForTests
             // Attempt to retrieve children list
             client.getChildren().inBackground(curatorCallback).forPath(""/"");
             // Check if the callback has been called with a correct return code
-            Assert.assertTrue(latch.await(10, TimeUnit.SECONDS), ""Callback has not been called by curator !"");
+            Assert.assertTrue(timing.awaitLatch(latch), ""Callback has not been called by curator !"");
         }
         finally
         {",Add timing for better test reliability,"""Refactor TestFrameworkBackground to use Timing class for session and connection timeouts, and retry policy""","""Refactor testCuratorCallbackOnError to use Timing class for timeout settings and latch waiting.""","""Update TestFrameworkBackground to use Timing class and adjust timeouts""

Explanation:

* The import statement for java.util.concurrent.TimeUnit has been removed.
* A new Timing object is created at the beginning of the testCuratorCallbackOnError() method.
* The sessionTimeoutMs and connectionTimeoutMs parameters in the CuratorFrameworkFactory.builder() call have been updated to use the session() and connection() methods of the Timing object, respectively.
* The RetryPolicy used in the CuratorFrameworkFactory.builder() call has been changed from RetryNTimes to RetryOneTime with a sleep time of 1000 ms.
* The latch.await() call has been replaced with timing.awaitLatch() call.

These changes suggest that the Timing class has been introduced to manage time-related settings in the test, and the timeouts have been adjusted accordingly. The RetryPolicy has also been simplified to retry only once with a fixed sleep time.","""Refactored test with Timing utility for session and connection timeouts and improved latch await mechanism.""",Model 1
"diff --git a/README.md b/README.md
index 2941e99..1d3d53b 100644
--- a/README.md
+++ b/README.md
@@ -55,6 +55,9 @@ Elasticsearch-SQL
 **5.6.4** [![5.6.4 Build Status](https://travis-ci.org/NLPchina/elasticsearch-sql.svg?branch=elastic5.6.4)](https://travis-ci.org/NLPchina/elasticsearch-sql)
 **5.6.5** [![5.6.5 Build Status](https://travis-ci.org/NLPchina/elasticsearch-sql.svg?branch=elastic5.6.5)](https://travis-ci.org/NLPchina/elasticsearch-sql)
 **6.0.0** [![6.0.0 Build Status](https://travis-ci.org/NLPchina/elasticsearch-sql.svg?branch=elastic6.0.0)](https://travis-ci.org/NLPchina/elasticsearch-sql)
+**6.0.1** [![6.0.1 Build Status](https://travis-ci.org/NLPchina/elasticsearch-sql.svg?branch=elastic6.0.1)](https://travis-ci.org/NLPchina/elasticsearch-sql)
+**6.1.0** [![6.1.0 Build Status](https://travis-ci.org/NLPchina/elasticsearch-sql.svg?branch=elastic6.1.0)](https://travis-ci.org/NLPchina/elasticsearch-sql)
+**6.1.1** [![6.1.1 Build Status](https://travis-ci.org/NLPchina/elasticsearch-sql.svg?branch=elastic6.1.1)](https://travis-ci.org/NLPchina/elasticsearch-sql)
 
 Query elasticsearch using familiar SQL syntax.
 You can also use ES functions in SQL.
@@ -123,6 +126,9 @@ Versions
 | 5.6.4                 | 5.6.4.0        | delete commands not supported  | elastic5.6.4 |
 | 5.6.5                 | 5.6.5.0        | delete commands not supported  | elastic5.6.5 |
 | 6.0.0                 | 6.0.0.0        |                                | elastic6.0.0 |
+| 6.0.1                 | 6.0.1.0        |                                | elastic6.0.1 |
+| 6.1.0                 | 6.1.0.0        |                                | elastic6.1.0 |
+| 6.1.1                 | 6.1.1.0        |                                | elastic6.1.1 |
 
 ### Elasticsearch 1.x
 ````
@@ -332,6 +338,21 @@ Versions
 ./bin/elasticsearch-plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/6.0.0.0/elasticsearch-sql-6.0.0.0.zip
 ````
 
+### Elasticsearch 6.0.1
+````
+./bin/elasticsearch-plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/6.0.1.0/elasticsearch-sql-6.0.1.0.zip
+````
+
+### Elasticsearch 6.1.0
+````
+./bin/elasticsearch-plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/6.1.0.0/elasticsearch-sql-6.1.0.0.zip
+````
+
+### Elasticsearch 6.1.1
+````
+./bin/elasticsearch-plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/6.1.1.0/elasticsearch-sql-6.1.1.0.zip
+````
+
 After doing this, you need to restart the Elasticsearch server. Otherwise you may get errors like `Invalid index name [sql], must not start with '']; "",""status"":400}`.
 
 ## Basic Usage",update README . md,"""Add support for Elasticsearch 6.0.1, 6.1.0, and 6.1.1 versions""","""Added support for Elasticsearch 6.0.1, 6.1.0, and 6.1.1, including plugin installation instructions and documentation updates.""","Updated README.md to include Elasticsearch-SQL versions for 6.0.1, 6.1.0, and 6.1.1.

The README.md file has been updated to include the Elasticsearch-SQL versions for 6.0.1, 6.1.0, and 6.1.1. The new versions have been added to the list of supported versions, and installation instructions have been provided for each version. The changes are as follows:

* Added Elasticsearch-SQL version 6.0.1 with the corresponding Travis CI build status badge and installation command.
* Added Elasticsearch-SQL version 6.1.0 with the corresponding Travis CI build status badge and installation command.
* Added Elasticsearch-SQL version 6.1.1 with the corresponding Travis CI build status badge and installation command.

These changes will allow users to easily install and use the appropriate version of Elasticsearch-SQL for their Elasticsearch server.","Added support and installation instructions for Elasticsearch versions 6.0.1, 6.1.0, and 6.1.1 in README.md.",Model 4
"diff --git a/languagetool-core/pom.xml b/languagetool-core/pom.xml
index e56a7dac85..63ba77cfc4 100644
--- a/languagetool-core/pom.xml
+++ b/languagetool-core/pom.xml
@@ -82,7 +82,6 @@
             <version>${morfologik.version}</version>
         </dependency>
         <dependency>
-            <!-- Note: if you update morfologik here, remember to also update morfologik-tools in languagetool-standalone -->
             <groupId>org.carrot2</groupId>
             <artifactId>morfologik-speller</artifactId>
             <version>${morfologik.version}</version>",remove outdated comment,"""Remove morfologik-speller dependency from languagetool-core""",Remove morfologik-speller dependency from languagetool-core.,"""Removed comment about updating morfologik-tools in languagetool-standalone from pom.xml""",Removed note about updating morfologik-tools in languagetool-standalone from languagetool-core/pom.xml.,Model 4
"diff --git a/maven-core/src/main/java/org/apache/maven/lifecycle/internal/LifecyclePluginResolver.java b/maven-core/src/main/java/org/apache/maven/lifecycle/internal/LifecyclePluginResolver.java
index 956e71723..f02552aec 100644
--- a/maven-core/src/main/java/org/apache/maven/lifecycle/internal/LifecyclePluginResolver.java
+++ b/maven-core/src/main/java/org/apache/maven/lifecycle/internal/LifecyclePluginResolver.java
@@ -19,6 +19,9 @@
  * under the License.
  */
 
+import java.util.HashMap;
+import java.util.Map;
+
 import org.apache.maven.execution.MavenSession;
 import org.apache.maven.model.Plugin;
 import org.apache.maven.model.PluginManagement;
@@ -30,9 +33,6 @@
 import org.codehaus.plexus.component.annotations.Component;
 import org.codehaus.plexus.component.annotations.Requirement;
 
-import java.util.HashMap;
-import java.util.Map;
-
 /**
  * @since 3.0
  * @author Benjamin Bentmann
@@ -46,7 +46,6 @@ public class LifecyclePluginResolver
     @Requirement
     private PluginVersionResolver pluginVersionResolver;
 
-
     public LifecyclePluginResolver( PluginVersionResolver pluginVersionResolver )
     {
         this.pluginVersionResolver = pluginVersionResolver;
@@ -65,9 +64,8 @@ public void resolveMissingPluginVersions( MavenProject project, MavenSession ses
         {
             if ( plugin.getVersion() == null )
             {
-                PluginVersionRequest request =
-                    new DefaultPluginVersionRequest( plugin, session.getRepositorySession(),
-                                                     project.getRemotePluginRepositories() );
+                PluginVersionRequest request = new DefaultPluginVersionRequest( plugin, session.getRepositorySession(),
+                                                                                project.getRemotePluginRepositories() );
                 plugin.setVersion( pluginVersionResolver.resolve( request ).getVersion() );
             }
             versions.put( plugin.getKey(), plugin.getVersion() );
diff --git a/maven-core/src/main/java/org/apache/maven/plugin/version/internal/DefaultPluginVersionResolver.java b/maven-core/src/main/java/org/apache/maven/plugin/version/internal/DefaultPluginVersionResolver.java
index f11ee956a..82e32fb31 100644
--- a/maven-core/src/main/java/org/apache/maven/plugin/version/internal/DefaultPluginVersionResolver.java
+++ b/maven-core/src/main/java/org/apache/maven/plugin/version/internal/DefaultPluginVersionResolver.java
@@ -87,8 +87,6 @@ public class DefaultPluginVersionResolver
     public PluginVersionResult resolve( PluginVersionRequest request )
         throws PluginVersionResolutionException
     {
-        logger.debug( ""Resolving plugin version for "" + request.getGroupId() + "":"" + request.getArtifactId() );
-
         PluginVersionResult result = resolveFromProject( request );
 
         if ( result == null )
@@ -103,8 +101,8 @@ public PluginVersionResult resolve( PluginVersionRequest request )
         }
         else if ( logger.isDebugEnabled() )
         {
-            logger.debug( ""Resolved plugin version for "" + request.getGroupId() + "":"" + request.getArtifactId()
-                + "" to "" + result.getVersion() + "" from POM "" + request.getPom() );
+            logger.debug( ""Resolved plugin version for "" + request.getGroupId() + "":"" + request.getArtifactId() + "" to ""
+                + result.getVersion() + "" from POM "" + request.getPom() );
         }
 
         return result;
diff --git a/maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java b/maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java
index 1d3a0f668..cea2a743e 100644
--- a/maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java
+++ b/maven-model-builder/src/main/java/org/apache/maven/model/validation/DefaultModelValidator.java
@@ -83,17 +83,18 @@ public void validateRawModel( Model m, ModelBuildingRequest request, ModelProble
             validateStringNotEmpty( ""parent.groupId"", problems, Severity.FATAL, Version.BASE, parent.getGroupId(),
                                     parent );
 
-            validateStringNotEmpty( ""parent.artifactId"", problems, Severity.FATAL, Version.BASE,
-                                    parent.getArtifactId(), parent );
+            validateStringNotEmpty( ""parent.artifactId"", problems, Severity.FATAL, Version.BASE, parent.getArtifactId(),
+                                    parent );
 
             validateStringNotEmpty( ""parent.version"", problems, Severity.FATAL, Version.BASE, parent.getVersion(),
                                     parent );
 
-            if ( equals( parent.getGroupId(), m.getGroupId() )
-                && equals( parent.getArtifactId(), m.getArtifactId() ) )
+            if ( equals( parent.getGroupId(), m.getGroupId() ) && equals( parent.getArtifactId(), m.getArtifactId() ) )
             {
-                addViolation( problems, Severity.FATAL, Version.BASE, ""parent.artifactId"", null, ""must be changed""
-                    + "", the parent element cannot have the same groupId:artifactId as the project."", parent );
+                addViolation( problems, Severity.FATAL, Version.BASE, ""parent.artifactId"", null,
+                              ""must be changed""
+                                  + "", the parent element cannot have the same groupId:artifactId as the project."",
+                              parent );
             }
         }
 
@@ -101,6 +102,14 @@ && equals( parent.getArtifactId(), m.getArtifactId() ) )
         {
             Severity errOn30 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_0 );
 
+            // [MNG-6074] Maven should produce an error if no model version has been set in a POM file used to build an
+            // effective model.
+            //
+            // As of 3.4, the model version is mandatory even in raw models. The XML element still is optional in the
+            // XML schema and this will not change anytime soon. We do not want to build effective models based on
+            // models without a version starting with 3.4.
+            validateStringNotEmpty( ""modelVersion"", problems, Severity.ERROR, Version.V20, m.getModelVersion(), m );
+
             validateEnum( ""modelVersion"", problems, Severity.ERROR, Version.V20, m.getModelVersion(), null, m,
                           ""4.0.0"" );
 
@@ -157,23 +166,23 @@ && equals( parent.getArtifactId(), m.getArtifactId() ) )
                                   ""must be unique but found duplicate profile with id "" + profile.getId(), profile );
                 }
 
-                validate30RawProfileActivation( problems, profile.getActivation(), profile.getId(), prefix
-                    + "".activation"", request );
+                validate30RawProfileActivation( problems, profile.getActivation(), profile.getId(),
+                                                prefix + "".activation"", request );
 
                 validate20RawDependencies( problems, profile.getDependencies(), prefix + "".dependencies.dependency"",
-                                         request );
+                                           request );
 
                 if ( profile.getDependencyManagement() != null )
                 {
-                    validate20RawDependencies( problems, profile.getDependencyManagement().getDependencies(), prefix
-                        + "".dependencyManagement.dependencies.dependency"", request );
+                    validate20RawDependencies( problems, profile.getDependencyManagement().getDependencies(),
+                                               prefix + "".dependencyManagement.dependencies.dependency"", request );
                 }
 
                 validateRawRepositories( problems, profile.getRepositories(), prefix + "".repositories.repository"",
-                                      request );
+                                         request );
 
-                validateRawRepositories( problems, profile.getPluginRepositories(), prefix
-                    + "".pluginRepositories.pluginRepository"", request );
+                validateRawRepositories( problems, profile.getPluginRepositories(),
+                                         prefix + "".pluginRepositories.pluginRepository"", request );
 
                 BuildBase buildBase = profile.getBuild();
                 if ( buildBase != null )
@@ -184,7 +193,7 @@ && equals( parent.getArtifactId(), m.getArtifactId() ) )
                     if ( mngt != null )
                     {
                         validate20RawPlugins( problems, mngt.getPlugins(), prefix + "".pluginManagement.plugins.plugin"",
-                                            request );
+                                              request );
                     }
                 }
             }
@@ -223,11 +232,8 @@ else if ( StringUtils.isNotEmpty( file.getMissing() ) )
 
             if ( path.contains( ""${project.basedir}"" ) )
             {
-                addViolation( problems,
-                              Severity.WARNING,
-                              Version.V30,
-                              prefix + ( missing ? "".file.missing"" : "".file.exists"" ),
-                              null,
+                addViolation( problems, Severity.WARNING, Version.V30,
+                              prefix + ( missing ? "".file.missing"" : "".file.exists"" ), null,
                               ""Failed to interpolate file location "" + path + "" for profile "" + sourceHint
                                   + "": ${project.basedir} expression not supported during profile activation, ""
                                   + ""use ${basedir} instead"",
@@ -235,15 +241,9 @@ else if ( StringUtils.isNotEmpty( file.getMissing() ) )
             }
             else if ( hasProjectExpression( path ) )
             {
-                addViolation( problems,
-                              Severity.WARNING,
-                              Version.V30,
-                              prefix + ( missing ? "".file.missing"" : "".file.exists"" ),
-                              null,
-                              ""Failed to interpolate file location ""
-                                  + path
-                                  + "" for profile ""
-                                  + sourceHint
+                addViolation( problems, Severity.WARNING, Version.V30,
+                              prefix + ( missing ? "".file.missing"" : "".file.exists"" ), null,
+                              ""Failed to interpolate file location "" + path + "" for profile "" + sourceHint
                                   + "": ${project.*} expressions are not supported during profile activation"",
                               file.getLocation( missing ? ""missing"" : ""exists"" ) );
             }
@@ -251,7 +251,7 @@ else if ( hasProjectExpression( path ) )
     }
 
     private void validate20RawPlugins( ModelProblemCollector problems, List<Plugin> plugins, String prefix,
-                                     ModelBuildingRequest request )
+                                       ModelBuildingRequest request )
     {
         Severity errOn31 = getSeverity( request, ModelBuildingRequest.VALIDATION_LEVEL_MAVEN_3_1 );
 
@@ -259,6 +259,27 @@ private void validate20RawPlugins( ModelProblemCollector problems, List<Plugin>
 
         for ( Plugin plugin : plugins )
         {
+            if ( plugin.getGroupId() == null
+                || ( plugin.getGroupId() != null && plugin.getGroupId().trim().isEmpty() ) )
+            {
+                addViolation( problems, Severity.FATAL, Version.V20, prefix + "".(groupId:artifactId)"", null,
+                              ""groupId of a plugin must be defined. "", plugin );
+            }
+
+            if ( plugin.getArtifactId() == null
+                || ( plugin.getArtifactId() != null && plugin.getArtifactId().trim().isEmpty() ) )
+            {
+                addViolation( problems, Severity.FATAL, Version.V20, prefix + "".(groupId:artifactId)"", null,
+                              ""artifactId of a plugin must be defined. "", plugin );
+            }
+
+            // This will catch cases like <version></version> or <version/>
+            if ( plugin.getVersion() != null && plugin.getVersion().trim().isEmpty() )
+            {
+                addViolation( problems, Severity.FATAL, Version.V20, prefix + "".(groupId:artifactId)"", null,
+                              ""version of a plugin must be defined. "", plugin );
+            }
+
             String key = plugin.getKey();
 
             Plugin existing = index.get( key );
@@ -279,9 +300,9 @@ private void validate20RawPlugins( ModelProblemCollector problems, List<Plugin>
             {
                 if ( !executionIds.add( exec.getId() ) )
                 {
-                    addViolation( problems, Severity.ERROR, Version.V20, prefix + ""["" + plugin.getKey()
-                        + ""].executions.execution.id"", null, ""must be unique but found duplicate execution with id ""
-                        + exec.getId(), exec );
+                    addViolation( problems, Severity.ERROR, Version.V20,
+                                  prefix + ""["" + plugin.getKey() + ""].executions.execution.id"", null,
+                                  ""must be unique but found duplicate execution with id "" + exec.getId(), exec );
                 }
             }
         }
@@ -302,9 +323,8 @@ public void validateEffectiveModel( Model m, ModelBuildingRequest request, Model
         {
             if ( !""pom"".equals( m.getPackaging() ) )
             {
-                addViolation( problems, Severity.ERROR, Version.BASE, ""packaging"", null,
-                              ""with value '"" + m.getPackaging() + ""' is invalid. Aggregator projects ""
-                                  + ""require 'pom' as packaging."", m );
+                addViolation( problems, Severity.ERROR, Version.BASE, ""packaging"", null, ""with value '""
+                    + m.getPackaging() + ""' is invalid. Aggregator projects "" + ""require 'pom' as packaging."", m );
             }
 
             for ( int i = 0, n = m.getModules().size(); i < n; i++ )
@@ -364,8 +384,8 @@ public void validateEffectiveModel( Model m, ModelBuildingRequest request, Model
                     validate20PluginVersion( ""build.plugins.plugin.version"", problems, p.getVersion(), p.getKey(), p,
                                              request );
 
-",Confusing error message in case of missing / empty .,"Here's a possible commit message based on the provided diff:

""Improve plugin version resolution and validation in Maven core and model builder""

This commit message is short and to the point, summarizing the main changes made in the commit. It doesn't go into too much detail, but it gives a general idea of what the commit is about.","The commit message should be:

""Fix plugin version resolution and model validation issues""

This commit message is concise and accurately reflects the changes made in the commit. It mentions the two main areas of change: plugin version resolution and model validation, which are the two main files affected by the changes.","Refactored import statements and formatted logger messages in LifecyclePluginResolver, DefaultPluginVersionResolver, and DefaultModelValidator classes. Added new validation for modelVersion in DefaultModelValidator.","""Refactor code for better readability and add validation checks for plugin definitions and model versions.""",Model 3
"diff --git a/netty/src/main/java/io/grpc/netty/GrpcSslContexts.java b/netty/src/main/java/io/grpc/netty/GrpcSslContexts.java
index a39925619..d87615fb3 100644
--- a/netty/src/main/java/io/grpc/netty/GrpcSslContexts.java
+++ b/netty/src/main/java/io/grpc/netty/GrpcSslContexts.java
@@ -33,6 +33,7 @@ package io.grpc.netty;
 
 import static com.google.common.base.Preconditions.checkArgument;
 
+import com.google.errorprone.annotations.CanIgnoreReturnValue;
 import io.grpc.ExperimentalApi;
 import io.netty.handler.codec.http2.Http2SecurityUtil;
 import io.netty.handler.ssl.ApplicationProtocolConfig;
@@ -133,6 +134,7 @@ public class GrpcSslContexts {
    * Set ciphers and APN appropriate for gRPC. Precisely what is set is permitted to change, so if
    * an application requires particular settings it should override the options set here.
    */
+  @CanIgnoreReturnValue
   public static SslContextBuilder configure(SslContextBuilder builder) {
     return configure(builder, defaultSslProvider());
   }
@@ -142,6 +144,7 @@ public class GrpcSslContexts {
    * an application requires particular settings it should override the options set here.
    */
   @ExperimentalApi(""https://github.com/grpc/grpc-java/issues/1784"")
+  @CanIgnoreReturnValue
   public static SslContextBuilder configure(SslContextBuilder builder, SslProvider provider) {
     return builder.sslProvider(provider)
                   .ciphers(Http2SecurityUtil.CIPHERS, SupportedCipherSuiteFilter.INSTANCE)
diff --git a/netty/src/main/java/io/grpc/netty/NettyChannelBuilder.java b/netty/src/main/java/io/grpc/netty/NettyChannelBuilder.java
index aec7b0f7e..a0fb0733d 100644
--- a/netty/src/main/java/io/grpc/netty/NettyChannelBuilder.java
+++ b/netty/src/main/java/io/grpc/netty/NettyChannelBuilder.java
@@ -39,6 +39,7 @@ import static io.grpc.internal.GrpcUtil.DEFAULT_KEEPALIVE_TIMEOUT_NANOS;
 
 import com.google.common.annotations.VisibleForTesting;
 import com.google.common.base.Preconditions;
+import com.google.errorprone.annotations.CanIgnoreReturnValue;
 import io.grpc.Attributes;
 import io.grpc.ExperimentalApi;
 import io.grpc.NameResolver;
@@ -57,6 +58,7 @@ import java.net.SocketAddress;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.concurrent.TimeUnit;
+import javax.annotation.CheckReturnValue;
 import javax.annotation.Nullable;
 import javax.net.ssl.SSLException;
 
@@ -64,6 +66,7 @@ import javax.net.ssl.SSLException;
  * A builder to help simplify construction of channels using the Netty transport.
  */
 @ExperimentalApi(""https://github.com/grpc/grpc-java/issues/1784"")
+@CanIgnoreReturnValue
 public final class NettyChannelBuilder
     extends AbstractManagedChannelImplBuilder<NettyChannelBuilder> {
   public static final int DEFAULT_FLOW_CONTROL_WINDOW = 1048576; // 1MiB
@@ -91,6 +94,7 @@ public final class NettyChannelBuilder
    * generally be preferred over this method, since that API permits delaying DNS lookups and
    * noticing changes to DNS.
    */
+  @CheckReturnValue
   public static NettyChannelBuilder forAddress(SocketAddress serverAddress) {
     return new NettyChannelBuilder(serverAddress);
   }
@@ -98,6 +102,7 @@ public final class NettyChannelBuilder
   /**
    * Creates a new builder with the given host and port.
    */
+  @CheckReturnValue
   public static NettyChannelBuilder forAddress(String host, int port) {
     return new NettyChannelBuilder(host, port);
   }
@@ -106,22 +111,27 @@ public final class NettyChannelBuilder
    * Creates a new builder with the given target string that will be resolved by
    * {@link io.grpc.NameResolver}.
    */
+  @CheckReturnValue
   public static NettyChannelBuilder forTarget(String target) {
     return new NettyChannelBuilder(target);
   }
 
+  @CheckReturnValue
   NettyChannelBuilder(String host, int port) {
     this(GrpcUtil.authorityFromHostAndPort(host, port));
   }
 
+  @CheckReturnValue
   NettyChannelBuilder(String target) {
     super(target);
   }
 
+  @CheckReturnValue
   NettyChannelBuilder(SocketAddress address) {
     super(address, getAuthorityFromAddress(address));
   }
 
+  @CheckReturnValue
   private static String getAuthorityFromAddress(SocketAddress address) {
     if (address instanceof InetSocketAddress) {
       InetSocketAddress inetAddress = (InetSocketAddress) address;
@@ -258,6 +268,7 @@ public final class NettyChannelBuilder
   }
 
   @Override
+  @CheckReturnValue
   protected ClientTransportFactory buildTransportFactory() {
     return new NettyTransportFactory(dynamicParamsFactory, channelType, channelOptions,
         negotiationType, sslContext, eventLoopGroup, flowControlWindow, maxInboundMessageSize(),
@@ -265,6 +276,7 @@ public final class NettyChannelBuilder
   }
 
   @Override
+  @CheckReturnValue
   protected Attributes getNameResolverParams() {
     int defaultPort;
     switch (negotiationType) {
@@ -287,6 +299,7 @@ public final class NettyChannelBuilder
   }
 
   @VisibleForTesting
+  @CheckReturnValue
   static ProtocolNegotiator createProtocolNegotiator(
       String authority,
       NegotiationType negotiationType,
@@ -306,6 +319,7 @@ public final class NettyChannelBuilder
     return negotiator;
   }
 
+  @CheckReturnValue
   private static ProtocolNegotiator createProtocolNegotiatorByType(
       String authority,
       NegotiationType negotiationType,
@@ -329,11 +343,13 @@ public final class NettyChannelBuilder
     }
   }
 
+  @CheckReturnValue
   interface OverrideAuthorityChecker {
     String checkAuthority(String authority);
   }
 
   @Override
+  @CheckReturnValue
   protected String checkAuthority(String authority) {
     if (authorityChecker != null) {
       return authorityChecker.checkAuthority(authority);
@@ -346,10 +362,12 @@ public final class NettyChannelBuilder
   }
 
   interface TransportCreationParamsFilterFactory {
+    @CheckReturnValue
     TransportCreationParamsFilter create(
         SocketAddress targetServerAddress, String authority, @Nullable String userAgent);
   }
 
+  @CheckReturnValue
   interface TransportCreationParamsFilter {
     SocketAddress getTargetServerAddress();
 
@@ -363,6 +381,7 @@ public final class NettyChannelBuilder
   /**
    * Creates Netty transports. Exposed for internal use, as it should be private.
    */
+  @CheckReturnValue
   private static final class NettyTransportFactory implements ClientTransportFactory {
     private final TransportCreationParamsFilterFactory transportCreationParamsFilterFactory;
     private final Class<? extends Channel> channelType;
@@ -446,6 +465,7 @@ public final class NettyChannelBuilder
       }
     }
 
+    @CheckReturnValue
     private final class DynamicNettyTransportParams implements TransportCreationParamsFilter {
 
       private final SocketAddress targetServerAddress;
diff --git a/netty/src/main/java/io/grpc/netty/NettyServerBuilder.java b/netty/src/main/java/io/grpc/netty/NettyServerBuilder.java
index 3b8739fb1..fae56650d 100644
--- a/netty/src/main/java/io/grpc/netty/NettyServerBuilder.java
+++ b/netty/src/main/java/io/grpc/netty/NettyServerBuilder.java
@@ -35,6 +35,7 @@ import static com.google.common.base.Preconditions.checkArgument;
 import static io.grpc.internal.GrpcUtil.DEFAULT_MAX_MESSAGE_SIZE;
 
 import com.google.common.base.Preconditions;
+import com.google.errorprone.annotations.CanIgnoreReturnValue;
 import io.grpc.ExperimentalApi;
 import io.grpc.Internal;
 import io.grpc.internal.AbstractServerImplBuilder;
@@ -46,6 +47,7 @@ import io.netty.handler.ssl.SslContext;
 import java.io.File;
 import java.net.InetSocketAddress;
 import java.net.SocketAddress;
+import javax.annotation.CheckReturnValue;
 import javax.annotation.Nullable;
 import javax.net.ssl.SSLException;
 
@@ -53,6 +55,7 @@ import javax.net.ssl.SSLException;
  * A builder to help simplify the construction of a Netty-based GRPC server.
  */
 @ExperimentalApi(""https://github.com/grpc/grpc-java/issues/1784"")
+@CanIgnoreReturnValue
 public final class NettyServerBuilder extends AbstractServerImplBuilder<NettyServerBuilder> {
   public static final int DEFAULT_FLOW_CONTROL_WINDOW = 1048576; // 1MiB
 
@@ -75,6 +78,7 @@ public final class NettyServerBuilder extends AbstractServerImplBuilder<NettySer
    * @param port the port on which the server is to be bound.
    * @return the server builder.
    */
+  @CheckReturnValue
   public static NettyServerBuilder forPort(int port) {
     return new NettyServerBuilder(port);
   }
@@ -85,14 +89,17 @@ public final class NettyServerBuilder extends AbstractServerImplBuilder<NettySer
    * @param address the socket address on which the server is to be bound.
    * @return the server builder
    */
+  @CheckReturnValue
   public static NettyServerBuilder forAddress(SocketAddress address) {
     return new NettyServerBuilder(address);
   }
 
+  @CheckReturnValue
   private NettyServerBuilder(int port) {
     this.address = new InetSocketAddress(port);
   }
 
+  @CheckReturnValue
   private NettyServerBuilder(SocketAddress address) {
     this.address = address;
   }
@@ -221,6 +228,7 @@ public final class NettyServerBuilder extends AbstractServerImplBuilder<NettySer
   }
 
   @Override
+  @CheckReturnValue
   protected NettyServer buildTransportServer() {
     ProtocolNegotiator negotiator = protocolNegotiator;
     if (negotiator == null) {
diff --git a/netty/src/main/java/io/grpc/netty/WriteQueue.java b/netty/src/main/java/io/grpc/netty/WriteQueue.java
index f909feb83..2b3f77e6c 100644
--- a/netty/src/main/java/io/grpc/netty/WriteQueue.java
+++ b/netty/src/main/java/io/grpc/netty/WriteQueue.java
@@ -33,6 +33,7 @@ package io.grpc.netty;
 
 import com.google.common.annotations.VisibleForTesting;
 import com.google.common.base.Preconditions;
+import com.google.errorprone.annotations.CanIgnoreReturnValue;
 import io.netty.channel.Channel;
 import io.netty.channel.ChannelFuture;
 import io.netty.channel.ChannelPromise;
@@ -87,6 +88,7 @@ class WriteQueue {
    * @param flush true if a flush of the write should be schedule, false if a later call to
    *              enqueue will schedule the flush.
    */
+  @CanIgnoreReturnValue
   ChannelFuture enqueue(QueuedCommand command, boolean flush) {
     return enqueue(command, channel.newPromise(), flush);
   }
@@ -99,6 +101,7 @@ class WriteQueue {
    * @param flush true if a flush of the write should be schedule, false if a later call to
    *              enqueue will schedule the flush.
    */
+  @CanIgnoreReturnValue
   ChannelFuture enqueue(QueuedCommand command, ChannelPromise promise, boolean flush) {
     // Detect erroneous code that tries to reuse command objects.
     Preconditions.checkArgument(command.promise() == null, ""promise must not be set on command"");
diff --git a/netty/src/main/java/io/grpc/netty/package-info.java b/netty/src/main/java/io/grpc/netty/package-info.java
index da4e374c1..cc7805e07 100644
--- a/netty/src/main/java/io/grpc/netty/package-info.java
+++ b/netty/src/main/java/io/grpc/netty/package-info.java
@@ -33,4 +33,5 @@
  * The main transport implementation based on <a target=""_blank"" href=""http://netty.io"">Netty</a>,
  * for both the client and the server.
  */
+@javax.annotation.CheckReturnValue
 package io.grpc.netty;
diff --git a/netty/src/test/java/io/grpc/netty/NettyClientHandlerTest.java b/netty/src/test/java/io/grpc/netty/NettyClientHandlerTest.java
index df6260e59..5ccdd90ce 100644
--- a/netty/src/test/java/io/grpc/netty/NettyClientHandlerTest.java
+++ b/netty/src/test/java/io/grpc/netty/NettyClientHandlerTest.java
@@ -60,6 +60,7 @@ import com.google.common.base.Ticker;
 import com.google.common.collect.ImmutableList;
 import com.google.common.io.ByteStreams;
 import com.google.common.util.concurrent.MoreExecutors;
+import com.google.errorprone.annotations.CanIgnoreReturnValue;
 import io.grpc.Metadata;
 import io.grpc.Status;
 import io.grpc.StatusException;
@@ -536,6 +537,7 @@ public class NettyClientHandlerTest extends NettyHandlerTestBase<NettyClientHand
     createStream();
   }
 
+  @CanIgnoreReturnValue
   private ChannelFuture sendPing(PingCallback callback) {
     return enqueue(new SendPingCommand(callback, MoreExecutors.directExecutor()));
   }
@@ -545,11 +547,13 @@ public class NettyClientHandlerTest extends NettyHandlerTestBase<NettyClientHand
     channelRead(serializedSettings);
   }
 
+  @CanIgnoreReturnValue
   private ChannelFuture createStream() throws Exception {
     ChannelFuture future = enqueue(new CreateStreamCommand(grpcHeaders, streamTransportState));
     return future;
   }
 
+  @CanIgnoreReturnValue
   private ChannelFuture cancelStream(Status status) throws Exception {
     return enqueue(new CancelClientStreamCommand(streamTransportState, status));
   }
diff --git a/netty/src/test/java/io/grpc/netty/NettyClientTransportTest.java b/netty/src/test/java/io/grpc/netty/NettyClientTransportTest.java
index e99fa859d..f2b4fc4d8 100644
--- a/netty/src/test/java/io/grpc/netty/NettyClientTransportTest.java
+++ b/netty/src/test/java/io/grpc/netty/NettyClientTransportTest.java
@@ -145,7 +145,7 @@ public class NettyClientTransportTest {
   public void addDefaultUserAgent() throws Exception {
     startServer();
     NettyClientTransport transport = newTransport(newNegotiator());
-    transport.start(clientTransportListener);
+    callMeMaybe(transport.start(clientTransportListener));
 
     // Send a single RPC and wait for the response.
     new Rpc(transport).halfClose().waitForResponse();
@@ -169,7 +169,7 @@ public class NettyClientTransportTest {
         DEFAULT_WINDOW_SIZE, DEFAULT_MAX_MESSAGE_SIZE, GrpcUtil.DEFAULT_MAX_HEADER_LIST_SIZE,
         authority, null /* user agent */);
     transports.add(transport);
-    transport.start(clientTransportListener);
+    callMeMaybe(transport.start(clientTransportListener));
 
     // verify SO_LINGER has been set
     ChannelConfig config = transport.channel().config();
@@ -182,7 +182,7 @@ public class NettyClientTransportTest {
     startServer();
     NettyClientTransport transport = newTransport(newNegotiator(),
         DEFAULT_MAX_MESSAGE_SIZE, GrpcUtil.DEFAULT_MAX_HEADER_LIST_SIZE, ""testUserAgent"");
-    transport.start(clientTransportListener);
+    callMeMaybe(transport.start(clientTransportListener));
 
     new Rpc(transport, new Metadata()).halfClose().waitForResponse();
 
@@ -199,7 +199,7 @@ public class NettyClientTransportTest {
     // Allow the response payloads of up to 1 byte.
     NettyClientTransport transport = newTransport(newNegotiator(),
         1, GrpcUtil.DEFAULT_MAX_HEADER_LIST_SIZE, null);
-    transport.start(clientTransportListener);
+    callMeMaybe(transport.start(clientTransportListener));
 
     try {
       // Send a single RPC and wait for the response.
@@ -224,7 +224,7 @@ public class NettyClientTransportTest {
     ProtocolNegotiator negotiator = newNegotiator();
     for (int index = 0; index < 2; ++index) {
       NettyClientTransport transport = newTransport(negotiator);
-      transport.start(clientTransportListener);
+      callMeMaybe(transport.start(clientTransportListener));
     }
 
     // Send a single RPC on each transport.
@@ -245,7 +245,7 @@ public class NettyClientTransportTest {
     startServer(1, GrpcUtil.DEFAULT_MAX_HEADER_LIST_SIZE);
 
     NettyClientTransport transport = newTransport(newNegotiator());
-    transport.start(clientTransportListener);
+    callMeMaybe(transport.start(clientTransportListener));
 
     // Send a dummy RPC in order to ensure that the updated SETTINGS_MAX_CONCURRENT_STREAMS
     // has been received by the remote endpoint.
@@ -281,7 +281,7 @@ public class NettyClientTransportTest {
 
     NettyClientTransport transport =
         newTransport(newNegotiator(), DEFAULT_MAX_MESSAGE_SIZE, 1, null);
-    transport.start(clientTransportListener);
+    callMeMaybe(transport.start(clientTransportListener));
 
     try {
       // Send a single RPC and wait for the response.
@@ -300,7 +300,7 @@ public class NettyClientTransportTest {
     startServer(100, 1);
 
     NettyClientTransport transport = newTransport(newNegotiator());
-    transport.start(clientTransportListener);
+    callMeMaybe(transport.start(clientTransportListener));
 
     try {
       // Send a single RPC and wait for the response.
@@ -338,7 +338,7 @@ public class NettyClientTransportTest {
   public void clientStreamGetsAttributes() throws Exception {
     startServer();
     NettyClientTransport transport = newTransport(newNegotiator());
-    transport.start(clientTransportListener);
+    callMeMaybe(transport.start(clientTransportListener));
     Rpc rpc = new Rpc(transport).halfClose();
     rpc.waitForResponse();
 
@@ -392,6 +392,12 @@ public class NettyClientTransportTest {
     authority = GrpcUtil.authorityFromHostAndPort(address.getHostString(), address.getPort());
   }
 
+  private void callMeMaybe(Runnable r) {
+    if (r != null) {
+      r.run();
+    }
+  }
+
   private static class Rpc {
     static final String MESSAGE = ""hello"";
     static final MethodDescriptor<String, String> METHOD =
diff --git a/netty/src/test/java/io/grpc/netty/NettyHandlerTestBase.java b/netty/src/test/java/io/grpc/netty/NettyHandlerTestBase.java
index 8a82c38b0..a16db1413 100644
--- a/netty/src/test/java/io/grpc/netty/NettyHandlerTestBase.java
+++ b/netty/src/test/java/io/grpc/netty/NettyHandlerTestBase.java
@@ -39,6 +39,7 @@ import static org.mockito.Mockito.spy;
 import static org.mockito.Mockito.verify;
 import static org.mockito.Mockito.when;
 
+import com.google.errorprone.annotations.CanIgnoreReturnValue;
 import io.grpc.internal.MessageFramer;
 import io.grpc.internal.StatsTraceContext;
 import io.grpc.internal.WritableBuffer;
@@ -221,6 +222,7 @@ public abstract class NettyHandlerTestBase<T extends Http2ConnectionHandler> {
     return handler().connection();
   }
 
+  @CanIgnoreReturnValue
   protected final ChannelFuture enqueue(WriteQueue.QueuedCommand command) {
     ChannelFuture future = writeQueue.enqueue(command, newPromise(), true);
     channel.runPendingTasks();",add return value errorprone annotations,"""Added @CanIgnoreReturnValue and @CheckReturnValue annotations to methods in Netty transport classes""","The commit message should be:

""Add @CheckReturnValue and @CanIgnoreReturnValue annotations""

This commit message accurately reflects the changes made in the diff, which is the addition of these two annotations to various methods in the codebase.","The commit message could be: ""Add @CanIgnoreReturnValue annotation to appropriate methods in GrpcSslContexts, NettyChannelBuilder, NettyServerBuilder, WriteQueue, NettyClientHandlerTest, and NettyHandlerTestBase."" This annotation is used to indicate that it's safe to ignore the result of a method, which can help static analysis tools like Error Prone detect potential issues in the code.",Added `@CanIgnoreReturnValue` and `@CheckReturnValue` annotations for improved return value handling in gRPC Netty transport classes.,Model 1
"diff --git a/language-server/modules/langserver-compiler/src/test/resources/testng.xml b/language-server/modules/langserver-compiler/src/test/resources/testng.xml
index b673d226d12..e6d67a90c3a 100644
--- a/language-server/modules/langserver-compiler/src/test/resources/testng.xml
+++ b/language-server/modules/langserver-compiler/src/test/resources/testng.xml
@@ -27,7 +27,7 @@ under the License.
             </run>
         </groups>
         <packages>
-            <package name=""org.ballerinalang.langserver.compiler.*""/>
+            <!--<package name=""org.ballerinalang.langserver.compiler.*""/>-->
         </packages>
     </test>
 </suite>
diff --git a/language-server/modules/langserver-core/pom.xml b/language-server/modules/langserver-core/pom.xml
index f68a8c1f8bb..8e3d9514eb6 100644
--- a/language-server/modules/langserver-core/pom.xml
+++ b/language-server/modules/langserver-core/pom.xml
@@ -114,6 +114,14 @@
             <type>zip</type>
             <classifier>ballerina-binary-repo</classifier>
         </dependency>
+        <dependency>
+            <groupId>com.fasterxml.jackson.core</groupId>
+            <artifactId>jackson-databind</artifactId>
+        </dependency>
+        <dependency>
+            <groupId>com.fasterxml.jackson.dataformat</groupId>
+            <artifactId>jackson-dataformat-yaml</artifactId>
+        </dependency>
     </dependencies>
 
     <build>
diff --git a/language-server/modules/langserver-core/spotbugs-exclude.xml b/language-server/modules/langserver-core/spotbugs-exclude.xml
index 89d0595ddda..3ecf338c9c0 100644
--- a/language-server/modules/langserver-core/spotbugs-exclude.xml
+++ b/language-server/modules/langserver-core/spotbugs-exclude.xml
@@ -76,4 +76,10 @@
             <Bug pattern=""RV_RETURN_VALUE_IGNORED_BAD_PRACTICE"" />
         </OR>
     </Match>
+    <Match>
+        <Class name=""org.ballerinalang.langserver.extensions.ballerina.document.BallerinaDocumentServiceImpl"" />
+    </Match>
+    <Match>
+        <Class name=""org.ballerinalang.langserver.extensions.ballerina.document.BallerinaServiceListResponse"" />
+    </Match>
 </FindBugsFilter>
\ No newline at end of file
diff --git a/language-server/modules/langserver-core/src/test/resources/testng.xml b/language-server/modules/langserver-core/src/test/resources/testng.xml
index 34999820466..e6630d827f2 100644
--- a/language-server/modules/langserver-core/src/test/resources/testng.xml
+++ b/language-server/modules/langserver-core/src/test/resources/testng.xml
@@ -27,7 +27,7 @@ under the License.
             </run>
         </groups>
         <packages>
-            <package name=""org.ballerinalang.langserver.*""/>
+            <!--<package name=""org.ballerinalang.langserver.*""/>-->
         </packages>
     </test>
 </suite>",Disable language server tests temporarily,"""Update test configurations and add Jackson dependencies""

This commit message is short and to the point, indicating that the commit involves changes to test configurations (as seen in the testng.xml files) and the addition of Jackson dependencies (as seen in the pom.xml file).","Based on the provided diff, a suitable commit message could be:

""Update dependencies and exclude classes from spotbugs analysis""

This commit message accurately reflects the changes made in the commit, which include adding new dependencies and excluding certain classes from spotbugs analysis.","""Update language-server dependencies and exclude classes from SpotBugs filter""

Explanation:

* In `language-server/modules/langserver-compiler/src/test/resources/testng.xml`, the package `org.ballerinalang.langserver.compiler.*` has been commented out from the testng.xml file.
* In `language-server/modules/langserver-core/pom.xml`, two new dependencies have been added: `com.fasterxml.jackson.core:jackson-databind` and `com.fasterxml.jackson.dataformat:jackson-dataformat-yaml`.
* In `language-server/modules/langserver-core/spotbugs-exclude.xml`, two new classes have been added to the SpotBugs filter: `org.ballerinalang.langserver.extensions.ballerina.document.BallerinaDocumentServiceImpl` and `org.ballerinalang.langserver.extensions.ballerina.document.BallerinaServiceListResponse`.
* In `language-server/modules/langserver-core/src/test/resources/testng.xml`, the package `org.ballerinalang.langserver.*` has been commented out from the testng.xml file.",Updated dependencies and excluded packages from testing and SpotBugs analysis in language-server modules.,Model 3
"diff --git a/bvm/ballerina-core/src/main/java/org/ballerinalang/model/values/BValueArray.java b/bvm/ballerina-core/src/main/java/org/ballerinalang/model/values/BValueArray.java
index 58eb9fe6be7..f3428239ddc 100644
--- a/bvm/ballerina-core/src/main/java/org/ballerinalang/model/values/BValueArray.java
+++ b/bvm/ballerina-core/src/main/java/org/ballerinalang/model/values/BValueArray.java
@@ -167,6 +167,9 @@ public class BValueArray extends BNewArray implements Serializable {
         } else if (type.getTag() == TypeTags.STRING_TAG) {
             stringValues = (String[]) newArrayInstance(String.class);
             Arrays.fill(stringValues, BLangConstants.STRING_EMPTY_VALUE);
+        } else {
+            refValues = (BRefType[]) newArrayInstance(BRefType.class);
+            Arrays.fill(refValues, type.getZeroValue());
         }
 
         super.arrayType = new BArrayType(type, size);",Handle refvalue in else block,"""Added support for initializing arrays of reference types with zero values""","""Added support for initializing array with default values for non-primitive types""","""Added initialization for reference type arrays in BValueArray""

This commit adds a new branch to the if-else statement in the constructor of the `BValueArray` class. If the type of the elements in the array is a reference type (i.e., `type.getTag()` does not match `TypeTags.BOOLEAN_TAG`, `TypeTags.INT_TAG`, `TypeTags.FLOAT_TAG`, or `TypeTags.STRING_TAG`), then it creates a new array of `BRefType` objects and fills it with the zero value for the element type. This ensures that reference type arrays are properly initialized.","Initialize `refValues` in `BValueArray` for types other than integer and string, and fill with zero values.",Model 3
"diff --git a/xdocs/changes.xml b/xdocs/changes.xml
index a47baf5e71..8975cae401 100644
--- a/xdocs/changes.xml
+++ b/xdocs/changes.xml
@@ -81,6 +81,8 @@ citizen in JMeter, you can now test your expressions very easily</h4>
 <figure width=""573"" height=""444"" image=""changes/2.10/06_http_request_delete_method.png""></figure>
 </p>
 
+<h4>* Best-practices section has been improved, ensure you read it to get the most out of JMeter</h4>
+
 <h3><u>GUI and ergonomy Improvements:</u></h3>
 
 ",Add section .,"""Update changes.xml to include best-practices section improvements""",Improved changes.xml with new best-practices section and GUI improvements,"The commit message should be:

 ""Added a new section to best-practices in JMeter documentation and improved the existing one to ensure users get the most out of JMeter""","""Improved best-practices section in JMeter documentation for optimized usage.""",Model 3
"diff --git a/presto-main/src/main/java/com/facebook/presto/execution/QueryManagerConfig.java b/presto-main/src/main/java/com/facebook/presto/execution/QueryManagerConfig.java
index 493ceffa29..1192b3b75f 100644
--- a/presto-main/src/main/java/com/facebook/presto/execution/QueryManagerConfig.java
+++ b/presto-main/src/main/java/com/facebook/presto/execution/QueryManagerConfig.java
@@ -46,6 +46,20 @@ public class QueryManagerConfig
     private int remoteTaskMaxConsecutiveErrorCount = 10;
     private Duration remoteTaskMinErrorDuration = new Duration(2, TimeUnit.MINUTES);
 
+    private boolean taskCpuTimerEnabled = true;
+
+    public boolean isTaskCpuTimerEnabled()
+    {
+        return taskCpuTimerEnabled;
+    }
+
+    @Config(""task.cpu-timer-enabled"")
+    public QueryManagerConfig setTaskCpuTimerEnabled(boolean taskCpuTimerEnabled)
+    {
+        this.taskCpuTimerEnabled = taskCpuTimerEnabled;
+        return this;
+    }
+
     public boolean isCoordinator()
     {
         return coordinator;
diff --git a/presto-main/src/main/java/com/facebook/presto/execution/SqlTaskExecution.java b/presto-main/src/main/java/com/facebook/presto/execution/SqlTaskExecution.java
index de1800365f..8474ea1a13 100644
--- a/presto-main/src/main/java/com/facebook/presto/execution/SqlTaskExecution.java
+++ b/presto-main/src/main/java/com/facebook/presto/execution/SqlTaskExecution.java
@@ -118,7 +118,8 @@ public class SqlTaskExecution
             ExecutorService notificationExecutor,
             DataSize maxTaskMemoryUsage,
             DataSize operatorPreAllocatedMemory,
-            QueryMonitor queryMonitor)
+            QueryMonitor queryMonitor,
+            boolean cpuTimerEnabled)
     {
         SqlTaskExecution task = new SqlTaskExecution(session,
                 taskId,
@@ -130,7 +131,8 @@ public class SqlTaskExecution
                 maxTaskMemoryUsage,
                 operatorPreAllocatedMemory,
                 queryMonitor,
-                notificationExecutor
+                notificationExecutor,
+                cpuTimerEnabled
         );
 
         try (SetThreadName setThreadName = new SetThreadName(""Task-%s"", taskId)) {
@@ -149,7 +151,8 @@ public class SqlTaskExecution
             DataSize maxTaskMemoryUsage,
             DataSize operatorPreAllocatedMemory,
             QueryMonitor queryMonitor,
-            Executor notificationExecutor)
+            Executor notificationExecutor,
+            boolean cpuTimerEnabled)
     {
         try (SetThreadName setThreadName = new SetThreadName(""Task-%s"", taskId)) {
             this.taskId = checkNotNull(taskId, ""taskId is null"");
@@ -173,7 +176,7 @@ public class SqlTaskExecution
                     session,
                     checkNotNull(maxTaskMemoryUsage, ""maxTaskMemoryUsage is null""),
                     checkNotNull(operatorPreAllocatedMemory, ""operatorPreAllocatedMemory is null""),
-                    true);
+                    cpuTimerEnabled);
 
             this.sharedBuffer = new SharedBuffer(checkNotNull(maxBufferSize, ""maxBufferSize is null""));
 
diff --git a/presto-main/src/main/java/com/facebook/presto/execution/SqlTaskManager.java b/presto-main/src/main/java/com/facebook/presto/execution/SqlTaskManager.java
index 763c912387..7f8ee8b240 100644
--- a/presto-main/src/main/java/com/facebook/presto/execution/SqlTaskManager.java
+++ b/presto-main/src/main/java/com/facebook/presto/execution/SqlTaskManager.java
@@ -80,6 +80,7 @@ public class SqlTaskManager
     private final DataSize operatorPreAllocatedMemory;
     private final Duration infoCacheTime;
     private final Duration clientTimeout;
+    private final boolean cpuTimerEnabled;
 
     private final ConcurrentMap<TaskId, TaskInfo> taskInfos = new ConcurrentHashMap<>();
     private final ConcurrentMap<TaskId, TaskExecution> tasks = new ConcurrentHashMap<>();
@@ -115,6 +116,7 @@ public class SqlTaskManager
         this.operatorPreAllocatedMemory = config.getOperatorPreAllocatedMemory();
         this.infoCacheTime = config.getInfoMaxAge();
         this.clientTimeout = config.getClientTimeout();
+        this.cpuTimerEnabled = config.isTaskCpuTimerEnabled();
 
         taskNotificationExecutor = Executors.newCachedThreadPool(threadsNamed(""task-notification-%d""));
         taskNotificationExecutorMBean = new ThreadPoolExecutorMBean((ThreadPoolExecutor) taskNotificationExecutor);
@@ -304,7 +306,8 @@ public class SqlTaskManager
                         taskNotificationExecutor,
                         maxTaskMemoryUsage,
                         operatorPreAllocatedMemory,
-                        queryMonitor
+                        queryMonitor,
+                        cpuTimerEnabled
                 );
                 tasks.put(taskId, taskExecution);
             }
@@ -389,7 +392,7 @@ public class SqlTaskManager
 ",Make cpu time tracking in OperatorStats configurable with .,"""Add configuration option to enable/disable CPU timer for tasks""","""Added task CPU timer configuration and enabled it by default""

This commit message accurately summarizes the changes made in the commit, which include adding a new configuration option for task CPU timer and enabling it by default.",This commit adds a new configuration option `task.cpu-timer-enabled` to the `QueryManagerConfig` class in Presto. The option controls whether the CPU timer is enabled for tasks. The default value is `true`. The `SqlTaskExecution` and `SqlTaskManager` classes have been updated to accept and use this new configuration option.,Add a configuration option to enable/disable the CPU timer in SQL task execution.,Model 2
"diff --git a/src/main/java/com/xtremelabs/robolectric/shadows/ShadowHandler.java b/src/main/java/com/xtremelabs/robolectric/shadows/ShadowHandler.java
index edc74343d..4c00d9727 100644
--- a/src/main/java/com/xtremelabs/robolectric/shadows/ShadowHandler.java
+++ b/src/main/java/com/xtremelabs/robolectric/shadows/ShadowHandler.java
@@ -18,7 +18,8 @@ import static com.xtremelabs.robolectric.Robolectric.shadowOf;
 @SuppressWarnings({""UnusedDeclaration""})
 @Implements(Handler.class)
 public class ShadowHandler {
-    @RealObject private Handler realHandler;
+    @RealObject
+    private Handler realHandler;
 
     private Looper looper = Looper.myLooper();
 
@@ -67,6 +68,16 @@ public class ShadowHandler {
         return sendMessage(msg);
     }
 
+    @Implementation
+    public final Looper getLooper() {
+        return looper;
+    }
+
+    @Implementation
+    public final void removeCallbacks(java.lang.Runnable r) {
+        shadowOf(looper).getScheduler().remove(r);
+    }
+
     /**
      * @deprecated use {@link #idleMainLooper()} instead
      */
diff --git a/src/main/java/com/xtremelabs/robolectric/util/Scheduler.java b/src/main/java/com/xtremelabs/robolectric/util/Scheduler.java
index 81c3dd902..548ce6ede 100644
--- a/src/main/java/com/xtremelabs/robolectric/util/Scheduler.java
+++ b/src/main/java/com/xtremelabs/robolectric/util/Scheduler.java
@@ -3,6 +3,7 @@ package com.xtremelabs.robolectric.util;
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
+import java.util.ListIterator;
 
 public class Scheduler {
     private List<PostedRunnable> postedRunnables = new ArrayList<PostedRunnable>();
@@ -36,6 +37,16 @@ public class Scheduler {
         postDelayed(runnable, 0);
     }
 
+    public void remove(Runnable runnable) {
+        ListIterator<PostedRunnable> iterator = postedRunnables.listIterator();
+        while (iterator.hasNext()) {
+            PostedRunnable next = iterator.next();
+            if (next.runnable == runnable) {
+                iterator.remove();
+            }
+        }
+    }
+
     public boolean advanceToLastPostedRunnable() {
         if (enqueuedTaskCount() < 1) {
             return false;
diff --git a/src/test/java/com/xtremelabs/robolectric/shadows/HandlerTest.java b/src/test/java/com/xtremelabs/robolectric/shadows/HandlerTest.java
index abfaa309c..31161c040 100644
--- a/src/test/java/com/xtremelabs/robolectric/shadows/HandlerTest.java
+++ b/src/test/java/com/xtremelabs/robolectric/shadows/HandlerTest.java
@@ -95,6 +95,19 @@ public class HandlerTest {
         assertThat(scratchRunnable.wasRun, equalTo(true));
     }
 
+    @Test
+    public void testRemoveCallbacks() throws Exception {
+        Handler handler = new Handler();
+        ShadowLooper shadowLooper = shadowOf(handler.getLooper());
+        shadowLooper.pause();
+        handler.post(scratchRunnable);
+        handler.removeCallbacks(scratchRunnable);
+
+        shadowLooper.unPause();
+
+        assertThat(scratchRunnable.wasRun, equalTo(false));
+    }
+
     @Test
     public void testPostDelayedThenRunMainLooperToNextTask_shouldRunOneTask() throws Exception {
         new Handler().postDelayed(scratchRunnable, 1);
@@ -146,9 +159,9 @@ public class HandlerTest {
 
     @Test
     public void sendEmptyMessageHandler() {
-        
+
         final Handler handler = new Handler(new Handler.Callback() {
-            
+
             @Override
             public boolean handleMessage(Message message) {
                 throw new UnsupportedOperationException(""Method not implemented"");
diff --git a/src/test/java/com/xtremelabs/robolectric/shadows/LooperTest.java b/src/test/java/com/xtremelabs/robolectric/shadows/LooperTest.java
index 4de9e526e..25664afb0 100644
--- a/src/test/java/com/xtremelabs/robolectric/shadows/LooperTest.java
+++ b/src/test/java/com/xtremelabs/robolectric/shadows/LooperTest.java
@@ -2,7 +2,6 @@ package com.xtremelabs.robolectric.shadows;
 
 import android.os.Handler;
 import android.os.Looper;
-import com.xtremelabs.robolectric.Robolectric;
 import com.xtremelabs.robolectric.WithTestDefaultsRunner;
 import org.junit.Test;
 import org.junit.runner.RunWith;
@@ -21,7 +20,7 @@ public class LooperTest {
 
     @Test
     public void idleMainLooper_executesScheduledTasks() {
-        final boolean[] wasRun = new boolean[] {false};
+        final boolean[] wasRun = new boolean[]{false};
         new Handler().postDelayed(new Runnable() {
             @Override
             public void run() {
diff --git a/src/test/java/com/xtremelabs/robolectric/util/SchedulerTest.java b/src/test/java/com/xtremelabs/robolectric/util/SchedulerTest.java
index 89675ccb0..2ecda5ef5 100644
--- a/src/test/java/com/xtremelabs/robolectric/util/SchedulerTest.java
+++ b/src/test/java/com/xtremelabs/robolectric/util/SchedulerTest.java
@@ -81,6 +81,19 @@ public class SchedulerTest {
         transcript.assertEventsSoFar(""three"");
     }
 
+    @Test
+    public void removeShouldRemoveAllInstancesOfRunnableFromQueue() throws Exception {
+        scheduler.post(new TestRunnable());
+        TestRunnable runnable = new TestRunnable();
+        scheduler.post(runnable);
+        scheduler.post(runnable);
+        assertThat(scheduler.enqueuedTaskCount(), equalTo(3));
+        scheduler.remove(runnable);
+        assertThat(scheduler.enqueuedTaskCount(), equalTo(1));
+        scheduler.advanceToLastPostedRunnable();
+        assertThat(runnable.wasRun, equalTo(false));
+    }
+
     @Test
     public void resetShouldUnPause() throws Exception {
         scheduler.pause();",Implement Handler # removeCallbacks,"""Implement removeCallbacks and getLooper methods in ShadowHandler""","""Implement Looper and Handler removeCallbacks functionality and add test cases for it""","""Added getLooper and removeCallbacks methods to ShadowHandler, updated Scheduler to handle removal of Runnables, and added corresponding tests""

Explanation:

* In ShadowHandler.java, two new methods (getLooper and removeCallbacks) have been added.
* In Scheduler.java, a new method (remove) has been added to handle the removal of Runnables from the postedRunnables list.
* In HandlerTest.java, a new test (testRemoveCallbacks) has been added to test the new removeCallbacks method in ShadowHandler.
* Some minor formatting changes have been made in HandlerTest.java and LooperTest.java.
* In SchedulerTest.java, a new test (removeShouldRemoveAllInstancesOfRunnableFromQueue) has been added to test the new remove method in Scheduler.","""Implemented removeCallbacks in ShadowHandler and added corresponding test cases; enhanced Scheduler to support removal of runnables.""",Model 3
"diff --git a/core/src/processing/core/PConstants.java b/core/src/processing/core/PConstants.java
index 46f5682a7..5d19fbec4 100644
--- a/core/src/processing/core/PConstants.java
+++ b/core/src/processing/core/PConstants.java
@@ -531,9 +531,9 @@ public interface PConstants {
   // hints - hint values are positive for the alternate version,
   // negative of the same value returns to the normal/default state
 
-  static final int DISABLE_OPENGL_2X_SMOOTH    =  1;
-  static final int ENABLE_OPENGL_2X_SMOOTH     = -1;
-  static final int ENABLE_OPENGL_4X_SMOOTH     =  2;
+//  static final int DISABLE_OPENGL_2X_SMOOTH    =  1;
+//  static final int ENABLE_OPENGL_2X_SMOOTH     = -1;
+//  static final int ENABLE_OPENGL_4X_SMOOTH     =  2;
 
   static final int ENABLE_NATIVE_FONTS         =  3;
   static final int DISABLE_NATIVE_FONTS         = -3;",removed opengl multi - sampling constants,"""Remove unused OpenGL smooth hint constants""","""Removed OpenGL 2X and 4X smooth rendering hints""","""Removed constants for disabling and enabling OpenGL 2x and 4x smooth in PConstants.java""",Commented out constants related to OpenGL smoothing in PConstants.java to disable 2X and 4X smoothing options.,Model 3
"diff --git a/htroot/Triple_p.html b/htroot/Triple_p.html
index f00d2cfa4..0765ebd0f 100644
--- a/htroot/Triple_p.html
+++ b/htroot/Triple_p.html
@@ -63,6 +63,15 @@
 	<h2>Query</h2>
 	<form action=""Triple_p.html"" method=""post"" enctype=""multipart/form-data"">
     
+    <textarea name=""query"" cols=""100"" rows=""10"">
+    #[query]#
+    </textarea>
+
+	<input type=""submit"" value=""Query"" />
+	
+	</form>
+	<form action=""Triple_p.csv"" method=""post"" enctype=""multipart/form-data"">
+    
     <textarea name=""query"" cols=""100"" rows=""10"">
     #[query]#
     </textarea>
diff --git a/htroot/Triple_p.java b/htroot/Triple_p.java
index 2662cbf28..c50df2067 100644
--- a/htroot/Triple_p.java
+++ b/htroot/Triple_p.java
@@ -40,13 +40,13 @@ public class Triple_p {
 		prop.put(""display"", 1); // Fixed to 1
 		prop.putHTML(""mode_output"", ""no query performed"");
 		
-		String q = ""PREFIX lln: <http://virtual.liebel-lab.org/n#>\n""+
+		String q = ""PREFIX lln: <http://virtual.x/>\n""+
 ""PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n""+
 ""PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n""+
 ""SELECT ?resource ?pa\n""+
 ""WHERE {\n""+
-	""?resource lln:percentageofarea ?pa .\n""+
-""FILTER (xsd:float (?pa) > 3.000)\n""+
+	""?resource lln:hasvalue ?pa .\n""+
+""FILTER (xsd:float (?pa) > 21.000)\n""+
 ""}"";
 
 		if (post != null) {
@@ -106,17 +106,29 @@ public class Triple_p {
 
 					prop.putHTML(""mode_rdfdump"", sos.toString());
 					
-
+					int scount = 0;
+					while (resultSet.hasNext()) {
+						QuerySolution s = resultSet.next();
+						prop.put(""entries_""+scount+""_s"", s.getResource(null).getURI());
+						prop.put(""entries_""+scount+""_p"", s.getResource(null).getURI());
+						prop.put(""entries_""+scount+""_o"", s.getResource(null).getURI());
+						scount ++;
+					}
 					
+					prop.putHTML(""entries"", """"+scount);
 					
 					for (String s: resultSet.getResultVars()) {
 						
 						prop.putHTML(""mode_output_""+count+""_caption"", s);
 						count ++;
 					}
+								
+					
 					 } catch (Exception e) {
 						 prop.putHTML(""mode_rdfdump"", ""error"");
 					 }
+					 
+					 
 									
 					prop.putHTML(""mode_output"", """"+count);
 
diff --git a/htroot/interaction/OverlayInteraction.html b/htroot/interaction/OverlayInteraction.html
index da7dee359..d3fea7278 100644
--- a/htroot/interaction/OverlayInteraction.html
+++ b/htroot/interaction/OverlayInteraction.html
@@ -52,9 +52,32 @@ border-bottom: 1px solid #ffffff;
 
 </div>
 
-<div id=""sidebar-document"" class=""sci_panel"" style=""top: 110px;"">
+<!-- <div id=""sidebar-document"" class=""sci_panel"" style=""top: 110px;"">
 
-<p>document</p> <img src=""/currentyacypeer/env/grafics/bad.png"" onclick=""contribution (document.location.href, 'like document', '#[username]#'); return false"">
+document <img src=""/currentyacypeer/env/grafics/bad.png"" width=""16px"" height=""16px"" onclick=""contribution (document.location.href, 'like document', '#[username]#'); return false"">
+
+</div> -->
+
+<div id=""sidebar-element"" class=""sci_panel"" style=""top: 110px;"">
+
+<input id=""SliderSingle"" type=""slider"" name=""price"" value=""20"" />
+
+<script type=""text/javascript"" charset=""utf-8"">
+	$(""#SliderSingle"").slider(
+		{
+			from: 0,
+			to: 100,
+			step: 2.5,
+			round: 1,
+			format: { format: '##.0', locale: 'de'},
+			dimension: '&nbsp;',
+			skin: 'round',
+			onstatechange: function(value) {
+				triple ('#[link]#', '#[link]#', 'http://virtual.x/hasvalue', value, '#[username]#');
+				}
+		}
+	);
+</script>
 
 </div>
 
diff --git a/htroot/yacysearchitem.html b/htroot/yacysearchitem.html
index de0086832..82e425ed1 100644
--- a/htroot/yacysearchitem.html
+++ b/htroot/yacysearchitem.html
@@ -2,7 +2,7 @@
   <div class=""searchresults"">
   <h4 class=""linktitle"">
   <img width=""16"" height=""16"" src=""ViewImage.png?width=16&amp;height=16&amp;code=#[faviconCode]#"" id=""f#[urlhash]#"" class=""favicon"" style=""width:16px; height:16px;"" alt="""" />
-  <a href=""#[link]#"" target=""#[target]#"">#[title]#</a></h4>
+  <a href=""#[link]#"" target=""#[target]#"">#[title]#</a> #[value]#</h4>
   <div class=""urlactions"">
     #(heuristic)#::
     <img width=""16"" height=""9"" src=""/env/grafics/heuristic_redundant.gif"" title=""heuristic:#[name]# (redundant)"" style=""width:16px; height:9px;"" alt=""heuristic:#[name]# (redundant)""/>::
diff --git a/htroot/yacysearchitem.java b/htroot/yacysearchitem.java
index 9604d2a5e..3c0f4d665 100644
--- a/htroot/yacysearchitem.java
+++ b/htroot/yacysearchitem.java
@@ -34,6 +34,7 @@ import net.yacy.cora.document.Classification.ContentDomain;
 import net.yacy.cora.protocol.HeaderFramework;
 import net.yacy.cora.protocol.RequestHeader;
 import net.yacy.cora.protocol.RequestHeader.FileType;
+import net.yacy.interaction.Interaction;
 import net.yacy.kelondro.data.meta.DigestURI;
 import net.yacy.kelondro.logging.Log;
 import net.yacy.kelondro.util.Formatter;
@@ -141,8 +142,44 @@ public class yacysearchitem {
             prop.putHTML(""content_title"", result.title());
             prop.putXML(""content_title-xml"", result.title());
             prop.putJSON(""content_title-json"", result.title());
-            prop.putHTML(""content_link"", resultUrlstring);
             prop.putHTML(""content_showPictures_link"", resultUrlstring);
+            //prop.putHTML(""content_link"", resultUrlstring);
+
+// START interaction
+            String modifyURL = resultUrlstring;
+			if (sb.getConfigBool(""proxyURL.useforresults"", false)) {
+				// check if url is allowed to view
+				if (sb.getConfig(""proxyURL.rewriteURLs"", ""all"").equals(""all"")) {
+					modifyURL = ""./proxy.html?url=""+modifyURL;
+				}
+
+				// check if url is allowed to view
+				if (sb.getConfig(""proxyURL.rewriteURLs"", ""all"").equals(""domainlist"")) {
+					try {
+						if (sb.crawlStacker.urlInAcceptedDomain(new DigestURI (modifyURL)) == null) {
+							modifyURL = ""./proxy.html?url=""+modifyURL;
+						}
+					} catch (MalformedURLException e) {
+						// TODO Auto-generated catch block
+						e.printStackTrace();
+					}
+				}
+
+				if (sb.getConfig(""proxyURL.rewriteURLs"", ""all"").equals(""yacy"")) {
+					try {
+						if ((new DigestURI (modifyURL).getHost().endsWith("".yacy""))) {
+							modifyURL = ""./proxy.html?url=""+modifyURL;
+						}
+					} catch (MalformedURLException e) {
+						// TODO Auto-generated catch block
+						e.printStackTrace();
+					}
+				}
+			}
+            prop.putHTML(""content_link"", modifyURL);
+            prop.putHTML(""content_value"", Interaction.getTriple(result.urlstring(), ""http://virtual.x/hasvalue""));
+// END interaction
+
             prop.putHTML(""content_target"", target);
             if (faviconURL != null && fileType == FileType.HTML) sb.loader.loadIfNotExistBackground(faviconURL, 1024 * 1024 * 10);
             prop.putHTML(""content_faviconCode"", sb.licensedURLs.aquireLicense(faviconURL)); // acquire license for favicon url loading
diff --git a/source/net/yacy/interaction/Interaction.java b/source/net/yacy/interaction/Interaction.java
index 285537b50..6bdf0b117 100644
--- a/source/net/yacy/interaction/Interaction.java
+++ b/source/net/yacy/interaction/Interaction.java
@@ -463,6 +463,23 @@ public static String Triple(String url, String s, String p, String o, String fro
 	return """";    
 }
 
+public static String getTriple(String s, String p) {
+
+	final Switchboard sb = Switchboard.getSwitchboard();
+
+	Resource r = TripleStore.model.getResource(s);
+	Property pr = TripleStore.model.getProperty(p);
+	
+	StmtIterator iter = TripleStore.model.listStatements(r, pr, (Resource) null);
+	
+	while (iter.hasNext()) {
+		return (iter.nextStatement().getObject().toString());
+	}
+	
+	return """";
+ 
+}
+
 public static String GetContribution(String url) {
 	
 	final Switchboard sb = Switchboard.getSwitchboard();",include value from interaction in search results .,"""Added interaction features and modified query functionality in Triple_p.html and yacysearchitem.html""","""Added query functionality and interaction elements to Triple_p.html, yacysearchitem.html, and OverlayInteraction.html, and implemented interaction logic in Interaction.java and yacysearchitem.java""","""Add form for query submission and update query prefix in Triple_p.html and Triple_p.java. Update interaction/OverlayInteraction.html to include slider input and yacysearchitem.html and yacysearchitem.java to display search result value. Add getTriple method in Interaction.java.""

Explanation:

* In Triple_p.html, a form for query submission has been added and the query prefix has been updated from ""<http://virtual.liebel-lab.org/n#>"" to ""<http://virtual.x/>"".
* In Triple_p.java, the query prefix has also been updated and a new method ""getTriple"" has been added to the ""Interaction"" class in source/net/yacy/interaction/Interaction.java.
* In interaction/OverlayInteraction.html, a slider input has been added for user interaction.
* In yacysearchitem.html and yacysearchitem.java, changes have been made to display the value of a search result.
* The commit message should summarize all these changes.","""Enhanced triple handling with custom queries, slider interaction, URL modification, and dynamic value display in search results.""",Model 2
"diff --git a/servers/src/main/java/tachyon/worker/block/BlockLockManager.java b/servers/src/main/java/tachyon/worker/block/BlockLockManager.java
index 5f68466571..88f4e7123c 100644
--- a/servers/src/main/java/tachyon/worker/block/BlockLockManager.java
+++ b/servers/src/main/java/tachyon/worker/block/BlockLockManager.java
@@ -4,9 +4,9 @@
  * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
  * ""License""); you may not use this file except in compliance with the License. You may obtain a
  * copy of the License at
- * 
+ *
  * http://www.apache.org/licenses/LICENSE-2.0
- * 
+ *
  * Unless required by applicable law or agreed to in writing, software distributed under the License
  * is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
  * or implied. See the License for the specific language governing permissions and limitations under
diff --git a/servers/src/main/java/tachyon/worker/block/BlockServiceHandler.java b/servers/src/main/java/tachyon/worker/block/BlockServiceHandler.java
index de28f47c74..b30f7fdfdc 100644
--- a/servers/src/main/java/tachyon/worker/block/BlockServiceHandler.java
+++ b/servers/src/main/java/tachyon/worker/block/BlockServiceHandler.java
@@ -22,6 +22,7 @@ import org.apache.thrift.TException;
 
 import tachyon.Users;
 import tachyon.thrift.FileAlreadyExistException;
+import tachyon.thrift.FileDoesNotExistException;
 import tachyon.thrift.OutOfSpaceException;
 import tachyon.thrift.TachyonException;
 import tachyon.thrift.WorkerService;
@@ -233,7 +234,7 @@ public class BlockServiceHandler implements WorkerService.Iface {
       long lockId = mWorker.lockBlock(userId, blockId);
       return mWorker.readBlock(userId, blockId, lockId);
     } catch (IOException ioe) {
-      throw new TException(ioe);
+      throw new FileDoesNotExistException(""Block "" + blockId + "" does not exist on this worker."");
     }
   }
 
@@ -273,7 +274,7 @@ public class BlockServiceHandler implements WorkerService.Iface {
       // TODO: Maybe add a constant for anyTier?
       return mWorker.createBlock(userId, blockId, 1, initialBytes);
     } catch (IOException ioe) {
-      throw new TException(ioe);
+      throw new OutOfSpaceException(""Failed to allocate "" + initialBytes + "" for user "" + userId);
     }
   }
 
@@ -291,7 +292,7 @@ public class BlockServiceHandler implements WorkerService.Iface {
       mWorker.requestSpace(userId, blockId, requestBytes);
       return true;
     } catch (IOException ioe) {
-      throw new TException(ioe);
+      return false;
     }
   }
 
diff --git a/servers/src/main/java/tachyon/worker/block/meta/StorageDir.java b/servers/src/main/java/tachyon/worker/block/meta/StorageDir.java
index 0bc0c67f70..b829aab743 100644
--- a/servers/src/main/java/tachyon/worker/block/meta/StorageDir.java
+++ b/servers/src/main/java/tachyon/worker/block/meta/StorageDir.java
@@ -4,9 +4,9 @@
  * copyright ownership. The ASF licenses this file to You under the Apache License, Version 2.0 (the
  * ""License""); you may not use this file except in compliance with the License. You may obtain a
  * copy of the License at
- * 
+ *
  * http://www.apache.org/licenses/LICENSE-2.0
- * 
+ *
  * Unless required by applicable law or agreed to in writing, software distributed under the License
  * is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
  * or implied. See the License for the specific language governing permissions and limitations under
@@ -257,6 +257,7 @@ public class StorageDir {
           mUserIdToTempBlockIdsMap.remove(userId);
         }
         reclaimSpace(tempBlockMeta.getBlockSize());
+        return;
       }
     }
     throw new IOException(""Failed to remove TempBlockMeta: No owner userId associated"");",Fix some exceptions in block service handler .,"""Improve error handling in BlockServiceHandler and StorageDir""

This commit message is short and to the point, indicating that the changes made were related to improving error handling in the specified classes.","""Improved error handling in BlockServiceHandler and StorageDir classes""","""Update copyright headers and add file does not exist exception in BlockServiceHandler""

This commit updates the copyright headers in two Java files, BlockLockManager.java and BlockServiceHandler.java, by adding the missing Apache License, Version 2.0 disclaimer.

In addition, it modifies the BlockServiceHandler class to throw a FileDoesNotExistException instead of a generic TException when a requested block is not found on the worker. It also updates the method that creates a new block to throw an OutOfSpaceException instead of a TException when there is not enough space to allocate the requested bytes for the user. Finally, it updates the method that requests additional space for a block to return a boolean value indicating whether the request was successful or not, instead of throwing a TException.

Overall, this commit improves error handling and provides more specific error messages to clients.",Fixed exception handling in BlockServiceHandler and corrected license URL formatting in Java files.,Model 1
"diff --git a/core/src/main/java/bisq/core/dao/monitoring/DaoStateMonitoringService.java b/core/src/main/java/bisq/core/dao/monitoring/DaoStateMonitoringService.java
index f99d7ea355..5abf862979 100644
--- a/core/src/main/java/bisq/core/dao/monitoring/DaoStateMonitoringService.java
+++ b/core/src/main/java/bisq/core/dao/monitoring/DaoStateMonitoringService.java
@@ -20,6 +20,7 @@ package bisq.core.dao.monitoring;
 import bisq.core.dao.DaoSetupService;
 import bisq.core.dao.monitoring.model.DaoStateBlock;
 import bisq.core.dao.monitoring.model.DaoStateHash;
+import bisq.core.dao.monitoring.model.UtxoMismatch;
 import bisq.core.dao.monitoring.network.DaoStateNetworkService;
 import bisq.core.dao.monitoring.network.messages.GetDaoStateHashesRequest;
 import bisq.core.dao.monitoring.network.messages.NewDaoStateHashMessage;
@@ -40,6 +41,9 @@ import javax.inject.Inject;
 
 import org.apache.commons.lang3.ArrayUtils;
 
+import javafx.collections.FXCollections;
+import javafx.collections.ObservableList;
+
 import java.util.LinkedList;
 import java.util.List;
 import java.util.Optional;
@@ -88,6 +92,8 @@ public class DaoStateMonitoringService implements DaoSetupService, DaoStateListe
     private boolean parseBlockChainComplete;
     @Getter
     private boolean isInConflict;
+    @Getter
+    private ObservableList<UtxoMismatch> utxoMismatches = FXCollections.observableArrayList();
 
 
     ///////////////////////////////////////////////////////////////////////////////////////////
@@ -142,13 +148,13 @@ public class DaoStateMonitoringService implements DaoSetupService, DaoStateListe
         long totalBurntFee = daoStateService.getTotalBurntFee();
         long compensationIssuance = daoStateService.getTotalIssuedAmount(IssuanceType.COMPENSATION);
         long reimbursementIssuance = daoStateService.getTotalIssuedAmount(IssuanceType.REIMBURSEMENT);
-        long totalConfiscatedAmount = daoStateService.getTotalAmountOfConfiscatedTxOutputs();
+        long totalInvalidAmount = daoStateService.getBurnedBsqOfAllInvalidTxs();
         // confiscated funds are still in the utxo set
         long sumUtxo = daoStateService.getUnspentTxOutputMap().values().stream().mapToLong(BaseTxOutput::getValue).sum();
-        long sumBsq = genesisTotalSupply + compensationIssuance + reimbursementIssuance - totalBurntFee;
+        long sumBsq = genesisTotalSupply + compensationIssuance + reimbursementIssuance - totalBurntFee - totalInvalidAmount;
 
         if (sumBsq != sumUtxo) {
-            throw new RuntimeException(""There is a mismatch between the UTXO set and the DAO state. Please contact the Bisq devlopers."");
+            utxoMismatches.add(new UtxoMismatch(block.getHeight(), sumUtxo, sumBsq));
         }
     }
 
diff --git a/core/src/main/java/bisq/core/dao/monitoring/model/UtxoMismatch.java b/core/src/main/java/bisq/core/dao/monitoring/model/UtxoMismatch.java
new file mode 100644
index 0000000000..1509023c92
--- /dev/null
+++ b/core/src/main/java/bisq/core/dao/monitoring/model/UtxoMismatch.java
@@ -0,0 +1,33 @@
+/*
+ * This file is part of Bisq.
+ *
+ * Bisq is free software: you can redistribute it and/or modify it
+ * under the terms of the GNU Affero General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or (at
+ * your option) any later version.
+ *
+ * Bisq is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE. See the GNU Affero General Public
+ * License for more details.
+ *
+ * You should have received a copy of the GNU Affero General Public License
+ * along with Bisq. If not, see <http://www.gnu.org/licenses/>.
+ */
+
+package bisq.core.dao.monitoring.model;
+
+import lombok.Value;
+
+@Value
+public class UtxoMismatch {
+    private final int height;
+    private final long sumUtxo;
+    private final long sumBsq;
+
+    public UtxoMismatch(int height, long sumUtxo, long sumBsq) {
+        this.height = height;
+        this.sumUtxo = sumUtxo;
+        this.sumBsq = sumBsq;
+    }
+}
diff --git a/desktop/src/main/java/bisq/desktop/main/dao/monitor/daostate/DaoStateMonitorView.java b/desktop/src/main/java/bisq/desktop/main/dao/monitor/daostate/DaoStateMonitorView.java
index e5b9cb79d1..722a44684f 100644
--- a/desktop/src/main/java/bisq/desktop/main/dao/monitor/daostate/DaoStateMonitorView.java
+++ b/desktop/src/main/java/bisq/desktop/main/dao/monitor/daostate/DaoStateMonitorView.java
@@ -19,6 +19,7 @@ package bisq.desktop.main.dao.monitor.daostate;
 
 import bisq.desktop.common.view.FxmlView;
 import bisq.desktop.main.dao.monitor.StateMonitorView;
+import bisq.desktop.main.overlays.Overlay;
 import bisq.desktop.main.overlays.popups.Popup;
 import bisq.desktop.util.FormBuilder;
 
@@ -28,11 +29,16 @@ import bisq.core.dao.governance.period.PeriodService;
 import bisq.core.dao.monitoring.DaoStateMonitoringService;
 import bisq.core.dao.monitoring.model.DaoStateBlock;
 import bisq.core.dao.monitoring.model.DaoStateHash;
+import bisq.core.dao.monitoring.model.UtxoMismatch;
 import bisq.core.dao.state.DaoStateService;
 import bisq.core.locale.Res;
 
+import bisq.common.util.Utilities;
+
 import javax.inject.Inject;
 
+import javafx.collections.ListChangeListener;
+
 import java.util.Map;
 import java.util.stream.Collectors;
 
@@ -40,6 +46,9 @@ import java.util.stream.Collectors;
 public class DaoStateMonitorView extends StateMonitorView<DaoStateHash, DaoStateBlock, DaoStateBlockListItem, DaoStateInConflictListItem>
         implements DaoStateMonitoringService.Listener {
     private final DaoStateMonitoringService daoStateMonitoringService;
+    private ListChangeListener<UtxoMismatch> utxoMismatchListChangeListener;
+    private Overlay warningPopup;
+
 
     ///////////////////////////////////////////////////////////////////////////////////////////
     // Constructor, lifecycle
@@ -59,6 +68,8 @@ public class DaoStateMonitorView extends StateMonitorView<DaoStateHash, DaoState
 
     @Override
     public void initialize() {
+        utxoMismatchListChangeListener = c -> updateUtxoMismatches();
+
         FormBuilder.addTitledGroupBg(root, gridRow, 3, Res.get(""dao.monitor.daoState.headline""));
 
         statusTextField = FormBuilder.addTopLabelTextField(root, ++gridRow,
@@ -71,7 +82,11 @@ public class DaoStateMonitorView extends StateMonitorView<DaoStateHash, DaoState
     @Override
     protected void activate() {
         super.activate();
+
         daoStateMonitoringService.addListener(this);
+        daoStateMonitoringService.getUtxoMismatches().addListener(utxoMismatchListChangeListener);
+
+        updateUtxoMismatches();
 
         resyncButton.setOnAction(e -> daoFacade.resyncDao(() ->
                 new Popup<>().attention(Res.get(""setting.preferences.dao.resync.popup""))
@@ -84,7 +99,9 @@ public class DaoStateMonitorView extends StateMonitorView<DaoStateHash, DaoState
     @Override
     protected void deactivate() {
         super.deactivate();
+
         daoStateMonitoringService.removeListener(this);
+        daoStateMonitoringService.getUtxoMismatches().removeListener(utxoMismatchListChangeListener);
     }
 
 
@@ -185,4 +202,28 @@ public class DaoStateMonitorView extends StateMonitorView<DaoStateHash, DaoState
     protected void requestHashesFromGenesisBlockHeight(String peerAddress) {
         daoStateMonitoringService.requestHashesFromGenesisBlockHeight(peerAddress);
     }
+
+
+    ///////////////////////////////////////////////////////////////////////////////////////////
+    // Private
+    ///////////////////////////////////////////////////////////////////////////////////////////
+
+    private void updateUtxoMismatches() {
+        if (!daoStateMonitoringService.getUtxoMismatches().isEmpty()) {
+            StringBuilder sb = new StringBuilder();
+            daoStateMonitoringService.getUtxoMismatches().forEach(e -> {
+                sb.append(""\n"").append(Res.get(""dao.monitor.daoState.utxoConflicts.blockHeight"", e.getHeight())).append(""\n"")
+                        .append(Res.get(""dao.monitor.daoState.utxoConflicts.sumUtxo"", e.getSumUtxo() / 100)).append(""\n"")
+                        .append(Res.get(""dao.monitor.daoState.utxoConflicts.sumBsq"", e.getSumBsq() / 100));
+            });
+
+            if (warningPopup == null) {
+                warningPopup = new Popup<>().headLine(Res.get(""dao.monitor.daoState.utxoConflicts""))
+                        .warning(Utilities.toTruncatedString(sb.toString(), 500, false)).onClose(() -> {
+                            warningPopup = null;
+                        });
+                warningPopup.show();
+            }
+        }
+    }
 }",Add popup in case the utxo balance does not match the bsq balance,"""Add UTXO mismatch detection and display in DAO state monitor""","""Added UTXO mismatch detection and display in DaoStateMonitorView""","""Add UTXO mismatch tracking and display in DaoStateMonitoringService and DaoStateMonitorView""

Explanation:

* The commit adds a new class `UtxoMismatch` in `bisq/core/dao/monitoring/model/UtxoMismatch.java` to represent UTXO mismatches.
* It adds a new `ObservableList<UtxoMismatch>` field `utxoMismatches` in `DaoStateMonitoringService` and updates it when there is a mismatch between the UTXO set and the DAO state.
* It adds a new `ListChangeListener<UtxoMismatch>` field `utxoMismatchListChangeListener` in `DaoStateMonitorView` and updates the UI when there are UTXO mismatches.
* It adds a new method `updateUtxoMismatches()` in `DaoStateMonitorView` to create and display a popup warning when there are UTXO mismatches.
* It adds code in `DaoStateMonitorView.activate()` to listen for changes in `utxoMismatches` and in `DaoStateMonitorView.deactivate()` to stop listening for changes.

Overall, the commit adds functionality to track and display UTXO mismatches in the Bisq DAO state monitoring service and view.",Add UTXO mismatch detection and display in DAO state monitor view for better conflict visibility.,Model 4
"diff --git a/pom.xml b/pom.xml
index 772d7ef6578..d28060f8cd7 100644
--- a/pom.xml
+++ b/pom.xml
@@ -47,6 +47,7 @@
         <tests.heap.size>512m</tests.heap.size>
         <tests.heapdump.path>${basedir}/logs/</tests.heapdump.path>
         <tests.topn>5</tests.topn>
+        <jvm.executable>${java.home}${file.separator}bin${file.separator}java</jvm.executable>
         <execution.hint.file>.local-${project.version}-execution-hints.log</execution.hint.file>
 
         <!-- Properties used for building RPM & DEB packages (see common/packaging.properties) -->
@@ -444,7 +445,7 @@
               </execution>
             </executions>
             <configuration>
-              <executable>java</executable>
+              <executable>${jvm.executable></executable>
               <arguments>
                 <argument>-classpath</argument>
                 <classpath/>
@@ -516,6 +517,7 @@
                             <goal>junit4</goal>
                         </goals>
                        ",Execute tests with $ JAVA_HOME .,"""Specify JVM executable path for test execution""","The commit message should be:

""Added JVM executable path configuration for tests""

This message accurately reflects the changes made in the commit, which involve adding a new configuration option for the JVM executable path in the `pom.xml` file.","""Added jvm.executable property and updated Maven Surefire Plugin configuration to use it""

This commit adds a new property `jvm.executable` in the pom.xml file, which specifies the path to the Java executable. The value of this property is then used to update the configuration of the Maven Surefire Plugin, which is used to run the JUnit tests. Specifically, the `<executable>` element in the plugin configuration is updated to use the value of the `jvm.executable` property. This change ensures that the correct Java executable is used to run the tests, which can be useful when there are multiple JDKs installed on the system.",Update POM to use configurable JVM executable path to ensure proper Java location during builds and executions.,Model 1
"diff --git a/.github/issue_template.md b/.github/issue_template.md
index 23d1c7d33b..55dca93962 100644
--- a/.github/issue_template.md
+++ b/.github/issue_template.md
@@ -1,13 +1,3 @@
-###### Research
-*Enter an [ x ] character to confirm the points below:*
-
-[  ] I have read the [support page](https://ankidroid.org/docs/help.html) and am reporting a bug or enhancement request specific to AnkiDroid
-
-[  ] I have checked the [manual](https://ankidroid.org/docs/manual.html) and the [FAQ](https://github.com/ankidroid/Anki-Android/wiki/FAQ) and could not find a solution to my issue
-
-[  ] I have searched for similar existing issues here and on the user forum
-
-
 ###### Reproduction Steps
 
 1. 
@@ -26,4 +16,12 @@
 ###### Debug info
 Refer to the [support page](https://ankidroid.org/docs/help.html) if you are unsure where to get the ""debug info"".
 
+###### Research
+*Enter an [ x ] character to confirm the points below:*
+
+[  ] I have read the [support page](https://ankidroid.org/docs/help.html) and am reporting a bug or enhancement request specific to AnkiDroid
+
+[  ] I have checked the [manual](https://ankidroid.org/docs/manual.html) and the [FAQ](https://github.com/ankidroid/Anki-Android/wiki/FAQ) and could not find a solution to my issue
+
+[  ] I have searched for similar existing issues here and on the user forum
 
diff --git a/.github/pull_request_template.md b/.github/pull_request_template.md
index f1d7d7a8cf..8c621e16d7 100644
--- a/.github/pull_request_template.md
+++ b/.github/pull_request_template.md
@@ -1,13 +1,5 @@
 ## Pull Request template
 
-Please, go through these checks before you submit a PR.
-
-- [ ] You have not changed whitespace unnecessarily (it makes diffs hard to read)
-- [ ] You have a descriptive commit message with a short title (first line, max 50 chars).
-- [ ] Your code follows the style of the project (e.g. never omit braces in `if` statements) 
-- [ ] You have commented your code, particularly in hard-to-understand areas
-- [ ] You have performed a self-review of your own code
-
 ## Purpose / Description
 _Describe the problem or feature and motivation_
 
@@ -25,3 +17,12 @@ Please describe the tests that you ran to verify your changes. Provide instructi
 _Describe the research stage_
 
 _Links to blog posts, patterns, libraries or addons used to solve this problem_
+
+## Checklist
+_Please, go through these checks before submitting the PR._
+
+- [ ] You have not changed whitespace unnecessarily (it makes diffs hard to read)
+- [ ] You have a descriptive commit message with a short title (first line, max 50 chars).
+- [ ] Your code follows the style of the project (e.g. never omit braces in `if` statements) 
+- [ ] You have commented your code, particularly in hard-to-understand areas
+- [ ] You have performed a self-review of your own code",Move the checklists in the templates to the bottom .,"""Reorder and reformat issue and pull request templates for consistency""","""Restored pull request and issue templates to their original state.""","It appears that you have made changes to two files in your Git repository:

1. `.github/issue_template.md`
2. `.github/pull_request_template.md`

In the first file, you have removed a section related to research steps and moved it to the end of the file. In the second file, you have removed a checklist section and added it back at the end of the file.

Based on the changes made, a suitable commit message could be:

`Refactor issue and pull request templates for improved structure`

This commit message summarizes the changes made to the two files and provides a clear description of the purpose of the changes.","The commit message should be:

""Reorganize issue and pull request templates to improve clarity and ensure completion checks are performed at the end""",Model 3
"diff --git a/presto-main/src/test/java/com/facebook/presto/operator/scalar/TestRegexpFunctions.java b/presto-main/src/test/java/com/facebook/presto/operator/scalar/TestRegexpFunctions.java
index 52deae518b..a1d24f34a6 100644
--- a/presto-main/src/test/java/com/facebook/presto/operator/scalar/TestRegexpFunctions.java
+++ b/presto-main/src/test/java/com/facebook/presto/operator/scalar/TestRegexpFunctions.java
@@ -30,6 +30,7 @@ import java.util.List;
 
 import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;
 import static com.facebook.presto.spi.type.BooleanType.BOOLEAN;
+import static com.facebook.presto.spi.type.VarcharType.createUnboundedVarcharType;
 import static com.facebook.presto.spi.type.VarcharType.createVarcharType;
 import static com.facebook.presto.sql.analyzer.RegexLibrary.JONI;
 import static com.facebook.presto.sql.analyzer.RegexLibrary.RE2J;
@@ -133,6 +134,8 @@ public class TestRegexpFunctions
         assertInvalidFunction(""REGEXP_REPLACE('xxx', '(?<name>x)', '${}')"", INVALID_FUNCTION_ARGUMENT);
         assertInvalidFunction(""REGEXP_REPLACE('xxx', '(?<name>x)', '${0}')"", INVALID_FUNCTION_ARGUMENT);
         assertInvalidFunction(""REGEXP_REPLACE('xxx', '(?<name>x)', '${nam}')"", INVALID_FUNCTION_ARGUMENT);
+
+        assertFunction(""REGEXP_REPLACE(VARCHAR 'x', '.*', 'xxxxx')"", createUnboundedVarcharType(), ""xxxxxxxxxx"");
     }
 
     @Test",Migrate product verification failing test to unit test case,"""Add test for REGEXP_REPLACE with unbounded varchar type""","According to the diff, the commit message should be:

""Add support for unbounded VARCHAR type in REGEXP_REPLACE function""

This message accurately reflects the changes made in the commit, which include adding the `createUnboundedVarcharType` import and a new test case for the `REGEXP_REPLACE` function with an unbounded VARCHAR type.","It looks like you're working with a code change in a Git repository and you're looking for a commit message. A suitable commit message for this change could be:

```
Add test case for REGEXP_REPLACE with unbounded VarcharType

This commit adds a new test case for the REGEXP_REPLACE function with an unbounded VarcharType input and output.
```

This commit message follows the convention of a short summary (50 characters or less), followed by a blank line and a more detailed explanation. The detailed explanation helps others understand the motivation for the change and can be particularly useful for larger or more complex changes.",Add a test for REGEXP_REPLACE with unbounded VARCHAR in TestRegexpFunctions.,Model 2
"diff --git a/docs/source/about/release-notes.rst b/docs/source/about/release-notes.rst
index 8a5a7dfe0..b3c053287 100644
--- a/docs/source/about/release-notes.rst
+++ b/docs/source/about/release-notes.rst
@@ -31,6 +31,7 @@ v0.3.0-SNAPSHOT
   require applications to open a single port.
 * Added ``http.adminUsername`` and ``http.adminPassword`` to allow for Basic HTTP Authentication
   for the admin servlet.
+* Upgraded to Metrics 2.1.0.
 
 .. _rel-0.2.1:
 ",Updated relnotes .,"""Update release notes for v0.3.0-SNAPSHOT""","""Upgrade to Metrics 2.1.0 and add admin authentication""","It seems like you're working with a version control system, possibly Git, and you're looking at a diff of a file related to release notes for a software project. The change you've made is adding a line indicating that the project has been upgraded to Metrics 2.1.0.

As for the commit message, it's typically a brief summary of the changes made. Given the changes you've shown, a suitable commit message might be: ""Upgraded to Metrics 2.1.0 and added Basic HTTP Authentication for admin servlet"". However, without more context, it's hard to provide a more specific suggestion.","""Added support for Basic HTTP Authentication with admin credentials and upgraded Metrics to version 2.1.0.""",Model 4
"diff --git a/res/layout/addfeed.xml b/res/layout/addfeed.xml
index 7036bcbf9..016bc621f 100644
--- a/res/layout/addfeed.xml
+++ b/res/layout/addfeed.xml
@@ -1,32 +1,47 @@
 <?xml version=""1.0"" encoding=""utf-8""?>
-<LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
-	android:layout_width=""fill_parent""
-	android:layout_height=""fill_parent""
-	android:orientation=""vertical"" >
-	<TextView
-		android:id=""@+id/txtvFeedurl""
-		android:text=""@string/feedurl_label""
-		android:layout_width=""fill_parent""
-		android:layout_height=""wrap_content""
-		/>
-	<EditText android:id=""@+id/etxtFeedurl""
-		android:layout_width=""fill_parent""
+<RelativeLayout xmlns:android=""http://schemas.android.com/apk/res/android""
+    android:layout_width=""fill_parent""
+    android:layout_height=""fill_parent""
+    android:orientation=""vertical"" >
+
+    <TextView
+        android:id=""@+id/txtvFeedurl""
+        android:layout_width=""fill_parent""
         android:layout_height=""wrap_content""
-        android:autoText=""false""
-        android:capitalize=""none""/>
-	<LinearLayout
-		android:layout_width=""match_parent""
-		android:layout_height=""wrap_content""
-		android:orientation=""horizontal"">
-		<Button android:id=""@+id/butConfirm""
-			android:text=""@string/confirm_label""
-			android:layout_width=""0px""
-			android:layout_height=""wrap_content""
-			android:layout_weight=""1""/>
-		<Button android:id=""@+id/butCancel""
-			android:layout_width=""0px""
-			android:layout_height=""wrap_content""
-			android:layout_weight=""1""
-			android:text=""@string/cancel_label""/>
-	</LinearLayout>
-</LinearLayout>
+        android:layout_alignParentTop=""true""
+        android:layout_margin=""8dp""
+        android:text=""@string/txtvfeedurl_label"" />
+
+    <EditText
+        android:id=""@+id/etxtFeedurl""
+        android:layout_width=""fill_parent""
+        android:layout_height=""wrap_content""
+        android:layout_below=""@id/txtvFeedurl""
+        android:layout_margin=""8dp""
+        android:hint=""@string/feedurl_label""
+        android:inputType=""textUri"" />
+
+    <LinearLayout
+        android:id=""@+id/footer""
+        style=""@android:style/ButtonBar""
+        android:layout_width=""fill_parent""
+        android:layout_height=""wrap_content""
+        android:layout_alignParentBottom=""true""
+        android:orientation=""horizontal"" >
+
+        <Button
+            android:id=""@+id/butConfirm""
+            android:layout_width=""0px""
+            android:layout_height=""wrap_content""
+            android:layout_weight=""1""
+            android:text=""@string/confirm_label"" />
+
+        <Button
+            android:id=""@+id/butCancel""
+            android:layout_width=""0px""
+            android:layout_height=""wrap_content""
+            android:layout_weight=""1""
+            android:text=""@string/cancel_label"" />
+    </LinearLayout>
+
+</RelativeLayout>
\ No newline at end of file
diff --git a/res/values/strings.xml b/res/values/strings.xml
index 138ca38d6..1c8f382a1 100644
--- a/res/values/strings.xml
+++ b/res/values/strings.xml
@@ -67,5 +67,6 @@
     <string name=""error_label"">Error</string>
     <string name=""error_msg_prefix"">An error occured:</string>
     <string name=""download_error_connection_error"">Connection error</string>
+    <string name=""txtvfeedurl_label"">Type in the URL of the Feed here:</string>
 
 </resources>
\ No newline at end of file",Improved layout of Addfeedactivity,"""Refactor add feed layout to use RelativeLayout and improve UI""

This commit message is short and to the point, indicating that the layout of the add feed feature has been refactored to use a RelativeLayout, which likely improves the user interface.","""Refactor add feed layout to use RelativeLayout and improve UI""

Alternatively, you could also use:

* ""Migrate add feed layout to RelativeLayout""
* ""Improve add feed layout UI with RelativeLayout""
* ""Enhance add feed layout with RelativeLayout and string resource updates""

These commit messages are concise and accurately describe the changes made in the commit.","""Updated addfeed.xml layout and added new string resource for feed URL label""

Explanation:
The changes made in this commit are as follows:

1. The layout for the `addfeed.xml` file has been updated from a `LinearLayout` to a `RelativeLayout`. Some properties and elements have been modified, added, or removed to improve the layout design.
2. A new string resource has been added to the `strings.xml` file with the name ""txtvfeedurl_label"".

Based on these changes, a suitable commit message would be: ""Updated addfeed.xml layout and added new string resource for feed URL label"". This message summarizes the changes made in this commit.","""Changed layout to RelativeLayout, updated string resources, and aligned UI elements properly in addfeed.xml.""",Model 1
"diff --git a/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocument.java b/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocument.java
index 492910291a..2fdb99ba99 100755
--- a/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocument.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocument.java
@@ -335,6 +335,11 @@ public interface ODatabaseDocument extends ODatabase<ORecord> {
 
   OElement newElement(final String className);
 
+  OElement newEmbeddedElement();
+
+  OElement newEmbeddedElement(final String className);
+
+
   /**
    * Creates a new Edge of type E
    *
diff --git a/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocumentAbstract.java b/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocumentAbstract.java
index 4ac4f5892e..2d59eee968 100755
--- a/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocumentAbstract.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocumentAbstract.java
@@ -1420,6 +1420,16 @@ public abstract class ODatabaseDocumentAbstract extends OListenerManger<ODatabas
     return new ODocument(this, iClassName);
   }
 
+  @Override
+  public OElement newEmbeddedElement() {
+    return new ODocumentEmbedded(this);
+  }
+
+  @Override
+  public OElement newEmbeddedElement(String className) {
+    return new ODocumentEmbedded(className, this);
+  }
+
   @Override
   public OElement newElement() {
     return newInstance();
diff --git a/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocumentTx.java b/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocumentTx.java
index 2483bb49b0..18916e2b06 100755
--- a/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocumentTx.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/db/document/ODatabaseDocumentTx.java
@@ -528,6 +528,18 @@ public class ODatabaseDocumentTx implements ODatabaseDocumentInternal {
     return internal.newElement(className);
   }
 
+  @Override
+  public OElement newEmbeddedElement() {
+    checkOpenness();
+    return internal.newEmbeddedElement();
+  }
+
+  @Override
+  public OElement newEmbeddedElement(String className) {
+    checkOpenness();
+    return internal.newEmbeddedElement(className);
+  }
+
   public boolean isUseLightweightEdges() {
     return internal.isUseLightweightEdges();
   }
diff --git a/core/src/main/java/com/orientechnologies/orient/core/record/impl/ODocumentEmbedded.java b/core/src/main/java/com/orientechnologies/orient/core/record/impl/ODocumentEmbedded.java
new file mode 100644
index 0000000000..ec501c55eb
--- /dev/null
+++ b/core/src/main/java/com/orientechnologies/orient/core/record/impl/ODocumentEmbedded.java
@@ -0,0 +1,27 @@
+package com.orientechnologies.orient.core.record.impl;
+
+import com.orientechnologies.orient.core.db.ODatabaseSession;
+
+public class ODocumentEmbedded extends ODocument {
+
+  public ODocumentEmbedded() {
+    super();
+  }
+
+  public ODocumentEmbedded(String clazz) {
+    super(clazz);
+  }
+
+  public ODocumentEmbedded(String clazz, ODatabaseSession session) {
+    super(clazz, session);
+  }
+
+  public ODocumentEmbedded(ODatabaseSession session) {
+    super(session);
+  }
+
+  @Override
+  public boolean isEmbedded() {
+    return true;
+  }
+}
diff --git a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV0.java b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV0.java
index 137e72e683..aeed61a7c6 100755
--- a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV0.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV0.java
@@ -35,6 +35,7 @@ import com.orientechnologies.orient.core.metadata.schema.*;
 import com.orientechnologies.orient.core.metadata.security.OPropertyEncryption;
 import com.orientechnologies.orient.core.record.ORecordInternal;
 import com.orientechnologies.orient.core.record.impl.ODocument;
+import com.orientechnologies.orient.core.record.impl.ODocumentEmbedded;
 import com.orientechnologies.orient.core.record.impl.ODocumentEntry;
 import com.orientechnologies.orient.core.record.impl.ODocumentInternal;
 import com.orientechnologies.orient.core.serialization.ODocumentSerializable;
@@ -399,7 +400,7 @@ public class ORecordSerializerBinaryV0 implements ODocumentSerializer {
   }
 
   protected Object deserializeEmbeddedAsDocument(final BytesContainer bytes, final ORecordElement owner) {
-    Object value = new ODocument();
+    Object value = new ODocumentEmbedded();
     deserializeWithClassName((ODocument) value, bytes);
     if (((ODocument) value).containsField(ODocumentSerializable.CLASS_NAME)) {
       String className = ((ODocument) value).field(ODocumentSerializable.CLASS_NAME);
diff --git a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV1.java b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV1.java
index b615e0f21e..7e4dd53b32 100755
--- a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV1.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerBinaryV1.java
@@ -15,6 +15,7 @@ import com.orientechnologies.orient.core.metadata.schema.*;
 import com.orientechnologies.orient.core.metadata.security.OPropertyEncryption;
 import com.orientechnologies.orient.core.record.ORecordInternal;
 import com.orientechnologies.orient.core.record.impl.ODocument;
+import com.orientechnologies.orient.core.record.impl.ODocumentEmbedded;
 import com.orientechnologies.orient.core.record.impl.ODocumentEntry;
 import com.orientechnologies.orient.core.record.impl.ODocumentInternal;
 import com.orientechnologies.orient.core.serialization.ODocumentSerializable;
@@ -1014,7 +1015,7 @@ public class ORecordSerializerBinaryV1 implements ODocumentSerializer {
   }
 
   protected Object deserializeEmbeddedAsDocument(final BytesContainer bytes, final ORecordElement owner) {
-    Object value = new ODocument();
+    Object value = new ODocumentEmbedded();
     deserializeWithClassName((ODocument) value, bytes);
     if (((ODocument) value).containsField(ODocumentSerializable.CLASS_NAME)) {
       String className = ((ODocument) value).field(ODocumentSerializable.CLASS_NAME);
diff --git a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerNetworkV0.java b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerNetworkV0.java
index 91405dc875..830cd10bc8 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerNetworkV0.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerNetworkV0.java
@@ -38,6 +38,7 @@ import com.orientechnologies.orient.core.metadata.security.OPropertyEncryption;
 import com.orientechnologies.orient.core.record.ORecord;
 import com.orientechnologies.orient.core.record.ORecordInternal;
 import com.orientechnologies.orient.core.record.impl.ODocument;
+import com.orientechnologies.orient.core.record.impl.ODocumentEmbedded;
 import com.orientechnologies.orient.core.record.impl.ODocumentEntry;
 import com.orientechnologies.orient.core.record.impl.ODocumentInternal;
 import com.orientechnologies.orient.core.serialization.ODocumentSerializable;
@@ -315,7 +316,7 @@ public class ORecordSerializerNetworkV0 implements ODocumentSerializer {
       value = new Date(savedTime);
       break;
     case EMBEDDED:
-      value = new ODocument();
+      value = new ODocumentEmbedded();
       deserialize((ODocument) value, bytes);
       if (((ODocument) value).containsField(ODocumentSerializable.CLASS_NAME)) {
         String className = ((ODocument) value).field(ODocumentSerializable.CLASS_NAME);
diff --git a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerNetworkV37.java b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerNetworkV37.java
index 01f997caaf..500bac9316 100755
--- a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerNetworkV37.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/binary/ORecordSerializerNetworkV37.java
@@ -251,7 +251,7 @@ public class ORecordSerializerNetworkV37 implements ORecordSerializer {
       value = new Date(savedTime);
       break;
     case EMBEDDED:
-      value = new ODocument();
+      value = new ODocumentEmbedded();
       deserialize((ODocument) value, bytes);
       if (((ODocument) value).containsField(ODocumentSerializable.CLASS_NAME)) {
         String className = ((ODocument) value).field(ODocumentSerializable.CLASS_NAME);
diff --git a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/string/ORecordSerializerJSON.java b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/string/ORecordSerializerJSON.java
index 75746792de..ee3b3a79bf 100755
--- a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/string/ORecordSerializerJSON.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/record/string/ORecordSerializerJSON.java
@@ -43,10 +43,7 @@ import com.orientechnologies.orient.core.metadata.schema.OType;
 import com.orientechnologies.orient.core.record.ORecord;
 import com.orientechnologies.orient.core.record.ORecordInternal;
 import com.orientechnologies.orient.core.record.ORecordStringable;
-import com.orientechnologies.orient.core.record.impl.OBlob;
-import com.orientechnologies.orient.core.record.impl.ODocument;
-import com.orientechnologies.orient.core.record.impl.ODocumentHelper;
-import com.orientechnologies.orient.core.record.impl.ODocumentInternal;
+import com.orientechnologies.orient.core.record.impl.*;
 import com.orientechnologies.orient.core.serialization.serializer.OJSONWriter;
 import com.orientechnologies.orient.core.serialization.serializer.OStringSerializerHelper;
 import com.orientechnologies.orient.core.util.ODateHelper;
@@ -497,7 +494,7 @@ public class ORecordSerializerJSON extends ORecordSerializerStringAbstract {
         }
 
       case EMBEDDED:
-        return fromString(iFieldValueAsString);
+        return fromString(iFieldValueAsString, new ODocumentEmbedded(), null);
 
       case DATE:
         if (iFieldValueAsString == null || iFieldValueAsString.equals(""""))
diff --git a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/string/OStringSerializerEmbedded.java b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/string/OStringSerializerEmbedded.java
index 9ba9c4db03..587299d1df 100755
--- a/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/string/OStringSerializerEmbedded.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/serialization/serializer/string/OStringSerializerEmbedded.java
@@ -23,6 +23,7 @@ import com.orientechnologies.common.exception.OException;
 import com.orientechnologies.common.log.OLogManager;
 import com.orientechnologies.orient.core.exception.OSerializationException;
 import com.orientechnologies.orient.core.record.impl.ODocument;
+import com.orientechnologies.orient.core.record.impl.ODocumentEmbedded;
 import com.orientechnologies.orient.core.serialization.ODocumentSerializable;
 import com.orientechnologies.orient.core.serialization.OSerializableStream;
 import com.orientechnologies.orient.core.serialization.serializer.record.string.ORecordSerializerSchemaAware2CSV;
@@ -43,7 +44,7 @@ public class OStringSerializerEmbedded implements OStringSerializer {
       // NULL VALUE
       return null;
 
-    final ODocument instance = new ODocument();
+    final ODocument instance = new ODocumentEmbedded();
     try {
       ORecordSerializerSchemaAware2CSV.INSTANCE.fromStream(iStream.getBytes(""UTF-8""), instance, null);
     } catch (UnsupportedEncodingException e) {
@@ -67,7 +68,7 @@ public class OStringSerializerEmbedded implements OStringSerializer {
     if (ODocumentSerializable.class.isAssignableFrom(clazz)) {
       try {
         final ODocumentSerializable documentSerializable = (ODocumentSerializable) clazz.newInstance();
-        final ODocument docClone = new ODocument();
+        final ODocument docClone = new ODocumentEmbedded();
         instance.copyTo(docClone);
         docClone.removeField(ODocumentSerializable.CLASS_NAME);
         documentSerializable.fromDocument(docClone);
diff --git a/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLSelectTest.java b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLSelectTest.java
index dfc132be71..3cb32d4d6a 100755
--- a/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLSelectTest.java
+++ b/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLSelectTest.java
@@ -254,7 +254,7 @@ public class SQLSelectTest extends AbstractSelectTest {
 
     List<ODocument> resultset = executeQuery(""select coll[name='Jay'] as value from Profile where coll is not null"", database);
     Assert.assertEquals(resultset.size(), 1);
-    Assert.assertEquals(resultset.get(0).field(""value"").getClass(), ODocument.class);
+    Assert.assertTrue(resultset.get(0).field(""value"") instanceof ODocument);
     Assert.assertEquals(((ODocument) resultset.get(0).field(""value"")).field(""name""), ""Jay"");
 
     doc.delete();
@@ -273,7 +273,7 @@ public class SQLSelectTest extends AbstractSelectTest {
 
     List<ODocument> resultset = executeQuery(""select coll[name='Jay'] as value from Profile where coll is not null"", database);
     Assert.assertEquals(resultset.size(), 1);
-    Assert.assertEquals(resultset.get(0).field(""value"").getClass(), ODocument.class);
+    Assert.assertTrue(resultset.get(0).field(""value"") instanceof ODocument);
     Assert.assertEquals(((ODocument) resultset.get(0).field(""value"")).field(""name""), ""Jay"");
 
     doc.delete();",add concept of embedded document and integrated in record deserializations,"""Introduce ODocumentEmbedded class and update serialization to use it for embedded documents""","""Added support for embedded documents in OrientDB""","Add newEmbeddedElement methods to ODatabaseDocument

This commit adds two new methods to the ODatabaseDocument interface: newEmbeddedElement() and newEmbeddedElement(String className). These methods allow for the creation of new embedded elements in a document database.

The first method, newEmbeddedElement(), creates a new embedded element with the default class name. The second method, newEmbeddedElement(String className), allows for the creation of a new embedded element with a specified class name.

These methods have been implemented in the ODatabaseDocumentAbstract and ODatabaseDocumentTx classes, and the appropriate tests have been added to the SQLSelectTest class.

Additionally, a new class ODocumentEmbedded has been created to represent embedded documents, and changes have been made to the ORecordSerializerBinaryV0 and ORecordSerializerBinaryV1 classes to properly serialize and deserialize embedded documents.",Added support for embedded elements with new ODocumentEmbedded class and corresponding methods in ODatabaseDocument interfaces.,Model 3
"diff --git a/sonar-plugin-api/src/main/java/org/sonar/api/resources/ProjectUtils.java b/sonar-plugin-api/src/main/java/org/sonar/api/resources/ProjectUtils.java
index f2f9b0511e4..bf89e3f8d6a 100644
--- a/sonar-plugin-api/src/main/java/org/sonar/api/resources/ProjectUtils.java
+++ b/sonar-plugin-api/src/main/java/org/sonar/api/resources/ProjectUtils.java
@@ -19,6 +19,11 @@
  */
 package org.sonar.api.resources;
 
+import com.google.common.collect.Lists;
+
+import java.util.Collection;
+import java.util.List;
+
 /**
  * @TODO Actually this class incorrectly named, because provides information not about project, but about Java project.
  *       And seems that only core plugins use this class.
@@ -52,4 +57,15 @@ public final class ProjectUtils {
     }
     return null;
   }
+
+  /**
+   * @since 2.7
+   */
+  public static List<java.io.File> toIoFiles(Collection<InputFile> inputFiles) {
+    List<java.io.File> files = Lists.newArrayList();
+    for (InputFile inputFile : inputFiles) {
+      files.add(inputFile.getFile());
+    }
+    return files;
+  }
 }",add the method ProjectUtils . toIoFiles ( . . ),"""Add method to convert InputFile collection to List of java.io.File in ProjectUtils""","""Added toIoFiles method to ProjectUtils class for converting InputFile collection to a list of java.io.File objects""","""Added new static method to ProjectUtils class to convert a collection of InputFile to java.io.File in Sonar Plugin API""","""Added method to convert collection of InputFiles to list of java.io.Files in ProjectUtils class.""",Model 2
"diff --git a/elasticsearch/src/main/java/org/elasticsearch/xpack/watcher/support/SearchRequestEquivalence.java b/elasticsearch/src/main/java/org/elasticsearch/xpack/watcher/support/SearchRequestEquivalence.java
deleted file mode 100644
index cc063d56920..00000000000
--- a/elasticsearch/src/main/java/org/elasticsearch/xpack/watcher/support/SearchRequestEquivalence.java
+++ /dev/null
@@ -1,49 +0,0 @@
-/*
- * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
- * or more contributor license agreements. Licensed under the Elastic License;
- * you may not use this file except in compliance with the Elastic License.
- */
-package org.elasticsearch.xpack.watcher.support;
-
-import org.elasticsearch.action.search.SearchRequest;
-import org.elasticsearch.common.Nullable;
-import org.elasticsearch.common.bytes.BytesArray;
-import org.elasticsearch.common.bytes.BytesReference;
-import org.elasticsearch.common.io.stream.BytesStreamOutput;
-
-import java.util.Arrays;
-
-import static org.elasticsearch.xpack.watcher.support.Exceptions.illegalState;
-
-
-/**
- * The only true way today to compare search request object (outside of core) is to
- * serialize it and compare the serialized output. this is heavy obviously, but luckily we
- * don't compare search requests in normal runtime... we only do it in the tests. The is here basically
- * due to the lack of equals/hashcode support in SearchRequest in core.
- */
-public final class SearchRequestEquivalence {
-
-    public static final SearchRequestEquivalence INSTANCE = new SearchRequestEquivalence();
-
-    private SearchRequestEquivalence() {
-    }
-
-    public boolean equivalent(@Nullable SearchRequest a, @Nullable SearchRequest b) {
-        return a == b ? true : (a != null && b != null ? this.doEquivalent(a, b) : false);
-    }
-
-    protected boolean doEquivalent(SearchRequest r1, SearchRequest r2) {
-        try {
-            BytesStreamOutput output1 = new BytesStreamOutput();
-            r1.writeTo(output1);
-            byte[] bytes1 = BytesReference.toBytes(output1.bytes());
-            output1.reset();
-            r2.writeTo(output1);
-            byte[] bytes2 = BytesReference.toBytes(output1.bytes());
-            return Arrays.equals(bytes1, bytes2);
-        } catch (Exception e) {
-            throw illegalState(""could not compare search requests"", e);
-        }
-    }
-}",Remove unused class .,"""Remove SearchRequestEquivalence class""","The commit message should be:

""Remove SearchRequestEquivalence class due to serialization comparison being unnecessary""

This message accurately reflects the changes made in the commit, which is the removal of the `SearchRequestEquivalence` class.","""Remove SearchRequestEquivalence class""

This class was used to compare SearchRequest objects by serializing them and comparing the serialized output. However, it was only used for testing and was heavy due to the serialization process. It seems to have been removed due to the lack of equals/hashcode support in SearchRequest in the core.",Removed `SearchRequestEquivalence` class for comparing `SearchRequest` objects through serialization in Elasticsearch Watcher support classes.,Model 4
"diff --git a/flags/src/main/java/com/yahoo/vespa/flags/Flags.java b/flags/src/main/java/com/yahoo/vespa/flags/Flags.java
index 815fcda6ee7..57228dfe49d 100644
--- a/flags/src/main/java/com/yahoo/vespa/flags/Flags.java
+++ b/flags/src/main/java/com/yahoo/vespa/flags/Flags.java
@@ -193,11 +193,6 @@ public class Flags {
             ""Takes effect on next node agent tick (but does not clear existing failure reports)"",
             HOSTNAME);
   
-    public static final UnboundBooleanFlag DISABLE_CM3 = defineFeatureFlag(
-            ""disable-cm3"", false,
-            ""Whether to disable CM3."", ""Takes effect on next host admin tick"",
-            HOSTNAME);
-
     public static final UnboundBooleanFlag GENERATE_L4_ROUTING_CONFIG = defineFeatureFlag(
             ""generate-l4-routing-config"", false,
             ""Whether routing nodes should generate",Remove unused flag .,"""Remove DISABLE_CM3 feature flag""","""Removed DISABLE_CM3 flag and added GENERATE_L4_ROUTING_CONFIG flag""","""Remove DISABLE_CM3 flag""

This commit removes the `DISABLE_CM3` flag from the Flags class in the Vespa project. This flag was used to disable CM3, but it has been removed without any replacement or alternative. The commit message should reflect this change to make it clear what has been done.","""Remove outdated DISABLE_CM3 flag for cleanup and maintainability.""",Model 2
"diff --git a/jetty-websocket/websocket-core/src/main/java/org/eclipse/jetty/websocket/driver/WebSocketEventDriver.java b/jetty-websocket/websocket-core/src/main/java/org/eclipse/jetty/websocket/driver/WebSocketEventDriver.java
index 8eedb92f16..03afd9846b 100644
--- a/jetty-websocket/websocket-core/src/main/java/org/eclipse/jetty/websocket/driver/WebSocketEventDriver.java
+++ b/jetty-websocket/websocket-core/src/main/java/org/eclipse/jetty/websocket/driver/WebSocketEventDriver.java
@@ -129,17 +129,24 @@ public class WebSocketEventDriver implements Parser.Listener
             {
                 case CLOSE:
                 {
-                    if (events.onClose != null)
+                    if (events.onClose == null)
                     {
-                        byte payload[] = frame.getPayloadData();
-                        int statusCode = CloseUtil.getStatusCode(payload);
-                        String reason = CloseUtil.getReason(payload);
-                        events.onClose.call(websocket,connection,statusCode,reason);
+                        // not interested in close events
+                        return;
                     }
+                    byte payload[] = frame.getPayloadData();
+                    int statusCode = CloseUtil.getStatusCode(payload);
+                    String reason = CloseUtil.getReason(payload);
+                    events.onClose.call(websocket,connection,statusCode,reason);
                     return;
                 }
                 case BINARY:
                 {
+                    if (events.onBinary == null)
+                    {
+                        // not interested in binary events
+                        return;
+                    }
                     if (events.onBinary.isStreaming())
                     {
                         boolean needsNotification = false;
@@ -205,6 +212,11 @@ public class WebSocketEventDriver implements Parser.Listener
                 }
                 case TEXT:
                 {
+                    if (events.onText == null)
+                    {
+                        // not interested in text events
+                        return;
+                    }
                     if (events.onText.isStreaming())
       ",Fixing more tests,"""Optimize WebSocketEventDriver by skipping unregistered event handlers""","""Add support for ignoring specific WebSocket events""","""Added null checks for onClose, onBinary, and onText in WebSocketEventDriver""

This commit adds null checks for the `onClose`, `onBinary`, and `onText` event handlers in the `WebSocketEventDriver` class. If any of these handlers are null, the method will return early, skipping the processing of the corresponding event. This change ensures that the application does not throw a `NullPointerException` when it does not provide an event handler for a specific event type.","Add null checks for onClose, onBinary, and onText event handlers in WebSocketEventDriver before handling respective events.",Model 3
"diff --git a/src/com/android/launcher3/BubbleTextView.java b/src/com/android/launcher3/BubbleTextView.java
index 3d91306f8..33b3ad347 100644
--- a/src/com/android/launcher3/BubbleTextView.java
+++ b/src/com/android/launcher3/BubbleTextView.java
@@ -56,11 +56,12 @@ public class BubbleTextView extends TextView
 
     private static SparseArray<Theme> sPreloaderThemes = new SparseArray<Theme>(2);
 
-    private static final float SHADOW_LARGE_RADIUS = 4.0f;
-    private static final float SHADOW_SMALL_RADIUS = 1.75f;
-    private static final float SHADOW_Y_OFFSET = 2.0f;
-    private static final int SHADOW_LARGE_COLOUR = 0xDD000000;
-    private static final int SHADOW_SMALL_COLOUR = 0xCC000000;
+    // Dimensions in DP
+    private static final float AMBIENT_SHADOW_RADIUS = 2.5f;
+    private static final float KEY_SHADOW_RADIUS = 1f;
+    private static final float KEY_SHADOW_OFFSET = 0.5f;
+    private static final int AMBIENT_SHADOW_COLOR = 0x33000000;
+    private static final int KEY_SHADOW_COLOR = 0x66000000;
 
     private static final int DISPLAY_WORKSPACE = 0;
     private static final int DISPLAY_ALL_APPS = 1;
@@ -136,6 +137,10 @@ public class BubbleTextView extends TextView
             // Draw the background itself as the parent is drawn twice.
             mBackground = getBackground();
             setBackground(null);
+
+            // Set shadow layer as the larger shadow to that the textView does not clip the shadow.
+            float density = getResources().getDisplayMetrics().density;
+            setShadowLayer(density * AMBIENT_SHADOW_RADIUS, 0, 0, AMBIENT_SHADOW_COLOR);
         } else {
             mBackground = null;
         }
@@ -144,10 +149,6 @@ public class BubbleTextView extends TextView
         mStylusEventHelper = new StylusEventHelper(new SimpleOnStylusPressListener(this), this);
 
         mOutlineHelper = HolographicOutlineHelper.obtain(getContext());
-        if (mCustomShadowsEnabled) {
-            setShadowLayer(SHADOW_LARGE_RADIUS, 0.0f, SHADOW_Y_OFFSET, SHADOW_LARGE_COLOUR);
-        }
-
         setAccessibilityDelegate(mLauncher.getAccessibilityDelegate());
     }
 
@@ -408,13 +409,15 @@ public class BubbleTextView extends TextView
         }
 
         // We enhance the shadow by drawing the shadow twice
-        getPaint().setShadowLayer(SHADOW_LARGE_RADIUS, 0.0f, SHADOW_Y_OFFSET, SHADOW_LARGE_COLOUR);
+        float density = getResources().getDisplayMetrics().density;
+        getPaint().setShadowLayer(density * AMBIENT_SHADOW_RADIUS, 0, 0, AMBIENT_SHADOW_COLOR);
         super.draw(canvas);
         canvas.save(Canvas.CLIP_SAVE_FLAG);
         canvas.clipRect(getScrollX(), getScrollY() + getExtendedPaddingTop(),
                 getScrollX() + getWidth(),
                 getScrollY() + getHeight(), Region.Op.INTERSECT);
-        getPaint().setShadowLayer(SHADOW_SMALL_RADIUS, 0.0f, 0.0f, SHADOW_SMALL_COLOUR);
+        getPaint().setShadowLayer(
+                density * KEY_SHADOW_RADIUS, 0.0f, density * KEY_SHADOW_OFFSET, KEY_SHADOW_COLOR);
         super.draw(canvas);
         canvas.restore();
     }
diff --git a/src/com/android/launcher3/allapps/AllAppsContainerView.java b/src/com/android/launcher3/allapps/AllAppsContainerView.java
index 8b1f95087..428f78401 100644
--- a/src/com/android/launcher3/allapps/AllAppsContainerView.java
+++ b/src/com/android/launcher3/allapps/AllAppsContainerView.java
@@ -210,6 +210,7 @@ public class AllAppsContainerView extends BaseContainerView implements DragSourc
      */
     public void addApps(List<AppInfo> apps) {
         mApps.addApps(apps);
+        mSearchBarController.refreshSearchResult();
     }
 
     /**
@@ -217,6 +218,7 @@ public class AllAppsContainerView extends BaseContainerView implements DragSourc
      */
     public void updateApps(List<AppInfo> apps) {
         mApps.updateApps(apps);
+        mSearchBarController.refreshSearchResult();
     }
 
     /**
@@ -224,6 +226,7 @@ public class AllAppsContainerView extends BaseContainerView implements DragSourc
      */
     public void removeApps(List<AppInfo> apps) {
         mApps.removeApps(apps);
+        mSearchBarController.refreshSearchResult();
     }
 
     public void setSearchBarVisible(boolean visible) {
diff --git a/src/com/android/launcher3/allapps/AllAppsSearchBarController.java b/src/com/android/launcher3/allapps/AllAppsSearchBarController.java
index ac3593238..e75210b93 100644
--- a/src/com/android/launcher3/allapps/AllAppsSearchBarController.java
+++ b/src/com/android/launcher3/allapps/AllAppsSearchBarController.java
@@ -45,6 +45,7 @@ public abstract class AllAppsSearchBarController
     protected AlphabeticalAppsList mApps;
     protected Callbacks mCb;
     protected ExtendedEditText mInput;
+    private String mQuery;
 
     protected DefaultAppSearchAlgorithm mSearchAlgorithm;
     protected InputMethodManager mInputMethodManager;
@@ -90,14 +91,23 @@ public abstract class AllAppsSearchBarController
 
     @Override
     public void afterTextChanged(final Editable s) {
-        String query = s.toString();
-        if (query.isEmpty()) {
+        mQuery = s.toString();
+        if (mQuery.isEmpty()) {
             mSearchAlgorithm.cancel(true);
             mCb.clearSearchResult();
         } else {
             mSearchAlgorithm.cancel(false);
-            mSearchAlgorithm.doSearch(query, mCb);
+            mSearchAlgorithm.doSearch(mQuery, mCb);
+        }
+    }
+
+    protected void refreshSearchResult() {
+        if (mQuery == null) {
+            return;
         }
+        // If play store continues auto updating an app, we want to show partial result.
+      ",Added custom actions for showing the shortcuts menu and adding a quick action on the home screen .,"""Update BubbleTextView shadow styles and refresh search results in AllAppsContainerView""

This commit message accurately reflects the changes made in the code. The BubbleTextView class has been updated to use new shadow styles, and the AllAppsContainerView class has been updated to refresh search results after adding, updating, or removing apps.","According to the diff, the commit message should be:

""Update shadow layer dimensions and add search result refresh functionality""

However, this commit message is a bit generic and doesn't fully capture the changes made in the commit. A more descriptive commit message would be:

""Update shadow layer dimensions to use density-independent pixels and add search result refresh functionality to AllAppsContainerView and AllAppsSearchBarController""

This commit message is more specific and accurately describes the changes made in the commit.","This commit makes several changes to the BubbleTextView and AllAppsContainerView classes in the Android Launcher3 application.

In the BubbleTextView class, the commit changes the shadow radius, offset, and color values for the text view. The new values are defined as constants in DP (density-independent pixels) and are then converted to pixels using the device's display metrics. The commit also modifies the draw() method to use these new shadow values when drawing the text.

In the AllAppsContainerView class, the commit adds a new method called refreshSearchResult() to the SearchBarController interface. This method is then called in the addApps(), updateApps(), and removeApps() methods to refresh the search results whenever the list of apps is modified.

The commit message for this change could be something like: ""Updated shadow values for BubbleTextView and added refreshSearchResult() method to SearchBarController in AllAppsContainerView.""","""Refactor shadow handling in BubbleTextView and refresh search results on app list changes in AllAppsContainerView.""",Model 2
"diff --git a/core/cas-server-core-authentication-mfa-api/src/main/java/org/apereo/cas/authentication/trigger/PredicatedPrincipalAttributeMultifactorAuthenticationTrigger.java b/core/cas-server-core-authentication-mfa-api/src/main/java/org/apereo/cas/authentication/trigger/PredicatedPrincipalAttributeMultifactorAuthenticationTrigger.java
index 6b2a94c2c0..4f5e383e5b 100644
--- a/core/cas-server-core-authentication-mfa-api/src/main/java/org/apereo/cas/authentication/trigger/PredicatedPrincipalAttributeMultifactorAuthenticationTrigger.java
+++ b/core/cas-server-core-authentication-mfa-api/src/main/java/org/apereo/cas/authentication/trigger/PredicatedPrincipalAttributeMultifactorAuthenticationTrigger.java
@@ -19,6 +19,7 @@ import org.springframework.context.ApplicationContext;
 import org.springframework.core.Ordered;
 
 import javax.servlet.http.HttpServletRequest;
+
 import java.util.Comparator;
 import java.util.Optional;
 import java.util.function.Predicate;
@@ -37,6 +38,7 @@ public class PredicatedPrincipalAttributeMultifactorAuthenticationTrigger implem
     private static final Class[] PREDICATE_CTOR_PARAMETERS = {Object.class, Object.class, Object.class, Object.class};
 
     private final CasConfigurationProperties casProperties;
+
     private final ApplicationContext applicationContext;
 
     private int order = Ordered.LOWEST_PRECEDENCE;
diff --git a/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/MultifactorAuthenticationTestsSuite.java b/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/MultifactorAuthenticationTestsSuite.java
index 308895c191..c2c6454f9f 100644
--- a/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/MultifactorAuthenticationTestsSuite.java
+++ b/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/MultifactorAuthenticationTestsSuite.java
@@ -12,6 +12,7 @@ import org.apereo.cas.authentication.mfa.trigger.AuthenticationAttributeMultifac
 import org.apereo.cas.authentication.mfa.trigger.GlobalMultifactorAuthenticationTriggerTests;
 import org.apereo.cas.authentication.mfa.trigger.GroovyScriptMultifactorAuthenticationTriggerTests;
 import org.apereo.cas.authentication.mfa.trigger.HttpRequestMultifactorAuthenticationTriggerTests;
+import org.apereo.cas.authentication.mfa.trigger.PredicatedPrincipalAttributeMultifactorAuthenticationTriggerTests;
 import org.apereo.cas.authentication.mfa.trigger.PrincipalAttributeMultifactorAuthenticationTriggerTests;
 import org.apereo.cas.authentication.mfa.trigger.RegisteredServiceMultifactorAuthenticationTriggerTests;
 import org.apereo.cas.authentication.mfa.trigger.RegisteredServicePrincipalAttributeMultifactorAuthenticationTriggerTests;
@@ -38,6 +39,7 @@ import org.junit.runner.RunWith;
     AdaptiveMultifactorAuthenticationTriggerTests.class,
     GlobalMultifactorAuthenticationTriggerTests.class,
     MultifactorAuthenticationUtilsTests.class,
+    PredicatedPrincipalAttributeMultifactorAuthenticationTriggerTests.class,
     ScriptedRegisteredServiceMultifactorAuthenticationTriggerTests.class,
     RegisteredServiceMultifactorAuthenticationTriggerTests.class,
     RegisteredServicePrincipalAttributeMultifactorAuthenticationTriggerTests.class,
diff --git a/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/mfa/trigger/GroovyScriptMultifactorAuthenticationTriggerTests.java b/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/mfa/trigger/GroovyScriptMultifactorAuthenticationTriggerTests.java
index 1de953fb7d..3464387306 100644
--- a/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/mfa/trigger/GroovyScriptMultifactorAuthenticationTriggerTests.java
+++ b/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/mfa/trigger/GroovyScriptMultifactorAuthenticationTriggerTests.java
@@ -28,4 +28,35 @@ public class GroovyScriptMultifactorAuthenticationTriggerTests extends BaseMulti
         val result = trigger.isActivated(authentication, registeredService, this.httpRequest, mock(Service.class));
         assertTrue(result.isPresent());
     }
+
+    @Test
+    public void verifyScriptDoesNotExist() {
+        val props = new CasConfigurationProperties();
+        var trigger = new GroovyScriptMultifactorAuthenticationTrigger(props, applicationContext);
+        var result = trigger.isActivated(authentication, registeredService, this.httpRequest, mock(Service.class));
+        assertFalse(result.isPresent());
+        
+        props.getAuthn().getMfa().setGroovyScript(new ClassPathResource(""DoesNotExist.groovy""));
+        trigger = new GroovyScriptMultifactorAuthenticationTrigger(props, applicationContext);
+        result = trigger.isActivated(authentication, registeredService, this.httpRequest, mock(Service.class));
+        assertFalse(result.isPresent());
+    }
+
+    @Test
+    public void verifyBadInputParameters() {
+        val props = new CasConfigurationProperties();
+        props.getAuthn().getMfa().setGroovyScript(new ClassPathResource(""GroovyMfaTrigger.groovy""));
+
+        var trigger = new GroovyScriptMultifactorAuthenticationTrigger(props, applicationContext);
+        var result = trigger.isActivated(null, registeredService, this.httpRequest, mock(Service.class));
+        assertFalse(result.isPresent());
+
+        result = trigger.isActivated(authentication, null, this.httpRequest, mock(Service.class));
+        assertFalse(result.isPresent());
+
+        result = trigger.isActivated(authentication, registeredService, this.httpRequest, null);
+        assertFalse(result.isPresent());
+
+        trigger.destroy();
+    }
 }
diff --git a/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/mfa/trigger/PredicatedPrincipalAttributeMultifactorAuthenticationTriggerTests.java b/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/mfa/trigger/PredicatedPrincipalAttributeMultifactorAuthenticationTriggerTests.java
new file mode 100644
index 0000000000..52491d71ff
--- /dev/null
+++ b/core/cas-server-core-authentication-mfa-api/src/test/java/org/apereo/cas/authentication/mfa/trigger/PredicatedPrincipalAttributeMultifactorAuthenticationTriggerTests.java
@@ -0,0 +1,31 @@
+package org.apereo.cas.authentication.mfa.trigger;
+
+import org.apereo.cas.authentication.principal.Service;
+import org.apereo.cas.authentication.trigger.PredicatedPrincipalAttributeMultifactorAuthenticationTrigger;
+import org.apereo.cas.configuration.CasConfigurationProperties;
+
+import lombok.val;
+import org.junit.jupiter.api.Tag;
+import org.junit.jupiter.api.Test;
+import org.springframework.core.io.ClassPathResource;
+
+import static org.junit.jupiter.api.Assertions.*;
+import static org.mockito.Mockito.*;
+
+/**
+ * This is {@link PredicatedPrincipalAttributeMultifactorAuthenticationTriggerTests}.
+ *
+ * @author Misagh Moayyed
+ * @since 6.2.0
+ */
+@Tag(""MFA"")
+public class PredicatedPrincipalAttributeMultifactorAuthenticationTriggerTests extends BaseMultifactorAuthenticationTriggerTests {
+    @Test
+    public void verifyOperationByHeader() {
+        val props = new CasConfigurationProperties();
+        props.getAuthn().getMfa().setGlobalPrincipalAttributePredicate(new ClassPathResource(""GroovyPredicate.groovy""));
+        val trigger = new PredicatedPrincipalAttributeMultifactorAuthenticationTrigger(props, this.applicationContext);
+        val result = trigger.isActivated(authentication, registeredService, this.httpRequest, mock(Service.class));
+        assertTrue(result.isPresent());
+    }
+}
diff --git a/core/cas-server-core-authentication-mfa-api/src/test/resources/GroovyPredicate.groovy b/core/cas-server-core-authentication-mfa-api/src/test/resources/GroovyPredicate.groovy
new file mode 100644
index 0000000000..d71d049a13
--- /dev/null
+++ b/core/cas-server-core-authentication-mfa-api/src/test/resources/GroovyPredicate.groovy
@@ -0,0 +1,18 @@
+import groovy.transform.TupleConstructor
+import org.apereo.cas.authentication.principal.Principal
+import org.apereo.cas.authentication.principal.Service
+
+import java.util.function.Predicate
+
+@TupleConstructor
+class GroovyPredicate implements Predicate {
+    Object service;
+    Object principal;
+    Object providers
+    Object logger;
+
+    @Override
+    boolean test(final Object o) {
+        return true
+    }
+}
diff --git a/core/cas-server-core-util-api/src/main/java/org/apereo/cas/util/crypto/GlibcCryptPasswordEncoder.java b/core/cas-server-core-util-api/src/main/java/org/apereo/cas/util/crypto/GlibcCryptPasswordEncoder.java
index 9fb0506815..62b251c478 100644
--- a/core/cas-server-core-util-api/src/main/java/org/apereo/cas/util/crypto/GlibcCryptPasswordEncoder.java
+++ b/core/cas-server-core-util-api/src/main/java/org/apereo/cas/util/crypto/GlibcCryptPasswordEncoder.java
@@ -22,7 +22,9 @@ public class GlibcCryptPasswordEncoder implements PasswordEncoder {
     private static final int SALT_LENGTH = 8;
 
     private final String encodingAlgorithm;
+
     private final int strength;
+
     private String secret;
 
     @Override
diff --git a/core/cas-server-core-util-api/src/main/java/org/apereo/cas/util/scripting/ScriptingUtils.java b/core/cas-server-core-util-api/src/main/java/org/apereo/cas/util/scripting/ScriptingUtils.java
index a4a7c0903a..94957ace83 100644
--- a/core/cas-server-core-util-api/src/main/java/org/apereo/cas/util/scripting/ScriptingUtils.java
+++ b/core/cas-server-core-util-api/src/main/java/org/apereo/cas/util/scripting/ScriptingUtils.java
@@ -522,7 +522,7 @@ public class ScriptingUtils {
                 return classLoader.parseClass(script);
             });
 
-            LOGGER.debug(""Preparing constructor arguments [{}] for resource [{}]"", args, resource);
+            LOGGER.trace(""Preparing constructor arguments [{}] for resource [{}]"", args, resource);
             val ctor = clazz.getDeclaredConstructor(constructorArgs);
             val result = ctor.newInstance(args);
 
diff --git a/core/cas-server-core-util-api/src/test/java/org/apereo/cas/util/crypto/GlibcCryptPasswordEncoderTests.java b/core/cas-server-core-util-api/src/test/java/org/apereo/cas/util/crypto/GlibcCryptPasswordEncoderTests.java
index f37d162b92..51bf91c159 100644
--- a/core/cas-server-core-util-api/src/test/java/org/apereo/cas/util/crypto/GlibcCryptPasswordEncoderTests.java
+++ b/core/cas-server-core-util-api/src/test/java/org/apereo/cas/util/crypto/GlibcCryptPasswordEncoderTests.java
@@ -17,6 +17,25 @@ public class GlibcCryptPasswordEncoderTests {
 
     private static final String PASSWORD_CLEAR = ""12345abcDEF!$"";
 
+    private static boolean testEncodingRoundtrip(final String algorithm) {
+        val encoder = new GlibcCryptPasswordEncoder(algorithm, 0, null);
+
+        val passwordHash = encoder.encode(PASSWORD_CLEAR);
+        LOGGER.debug(""Password [{}] was encoded by algorithm [{}] to hash [{}]"", PASSWORD_CLEAR, algorithm, passwordHash);
+
+        val match = encoder.matches(PASSWORD_CLEAR, passwordHash);
+        LOGGER.debug(""Does password [{}] match original password [{}]: [{}]"", passwordHash, PASSWORD_CLEAR, match);
+
+        return match;
+    }
+
+    private static boolean testMatchWithDifferentSalt(final String algorithm, final String encodedPassword) {
+        val encoder = new GlibcCryptPasswordEncoder(algorithm, 0, null);
+        val match = encoder.matches(PASSWORD_CLEAR, encodedPassword);
+        LOGGER.debug(""Does password [{}] match original password [{}]: [{}]"", encodedPassword, PASSWORD_CLEAR, match);
+        return match;
+    }
+
     @Test
     public void sha512EncodingTest() {
         assertTrue(testEncodingRoundtrip(""SHA-512""));
@@ -45,23 +64,4 @@ public class GlibcCryptPasswordEncoderTests {
         assertTrue(testMatchWithDifferentSalt(""aB"", ""aB4fMcNOggJoQ""));
     }
 
-    private static boolean testEncodingRoundtrip(final String algorithm) {
-        val encoder = new GlibcCryptPasswordEncoder(algorithm, 0, null);
-
-        val passwordHash = encoder.encode(PASSWORD_CLEAR);
-        LOGGER.debug(""Password [{}] was encoded by algorithm [{}] to hash [{}]"", PASSWORD_CLEAR, algorithm, passwordHash);
-
-        val match = encoder.matches(PASSWORD_CLEAR, passwordHash);
-        LOGGER.debug(""Does password [{}] match original password [{}]: [{}]"", passwordHash, PASSWORD_CLEAR, match);
-
-        return match;
-    }
-
-    private static boolean testMatchWithDifferentSalt(final String algorithm, final String encodedPassword) {
-        val encoder = new GlibcCryptPasswordEncoder(algorithm, 0, null);
-        val match = encoder.matches(PASSWORD_CLEAR, encodedPassword);
-        LOGGER.debug(""Does password [{}] match original password [{}]: [{}]"", encodedPassword, PASSWORD_CLEAR, match);
-        return match;
-    }
-
 }
diff --git a/gradle.properties b/gradle.properties
index 43ec97ec74..1f78ecdedb 100644
--- a/gradle.properties
+++ b/gradle.properties
@@ -56,7 +56,7 @@ istackVersion=3.0.10
 spotbugsVersion=4.0.0
 spotbugsContribVersion=7.4.7
 findbugsSecVersion=1.10.1
-checkstyleVersion=8.29
+checkstyleVersion=8.30
 gradleRetryVersion=1.1.1
 gradleGitVersion=2.2.2
 gradleLombokVersion=3.3.0
diff --git a/support/cas-server-support-aup-jdbc/src/test/java/org/apereo/cas/aup/BaseJdbcAcceptableUsagePolicyRepositoryTests.java b/support/cas-server-support-aup-jdbc/src/test/java/org/apereo/cas/aup/BaseJdbcAcceptableUsagePolicyRepositoryTests.java
index 78d13579f3..e9022de979 100644
--- a/support/cas-server-support-aup-jdbc/src/test/java/org/apereo/cas/aup/BaseJdbcAcceptableUsagePolicyRepositoryTests.java
+++ b/support/cas-server-support-aup-jdbc/src/test/java/org/apereo/cas/aup/BaseJdbcAcceptableUsagePolicyRepositoryTests.java
@@ -95,11 +95,6 @@ public abstract class BaseJdbcAcceptableUsagePolicyRepositoryTests extends BaseA
     @Autowired
     protected CasConfigurationProperties casProperties;
 
-    @Override
-    public boolean hasLiveUpdates() {
-        return false;
-    }
-
     protected String determinePrincipalId(final String actualPrincipalId, final Map<String, List<Object>> profileAttributes) {
         val aupProperties = casProperties.getAcceptableUsagePolicy();
         val jdbcAupRepository = new JdbcAcceptableUsagePolicyRepository(ticketRegistrySupport.getObject(),
@@ -120,4 +115,9 @@ public abstract class BaseJdbcAcceptableUsagePolicyRepositoryTests extends BaseA
     public AcceptableUsagePolicyRepository getAcceptableUsagePolicyRepository() {
         return acceptableUsagePolicyRepository.getObject();
     }
+
+    @Override
+    public boolean hasLiveUpdates() {
+        return false;
+    }
 }
diff --git a/support/cas-server-support-aup-jdbc/src/test/java/org/apereo/cas/aup/JdbcAcceptableUsagePolicyRepositoryAdvancedTests.java b/support/cas-server-support-aup-jdbc/src/test/java/org/apereo/cas/aup/JdbcAcceptableUsagePolicyRepositoryAdvancedTests.java
index 300a30709e..0646c6f5ed 100644
--- a/support/cas-server-support-aup-jdbc/src/test/java/org/apereo/cas/aup/JdbcAcceptableUsagePolicyRepositoryAdvancedTests.java
+++ b/support/cas-server-support-aup-jdbc/src/test/java/org/apereo/cas/aup/JdbcAcceptableUsagePolicyRepositoryAdvancedTests.java
@@ -49,7 +49,7 @@ public class JdbcAcceptableUsagePolicyRepositoryAdvancedTests extends BaseJdbcAc
             }
         }
     }
-    
+
     @AfterEach
     public void cleanup() throws SQLException {
         try (val c = this.acceptableUsagePolicyDataSource.getObject().getConnection()) {
@@ -65,14 +65,14 @@ public class JdbcAcceptableUsagePolicyRepositoryAdvancedTests extends BaseJdbcAc
         verifyRepositoryAction(""casuser"",
             CollectionUtils.wrap(""aupAccepted"", List.of(""false""), ""email"", List.of(""CASuser@example.org"")));
     }
-    
+
     @Test
     public void determinePrincipalIdWithAdvancedConfig() {
         val principalId = determinePrincipalId(""casuser"",
             CollectionUtils.wrap(""aupAccepted"", List.of(""false""), ""email"", List.of(""CASuser@example.org"")));
         assertEquals(""CASuser@example.org"", principalId);
     }
-    
+
     @Test
     public void raiseMissingPrincipalAttributeError() {
         val exception = assertThrows(IllegalStateException.class,
@@ -80,29 +80,29 @@ public class JdbcAcceptableUsagePolicyRepositoryAdvancedTests extends BaseJdbcAc
                 List.of(""CASuser@example.org""))));
         assertTrue(exception.getMessage().contains(""cannot be found""));
     }
-    
+
     @Test
     public void raiseEmptyPrincipalAttributeError() {
         val exception = assertThrows(IllegalStateException.class,
             () -> raiseException(CollectionUtils.wrap(""aupAccepted"", List.of(""false""), ""email"", new ArrayList<>())));
         assertTrue(exception.getMessage().contains(""empty or multi-valued with an empty element""));
     }
-    
+
     private void raiseException(final Map<String, List<Object>> profileAttributes) {
         val aupProperties = casProperties.getAcceptableUsagePolicy();
         val jdbcAupRepository = new JdbcAcceptableUsagePolicyRepository(ticketRegistrySupport.getObject(),
-                aupProperties.getAupAttributeName(),
+            aupProperties.getAupAttributeName(),
             acceptableUsagePolicyDataSource.getObject(), aupProperties);
-        
+
         val context = new MockRequestContext();
         val request = new MockHttpServletRequest();
         context.setExternalContext(new ServletExternalContext(new MockServletContext(), request, new MockHttpServletResponse()));
-        
+
         val c = CoreAuthenticationTestUtils.getCredentialsWithSameUsernameAndPassword(""casuser"");
         val principal = CoreAuthenticationTestUtils.getPrincipal(c.getId(), profileAttributes);
         val auth = CoreAuthenticationTestUtils.getAuthentication(principal);
         WebUtils.putAuthentication(auth, context);
-        
+
         jdbcAupRepository.determinePrincipalId(context, c);
     }
 }
diff --git a/support/cas-server-support-openid/src/main/java/org/apereo/cas/support/openid/web/mvc/SmartOpenIdController.java b/support/cas-server-support-openid/src/main/java/org/apereo/cas/support/openid/web/mvc/SmartOpenIdController.java
index 6452a2d6a0..dbcc5a0cf6 100644
--- a/support/cas-server-support-openid/src/main/java/org/apereo/cas/support/openid/web/mvc/SmartOpenIdController.java
+++ b/support/cas-server-support-openid/src/main/java/org/apereo/cas/support/openid/web/mvc/SmartOpenIdController.java
@@ -15,6 +15,7 @@ import org.springframework.web.servlet.View;
 
 import javax.servlet.http.HttpServletRequest;
 import javax.servlet.http.HttpServletResponse;
+
 import java.io.Serializable;
 import java.util.HashMap;
 import java.util.Map;
@@ -33,6 +34,7 @@ public class SmartOpenIdController extends AbstractDelegateController implements
     private static final long serialVersionUID = -594058549445950430L;
 
     private final transient ServerManager serverManager;
+
     private final transient View successView;
 
     /**
@@ -62,12 +64,6 @@ public class SmartOpenIdController extends AbstractDelegateController implements
         return responseParams;
     }
 
-    @Override
-    protected ModelAndView handleRequestInternal(final HttpServletRequest request, final HttpServletResponse response) {
-        val parameters = new HashMap<String, String>(getAssociationResponse(request));
-        return new ModelAndView(this.successView, parameters);
-    }
-
     @Override
     public boolean canHandle(final HttpServletRequest request, final HttpServletResponse response) {
         val openIdMode = request.getParameter(OpenIdProtocolConstants.OPENID_MODE);
@@ -78,4 +74,10 @@ public class SmartOpenIdController extends AbstractDelegateController implements
         LOGGER.info(""Cannot handle request. openid.mode : [{}]"", openIdMode);
         return false;
     }
+
+    @Override
+    protected ModelAndView handleRequestInternal(final HttpServletRequest request, final HttpServletResponse response) {
+        val parameters = new HashMap<String, String>(getAssociationResponse(request));
+        return new ModelAndView(this.successView, parameters);
+    }
 }
diff --git a/support/cas-server-support-spnego-webflow/src/main/java/org/apereo/cas/web/flow/client/LdapSpnegoKnownClientSystemsFilterAction.java b/support/cas-server-support-spnego-webflow/src/main/java/org/apereo/cas/web/flow/client/LdapSpnegoKnownClientSystemsFilterAction.java
index 88873317d8..cfe20537e5 100644
--- a/support/cas-server-support-spnego-webflow/src/main/java/org/apereo/cas/web/flow/client/LdapSpnegoKnownClientSystemsFilterAction.java
+++ b/support/cas-server-support-spnego-webflow/src/main/java/org/apereo/cas/web/flow/client/LdapSpnegoKnownClientSystemsFilterAction.java
@@ -25,6 +25,7 @@ public class LdapSpnegoKnownClientSystemsFilterAction extends BaseSpnegoKnownCli
      * The must-have attribute name.
      */
     private final String spnegoAttributeName;
+
     private final SearchOperation searchOperation;
 
     /**
diff --git a/support/cas-server-support-spnego-webflow/src/main/java/org/apereo/cas/web/flow/config/SpnegoWebflowActionsConfiguration.java b/support/cas-server-support-spnego-webflow/src/main/java/org/apereo/cas/web/flow/config/SpnegoWebflowActionsConfiguration.java
index 4e5d36dcc2..5c8886ecd2 100644
--- a/support/cas-server-support-spnego-webflow/src/main/java/org/apereo/cas/web/flow/config/SpnegoWebflowActionsConfiguration.java
+++ b/support/cas-server-support-spnego-webflow/src/main/java/org/apereo/cas/web/flow/config/SpnegoWebflowActionsConfiguration.java
@@ -102,7 +102,7 @@ public class SpnegoWebflowActionsConfiguration {
         val searchRequest = LdapUtils.newLdaptiveSearchRequest(spnegoProperties.getLdap().getBaseDn(), filter);
         val searchOperation = new SearchOperation(connectionFactory, searchRequest);
         searchOperation.setTemplate(filter);
-        
+
         return new LdapSpnegoKnownClientSystemsFilterAction(RegexUtils.createPattern(spnegoProperties.getIpsToCheckPattern()),
             spnegoProperties.getAlternativeRemoteHostAttribute(),
             Beans.newDuration(spnegoProperties.getDnsTimeout()).toMillis(),",add more tests,"""Update MFA triggers, add PredicatedPrincipalAttributeMultifactorAuthenticationTrigger tests, and fix various issues""","Here is a possible commit message based on the provided diff:

""Refactor multifactor authentication triggers and password encoding, add test cases for Groovy script triggers, and make various minor improvements and bug fixes across the CAS codebase.""

However, a more concise and conventional commit message would be:

""Refactor multifactor authentication triggers and password encoding""

This commit message follows the conventional format of being short, descriptive, and in the imperative mood (i.e., it tells the reader what the commit does, rather than what it has done).","""Add PredicatedPrincipalAttributeMultifactorAuthenticationTrigger and tests""

This commit adds a new class called PredicatedPrincipalAttributeMultifactorAuthenticationTrigger and its corresponding tests. It also modifies some existing files related to multifactor authentication triggers and updates the MultifactorAuthenticationTestsSuite to include the new tests. Additionally, it includes a new Groovy script called GroovyPredicate.groovy which is used in the tests.","Added new MFA trigger tests, refactored existing tests, upgraded checkstyle version, and adjusted logging levels in ScriptingUtils.",Model 4
"diff --git a/src/components/org/apache/jmeter/control/RandomController.java b/src/components/org/apache/jmeter/control/RandomController.java
index ed7fdc0f7f..4e26c4d4c8 100644
--- a/src/components/org/apache/jmeter/control/RandomController.java
+++ b/src/components/org/apache/jmeter/control/RandomController.java
@@ -89,6 +89,7 @@ public class RandomController
 	 */
 	protected void incrementCurrent()
 	{
+		super.incrementCurrent();
 		current = rand.nextInt(this.getSubControllers().size());
 	}
 ",Fixed a bug that lead to stack overflows in certain situations .,"""Added call to super.incrementCurrent() in RandomController""","""Added call to super.incrementCurrent() in RandomController's incrementCurrent() method""","""Added super.incrementCurrent() in RandomController's incrementCurrent() method""",Added call to super.incrementCurrent() in RandomController to ensure correct incrementing before selecting a random sub-controller.,Model 3
"diff --git a/runtime/Swift/Sources/Antlr4/Lexer.swift b/runtime/Swift/Sources/Antlr4/Lexer.swift
index e47aa1a93..453d92aac 100644
--- a/runtime/Swift/Sources/Antlr4/Lexer.swift
+++ b/runtime/Swift/Sources/Antlr4/Lexer.swift
@@ -92,7 +92,7 @@ open class Lexer: Recognizer<LexerATNSimulator>, TokenSource {
         self._tokenFactorySourcePair.tokenSource = self
     }
 
-    public init(_ input: CharStream) {
+    public required init(_ input: CharStream) {
         self._input = input
         self._tokenFactorySourcePair = TokenSourceAndStream()
         super.init()
diff --git a/runtime/Swift/Sources/Antlr4/LexerInterpreter.swift b/runtime/Swift/Sources/Antlr4/LexerInterpreter.swift
index 99d9f72d8..815ee5c3a 100644
--- a/runtime/Swift/Sources/Antlr4/LexerInterpreter.swift
+++ b/runtime/Swift/Sources/Antlr4/LexerInterpreter.swift
@@ -18,19 +18,6 @@ public class LexerInterpreter: Lexer {
     internal final var _decisionToDFA: [DFA]
     internal final var _sharedContextCache = PredictionContextCache()
 
-//   public override init() {
-//    super.init()}
-
-//    public  convenience   init(_ input : CharStream) {
-//        self.init()
-//        self._input = input;
-//        self._tokenFactorySourcePair = (self, input);
-//    }
-    //@Deprecated
-    public convenience init(_ grammarFileName: String, _ tokenNames: Array<String?>?, _ ruleNames: Array<String>, _ channelNames: Array<String>, _ modeNames: Array<String>, _ atn: ATN, _ input: CharStream) throws {
-        try self.init(grammarFileName, Vocabulary.fromTokenNames(tokenNames), ruleNames, channelNames, modeNames, atn, input)
-    }
-
     public init(_ grammarFileName: String, _ vocabulary: Vocabulary, _ ruleNames: Array<String>, _ channelNames: Array<String>, _ modeNames: Array<String>, _ atn: ATN, _ input: CharStream) throws {
 
         self.grammarFileName = grammarFileName
@@ -54,6 +41,10 @@ public class LexerInterpreter: Lexer {
         }
     }
 
+    public required init(_ input: CharStream) {
+        fatalError(""Use the other initializer"")
+    }
+
     override
     public func getATN() -> ATN {
         return atn
diff --git a/tool/resources/org/antlr/v4/tool/templates/codegen/Swift/Swift.stg b/tool/resources/org/antlr/v4/tool/templates/codegen/Swift/Swift.stg
index 2cae8daf2..6586a3878 100755
--- a/tool/resources/org/antlr/v4/tool/templates/codegen/Swift/Swift.stg
+++ b/tool/resources/org/antlr/v4/tool/templates/codegen/Swift/Swift.stg
@@ -964,7 +964,7 @@ open class <lexer.name>: <superClass; null=""Lexer""> {
         return <lexer.name>.VOCABULARY
     }
 
-	public override init(_ input: CharStream) {
+	public required init(_ input: CharStream) {
 	    RuntimeMetaData.checkVersion(""<lexerFile.ANTLRVersion>"", RuntimeMetaData.VERSION)
 		super.init(input)
 		_interp = LexerATNSimulator(self, <lexer.name>._ATN, <lexer.name>._decisionToDFA, <lexer.name>._sharedContextCache)",Make CharStream . init ( CharStream ) required ( in the Swift runtime ) . .,"""Mark Lexer init(_:) as required to enforce use of designated initializer""","""Added required initializer to Lexer and LexerInterpreter classes and updated code generation template to reflect the change.""","""Update Lexer and LexerInterpreter initializers in Swift""

Explanation:
The changes made in the provided diff are related to the initializers of the `Lexer` and `LexerInterpreter` classes in Swift. In the `Lexer` class, the initializer has been updated from `public init(_ input: CharStream)` to `public required init(_ input: CharStream)`. In the `LexerInterpreter` class, the deprecated initializer has been removed, and a new initializer with the same signature as the updated `Lexer` initializer has been added, which throws a fatal error when called. The commit message should reflect these changes.",Make `init(_ input: CharStream)` a required initializer for `Lexer` and adjust `LexerInterpreter`.,Model 2
"diff --git a/config/single_node_cluster/config/server.properties b/config/single_node_cluster/config/server.properties
index 37f9c3244..eb74fffb2 100644
--- a/config/single_node_cluster/config/server.properties
+++ b/config/single_node_cluster/config/server.properties
@@ -9,7 +9,8 @@ http.enable=true
 socket.enable=true
 
 # BDB
-bdb.sync.transactions=false
+bdb.write.transactions=false
+bdb.flush.transactions=false
 bdb.cache.size=1G
 
 # Mysql
diff --git a/config/test_config1/config/server.properties b/config/test_config1/config/server.properties
index b5dfe8392..b2862ad9b 100644
--- a/config/test_config1/config/server.properties
+++ b/config/test_config1/config/server.properties
@@ -10,7 +10,8 @@ socket.enable=true
 jmx.enable=true
 
 # BDB
-bdb.sync.transactions=false
+bdb.write.transactions=false
+bdb.flush.transactions=false
 bdb.cache.size=100MB
 
 # Mysql
diff --git a/config/test_config2/config/server.properties b/config/test_config2/config/server.properties
index fa8f77eb9..c423f7c8f 100644
--- a/config/test_config2/config/server.properties
+++ b/config/test_config2/config/server.properties
@@ -1,5 +1,6 @@
 # The size of the in-memory cache used by bdb
-bdb.sync.transactions=false
+bdb.write.transactions=false
+bdb.flush.transactions=false
 bdb.cache.size=100MB
 
 max.threads=100",Remove references to obsolete bdb property from example configs .,"""Update BDB transaction settings in server properties""

or 

""Replace bdb.sync.transactions with bdb.write.transactions and bdb.flush.transactions in server properties""","""Optimize BDB transaction settings and adjust cache sizes in server.properties across multiple configurations""","""Updated BDB configuration in server.properties for single_node_cluster, test_config1, and test_config2:

- Disabled bdb.sync.transactions
+ Disabled bdb.write.transactions and bdb.flush.transactions""",Update BDB transaction and cache settings in server.properties for single node and test configurations.,Model 4
"diff --git a/eureka-core/src/main/java/com/netflix/eureka/util/batcher/AcceptorExecutor.java b/eureka-core/src/main/java/com/netflix/eureka/util/batcher/AcceptorExecutor.java
index e5baae40..42fadd87 100644
--- a/eureka-core/src/main/java/com/netflix/eureka/util/batcher/AcceptorExecutor.java
+++ b/eureka-core/src/main/java/com/netflix/eureka/util/batcher/AcceptorExecutor.java
@@ -222,13 +222,14 @@ class AcceptorExecutor<ID, T> {
                 drainReprocessQueue();
                 drainAcceptorQueue();
 
-                if (!isShutdown.get()) {
-                    // If all queues are empty, block for a while on the acceptor queue
-                    if (reprocessQueue.isEmpty() && acceptorQueue.isEmpty() && pendingTasks.isEmpty()) {
-                        TaskHolder<ID, T> taskHolder = acceptorQueue.poll(10, TimeUnit.MILLISECONDS);
-                        if (taskHolder != null) {
-                            appendTaskHolder(taskHolder);
-                        }
+                if (isShutdown.get()) {
+                    break;
+                }
+         ",Resolve spinlock issue in AcceptorExecutor thread ( <issue_id> ),"""Fix AcceptorExecutor to exit loop when shutdown""

This commit message is based on the changes made in the diff. The original code checked if the executor was not shut down and then proceeded to block on the acceptor queue if all queues were empty. The updated code checks if the executor is shut down and breaks out of the loop if it is, which is a more logical and efficient way to handle the shutdown scenario.","According to the diff, the commit message should be:

""Add shutdown check before blocking on acceptor queue""

This commit message accurately describes the change made in the code, which is to add a shutdown check before blocking on the acceptor queue.","""Refactor AcceptorExecutor to break loop when shutdown and avoid unnecessary queue checks""

Explanation:
The code change introduces a break statement inside the while loop when the isShutdown flag is set to true. This ensures that the loop terminates immediately when the executor is shutdown, instead of continuing with unnecessary queue checks.

Additionally, the condition for blocking on the acceptor queue when all queues are empty has been removed. This simplifies the code and avoids potential delays in processing tasks. The new code simply checks if the executor is shutdown and breaks the loop if it is, without checking the state of the queues.","""Fixed premature termination by adding shutdown check before polling acceptor queue in AcceptorExecutor.""",Model 4
"diff --git a/lib/src/main/java/com/auth0/jwt/impl/PayloadDeserializer.java b/lib/src/main/java/com/auth0/jwt/impl/PayloadDeserializer.java
index 3806887..8f872cb 100644
--- a/lib/src/main/java/com/auth0/jwt/impl/PayloadDeserializer.java
+++ b/lib/src/main/java/com/auth0/jwt/impl/PayloadDeserializer.java
@@ -65,9 +65,12 @@ class PayloadDeserializer extends StdDeserializer<Payload> {
 
     Date getDateFromSeconds(Map<String, JsonNode> tree, String claimName) {
         JsonNode node = tree.get(claimName);
-        if (node == null || node.isNull() || !node.canConvertToLong()) {
+        if (node == null || node.isNull()) {
             return null;
         }
+        if (!node.canConvertToLong()) {
+            throw new JWTDecodeException(String.format(""The claim '%s' contained an unexpected value."", claimName));
+        }
         final long ms = node.asLong() * 1000;
         return new Date(ms);
     }
diff --git a/lib/src/test/java/com/auth0/jwt/JWTDecoderTest.java b/lib/src/test/java/com/auth0/jwt/JWTDecoderTest.java
index a482685..e164dc0 100644
--- a/lib/src/test/java/com/auth0/jwt/JWTDecoderTest.java
+++ b/lib/src/test/java/com/auth0/jwt/JWTDecoderTest.java
@@ -275,7 +275,7 @@ public class JWTDecoderTest {
 
     @Test
     public void shouldGetAvailableClaims() throws Exception {
-        DecodedJWT jwt = JWT.decode(""eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOiIxMjM0NTY3ODkwIiwiaWF0IjoiMTIzNDU2Nzg5MCIsIm5iZiI6IjEyMzQ1Njc4OTAiLCJqdGkiOiJodHRwczovL2p3dC5pby8iLCJhdWQiOiJodHRwczovL2RvbWFpbi5hdXRoMC5jb20iLCJzdWIiOiJsb2dpbiIsImlzcyI6ImF1dGgwIiwiZXh0cmFDbGFpbSI6IkpvaG4gRG9lIn0.TX9Ct4feGp9YyeGK9Zl91tO0YBOrguJ4As9jeqgHdZQ"");
+        DecodedJWT jwt = JWT.decode(""eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjEyMzQ1Njc4OTAsImlhdCI6MTIzNDU2Nzg5MCwibmJmIjoxMjM0NTY3ODkwLCJqdGkiOiJodHRwczovL2p3dC5pby8iLCJhdWQiOiJodHRwczovL2RvbWFpbi5hdXRoMC5jb20iLCJzdWIiOiJsb2dpbiIsImlzcyI6ImF1dGgwIiwiZXh0cmFDbGFpbSI6IkpvaG4gRG9lIn0.2_0nxDPJwOk64U5V5V9pt8U92jTPJbGsHYQ35HYhbdE"");
         assertThat(jwt, is(notNullValue()));
         assertThat(jwt.getClaims(), is(notNullValue()));
         assertThat(jwt.getClaims(), is(instanceOf(Map.class)));
diff --git a/lib/src/test/java/com/auth0/jwt/impl/PayloadDeserializerTest.java b/lib/src/test/java/com/auth0/jwt/impl/PayloadDeserializerTest.java
index 014ae83..7fe9145 100644
--- a/lib/src/test/java/com/auth0/jwt/impl/PayloadDeserializerTest.java
+++ b/lib/src/test/java/com/auth0/jwt/impl/PayloadDeserializerTest.java
@@ -198,13 +198,15 @@ public class PayloadDeserializerTest {
     }
 
     @Test
-    public void shouldGetNullDateWhenParsingNonNumericNode() throws Exception {
+    public void shouldThrowWhenParsingNonNumericNode() throws Exception {
+        exception.expect(JWTDecodeException.class);
+        exception.expectMessage(""The claim 'key' contained an unexpected value."");
+
         Map<String, JsonNode> tree = new HashMap<>();
         TextNode node = new TextNode(""123456789"");
         tree.put(""key"", node);
 
-        Date date = deserializer.getDateFromSeconds(tree, ""key"");
-        assertThat(date, is(nullValue()));
+        deserializer.getDateFromSeconds(tree, ""key"");
     }
 
     @Test",throw JWTDecodeException when date claim format is invalid,"""Throw JWTDecodeException when parsing non-numeric node in PayloadDeserializer""","""Improved date deserialization and added test for non-numeric claim values""","""Update PayloadDeserializer to throw exception when claim value is unexpected and update tests""

Explanation:

* The change in `PayloadDeserializer.java` adds a new check for the `node.canConvertToLong()` condition and throws a `JWTDecodeException` if it fails.
* The change in `JWTDecoderTest.java` updates the JWT token used for the test case.
* The change in `PayloadDeserializerTest.java` updates the test case to expect a `JWTDecodeException` to be thrown when parsing a non-numeric node.

Based on the changes, it appears that the library has been updated to throw an exception when a claim value is unexpected (i.e., not a long value) rather than returning a null date. The test cases have also been updated to reflect this new behavior.","Enhance PayloadDeserializer to handle non-numeric claims with JWTDecodeException, update relevant tests for better validation of such scenarios.",Model 3
"diff --git a/.hgtags b/.hgtags
index e583046c16..bd28104aa7 100644
--- a/.hgtags
+++ b/.hgtags
@@ -162,3 +162,4 @@ b3a91113026c99b0da010d41055719ab0d8938f0 jdk8-b37
 4cc5610a6dd6227da766ebf9742eb11ff5ded6c0 jdk8-b38
 35a5397278779a2f8f3013f81586dc8f30cb149d jdk8-b39
 6e4e654931b976304bf6e7b4d0d6db8f75bac5d9 jdk8-b40
+c029c972396cea042a0dc67c0f7ccf2fe68007d4 jdk8-b41",Added tag jdk8 - b41 for changeset c029c972396c,"""Added jdk8-b41 tag""",Added jdk8-b41 to .hgtags.,"Based on the diff you provided, the commit message should be:

```
""jdk8-b41""
```

This is the new line that has been added in the `.hgtags` file. The commit message should ideally provide a brief description of the changes made in the commit. In this case, it seems like a new tag `jdk8-b41` has been added.",Added a new tag jdk8-b41 with commit ID c029c972396cea042a0dc67c0f7ccf2fe68007d4 to .hgtags file.,Model 1
"diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Max.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Max.java
index f6460b6d12..91851bcbe9 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Max.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Max.java
@@ -212,14 +212,7 @@ public class Max {
 
   /////////////////////////////////////////////////////////////////////////////
 
-  /**
-   * A {@code CombineFn} that computes the maximum of a collection of elements of type {@code T}
-   * using an arbitrary {@link Comparator}, useful as an argument to {@link Combine#globally} or
-   * {@link Combine#perKey}.
-   *
-   * @param <T> the type of the values being compared
-   */
-  public static class MaxFn<T> extends BinaryCombineFn<T> {
+  private static class MaxFn<T> extends BinaryCombineFn<T> {
 
     private final T identity;
     private final Comparator<? super T> comparator;
@@ -248,11 +241,7 @@ public class Max {
     }
   }
 
-  /**
-   * A {@code CombineFn} that computes the maximum of a collection of {@code Integer}s, useful as an
-   * argument to {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class MaxIntegerFn extends Combine.BinaryCombineIntegerFn {
+  private static class MaxIntegerFn extends Combine.BinaryCombineIntegerFn {
 
     @Override
     public int apply(int left, int right) {
@@ -265,11 +254,7 @@ public class Max {
     }
   }
 
-  /**
-   * A {@code CombineFn} that computes the maximum of a collection of {@code Long}s, useful as an
-   * argument to {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class MaxLongFn extends Combine.BinaryCombineLongFn {
+  private static class MaxLongFn extends Combine.BinaryCombineLongFn {
 
     @Override
     public long apply(long left, long right) {
@@ -282,11 +267,7 @@ public class Max {
     }
   }
 
-  /**
-   * A {@code CombineFn} that computes the maximum of a collection of {@code Double}s, useful as an
-   * argument to {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class MaxDoubleFn extends Combine.BinaryCombineDoubleFn {
+  private static class MaxDoubleFn extends Combine.BinaryCombineDoubleFn {
 
     @Override
     public double apply(double left, double right) {
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Mean.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Mean.java
index 17dbe6cf42..5e7c00317a 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Mean.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Mean.java
@@ -101,17 +101,7 @@ public class Mean {
 
   /////////////////////////////////////////////////////////////////////////////
 
-  /**
-   * A {@code Combine.CombineFn} that computes the arithmetic mean
-   * (a.k.a. average) of an {@code Iterable} of numbers of type
-   * {@code N}, useful as an argument to {@link Combine#globally} or
-   * {@link Combine#perKey}.
-   *
-   * <p>Returns {@code Double.NaN} if combining zero elements.
-   *
-   * @param <NumT> the type of the {@code Number}s being combined
-   */
-  public static class MeanFn<NumT extends Number>
+  private static class MeanFn<NumT extends Number>
   extends Combine.AccumulatingCombineFn<NumT, CountSum<NumT>, Double> {
     /**
      * Constructs a combining function that computes the mean over
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Min.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Min.java
index 47d831ceb7..109f4e5cb5 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Min.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Min.java
@@ -212,14 +212,7 @@ public class Min {
 
   /////////////////////////////////////////////////////////////////////////////
 
-  /**
-   * A {@code CombineFn} that computes the maximum of a collection of elements of type {@code T}
-   * using an arbitrary {@link Comparator}, useful as an argument to {@link Combine#globally} or
-   * {@link Combine#perKey}.
-   *
-   * @param <T> the type of the values being compared
-   */
-  public static class MinFn<T> extends BinaryCombineFn<T> {
+  private static class MinFn<T> extends BinaryCombineFn<T> {
 
     private final T identity;
     private final Comparator<? super T> comparator;
@@ -248,11 +241,7 @@ public class Min {
     }
   }
 
-  /**
-   * A {@code CombineFn} that computes the minimum of a collection of {@code Integer}s, useful as an
-   * argument to {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class MinIntegerFn extends Combine.BinaryCombineIntegerFn {
+  private static class MinIntegerFn extends Combine.BinaryCombineIntegerFn {
 
     @Override
     public int apply(int left, int right) {
@@ -265,11 +254,7 @@ public class Min {
     }
   }
 
-  /**
-   * A {@code CombineFn} that computes the minimum of a collection of {@code Long}s, useful as an
-   * argument to {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class MinLongFn extends Combine.BinaryCombineLongFn {
+  private static class MinLongFn extends Combine.BinaryCombineLongFn {
 
     @Override
     public long apply(long left, long right) {
@@ -282,11 +267,7 @@ public class Min {
     }
   }
 
-  /**
-   * A {@code CombineFn} that computes the minimum of a collection of {@code Double}s, useful as an
-   * argument to {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class MinDoubleFn extends Combine.BinaryCombineDoubleFn {
+  private static class MinDoubleFn extends Combine.BinaryCombineDoubleFn {
 
     @Override
     public double apply(double left, double right) {
diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Sum.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Sum.java
index 504473240d..ccade4db70 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Sum.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Sum.java
@@ -140,12 +140,7 @@ public class Sum {
 
   /////////////////////////////////////////////////////////////////////////////
 
-  /**
-   * A {@code SerializableFunction} that computes the sum of an
-   * {@code Iterable} of {@code Integer}s, useful as an argument to
-   * {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class SumIntegerFn extends Combine.BinaryCombineIntegerFn {
+  private static class SumIntegerFn extends Combine.BinaryCombineIntegerFn {
 
     @Override
     public int apply(int a, int b) {
@@ -158,12 +153,7 @@ public class Sum {
     }
   }
 
-  /**
-   * A {@code SerializableFunction} that computes the sum of an
-   * {@code Iterable} of {@code Long}s, useful as an argument to
-   * {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class SumLongFn extends Combine.BinaryCombineLongFn {
+  private static class SumLongFn extends Combine.BinaryCombineLongFn {
 
     @Override
     public long apply(long a, long b) {
@@ -176,12 +166,7 @@ public class Sum {
     }
   }
 
-  /**
-   * A {@code SerializableFunction} that computes the sum of an
-   * {@code Iterable} of {@code Double}s, useful as an argument to
-   * {@link Combine#globally} or {@link Combine#perKey}.
-   */
-  public static class SumDoubleFn extends Combine.BinaryCombineDoubleFn {
+  private static class SumDoubleFn extends Combine.BinaryCombineDoubleFn {
 
     @Override
     public double apply(double a, double b) {","Reduced visibility for Sum , Min , Max , Mean combine Fns .","""Internalize CombineFn implementations in Max, Mean, Min, and Sum transforms""","The commit message should be:

""Convert static inner classes to private static classes""

This commit message accurately reflects the changes made in the code, which involve changing the access modifier of the inner classes from `public` to `private`.","""Make Max, Mean, Min, and Sum CombineFn classes private in Apache Beam SDK""

This commit changes the access modifier of several CombineFn classes (MaxFn, MeanFn, MinFn, SumIntegerFn, SumLongFn, SumDoubleFn) from public to private in the Apache Beam SDK. This means that these classes can no longer be accessed directly from outside the package and must be used through the public methods provided by the Max, Mean, Min, and Sum classes.","""Modify Max, Mean, Min, and Sum classes to make various CombineFns private instead of public for encapsulation.""",Model 3
"diff --git a/engine/src/main/java/org/terasology/rendering/nui/layers/ingame/PauseMenu.java b/engine/src/main/java/org/terasology/rendering/nui/layers/ingame/PauseMenu.java
index 02492aeba..972cd1253 100644
--- a/engine/src/main/java/org/terasology/rendering/nui/layers/ingame/PauseMenu.java
+++ b/engine/src/main/java/org/terasology/rendering/nui/layers/ingame/PauseMenu.java
@@ -15,9 +15,7 @@
  */
 package org.terasology.rendering.nui.layers.ingame;
 
-import org.terasology.crashreporter.CrashReporter;
 import org.terasology.engine.GameEngine;
-import org.terasology.engine.LoggingContext;
 import org.terasology.engine.modes.StateMainMenu;
 import org.terasology.registry.CoreRegistry;
 import org.terasology.rendering.nui.CoreScreenLayer;",Delete two import,"""Remove unused imports in PauseMenu.java""","""Removed unused imports from PauseMenu.java""","""Remove unused imports in PauseMenu.java""",Removed unused CrashReporter and LoggingContext imports from PauseMenu in the Terasology engine rendering module.,Model 3
"diff --git a/wear/wear/src/main/java/androidx/wear/widget/WearArcLayout.java b/wear/wear/src/main/java/androidx/wear/widget/WearArcLayout.java
index bd5948cdb48..0edbebf49ca 100644
--- a/wear/wear/src/main/java/androidx/wear/widget/WearArcLayout.java
+++ b/wear/wear/src/main/java/androidx/wear/widget/WearArcLayout.java
@@ -287,6 +287,15 @@ public class WearArcLayout extends ViewGroup {
         a.recycle();
     }
 
+    @Override
+    public void requestLayout() {
+        super.requestLayout();
+
+        for (int i = 0; i < getChildCount(); i++) {
+            getChildAt(i).forceLayout();
+        }
+    }
+
     @Override
     protected void onMeasure(int widthMeasureSpec, int heightMeasureSpec) {
         // Need to derive the thickness of the curve from the children. We're a curve, so the
diff --git a/wear/wear/src/main/java/androidx/wear/widget/WearCurvedTextView.java b/wear/wear/src/main/java/androidx/wear/widget/WearCurvedTextView.java
index 6a3a8e57023..097dc1f90da 100644
--- a/wear/wear/src/main/java/androidx/wear/widget/WearCurvedTextView.java
+++ b/wear/wear/src/main/java/androidx/wear/widget/WearCurvedTextView.java
@@ -189,6 +189,7 @@ public class WearCurvedTextView extends View implements WearArcLayout.ArcLayoutW
         a.recycle();
 
         applyTextAppearance(attributes);
+        mPaint.setTextSize(mTextSize);
     }
 
     @Override
@@ -237,12 +238,13 @@ public class WearCurvedTextView extends View implements WearArcLayout.ArcLayoutW
         doUpdate();
     }
 
-    private void updatePaint() {
-        mPaint.setTextSize(mTextSize);
+    @Override
+    protected void onLayout(boolean changed, int l, int t, int r, int b) {
+        super.onLayout(changed, l, t, r, b);
+
         mPaint.getTextBounds(mText, 0, mText.length(), mBounds);
 
         // Note that ascent is negative.
-
         mPathRadius = min(getWidth(), getHeight()) / 2f
                 + (mClockwise ? mPaint.getFontMetrics().ascent - getPaddingTop() :
                 -mPaint.getFontMetrics().descent - getPaddingBottom());
@@ -292,7 +294,6 @@ public class WearCurvedTextView extends View implements WearArcLayout.ArcLayoutW
 
         mDirty = false;
         mLastUsedTextAlignment = (int) getTextAlignment();
-        mPaint.setTextSize(mTextSize);
 
         if (mTextSweepDegrees <= mMaxSweepDegrees) {
             mTextToDraw = mText;
@@ -649,7 +650,6 @@ public class WearCurvedTextView extends View implements WearArcLayout.ArcLayoutW
 
     private void doUpdate() {
         mDirty = true;
-        updatePaint();
         requestLayout();
         postInvalidate();
     }
@@ -735,6 +735,7 @@ public class WearCurvedTextView extends View implements WearArcLayout.ArcLayoutW
     /** sets the text size for rendering the text */
     public void setTextSize(float value) {
         mTextSize = value;
+        mPaint.setTextSize(mTextSize);
         doUpdate();
     }
 ",Fix the layout issues with WearArcLayout & WearCurvedTextView .,"""Fix WearArcLayout and WearCurvedTextView layout issues""

or 

""Improve WearArcLayout and WearCurvedTextView layout handling""

or 

""Enhance WearArcLayout and WearCurvedTextView to correctly handle child layouts and text rendering""

The commit message should be short and descriptive, indicating the main purpose of the changes. In this case, the changes seem to be related to fixing layout issues in WearArcLayout and WearCurvedTextView, so the commit message should reflect that.","""Update WearArcLayout and WearCurvedTextView to force layout of children and update text size on layout changes""","""Add force layout to WearArcLayout and update text size in WearCurvedTextView""

Explanation:

* In WearArcLayout.java, a new method `requestLayout()` is added that calls `super.requestLayout()` and forces layout for all child views.
* In WearCurvedTextView.java, the `mPaint.setTextSize(mTextSize)` line is added in two places: in the constructor and in the `setTextSize()` method. This sets the text size for rendering the text in the `WearCurvedTextView`. Additionally, the `updatePaint()` method is removed and its contents are moved to the `onLayout()` method.","""Fix layout update and text size issues in WearArcLayout and WearCurvedTextView for consistent rendering.""",Model 4
"diff --git a/sulong/projects/com.oracle.truffle.llvm.runtime/src/com/oracle/truffle/llvm/runtime/nodes/intrinsics/llvm/LLVMExpect.java b/sulong/projects/com.oracle.truffle.llvm.runtime/src/com/oracle/truffle/llvm/runtime/nodes/intrinsics/llvm/LLVMExpect.java
index 5b7f50bab4e..2ead0b1750c 100644
--- a/sulong/projects/com.oracle.truffle.llvm.runtime/src/com/oracle/truffle/llvm/runtime/nodes/intrinsics/llvm/LLVMExpect.java
+++ b/sulong/projects/com.oracle.truffle.llvm.runtime/src/com/oracle/truffle/llvm/runtime/nodes/intrinsics/llvm/LLVMExpect.java
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2016, 2019, Oracle and/or its affiliates.
+ * Copyright (c) 2016, 2020, Oracle and/or its affiliates.
  *
  * All rights reserved.
  *
@@ -104,6 +104,6 @@ public abstract class LLVMExpect {
     }
 
     static ConditionProfile getExpectConditionProfile() {
-        return ConditionProfile.createBinaryProfile();
+        return ConditionProfile.create();
     }
 }
diff --git a/truffle/src/com.oracle.truffle.api.test/src/com/oracle/truffle/api/test/parser/PEParser.java b/truffle/src/com.oracle.truffle.api.test/src/com/oracle/truffle/api/test/parser/PEParser.java
index 1fee7a15618..27eeae4c99d 100644
--- a/truffle/src/com.oracle.truffle.api.test/src/com/oracle/truffle/api/test/parser/PEParser.java
+++ b/truffle/src/com.oracle.truffle.api.test/src/com/oracle/truffle/api/test/parser/PEParser.java
@@ -355,7 +355,7 @@ final class Sequence4<T, A, B, C, D> extends SequenceBase<T> {
 
 final class Alternative<T> extends Element<T> {
     @Children private final Element<? extends T>[] options;
-    private final ConditionProfile seenEof = ConditionProfile.createBinaryProfile();
+    private final ConditionProfile seenEof = ConditionProfile.create();
 
     Alternative(Element<? extends T>[] options) {
         this.options = options;
@@ -398,7 +398,7 @@ final class Repetition<T, ListT, R> extends Element<R> {
     private final Supplier<ListT> createList;
     private final BiFunction<ListT, T, ListT> addToList;
     private final Function<ListT, R> createResult;
-    private final ConditionProfile seenEof = ConditionProfile.createBinaryProfile();
+    private final ConditionProfile seenEof = ConditionProfile.create();
 
     Repetition(Element<T> element, Supplier<ListT> createList, BiFunction<ListT, T, ListT> addToList, Function<ListT, R> createResult) {
         this.element = element;
@@ -433,7 +433,7 @@ final class Repetition<T, ListT, R> extends Element<R> {
 
 final class StackRepetition<T> extends Element<LexerList<T>> {
     @Child private Element<T> element;
-    private final ConditionProfile seenEof = ConditionProfile.createBinaryProfile();
+    private final ConditionProfile seenEof = ConditionProfile.create();
 
     StackRepetition(Element<T> element) {
         this.element = element;
@@ -469,7 +469,7 @@ final class OptionalElement<T, R> extends Element<R> {
     @Child Element<T> element;
     private final Function<T, R> hasValueAction;
     private final Supplier<R> hasNoValueAction;
-    private final ConditionProfile seenEof = ConditionProfile.createBinaryProfile();
+    private final ConditionProfile seenEof = ConditionProfile.create();
 
     OptionalElement(Element<T> element, Function<T, R> hasValueAction, Supplier<R> hasNoValueAction) {
         this.element = element;
@@ -501,7 +501,7 @@ final class OptionalElement<T, R> extends Element<R> {
 final class TokenReference<T> extends Element<T> {
     private final byte token;
     private final TokenFunction<T> action;
-    private final ConditionProfile seenEof = ConditionProfile.createBinaryProfile();
+    private final ConditionProfile seenEof = ConditionProfile.create();
 
     TokenReference(byte token, TokenFunction<T> action) {
         this.token = token;
diff --git a/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotLimits.java b/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotLimits.java
index d46cde75725..b87d126e4f7 100644
--- a/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotLimits.java
+++ b/truffle/src/com.oracle.truffle.polyglot/src/com/oracle/truffle/polyglot/PolyglotLimits.java
@@ -123,7 +123,7 @@ final class PolyglotLimits {
         final EventContext eventContext;
         final PolyglotEngineImpl engine;
         final FrameSlot readContext;
-        final ConditionProfile needsLookup = ConditionProfile.createBinaryProfile();
+        final ConditionProfile needsLookup = ConditionProfile.create();
         final FrameDescriptor descriptor;
         @CompilationFinal private boolean seenInnerContext;
 
diff --git a/wasm/src/org.graalvm.wasm/src/org/graalvm/wasm/memory/UnsafeWasmMemory.java b/wasm/src/org.graalvm.wasm/src/org/graalvm/wasm/memory/UnsafeWasmMemory.java
index 4e8f4272eb5..8b6cfe96bde 100644
--- a/wasm/src/org.graalvm.wasm/src/org/graalvm/wasm/memory/UnsafeWasmMemory.java
+++ b/wasm/src/org.graalvm.wasm/src/org/graalvm/wasm/memory/UnsafeWasmMemory.java
@@ -54,7 +54,7 @@ public class UnsafeWasmMemory extends WasmMemory {
     private long startAddress;
     private long pageSize;
     private final long maxPageSize;
-    private final ConditionProfile outOfBoundsAccesses = ConditionProfile.createBinaryProfile();
+    private final ConditionProfile outOfBoundsAccesses = ConditionProfile.create();
 
     public UnsafeWasmMemory(long initPageSize, long maxPageSize) {
         try {",Replace ConditionProfile . createBinaryProfile ( ) with ConditionProfile . create ( ),Replace ConditionProfile.createBinaryProfile() with ConditionProfile.create(),"""Update ConditionProfile creation to use the default constructor instead of createBinaryProfile()""","""Update copyright year and use ConditionProfile.create() instead of ConditionProfile.createBinaryProfile()""

This commit updates the copyright year from 2019 to 2020 in the file `LLVMExpect.java`. It also replaces the usage of `ConditionProfile.createBinaryProfile()` with `ConditionProfile.create()` in several files, including `PEParser.java`, `PolyglotLimits.java`, and `UnsafeWasmMemory.java`. The `ConditionProfile.create()` method is used to create a new condition profile, which is a performance optimization technique used in the Truffle framework.","""Refactor to use ConditionProfile.create() instead of ConditionProfile.createBinaryProfile() for improved flexibility in profiling conditions.""",Model 4
"diff --git a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/ExecutionEngineTest.scala b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/ExecutionEngineTest.scala
index 77532f9c48b..ec8b315e80f 100644
--- a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/ExecutionEngineTest.scala
+++ b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/ExecutionEngineTest.scala
@@ -1054,9 +1054,9 @@ order by a.COL1"""""")
 
   private def createReadOnlyEngine(): ExecutionEngine = {
     FileUtils.deleteRecursively(new File(""target/readonly""))
-    val old = new TestGraphDatabaseFactory().newEmbeddedDatabase(""target/readonly"")
+    val old = new TestGraphDatabaseFactory().newEmbeddedDatabase( new File( ""target/readonly"" ) )
     old.shutdown()
-    val db = new TestGraphDatabaseFactory().newEmbeddedDatabaseBuilder(""target/readonly"")
+    val db = new TestGraphDatabaseFactory().newEmbeddedDatabaseBuilder( new File( ""target/readonly"" ) )
       .setConfig( GraphDatabaseSettings.read_only, ""true"" )
       .newGraphDatabase()
     new ExecutionEngine(new GraphDatabaseCypherService(db))
diff --git a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/IndexOpAcceptanceTest.scala b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/IndexOpAcceptanceTest.scala
index 84fca67a234..21eddf2bbf9 100644
--- a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/IndexOpAcceptanceTest.scala
+++ b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/IndexOpAcceptanceTest.scala
@@ -96,8 +96,9 @@ class IndexOpAcceptanceTest extends ExecutionEngineFunSuite with QueryStatistics
   }
 
   private def createDbWithFailedIndex: GraphDatabaseService = {
-    new File(""target/test-data/impermanent-db"").deleteAll()
-    graph = new GraphDatabaseCypherService(new TestGraphDatabaseFactory().newEmbeddedDatabase(""target/test-data/impermanent-db""))
+    val storeDir = new File(""target/test-data/impermanent-db"")
+    storeDir.deleteAll()
+    graph = new GraphDatabaseCypherService(new TestGraphDatabaseFactory().newEmbeddedDatabase(storeDir))
     eengine = new ExecutionEngine(graph)
     execute(""CREATE INDEX ON :Person(name)"")
     execute(""create (:Person {name:42})"")
@@ -114,7 +115,7 @@ class IndexOpAcceptanceTest extends ExecutionEngineFunSuite with QueryStatistics
     stream.write(65)
     stream.close()
 
-    graph = new GraphDatabaseCypherService(new TestGraphDatabaseFactory().newEmbeddedDatabase(""target/test-data/impermanent-db""))
+    graph = new GraphDatabaseCypherService(new TestGraphDatabaseFactory().newEmbeddedDatabase(storeDir))
     eengine = new ExecutionEngine(graph)
     graph.getGraphDatabaseService
   }
diff --git a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/internal/compiler/v3_0/CompilerComparisonTest.scala b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/internal/compiler/v3_0/CompilerComparisonTest.scala
index ea34b869c6d..a7d7aa9a67b 100644
--- a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/internal/compiler/v3_0/CompilerComparisonTest.scala
+++ b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/internal/compiler/v3_0/CompilerComparisonTest.scala
@@ -379,7 +379,7 @@ class CompilerComparisonTest extends ExecutionEngineFunSuite with QueryStatistic
 
   private def executionResults: Seq[DataSetResults] = (for ((dataSet, queries) <- queriesByDataSet) yield {
     val (dataSetName, dataSetDir) = dataSet
-    val db = new GraphDatabaseCypherService(new GraphDatabaseFactory().newEmbeddedDatabase(dataSetDir))
+    val db = new GraphDatabaseCypherService(new GraphDatabaseFactory().newEmbeddedDatabase(new File(dataSetDir)))
     try {
       val queryResults = for ((queryName, queryText) <- queries) yield {
         val results = for ((compilerName, compilerCreator) <- compilers) yield {
diff --git a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/performance/DataImportTest.scala b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/performance/DataImportTest.scala
index b5d884a645e..662d534ac24 100644
--- a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/performance/DataImportTest.scala
+++ b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/performance/DataImportTest.scala
@@ -36,11 +36,10 @@ class DataImportTest extends CypherFunSuite {
   // This test creates a database
   ignore(""createDatabase"") {
     val sourceDir = new File(""/Users/ata/Downloads/apa/ml-10M100K"")
-    val targetDir = ""target/perf-graph.db""
-    val dir = new File(targetDir)
-    deleteAll(dir)
+    val targetDir = new File(""target/perf-graph.db"")
+    deleteAll(targetDir)
 
-    dir.exists() should equal(false)
+    targetDir.exists() should equal(false)
 
     val (inserter, moviesId, moviesTitles, indexProvider, typeIdx) = createInserters(targetDir)
 
@@ -82,7 +81,7 @@ class DataImportTest extends CypherFunSuite {
     moviesId
   }
 
-  private def createInserters(targetDir: String) = {
+  private def createInserters(targetDir: File) = {
     val inserter = BatchInserters.inserter(targetDir)
     val indexProvider = new LuceneBatchInserterIndexProviderNewImpl(inserter)
 
diff --git a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/performance/PerformanceTest.scala b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/performance/PerformanceTest.scala
index 31374c7b42c..2c54b8ce51e 100644
--- a/community/cypher/cypher/src/test/scala/org/neo4j/cypher/performance/PerformanceTest.scala
+++ b/community/cypher/cypher/src/test/scala/org/neo4j/cypher/performance/PerformanceTest.scala
@@ -19,6 +19,7 @@
  */
 package org.neo4j.cypher.performance
 
+import java.io.File
 import java.util.Collections
 
 import org.neo4j.cypher.internal.frontend.v3_0.test_helpers.CypherFunSuite
@@ -34,7 +35,7 @@ class PerformanceTest extends CypherFunSuite {
 
   override def beforeEach() {
     super.beforeEach()
-    db = new GraphDatabaseFactory().newEmbeddedDatabase(""target/db"")
+    db = new GraphDatabaseFactory().newEmbeddedDatabase(new File(""target/db""))
   }
 
   override def afterEach() {
diff --git a/community/graph-algo/src/test/java/org/neo4j/graphalgo/path/AStarPerformanceIT.java b/community/graph-algo/src/test/java/org/neo4j/graphalgo/path/AStarPerformanceIT.java
index 8f6da1b91f6..a9166edaa8a 100644
--- a/community/graph-algo/src/test/java/org/neo4j/graphalgo/path/AStarPerformanceIT.java
+++ b/community/graph-algo/src/test/java/org/neo4j/graphalgo/path/AStarPerformanceIT.java
@@ -74,7 +74,7 @@ public class AStarPerformanceIT
                 new long[]{291, 86707},
                 new long[]{188345, 158468}
         };
-        GraphDatabaseService db = new GraphDatabaseFactory().newEmbeddedDatabase( directory.getAbsolutePath() );
+        GraphDatabaseService db = new GraphDatabaseFactory().newEmbeddedDatabase( directory.getAbsoluteFile() );
         PathFinder<WeightedPath> algo = aStar( allTypesAndDirections(),
                 doubleCostEvaluator( ""weight"", 0 ), GeoDataGenerator.estimateEvaluator() );
         for ( int i = 0; i < 10; i++ )
diff --git a/community/graphviz/src/main/java/org/neo4j/visualization/graphviz/Script.java b/community/graphviz/src/main/java/org/neo4j/visualization/graphviz/Script.java
index 7759ad2134f..6abfe8533e9 100644
--- a/community/graphviz/src/main/java/org/neo4j/visualization/graphviz/Script.java
+++ b/community/graphviz/src/main/java/org/neo4j/visualization/graphviz/Script.java
@@ -41,7 +41,7 @@ public class Script extends ConfigurationParser
         super( format );
     }
 
-    protected String storeDir;
+    protected File storeDir;
 
     public static <S extends Script> S initialize( Class<S> scriptClass, String... args )
     {
@@ -115,7 +115,7 @@ public class Script extends ConfigurationParser
         {
             throw new UnsupportedOperationException( ""Could not initialize script"", e );
         }
-        script.storeDir = args[0];
+        script.storeDir = new File( args[0] );
         return script;
     }
 
@@ -154,7 +154,7 @@ public class Script extends ConfigurationParser
         }
     }
 
-    protected String storeDir()
+    protected File storeDir()
     {
         return storeDir;
     }
diff --git a/community/import-tool/src/test/java/org/neo4j/tooling/ImportToolDocIT.java b/community/import-tool/src/test/java/org/neo4j/tooling/ImportToolDocIT.java
index 3d5508fe296..48d02f4a7a5 100644
--- a/community/import-tool/src/test/java/org/neo4j/tooling/ImportToolDocIT.java
+++ b/community/import-tool/src/test/java/org/neo4j/tooling/ImportToolDocIT.java
@@ -104,7 +104,7 @@ public class ImportToolDocIT
 
         // WHEN
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", movies.getAbsolutePath(),
                 ""--nodes"", actors.getAbsolutePath(),
                 ""--relationships"", roles.getAbsolutePath() );
@@ -157,7 +157,7 @@ public class ImportToolDocIT
 
         // WHEN
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", movies.getAbsolutePath(),
                 ""--nodes"", actors.getAbsolutePath(),
                 ""--relationships"", roles.getAbsolutePath(),
@@ -224,7 +224,7 @@ public class ImportToolDocIT
 
         // WHEN
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", moviesHeader.getAbsolutePath() + MULTI_FILE_DELIMITER + movies.getAbsolutePath(),
                 ""--nodes"", actorsHeader.getAbsolutePath() + MULTI_FILE_DELIMITER + actors.getAbsolutePath(),
                 ""--relationships"", rolesHeader.getAbsolutePath() + MULTI_FILE_DELIMITER + roles.getAbsolutePath());
@@ -299,7 +299,7 @@ public class ImportToolDocIT
 
         // WHEN
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", moviesHeader.getAbsolutePath() + MULTI_FILE_DELIMITER + moviesPart1.getAbsolutePath() +
                         MULTI_FILE_DELIMITER + moviesPart2.getAbsolutePath(),
                 ""--nodes"", actorsHeader.getAbsolutePath() + MULTI_FILE_DELIMITER + actorsPart1.getAbsolutePath() +
@@ -360,7 +360,7 @@ public class ImportToolDocIT
         }
         // WHEN
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes:"" + join( new String[] { ""Movie"" }, "":"" ),
                     movies.getAbsolutePath(),
                 ""--nodes:"" + join( new String[] { ""Movie"", ""Sequel"" }, "":"" ),
@@ -416,7 +416,7 @@ public class ImportToolDocIT
         }
         // WHEN
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", movies.getAbsolutePath(),
                 ""--nodes"", actors.getAbsolutePath(),
                 ""--relationships:"" + join( new String[] { ""ACTED_IN"" }, "":"" ), roles.getAbsolutePath());
@@ -468,7 +468,7 @@ public class ImportToolDocIT
         }
         // WHEN
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", movies.getAbsolutePath(),
                 ""--nodes"", actors.getAbsolutePath(),
                 ""--relationships:"" + join( new String[] { ""ACTED_IN"" }, "":"" ), roles.getAbsolutePath());
@@ -523,7 +523,7 @@ public class ImportToolDocIT
         // WHEN
         File badFile = new File( directory.directory(), Configuration.BAD_FILE_NAME );
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", movies.getAbsolutePath(),
                 ""--nodes"", actors.getAbsolutePath(),
                 ""--relationships"", roles.getAbsolutePath() );
@@ -556,7 +556,7 @@ public class ImportToolDocIT
         // WHEN
         File badFile = new File( directory.directory(), Configuration.BAD_FILE_NAME );
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", actors.getAbsolutePath(),
                 ""--skip-duplicate-nodes"" );
         importTool( arguments );
@@ -604,7 +604,7 @@ public class ImportToolDocIT
 
         // WHEN
         String[] arguments = arguments(
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
                 ""--nodes"", movies.getAbsolutePath(),
                 ""--nodes"", actors.getAbsolutePath(),
                 ""--relationships"", roles.getAbsolutePath() );
@@ -698,8 +698,8 @@ public class ImportToolDocIT
         }
         String documentationArgs = StringUtils.join( cleanedArguments, "" "" );
         documentationArgs =
-                documentationArgs.replace( dir + File.separator, """" ).replace( directory.absolutePath(),
-                        ""path_to_target_directory"" );
+                documentationArgs.replace( dir + File.separator, """" ).replace(
+                        directory.absolutePath().getAbsolutePath(), ""path_to_target_directory"" );
         String docsCommand = ""neo4j-import "" + documentationArgs;
         try ( PrintStream out = new PrintStream( file( ""ops"", fileName ) ) )
         {
diff --git a/community/io/src/test/java/org/neo4j/test/TargetDirectory.java b/community/io/src/test/java/org/neo4j/test/TargetDirectory.java
index b090cf66fff..3cbd2edb4ee 100644
--- a/community/io/src/test/java/org/neo4j/test/TargetDirectory.java
+++ b/community/io/src/test/java/org/neo4j/test/TargetDirectory.java
@@ -73,9 +73,9 @@ public class TargetDirectory
             return this;
         }
 
-        public String absolutePath()
+        public File absolutePath()
         {
-            return directory().getAbsolutePath();
+            return directory().getAbsoluteFile();
         }
 
         public File directory()
diff --git a/community/kernel/src/main/java/org/neo4j/graphdb/factory/GraphDatabaseFactory.java b/community/kernel/src/main/java/org/neo4j/graphdb/factory/GraphDatabaseFactory.java
index 691af8c0e07..d10fb09ca4d 100644
--- a/community/kernel/src/main/java/org/neo4j/graphdb/factory/GraphDatabaseFactory.java
+++ b/community/kernel/src/main/java/org/neo4j/graphdb/factory/GraphDatabaseFactory.java
@@ -20,20 +20,16 @@
 package org.neo4j.graphdb.factory;
 
 import java.io.File;
-import java.util.List;
 import java.util.Map;
 
 import org.neo4j.graphdb.GraphDatabaseService;
-import org.neo4j.kernel.extension.KernelExtensionFactory;
+import org.neo4j.graphdb.security.URLAccessRule;
 import org.neo4j.kernel.impl.factory.CommunityFacadeFactory;
 import org.neo4j.kernel.impl.factory.Edition;
 import org.neo4j.kernel.impl.factory.GraphDatabaseFacadeFactory;
 import org.neo4j.kernel.monitoring.Monitors;
-import org.neo4j.graphdb.security.URLAccessRule;
 import org.neo4j.logging.LogProvider;
 
-import static java.util.Arrays.asList;
-
 /**
  * Creates a {@link org.neo4j.graphdb.GraphDatabaseService}.
  * <p>
@@ -64,32 +60,11 @@ public class GraphDatabaseFactory
         return new GraphDatabaseFactoryState( getCurrentState() );
     }
 
-    /**
-     * @deprecated use {@link #newEmbeddedDatabase(File)} instead.
-     * @param storeDir the location of the database
-     * @return the database
-     */
-    @Deprecated
-    public GraphDatabaseService newEmbeddedDatabase( String storeDir )
-    {
-        return newEmbeddedDatabase( new File( storeDir ) );
-    }
-
     public GraphDatabaseService newEmbeddedDatabase( File storeDir )
     {
         return newEmbeddedDatabaseBuilder( storeDir ).newGraphDatabase();
     }
 
-    /**
-     * @deprecated use {@link #newEmbeddedDatabaseBuilder(File)} instead
-     * @param storeDir the location of the database
-     * @return a builder which is used to configure and start a database
-     */
-    @Deprecated
-    public GraphDatabaseBuilder newEmbeddedDatabaseBuilder( String storeDir )
-    {
-        return newEmbeddedDatabaseBuilder( new File( storeDir ) );
-    }
 
     public GraphDatabaseBuilder newEmbeddedDatabaseBuilder( File storeDir )
     {
@@ -108,15 +83,10 @@ public class GraphDatabaseFactory
     protected GraphDatabaseBuilder.DatabaseCreator createDatabaseCreator(
             final File storeDir, final GraphDatabaseFactoryState state )
     {
-        return new GraphDatabaseBuilder.DatabaseCreator()
-        {
-            @Override
-            public GraphDatabaseService newDatabase( Map<String,String> config )
-            {
-                config.put( ""unsupported.dbms.ephemeral"", ""false"" );
-                GraphDatabaseFacadeFactory.Dependencies dependencies = state.databaseDependencies();
-                return GraphDatabaseFactory.this.newDatabase( storeDir, config, dependencies );
-            }
+        return config -> {
+            config.put( ""unsupported.dbms.ephemeral"", ""false"" );
+            GraphDatabaseFacadeFactory.Dependencies dependencies = state.databaseDependencies();
+            return GraphDatabaseFactory.this.newDatabase( storeDir, config, dependencies );
         };
     }
 
@@ -130,57 +100,6 @@ public class GraphDatabaseFactory
         return new CommunityFacadeFactory().newFacade( storeDir, config, dependencies );
     }
 
-    /**
-     * @deprecated Manipulating kernel extensions is deprecated and will be moved to internal components.
-     *
-     * @return kernel extensions
-     */
-    @Deprecated
-    public Iterable<KernelExtensionFactory<?>> getKernelExtension()
-    {
-        return getCurrentState().getKernelExtension();
-    }
-
-    /**
-     * @deprecated Manipulating kernel extensions is deprecated and will be moved to internal components.
-     *
-     * @param newKernelExtensions New kernel extensions to add
-     * @return the factory
-     */
-    @Deprecated
-    public GraphDatabaseFactory addKernelExtensions( Iterable<KernelExtensionFactory<?>> newKernelExtensions )
-    {
-        getCurrentState().addKernelExtensions( newKernelExtensions );
-        return this;
-    }
-
-    /**
-     * @deprecated Manipulating kernel extensions is deprecated and will be moved to internal components.
-     *
-     * @param newKernelExtension New kernel extension too add
-     * @return the factory
-     */
-    @Deprecated
-    @SuppressWarnings({""rawtypes"", ""unchecked""})
-    public GraphDatabaseFactory addKernelExtension( KernelExtensionFactory<?> newKernelExtension )
-    {
-        List extensions = asList( newKernelExtension );
-        return addKernelExtensions( extensions );
-    }
-
-    /**
-     * @deprecated Manipulating kernel extensions is deprecated and will be moved to internal components.
-     *
-     * @param newKernelExtensions New kernel extensions to set
-     * @return the factory
-     */
-    @Deprecated
-    public GraphDatabaseFactory setKernelExtensions( Iterable<KernelExtensionFactory<?>> newKernelExtensions )
-    {
-        getCurrentState().setKernelExtensions( newKernelExtensions );
-        return this;
-    }
-
     public GraphDatabaseFactory addURLAccessRule( String protocol, URLAccessRule rule )
     {
         getCurrentState().addURLAccessRule( protocol, rule );
diff --git a/community/kernel/src/main/java/org/neo4j/kernel/impl/util/dbstructure/DbStructureTool.java b/community/kernel/src/main/java/org/neo4j/kernel/impl/util/dbstructure/DbStructureTool.java
index 8ffb572de3e..bc7aa6b3d49 100644
--- a/community/kernel/src/main/java/org/neo4j/kernel/impl/util/dbstructure/DbStructureTool.java
+++ b/community/kernel/src/main/java/org/neo4j/kernel/impl/util/dbstructure/DbStructureTool.java
@@ -57,7 +57,7 @@ public class DbStructureTool
                 generatedClassWithPackage
         );
 
-        GraphDatabaseService graph = new GraphDatabaseFactory().newEmbeddedDatabase( dbDir );
+        GraphDatabaseService graph = new GraphDatabaseFactory().newEmbeddedDatabase( new File( dbDir ) );
         try
         {
             if ( writeToFile )
diff --git a/community/kernel/src/main/java/org/neo4j/kernel/internal/GraphDatabaseAPI.java b/community/kernel/src/main/java/org/neo4j/kernel/internal/GraphDatabaseAPI.java
index 2101f7638d9..3dda0f100a9 100644
--- a/community/kernel/src/main/java/org/neo4j/kernel/internal/GraphDatabaseAPI.java
+++ b/community/kernel/src/main/java/org/neo4j/kernel/internal/GraphDatabaseAPI.java
@@ -48,6 +48,5 @@ public interface GraphDatabaseAPI extends GraphDatabaseService
      */
     URL validateURLAccess( URL url ) throws URLAccessValidationError;
 
-    @Deprecated
     String getStoreDir();
 }
diff --git a/community/kernel/src/main/java/org/neo4j/unsafe/batchinsert/BatchInserters.java b/community/kernel/src/main/java/org/neo4j/unsafe/batchinsert/BatchInserters.java
index 2c4c6bb7cf0..bf3f6b9927e 100644
--- a/community/kernel/src/main/java/org/neo4j/unsafe/batchinsert/BatchInserters.java
+++ b/community/kernel/src/main/java/org/neo4j/unsafe/batchinsert/BatchInserters.java
@@ -35,19 +35,6 @@ import static org.neo4j.helpers.collection.MapUtil.stringMap;
  */
 public final class BatchInserters
 {
-    /**
-     * Get a {@link BatchInserter} given a store directory.
-     *
-     * @param storeDir the store directory
-     * @return a new {@link BatchInserter}
-     * @deprecated use {@link #inserter(File)} instead
-     */
-    @Deprecated
-    public static BatchInserter inserter( String storeDir )
-    {
-        return inserter( storeDir, stringMap() );
-    }
-
     /**
      * Get a {@link BatchInserter} given a store directory.
      *
@@ -57,21 +44,12 @@ public final class BatchInserters
      */
     public static BatchInserter inserter( File storeDir ) throws IOException
     {
-        return inserter( storeDir, new DefaultFileSystemAbstraction(), stringMap() );
+        return inserter( storeDir, stringMap() );
     }
 
-    /**
-     * Get a {@link BatchInserter} given a store directory.
-     *
-     * @param storeDir the store directory
-     * @param config configuration settings to use
-     * @return a new {@link BatchInserter}
-     * @deprecated use {@link #inserter(File, Map)} instead
-     */
-    @Deprecated
-    public static BatchInserter inserter( String storeDir, Map<String,String> config )
+    public static BatchInserter inserter( File storeDir, FileSystemAbstraction fs ) throws IOException
     {
-        return inserter( storeDir, new DefaultFileSystemAbstraction(), config );
+        return inserter( storeDir, fs, stringMap(), (Iterable) Service.load( KernelExtensionFactory.class )  );
     }
 
     /**
@@ -84,96 +62,15 @@ public final class BatchInserters
      */
     public static BatchInserter inserter( File storeDir, Map<String,String> config ) throws IOException
     {
-        return inserter( storeDir, new DefaultFileSystemAbstraction(), config );
+        return inserter( storeDir, new DefaultFileSystemAbstraction(), config, (Iterable) Service.load( KernelExtensionFactory.class ) );
     }
 
-    /**
-     * @deprecated use {@link #inserter(File)} instead
-     * @param storeDir the store directory
-     * @param fileSystem the file system abstraction to use
-     * @return a new {@link BatchInserter}
-     */
-    @Deprecated
-    public static BatchInserter inserter( String storeDir, FileSystemAbstraction fileSystem )
-    {
-        return inserter( storeDir, fileSystem, stringMap() );
-    }
 
-    /**
-     * Get a {@link BatchInserter} given a store directory.
-     *
-     * @param storeDir the store directory
-     * @param fileSystem the file system abstraction to use
-     * @return a new {@link BatchInserter}
-     * @deprecated use {@link #inserter(File)} instead
-     * @throws IOException if there is an IO error
-     */
-    @Deprecated
-    public static BatchInserter inserter( File storeDir, FileSystemAbstraction fileSystem ) throws IOException
+    public static BatchInserter inserter( File storeDir, FileSystemAbstraction fs, Map<String,String> config ) throws IOException
     {
-        return inserter( storeDir, fileSystem, stringMap() );
+        return inserter( storeDir, fs, config, (Iterable) Service.load( KernelExtensionFactory.class )  );
     }
 
-    /**
-     * @deprecated use {@link #inserter(File, Map)} instead
-     * @param storeDir the store directory
-     * @param fileSystem the file system abstraction to use
-     * @param config configuration settings to use
-     * @return a new {@link BatchInserter}
-     */
-    @Deprecated
-    public static BatchInserter inserter( String storeDir, FileSystemAbstraction fileSystem,
-            Map<String,String> config )
-    {
-        try
-        {
-            return inserter( new File( storeDir ), fileSystem, config );
-        }
-        catch ( IOException e )
-        {
-            throw new RuntimeException( e );
-        }
-    }
-
-    /**
-     * Get a {@link BatchInserter} given a store directory.
-     *
-     * @param storeDir the store directory
-     * @param fileSystem the file system abstraction to use
-     * @param config configuration settings to use
-     * @return a new {@link BatchInserter}
-     * @deprecated use {@link #inserter(File, Map)} instead
-     * @throws IOException if there is",Remove deprecated methods from GraphDatabaseFactory,"""Remove deprecated methods and replace string paths with File objects""","The commit message should be:

""Convert all String paths to File paths in various places""

This commit message accurately reflects the changes made in the code, which involve replacing String paths with File paths in various places.","This commit updates several files in the Neo4j codebase to use the `File` object instead of a `String` to represent file paths. This change affects the following files:

* `ExecutionEngineTest.scala`
* `IndexOpAcceptanceTest.scala`
* `CompilerComparisonTest.scala`
* `DataImportTest.scala`
* `PerformanceTest.scala`
* `AStarPerformanceIT.java`
* `Script.java`
* `ImportToolDocIT.java`
* `TargetDirectory.java`
* `GraphDatabaseFactory.java`
* `DbStructureTool.java`
* `BatchInserters.java`

In general, the changes involve replacing `String` representations of file paths with `File` objects, and updating methods that accept or return file paths to use `File` objects instead of `String`s. This change may have been made to improve the consistency and robustness of the codebase, as `File` objects provide more functionality and error checking than `String` representations of file paths.

For example, in `ExecutionEngineTest.scala`, the `createReadOnlyEngine()` method is updated to use a `File` object to represent the database directory:
```
-    val old = new TestGraphDatabaseFactory().newEmbeddedDatabase(""target/readonly"")
+    val old = new TestGraphDatabaseFactory().newEmbeddedDatabase( new File( ""target/readonly"" ) )
```
Similarly, in `IndexOpAcceptanceTest.scala`, the `createDbWithFailedIndex` method is updated to use a `File` object to represent the database directory:
```
-    graph = new GraphDatabaseCypherService(new TestGraphDatabaseFactory().newEmbeddedDatabase(""target/test-data/impermanent-db""))
+    graph = new GraphDatabaseCypherService(new TestGraphDatabaseFactory().newEmbeddedDatabase(storeDir))
```
In `CompilerComparisonTest.scala`, the `executionResults` method is updated to use a `File` object to represent the database directory:
```
-    val db = new GraphDatabaseCypherService(new GraphDatabaseFactory().newEmbeddedDatabase(dataSetDir))
+    val db = new GraphDatabaseCypherService(new GraphDatabaseFactory().newEmbeddedDatabase(new File(dataSetDir)))
```
In `DataImportTest.scala`, the `createInserters()` method is updated to use a `File` object to represent the database directory:
```
-  private def createInserters(targetDir: String) = {
+  private def createInserters(targetDir: File) = {
```
In `PerformanceTest.scala`, the `beforeEach()` method is updated to use a `File` object to represent the database directory:
```
-    db = new GraphDatabaseFactory().newEmbeddedDatabase(""target/db"")
+    db = new GraphDatabaseFactory().newEmbeddedDatabase(new File(""target/db""))
```
In `AStarPerformanceIT.java`, the `setUp()` method is updated to use a `File` object to represent the database directory:
```
-        GraphDatabaseService db = new GraphDatabaseFactory().newEmbeddedDatabase( directory.getAbsolutePath() );
+        GraphDatabaseService db = new GraphDatabaseFactory().newEmbeddedDatabase( directory.getAbsoluteFile() );
```
In `Script.java`, the `storeDir` field is changed from a `String` to a `File`, and the `storeDir()` method is updated to return a `File` object:
```
-    protected String storeDir;
+    protected File storeDir;

     ...

-    protected String storeDir()
+    protected File storeDir()
     {
         return storeDir;
     }
```
In `ImportToolDocIT.java`, several methods are updated to use `File` objects to represent file paths:
```
-                ""--into"", directory.absolutePath(),
+                ""--into"", directory.absolutePath().getAbsolutePath(),
```
In `TargetDirectory.java`, the `absolutePath()` method is updated to return a `File` object instead of a `String`:
```
-        public String absolutePath()
+        public File absolutePath()
         {
```","""Refactor: Replace string path with File objects across various Neo4j test and core classes for better file handling consistency.""",Model 1
"diff --git a/modules/activiti-engine/src/test/java/org/activiti/engine/test/api/runtime/RuntimeServiceTest.java b/modules/activiti-engine/src/test/java/org/activiti/engine/test/api/runtime/RuntimeServiceTest.java
index 29707dbc86..fab9ced37f 100644
--- a/modules/activiti-engine/src/test/java/org/activiti/engine/test/api/runtime/RuntimeServiceTest.java
+++ b/modules/activiti-engine/src/test/java/org/activiti/engine/test/api/runtime/RuntimeServiceTest.java
@@ -219,6 +219,86 @@ public class RuntimeServiceTest extends PluggableActivitiTestCase {
     }
   }
   
+  /**
+   * Testcase to reproduce ACT-950 (https://jira.codehaus.org/browse/ACT-950) 
+   */
+  @Deployment
+  public void testFindActiveActivityIdProcessWithErrorEventAndSubProcess() {
+    ProcessInstance processInstance = processEngine.getRuntimeService().startProcessInstanceByKey(""errorEventSubprocess"");
+    
+    List<String> activeActivities = runtimeService.getActiveActivityIds(processInstance.getId());
+    assertEquals(3, activeActivities.size());
+    
+    List<Task> tasks = taskService.createTaskQuery().list();
+    assertEquals(2, tasks.size());
+    
+    Task parallelUserTask = null;
+    for (Task task : tasks) {
+      if (!task.getName().equals(""ParallelUserTask"") && !task.getName().equals(""MainUserTask"")) {
+        fail(""Expected: <ParallelUserTask> or <MainUserTask> but was <"" + task.getName() + "">."");
+      }
+      if (task.getName().equals(""ParallelUserTask"")) {
+        parallelUserTask = task;
+      }
+    }
+    assertNotNull(parallelUserTask);
+
+    taskService.complete(parallelUserTask.getId());
+    
+    Execution execution = runtimeService.createExecutionQuery().processInstanceId(processInstance.getId()).activityId(""subprocess1WaitBeforeError"").singleResult();
+    runtimeService.signal(execution.getId());
+    
+    activeActivities = runtimeService.getActiveActivityIds(processInstance.getId());
+    assertEquals(2, activeActivities.size());
+    
+    tasks = taskService.createTaskQuery().list();
+    assertEquals(2, tasks.size());
+    
+    Task beforeErrorUserTask = null;
+    for (Task task : tasks) {
+      if (!task.getName().equals(""BeforeError"") && !task.getName().equals(""MainUserTask"")) {
+        fail(""Expected: <BeforeError> or <MainUserTask> but was <"" + task.getName() + "">."");
+      }
+      if (task.getName().equals(""BeforeError"")) {
+        beforeErrorUserTask = task;
+      }
+    }
+    assertNotNull(beforeErrorUserTask);
+    
+    taskService.complete(beforeErrorUserTask.getId());
+    
+    activeActivities = runtimeService.getActiveActivityIds(processInstance.getId());
+    assertEquals(2, activeActivities.size());
+    
+    tasks = taskService.createTaskQuery().list();
+    assertEquals(2, tasks.size());
+
+    Task afterErrorUserTask = null;
+    for (Task task : tasks) {
+      if (!task.getName().equals(""AfterError"") && !task.getName().equals(""MainUserTask"")) {
+        fail(""Expected: <AfterError> or <MainUserTask> but was <"" + task.getName() + "">."");
+      }
+      if (task.getName().equals(""AfterError"")) {
+        afterErrorUserTask = task;
+      }
+    }
+    assertNotNull(afterErrorUserTask);
+    
+    taskService.complete(afterErrorUserTask.getId());
+    
+    tasks = taskService.createTaskQuery().list();
+    assertEquals(1, tasks.size());
+    assertEquals(""MainUserTask"", tasks.get(0).getName());
+    
+    activeActivities = runtimeService.getActiveActivityIds(processInstance.getId());
+    assertEquals(1, activeActivities.size());
+    assertEquals(""MainUserTask"", activeActivities.get(0));
+    
+    taskService.complete(tasks.get(0).getId());
+    
+    assertProcessEnded(processInstance.getId());
+  }
+  
   public void testSignalUnexistingExecututionId() {
     try {
       runtimeService.signal(""unexistingExecutionId"");      
diff --git a/modules/activiti-engine/src/test/resources/org/activiti/engine/test/api/runtime/RuntimeServiceTest.testFindActiveActivityIdProcessWithErrorEventAndSubProcess.bpmn20.xml b/modules/activiti-engine/src/test/resources/org/activiti/engine/test/api/runtime/RuntimeServiceTest.testFindActiveActivityIdProcessWithErrorEventAndSubProcess.bpmn20.xml
new file mode 100644
index 0000000000..0650b280d8
--- /dev/null
+++ b/modules/activiti-engine/src/test/resources/org/activiti/engine/test/api/runtime/RuntimeServiceTest.testFindActiveActivityIdProcessWithErrorEventAndSubProcess.bpmn20.xml
@@ -0,0 +1,76 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<definitions id=""definitions"" xmlns=""http://www.omg.org/spec/BPMN/20100524/MODEL""
+  xmlns:activiti=""http://activiti.org/bpmn"" targetNamespace=""Examples"">
+
+  <process id=""errorEventSubprocess"" name=""ErrorEventSubprocess"">
+  
+    <startEvent id=""startevent1"" name=""Start"" />
+    
+    <subProcess id=""subprocess1"" name=""Sub Process"">
+    
+      <startEvent id=""subprocess1startevent2"" name=""Start"" />
+      
+      <sequenceFlow id=""subprocess1flow2"" name="""" sourceRef=""subprocess1startevent2"" targetRef=""subprocess1parallelgateway1"" />
+      
+      <parallelGateway id=""subprocess1parallelgateway1"" name=""Parallel Gateway"" />
+      
+      <userTask id=""subprocess1ParallelUserTask"" name=""ParallelUserTask"" activiti:assignee=""user1"" />
+      
+      <sequenceFlow id=""subprocess1flow3"" name="""" sourceRef=""subprocess1parallelgateway1"" targetRef=""subprocess1ParallelUserTask"" />
+      
+      <endEvent id=""subprocess1endevent1"" name=""ErrorEnd"">
+        <errorEventDefinition errorRef=""err1"" />
+      </endEvent>
+      
+      <endEvent id=""subprocess1endevent2"" name=""End"" />
+      
+      <sequenceFlow id=""subprocess1flow6"" name="""" sourceRef=""subprocess1ParallelUserTask"" targetRef=""subprocess1endevent2"" />
+      
+      <receiveTask id=""subprocess1WaitBeforeError"" name=""WaitBeforeError""/>
+      
+      <sequenceFlow id=""subprocess1flow9"" name="""" sourceRef=""subprocess1parallelgateway1"" targetRef=""subprocess1WaitBeforeError"" />
+      
+      <userTask id=""subprocess1BeforeError"" name=""BeforeError"" />
+      
+      <sequenceFlow id=""subprocess1flow10"" name="""" sourceRef=""subprocess1WaitBeforeError"" targetRef=""subprocess1BeforeError"" />
+      
+      <sequenceFlow id=""subprocess1flow11"" name="""" sourceRef=""subprocess1BeforeError"" targetRef=""subprocess1endevent1""/>
+      
+    </subProcess>
+    
+    <sequenceFlow id=""flow1"" name="""" sourceRef=""startevent1"" targetRef=""parallelgateway2"" />
+    
+    <endEvent id=""EndSuccess"" name=""EndSuccess"" />
+    
+    <userTask id=""AfterSuccess"" name=""AfterSuccess"" />
+    
+    <sequenceFlow id=""flow12"" name="""" sourceRef=""subprocess1"" targetRef=""AfterSuccess"" />
+    
+    <sequenceFlow id=""flow13"" name="""" sourceRef=""AfterSuccess"" targetRef=""EndSuccess"" />
+    
+    <boundaryEvent id=""boundaryerror1"" attachedToRef=""subprocess1"">
+      <errorEventDefinition errorRef=""err1"" />
+    </boundaryEvent>
+    
+    <userTask id=""AfterError"" name=""AfterError"" />
+    
+    <sequenceFlow id=""flow14"" name="""" sourceRef=""boundaryerror1"" targetRef=""AfterError"" />
+    
+    <endEvent id=""EndError"" name=""EndError"" />
+    
+    <sequenceFlow id=""flow15"" name="""" sourceRef=""AfterError"" targetRef=""EndError"" />
+    
+    <parallelGateway id=""parallelgateway2"" name=""Parallel Gateway"" />
+    
+    <sequenceFlow id=""flow16"" name="""" sourceRef=""parallelgateway2"" targetRef=""subprocess1"" />
+    
+    <userTask id=""MainUserTask"" name=""MainUserTask"" activiti:assignee=""user1"" />
+    
+    <sequenceFlow id=""flow17"" name="""" sourceRef=""parallelgateway2"" targetRef=""MainUserTask"" />
+    
+    <endEvent id=""EndMainUserTask"" name=""EndMainUserTask"" />
+    
+    <sequenceFlow id=""flow18"" name="""" sourceRef=""MainUserTask"" targetRef=""EndMainUserTask""/>
+  </process>
+
+</definitions>
\ No newline at end of file",Added testcase for Issue ACT - 950,"""Added test case for ACT-950: Find active activity id process with error event and sub process""","""Added test case for ACT-950: Find active activity IDs in a process with error event and sub-process""","""Added test case for reproducing ACT-950 (<https://jira.codehaus.org/browse/ACT-950>) and corresponding BPMN file.""

The commit adds a new test case to the `RuntimeServiceTest` class to reproduce the issue described in ACT-950. The test case starts a process instance of the process defined in the `RuntimeServiceTest.testFindActiveActivityIdProcessWithErrorEventAndSubProcess.bpmn20.xml` file, which is also added in this commit. The test case then checks that the process behaves as expected when an error event occurs in a subprocess.",Add test to reproduce ACT-950 with error event and subprocess. Include BPMN XML for the process definition.,Model 2
"diff --git a/motan-extension/protocol-extension/motan-protocol-grpc/pom.xml b/motan-extension/protocol-extension/motan-protocol-grpc/pom.xml
index 09d4079..02db166 100644
--- a/motan-extension/protocol-extension/motan-protocol-grpc/pom.xml
+++ b/motan-extension/protocol-extension/motan-protocol-grpc/pom.xml
@@ -14,7 +14,7 @@
     <parent>
         <groupId>com.weibo</groupId>
         <artifactId>protocol-extension</artifactId>
-        <version>0.2.2-SNAPSHOT</version>
+        <version>0.2.3-SNAPSHOT</version>
     </parent>
     <artifactId>motan-protocol-grpc</artifactId>
     <name>motan-protocol-grpc</name>",update version,"""Bump motan-protocol-grpc parent version to 0.2.3-SNAPSHOT""","""Update motan-protocol-grpc parent version to 0.2.3-SNAPSHOT""","""Update motan-protocol-grpc pom.xml parent version from 0.2.2-SNAPSHOT to 0.2.3-SNAPSHOT""",Update motan-protocol-grpc version from 0.2.2-SNAPSHOT to 0.2.3-SNAPSHOT in pom.xml,Model 4
"diff --git a/api/src/main/java/org/geysermc/api/Geyser.java b/api/src/main/java/org/geysermc/api/Geyser.java
index 4bb13a41..37099339 100644
--- a/api/src/main/java/org/geysermc/api/Geyser.java
+++ b/api/src/main/java/org/geysermc/api/Geyser.java
@@ -30,10 +30,6 @@ import org.geysermc.api.logger.Logger;
 import org.geysermc.api.plugin.PluginManager;
 
 import java.util.Collection;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Objects;
-import java.util.UUID;
 import java.util.concurrent.ScheduledExecutorService;
 
 public class Geyser {
diff --git a/connector/src/main/java/org/geysermc/connector/network/translators/item/ItemTranslator.java b/connector/src/main/java/org/geysermc/connector/network/translators/item/ItemTranslator.java
index 9bf5d3c4..437a8dc4 100644
--- a/connector/src/main/java/org/geysermc/connector/network/translators/item/ItemTranslator.java
+++ b/connector/src/main/java/org/geysermc/connector/network/translators/item/ItemTranslator.java
@@ -85,7 +85,7 @@ public class ItemTranslator {
     }
 
     public ItemEntry getItem(ItemData data) {
-        for (ItemEntry itemEntry : Toolbox.ITEM_ENTRIES.values()) {
+        for (ItemEntry itemEntry : Toolbox.ITEM_ENTRIES.valueCollection()) {
             if (itemEntry.getBedrockId() == data.getId() && itemEntry.getBedrockData() == data.getDamage()) {
                 return itemEntry;
             }
diff --git a/connector/src/main/java/org/geysermc/connector/utils/Toolbox.java b/connector/src/main/java/org/geysermc/connector/utils/Toolbox.java
index be32ada7..4aee4d70 100644
--- a/connector/src/main/java/org/geysermc/connector/utils/Toolbox.java
+++ b/connector/src/main/java/org/geysermc/connector/utils/Toolbox.java
@@ -4,6 +4,8 @@ import com.fasterxml.jackson.databind.ObjectMapper;
 import com.nukkitx.network.VarInts;
 import com.nukkitx.protocol.bedrock.packet.StartGamePacket;
 import com.nukkitx.protocol.bedrock.v361.BedrockUtils;
+import gnu.trove.map.TIntObjectMap;
+import gnu.trove.map.hash.TIntObjectHashMap;
 import io.netty.buffer.ByteBuf;
 import io.netty.buffer.Unpooled;
 import org.geysermc.connector.console.GeyserLogger;
@@ -19,8 +21,8 @@ public class Toolbox {
     public static final Collection<StartGamePacket.ItemEntry> ITEMS;
     public static final ByteBuf CACHED_PALLETE;
 
-    public static final Map<Integer, ItemEntry> ITEM_ENTRIES;
-    public static final Map<Integer, BlockEntry> BLOCK_ENTRIES;
+    public static final TIntObjectMap<ItemEntry> ITEM_ENTRIES;
+    public static final TIntObjectMap<BlockEntry> BLOCK_ENTRIES;
 
     static {
         InputStream stream = Toolbox.class.getClassLoader().getResourceAsStream(""bedrock/cached_palette.json"");
@@ -79,7 +81,7 @@ public class Toolbox {
             ex.printStackTrace();
         }
 
-        Map<Integer, ItemEntry> itemEntries = new HashMap<>();
+        TIntObjectMap<ItemEntry> itemEntries = new TIntObjectHashMap<>();
         int itemIndex = 0;
 
         for (Map.Entry<String, Map<String, Object>> itemEntry : items.entrySet()) {
@@ -87,7 +89,7 @@ public class Toolbox {
             itemIndex++;
         }
 
-        ITEM_ENTRIES = Collections.unmodifiableMap(itemEntries);
+        ITEM_ENTRIES = itemEntries;
 
         InputStream blockStream = Toolbox.class.getClassLoader().getResourceAsStream(""blocks.json"");
         ObjectMapper blockMapper = new ObjectMapper();
@@ -99,7 +101,7 @@ public class Toolbox {
             ex.printStackTrace();
         }
 
-        Map<Integer, BlockEntry> blockEntries = new HashMap<>();
+        TIntObjectMap<BlockEntry> blockEntries = new TIntObjectHashMap<>();
         int blockIndex = 0;
 
         for (Map.Entry<String, Map<String, Object>> itemEntry : blocks.entrySet()) {
@@ -113,6 +115,6 @@ public class Toolbox {
             blockIndex++;
         }
 
-        BLOCK_ENTRIES = Collections.unmodifiableMap(blockEntries);
+        BLOCK_ENTRIES = blockEntries;
     }
 }
\ No newline at end of file",Convert item and block maps in Toolbox to TIntObjectMaps,"""Replace HashMap with TIntObjectHashMap in Toolbox for improved performance""","""Switched from using Java's built-in `Map` and `HashMap` to Trove's `TIntObjectMap` for improved performance.""","""Refactor Geyser and Toolbox classes to use Trove's TIntObjectMap instead of HashMap for ITEM_ENTRIES and BLOCK_ENTRIES""

This commit appears to refactor the `Geyser` and `Toolbox` classes to use the `TIntObjectMap` class from the Trove library instead of `HashMap` for the `ITEM_ENTRIES` and `BLOCK_ENTRIES` fields. The `TIntObjectMap` class is a specialized map implementation for mapping integers to objects, which may offer better performance or memory usage than `HashMap` in certain situations.

In `Geyser.java`, the import for `java.util.Map` and the declaration of `ITEM_ENTRIES` as a `Map` have been removed.

In `Toolbox.java`, the imports for `java.util.Map` and `java.util.HashMap` have been replaced with imports for `gnu.trove.map.TIntObjectMap` and `gnu.trove.map.hash.TIntObjectHashMap`. The declarations of `ITEM_ENTRIES` and `BLOCK_ENTRIES` have also been changed to use `TIntObjectMap` instead of `Map`. The initialization of `ITEM_ENTRIES` and `BLOCK_ENTRIES` has been changed to use the `TIntObjectHashMap` constructor instead of the `HashMap` constructor.

Additionally, in `ItemTranslator.java`, the loop that iterates over `ITEM_ENTRIES` has been updated to use the `valueCollection()` method instead of `values()`. This is likely because `TIntObjectMap` does not have a `values()` method, but it does have a `valueCollection()` method that returns a collection of the map's values.","""Refactor data structures to use TIntObjectMap for performance improvements in Toolbox class.""",Model 4
"diff --git a/nashorn/make/build.xml b/nashorn/make/build.xml
index 93342248de5..78a713bfc46 100644
--- a/nashorn/make/build.xml
+++ b/nashorn/make/build.xml
@@ -282,6 +282,11 @@ grant codeBase ""file:/${basedir}/test/script/trusted/*"" {
     permission java.security.AllPermission;
 };
 
+grant codeBase ""file:/${basedir}/test/script/maptests/*"" {
+    permission java.io.FilePermission ""${basedir}/test/script/maptests/*"",""read"";
+    permission java.lang.RuntimePermission ""nashorn.debugMode"";
+};
+
 grant codeBase ""file:/${basedir}/test/script/basic/*"" {
     permission java.io.FilePermission ""${basedir}/test/script/-"", ""read"";
     permission java.io.FilePermission ""$${user.dir}"", ""read"";
diff --git a/nashorn/make/project.properties b/nashorn/make/project.properties
index ad36744836b..d51e72e4180 100644
--- a/nashorn/make/project.properties
+++ b/nashorn/make/project.properties
@@ -115,6 +115,7 @@ run.classpath=\
 test.dir=test
 test.script.dir=test/script
 test.basic.dir=test/script/basic
+test.maptests.dir=test/script/maptests
 test.error.dir=test/script/error
 test.sandbox.dir=test/script/sandbox
 test.trusted.dir=test/script/trusted
@@ -125,7 +126,7 @@ testjfx.dir=${test.script.dir}/jfx
 testmarkdown.dir=${test.script.dir}/markdown
 
 test-sys-prop.test.dir=${test.dir}
-test-sys-prop.test.js.roots=${test.basic.dir} ${test.error.dir} ${test.sandbox.dir} ${test.trusted.dir}
+test-sys-prop.test.js.roots=${test.basic.dir} ${test.maptests.dir} ${test.error.dir} ${test.sandbox.dir} ${test.trusted.dir}
 test-sys-prop.test262.suite.dir=${test262.suite.dir}
 test-sys-prop.es5conform.testcases.dir=${test.external.dir}/ES5Conform/TestCases
 test-sys-prop.test.basic.dir=${test.basic.dir}
@@ -278,7 +279,7 @@ run.test.jvmargs.octane.main=${run.test.jvmargs.common}
 run.test.jvmsecurityargs=-Xverify:all -Djava.security.manager -Djava.security.policy=${basedir}/build/nashorn.policy
 
 # VM options for script tests with @fork option
-test-sys-prop.test.fork.jvm.options=${run.test.jvmargs.main} -Xmx${run.test.xmx} ${run.test.jvmsecurityargs}
+test-sys-prop.test.fork.jvm.options=${run.test.jvmargs.main} -Xmx${run.test.xmx} ${run.test.jvmsecurityargs} -cp ${run.test.classpath}
 
 # path of rhino.jar for benchmarks
 rhino.jar=
diff --git a/nashorn/test/script/currently-failing/gettersetter.js b/nashorn/test/script/currently-failing/gettersetter.js
new file mode 100644
index 00000000000..88f6949233c
--- /dev/null
+++ b/nashorn/test/script/currently-failing/gettersetter.js
@@ -0,0 +1,48 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @test
+ * @option -Dnashorn.debug=true
+ * @fork
+ */
+
+load(__DIR__ + ""maputil.js"");
+
+function Foo() {
+    return {
+       get foo() { return 42; },
+       set foo(x) {}
+    }
+}
+
+var obj1 = Foo();
+var obj2 = Foo();
+
+assertSameMap(obj1, obj2, ""Object literals before change"");
+
+Object.defineProperty(obj2, ""foo"", { get: function() { return 'hello' } });
+assertSameMap(obj1, obj2);
+
+Object.defineProperty(obj2, ""foo"", { set: function(x) { print(x) } });
+assertSameMap(obj1, obj2);
diff --git a/nashorn/test/script/maptests/builtins.js b/nashorn/test/script/maptests/builtins.js
new file mode 100644
index 00000000000..4de2ec9a8da
--- /dev/null
+++ b/nashorn/test/script/maptests/builtins.js
@@ -0,0 +1,58 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @test
+ * @option -Dnashorn.debug=true
+ * @fork
+ */
+
+load(__DIR__ + ""maputil.js"");
+
+// check that builtin objects share property map
+
+assertSameMap(new Boolean(true), new Boolean(false));
+assertSameMap(new Number(3), new Number(Math.PI));
+assertSameMap(new String('hello'), new String('world'));
+assertSameMap(new Object(), new Object());
+assertSameMap(/hello/, /world/);
+// try w/without regexp flags
+assertSameMap(/hello/i, /world/g);
+assertSameMap(new Date(), new Date());
+assertSameMap(new Date(2000, 1, 1), new Date(1972, 5, 6));
+assertSameMap(Function(), Function());
+assertSameMap(Function(""x"", ""return x""), Function(""x"", ""return x*x""));
+assertSameMap(new Error(), new Error());
+assertSameMap(new Error('foo'), new Error('bar'));
+assertSameMap(new EvalError(), new EvalError());
+assertSameMap(new EvalError('foo'), new EvalError('bar'));
+assertSameMap(new RangeError(), new RangeError());
+assertSameMap(new RangeError('foo'), new RangeError('bar'));
+assertSameMap(new ReferenceError(), new ReferenceError());
+assertSameMap(new ReferenceError('foo'), new ReferenceError('bar'));
+assertSameMap(new SyntaxError(), new SyntaxError());
+assertSameMap(new SyntaxError('foo'), new SyntaxError('bar'));
+assertSameMap(new TypeError(), new TypeError());
+assertSameMap(new TypeError('foo'), new TypeError('bar'));
+assertSameMap(new URIError(), new URIError());
+assertSameMap(new URIError('foo'), new URIError('bar'));
diff --git a/nashorn/test/script/maptests/constructor.js b/nashorn/test/script/maptests/constructor.js
new file mode 100644
index 00000000000..5722a3c15b9
--- /dev/null
+++ b/nashorn/test/script/maptests/constructor.js
@@ -0,0 +1,36 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @test
+ * @option -Dnashorn.debug=true
+ * @fork
+ */
+
+load(__DIR__ + ""point.js"");
+
+// use constructor defined in a different script file
+// These objects should share the map
+assertSameMap(new Point(2, 3), new Point(43, 23));
+assertSameMap(new Point(), new Point());
+assertSameMap(new Point(), new Point(3, 1));
diff --git a/nashorn/test/script/maptests/maputil.js b/nashorn/test/script/maptests/maputil.js
new file mode 100644
index 00000000000..aa85d7f1220
--- /dev/null
+++ b/nashorn/test/script/maptests/maputil.js
@@ -0,0 +1,38 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @subtest
+ */
+
+function assertSameMap(obj1, obj2, msg) {
+    if (! Debug.identical(Debug.map(obj1), Debug.map(obj2))) {
+        fail(obj1.constructor + "" instances don't share map"");
+    }
+}
+
+function assertNotSameMap(obj1, obj2, msg) {
+    if (Debug.identical(Debug.map(obj1), Debug.map(obj2))) {
+        fail(obj1.constructor + "" and "" + obj2.constructor + "" instances share map"");
+    }
+}
diff --git a/nashorn/test/script/maptests/object_create.js b/nashorn/test/script/maptests/object_create.js
new file mode 100644
index 00000000000..1b1bd604c85
--- /dev/null
+++ b/nashorn/test/script/maptests/object_create.js
@@ -0,0 +1,40 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @test
+ * @option -Dnashorn.debug=true
+ * @fork
+ */
+
+load(__DIR__ + ""maputil.js"");
+
+// Objects created by Object.create
+var obj1 = Object.create(Object.prototype);
+var obj2 = Object.create(Object.prototype);
+assertSameMap(obj1, obj2);
+
+var proto = { foo: 233 };
+obj1 = Object.create(proto);
+obj2 = Object.create(proto);
+assertSameMap(obj1, obj2);
diff --git a/nashorn/test/script/maptests/object_literals.js b/nashorn/test/script/maptests/object_literals.js
new file mode 100644
index 00000000000..c73d80140c7
--- /dev/null
+++ b/nashorn/test/script/maptests/object_literals.js
@@ -0,0 +1,46 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @test
+ * @option -Dnashorn.debug=true
+ * @fork
+ */
+
+load(__DIR__ + ""maputil.js"");
+
+// Object literals created at the same callsite
+function makeObject() {
+    return { foo: 34 }
+}
+assertSameMap(makeObject(), makeObject());
+
+function makeObject2() {
+    return { foo: 42, bar: 'hello' }
+}
+assertSameMap(makeObject2(), makeObject2());
+
+// Object literals created at different callsites
+assertSameMap({}, {});
+assertSameMap({foo: 4}, {foo: 'hello'});
+assertSameMap({foo: 34, bar: 'fdgd'}, {foo: 'world', bar: 54});
diff --git a/nashorn/test/script/maptests/point.js b/nashorn/test/script/maptests/point.js
new file mode 100644
index 00000000000..38b8fa2513a
--- /dev/null
+++ b/nashorn/test/script/maptests/point.js
@@ -0,0 +1,49 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+
+/**
+ * @subtest
+ */
+
+function Point(x, y) {
+   this.x =x; this.y =y;
+}
+
+Point.prototype.toString = function() {
+    return ""("" + this.x + "","" + this.y + "")"";
+}
+
+Point.prototype.modulus = function() {
+    return Math.sqrt(this.x*this.x + this.y*this.y);
+}
+
+Point.prototype.argument = function() {
+    return Math.atan2(this.y, this.x);
+}
+
+load(__DIR__ + ""maputil.js"");
+
+assertSameMap(new Point(2, 3), new Point(43, 23));
+assertSameMap(new Point(), new Point());
+assertSameMap(new Point(), new Point(3, 1));
diff --git a/nashorn/test/script/maptests/property_add.js b/nashorn/test/script/maptests/property_add.js
new file mode 100644
index 00000000000..2026455459d
--- /dev/null
+++ b/nashorn/test/script/maptests/property_add.js
@@ -0,0 +1,46 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @test
+ * @option -Dnashorn.debug=true
+ * @fork
+ */
+
+load(__DIR__ + ""maputil.js"");
+
+function Foo() {}
+
+var obj1 = new Foo();
+var obj2 = new Foo();
+
+assertSameMap(obj1, obj2);
+
+// property addition at same callsite
+function addX(obj, val) {
+   obj.x = val;
+}
+addX(obj1, 3);
+addX(obj2, 'hello');
+
+assertSameMap(obj1, obj2);
diff --git a/nashorn/test/script/maptests/property_delete.js b/nashorn/test/script/maptests/property_delete.js
new file mode 100644
index 00000000000..e2824dd6315
--- /dev/null
+++ b/nashorn/test/script/maptests/property_delete.js
@@ -0,0 +1,48 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @test
+ * @option -Dnashorn.debug=true
+ * @fork
+ */
+
+load(__DIR__ + ""maputil.js"");
+
+function Foo() {
+    this.x = 33;
+}
+
+var obj1 = new Foo();
+var obj2 = new Foo();
+
+assertSameMap(obj1, obj2);
+
+// property deletion at same callsite
+function deleteX(obj) {
+   delete obj.x;
+}
+deleteX(obj1);
+deleteX(obj2);
+
+assertSameMap(obj1, obj2);
diff --git a/nashorn/test/script/maptests/proto.js b/nashorn/test/script/maptests/proto.js
new file mode 100644
index 00000000000..afb59509a0a
--- /dev/null
+++ b/nashorn/test/script/maptests/proto.js
@@ -0,0 +1,56 @@
+/*
+ * Copyright (c) 2014 Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ * 
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ * 
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ * 
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ * 
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/**
+ * @test
+ * @option -Dnashorn.debug=true
+ * @fork
+ */
+
+load(__DIR__ + ""maputil.js"");
+
+// add/delete property to proto (direct/indirect) should
+// not affect the property map of the objects
+
+var proto2 = { foo: 334 }
+var proto  = Object.create(proto2);
+proto.bar = ""hello"";
+
+var obj1 = Object.create(proto);
+var obj2 = Object.create(proto);
+
+assertSameMap(obj1, obj2);
+
+proto.newX = 'world';
+assertSameMap(obj1, obj2);
+
+delete proto.newX;
+assertSameMap(obj1, obj2);
+
+proto2.newX = ""foo"";
+assertSameMap(obj1, obj2);
+
+delete proto2.newX;
+assertSameMap(obj1, obj2);
+
+",Add tests to assert map identity of certain objects .,"""Added tests for property map sharing in Nashorn""","Added tests for property maps in Nashorn

This commit adds a new directory `maptests` with several test scripts that verify the behavior of property maps in Nashorn. The tests cover various scenarios, including:

* Object literals created at the same callsite
* Object literals created at different callsites
* Objects created by `Object.create`
* Property addition and deletion at the same callsite
* Property addition and deletion to a prototype object
* Constructor functions

The tests use the `assertSameMap` function to verify that the property maps of two objects are identical. The tests are designed to ensure that Nashorn's property map implementation is correct and consistent.","The commit message could be:

""Adding currently-failing and maptests directories and test files for Nashorn

The currently-failing directory contains the gettersetter.js test file, which tests the behavior of getter and setter functions in Nashorn. The maptests directory contains several test files that test the behavior of Nashorn's property maps for built-in objects, constructors, object literals, object creation, property addition, and property deletion. The test files use a utility function, assertSameMap, to check whether two objects share the same property map.""

Additionally, it appears that the project.properties file has been updated to include the new test directories and test files, and the build.xml file has been updated to grant permissions for the new test files. The commit message could include a brief description of these changes as well.","""Added new map tests and adjusted permissions and properties for Nashorn project for better debugging and validation.""",Model 3
"diff --git a/transport-native-epoll/src/main/c/io_netty_channel_epoll_Native.c b/transport-native-epoll/src/main/c/io_netty_channel_epoll_Native.c
index 6d7c407f74..d8b3184454 100644
--- a/transport-native-epoll/src/main/c/io_netty_channel_epoll_Native.c
+++ b/transport-native-epoll/src/main/c/io_netty_channel_epoll_Native.c
@@ -27,6 +27,7 @@
 #include <unistd.h>
 #include <arpa/inet.h>
 #include <fcntl.h>
+#include <sys/utsname.h>
 #include ""io_netty_channel_epoll_Native.h""
 
 
@@ -896,6 +897,10 @@ JNIEXPORT void JNICALL Java_io_netty_channel_epoll_Native_setReuseAddress(JNIEnv
     setOption(env, fd, SOL_SOCKET, SO_REUSEADDR, &optval, sizeof(optval));
 }
 
+JNIEXPORT void JNICALL Java_io_netty_channel_epoll_Native_setReusePort(JNIEnv * env, jclass clazz, jint fd, jint optval) {
+    setOption(env, fd, SOL_SOCKET, SO_REUSEPORT, &optval, sizeof(optval));
+}
+
 JNIEXPORT void JNICALL Java_io_netty_channel_epoll_Native_setTcpNoDelay(JNIEnv *env, jclass clazz, jint fd, jint optval) {
     setOption(env, fd, IPPROTO_TCP, TCP_NODELAY, &optval, sizeof(optval));
 }
@@ -940,6 +945,14 @@ JNIEXPORT jint JNICALL Java_io_netty_channel_epoll_Native_isReuseAddresss(JNIEnv
     return optval;
 }
 
+JNIEXPORT jint JNICALL Java_io_netty_channel_epoll_Native_isReusePort(JNIEnv *env, jclass clazz, jint fd) {
+    int optval;
+    if (getOption(env, fd, SOL_SOCKET, SO_REUSEPORT, &optval, sizeof(optval)) == -1) {
+        return -1;
+    }
+    return optval;
+}
+
 JNIEXPORT jint JNICALL Java_io_netty_channel_epoll_Native_isTcpNoDelay(JNIEnv *env, jclass clazz, jint fd) {
     int optval;
     if (getOption(env, fd, IPPROTO_TCP, TCP_NODELAY, &optval, sizeof(optval)) == -1) {
@@ -991,3 +1004,16 @@ JNIEXPORT jint JNICALL Java_io_netty_channel_epoll_Native_getTrafficClass(JNIEnv
     }
     return optval;
 }
+
+JNIEXPORT jstring JNICALL Java_io_netty_channel_epoll_Native_kernelVersion(JNIEnv *env, jclass clazz) {
+    struct utsname name;
+
+    int res = uname(&name);
+    if (res == 0) {
+        return (*env)->NewStringUTF(env, name.release);
+    }
+    int err = errno;
+    throwRuntimeException(env, exceptionMessage(""Error during uname(...): "", err));
+    return NULL;
+
+}
diff --git a/transport-native-epoll/src/main/c/io_netty_channel_epoll_Native.h b/transport-native-epoll/src/main/c/io_netty_channel_epoll_Native.h
index 6b6943da45..a82107ee02 100644
--- a/transport-native-epoll/src/main/c/io_netty_channel_epoll_Native.h
+++ b/transport-native-epoll/src/main/c/io_netty_channel_epoll_Native.h
@@ -48,6 +48,7 @@ jlong Java_io_netty_channel_epoll_Native_sendfile(JNIEnv *env, jclass clazz, jin
 jobject Java_io_netty_channel_epoll_Native_remoteAddress(JNIEnv * env, jclass clazz, jint fd);
 jobject Java_io_netty_channel_epoll_Native_localAddress(JNIEnv * env, jclass clazz, jint fd);
 void Java_io_netty_channel_epoll_Native_setReuseAddress(JNIEnv * env, jclass clazz, jint fd, jint optval);
+void Java_io_netty_channel_epoll_Native_setReusePort(JNIEnv * env, jclass clazz, jint fd, jint optval);
 void Java_io_netty_channel_epoll_Native_setTcpNoDelay(JNIEnv *env, jclass clazz, jint fd, jint optval);
 void Java_io_netty_channel_epoll_Native_setReceiveBufferSize(JNIEnv *env, jclass clazz, jint fd, jint optval);
 void Java_io_netty_channel_epoll_Native_setSendBufferSize(JNIEnv *env, jclass clazz, jint fd, jint optval);
@@ -56,9 +57,11 @@ void Java_io_netty_channel_epoll_Native_setTcpCork(JNIEnv *env, jclass clazz, ji
 void Java_io_netty_channel_epoll_Native_setSoLinger(JNIEnv *env, jclass clazz, jint fd, jint optval);
 void Java_io_netty_channel_epoll_Native_setTrafficClass(JNIEnv *env, jclass clazz, jint fd, jint optval);
 jint Java_io_netty_channel_epoll_Native_isReuseAddresss(JNIEnv *env, jclass clazz, jint fd);
+jint Java_io_netty_channel_epoll_Native_isReusePort(JNIEnv *env, jclass clazz, jint fd);
 jint Java_io_netty_channel_epoll_Native_isTcpNoDelay(JNIEnv *env, jclass clazz, jint fd);
 jint Java_io_netty_channel_epoll_Native_getReceiveBufferSize(JNIEnv * env, jclass clazz, jint fd);
 jint Java_io_netty_channel_epoll_Native_getSendBufferSize(JNIEnv *env, jclass clazz, jint fd);
 jint Java_io_netty_channel_epoll_Native_isTcpCork(JNIEnv *env, jclass clazz, jint fd);
 jint Java_io_netty_channel_epoll_Native_getSoLinger(JNIEnv *env, jclass clazz, jint fd);
 jint Java_io_netty_channel_epoll_Native_getTrafficClass(JNIEnv *env, jclass clazz, jint fd);
+jstring Java_io_netty_channel_epoll_Native_kernelVersion(JNIEnv *env, jclass clazz);
diff --git a/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollChannelOption.java b/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollChannelOption.java
index 58f189641f..060874563b 100644
--- a/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollChannelOption.java
+++ b/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollChannelOption.java
@@ -21,6 +21,8 @@ public final class EpollChannelOption {
     private static final Class<EpollChannelOption> T = EpollChannelOption.class;
 
     public static final ChannelOption<Boolean> TCP_CORK = ChannelOption.valueOf(T, ""TCP_CORK"");
+    public static final ChannelOption<Boolean> SO_REUSEPORT = ChannelOption.valueOf(T, ""SO_REUSEPORT"");
 
     private EpollChannelOption() { }
+
 }
diff --git a/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollServerSocketChannel.java b/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollServerSocketChannel.java
index fb851e1ab8..ae5d545b87 100644
--- a/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollServerSocketChannel.java
+++ b/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollServerSocketChannel.java
@@ -20,7 +20,6 @@ import io.netty.channel.ChannelPipeline;
 import io.netty.channel.ChannelPromise;
 import io.netty.channel.EventLoop;
 import io.netty.channel.socket.ServerSocketChannel;
-import io.netty.channel.socket.ServerSocketChannelConfig;
 
 import java.net.InetSocketAddress;
 import java.net.SocketAddress;
@@ -55,7 +54,7 @@ public final class EpollServerSocketChannel extends AbstractEpollChannel impleme
     }
 
     @Override
-    public ServerSocketChannelConfig config() {
+    public EpollServerSocketChannelConfig config() {
         return config;
     }
 
diff --git a/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollServerSocketChannelConfig.java b/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollServerSocketChannelConfig.java
index 791a65b46a..9b8a947def 100644
--- a/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollServerSocketChannelConfig.java
+++ b/transport-native-epoll/src/main/java/io/netty/channel/epoll/EpollServerSocketChannelConfig.java
@@ -29,7 +29,7 @@ import static io.netty.channel.ChannelOption.SO_BACKLOG;
 import static io.netty.channel.ChannelOption.SO_RCVBUF;
 import static io.netty.channel.ChannelOption.SO_REUSEADDR;
 
-final class EpollServerSocketChannelConfig extends DefaultChannelConfig
+public final class EpollServerSocketChannelConfig extends DefaultChannelConfig
         implements ServerSocketChannelConfig {
 
     private final EpollServerSocketChannel channel;
@@ -42,7 +42,7 @@ final class EpollServerSocketChannelConfig extends DefaultChannelConfig
 
     @Override
     public Map<ChannelOption<?>, Object> getOptions() {
-        return getOptions(super.getOptions(), SO_RCVBUF, SO_REUSEADDR, SO_BACKLOG);
+        return getOptions(super.getOptions(), SO_RCVBUF, SO_REUSEADDR, SO_BACKLOG, EpollChannelOption.SO_REUSEPORT);
     }
 
     @SuppressWarnings(""unchecked"")
@@ -57,7 +57,9 @@ final class EpollServerSocketChannelConfig extends DefaultChannelConfig
         if (option == SO_BACKLOG) {
             return (T) Integer.valueOf(getBacklog());
         }
-
+        if (option == EpollChannelOption.SO_REUSEPORT) {
+            return (T) Boolean.valueOf(isReusePort());
+        }
         return super.getOption(option);
     }
 
@@ -71,6 +73,8 @@ final class EpollServerSocketChannelConfig extends DefaultChannelConfig
             setReuseAddress((Boolean) value);
         } else if (option == SO_BACKLOG) {
             setBacklog((Integer) value);
+        } else if (option == EpollChannelOption.SO_REUSEPORT) {
+            setReusePort((Boolean) value);
         } else {
             return super.setOption(option, value);
         }
@@ -84,7 +88,7 @@ final class EpollServerSocketChannelConfig extends DefaultChannelConfig
     }
 
     @Override
-    public ServerSocketChannelConfig setReuseAddress(boolean reuseAddress) {
+    public EpollServerSocketChannelConfig setReuseAddress(boolean reuseAddress) {
         Native.setReuseAddress(channel.fd, reuseAddress ? 1 : 0);
         return this;
     }
@@ -95,14 +99,14 @@ final class EpollServerSocketChannelConfig extends DefaultChannelConfig
     }
 
     @Override
-    public ServerSocketChannelConfig setReceiveBufferSize(int receiveBufferSize) {
+    public EpollServerSocketChannelConfig setReceiveBufferSize(int receiveBufferSize) {
         Native.setReceiveBufferSize(channel.fd, receiveBufferSize);
 
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setPerformancePreferences(int connectionTime, int latency, int bandwidth) {
+    public EpollServerSocketChannelConfig setPerformancePreferences(int connectionTime, int latency, int bandwidth) {
         return this;
     }
 
@@ -112,7 +116,7 @@ final class EpollServerSocketChannelConfig extends DefaultChannelConfig
     }
 
     @Override
-    public ServerSocketChannelConfig setBacklog(int backlog) {
+    public EpollServerSocketChannelConfig setBacklog(int backlog) {
         if (backlog < 0) {
             throw new IllegalArgumentException(""backlog: "" + backlog);
         }
@@ -121,56 +125,76 @@ final class EpollServerSocketChannelConfig extends DefaultChannelConfig
     }
 
     @Override
-    public ServerSocketChannelConfig setConnectTimeoutMillis(int connectTimeoutMillis) {
+    public EpollServerSocketChannelConfig setConnectTimeoutMillis(int connectTimeoutMillis) {
         super.setConnectTimeoutMillis(connectTimeoutMillis);
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setMaxMessagesPerRead(int maxMessagesPerRead) {
+    public EpollServerSocketChannelConfig setMaxMessagesPerRead(int maxMessagesPerRead) {
         super.setMaxMessagesPerRead(maxMessagesPerRead);
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setWriteSpinCount(int writeSpinCount) {
+    public EpollServerSocketChannelConfig setWriteSpinCount(int writeSpinCount) {
         super.setWriteSpinCount(writeSpinCount);
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setAllocator(ByteBufAllocator allocator) {
+    public EpollServerSocketChannelConfig setAllocator(ByteBufAllocator allocator) {
         super.setAllocator(allocator);
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setRecvByteBufAllocator(RecvByteBufAllocator allocator) {
+    public EpollServerSocketChannelConfig setRecvByteBufAllocator(RecvByteBufAllocator allocator) {
         super.setRecvByteBufAllocator(allocator);
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setAutoRead(boolean autoRead) {
+    public EpollServerSocketChannelConfig setAutoRead(boolean autoRead) {
         super.setAutoRead(autoRead);
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setWriteBufferHighWaterMark(int writeBufferHighWaterMark) {
+    public EpollServerSocketChannelConfig setWriteBufferHighWaterMark(int writeBufferHighWaterMark) {
         super.setWriteBufferHighWaterMark(writeBufferHighWaterMark);
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setWriteBufferLowWaterMark(int writeBufferLowWaterMark) {
+    public EpollServerSocketChannelConfig setWriteBufferLowWaterMark(int writeBufferLowWaterMark) {
         super.setWriteBufferLowWaterMark(writeBufferLowWaterMark);
         return this;
     }
 
     @Override
-    public ServerSocketChannelConfig setMessageSizeEstimator(MessageSizeEstimator estimator) {
+    public EpollServerSocketChannelConfig setMessageSizeEstimator(MessageSizeEstimator estimator) {
         super.setMessageSizeEstimator(estimator);
         return this;
     }
+
+    /**
+     * Returns {@code true} if the SO_REUSEPORT option is set.
+     */
+    public boolean isReusePort() {
+        return Native.isReusePort(channel.fd) == 1;
+    }
+
+    /**
+     * Set the SO_REUSEPORT option on the underlying Channel. This will allow to bind multiple
+     * {@link EpollSocketChannel}s to the same port and so accept connections with multiple threads.
+     *
+     * Be aware this method needs be called before {@link EpollSocketChannel#bind(java.net.SocketAddress)} to have
+     * any affect.
+     */
+    public EpollServerSocketChannelConfig setReusePort(boolean reusePort) {
+        Native.setReusePort(channel.fd, reusePort ? 1 : 0);
+        return this;
+    }
+
 }
diff --git a/transport-native-epoll/src/main/java/io/netty/channel/epoll/Native.java b/transport-native-epoll/src/main/java/io/netty/channel/epoll/Native.java
index 43f7cfeebb..0a9532ede4 100644
--- a/transport-native-epoll/src/main/java/io/netty/channel/epoll/Native.java
+++ b/transport-native-epoll/src/main/java/io/netty/channel/epoll/Native.java
@@ -127,6 +127,7 @@ final class Native {
     public static native int getSendBufferSize(int fd);
     public static native int isKeepAlive(int fd);
     public static native int isReuseAddress(int fd);
+    public static native int isReusePort(int fd);
     public static native int isTcpNoDelay(int fd);
     public static native int isTcpCork(int fd);
     public static native int getSoLinger(int fd);
@@ -135,12 +136,14 @@ final class Native {
     public static native void setKeepAlive(int fd, int keepAlive);
     public static native void setReceiveBufferSize(int fd, int receiveBufferSize);
     public static native void setReuseAddress(int fd, int reuseAddress);
+    public static native void setReusePort(int fd, int reuseAddress);
     public static native void setSendBufferSize(int fd, int sendBufferSize);
     public static native void setTcpNoDelay(int fd, int tcpNoDelay);
     public static native void setTcpCork(int fd, int tcpCork);
     public static native void setSoLinger(int fd, int soLinger);
     public static native void setTrafficClass(int fd, int tcpNoDelay);
 
+    public static native String kernelVersion();
     private Native() {
         // utility
     }
diff --git a/transport-native-epoll/src/test/java/io/netty/channel/epoll/EpollReuseAddrTest.java b/transport-native-epoll/src/test/java/io/netty/channel/epoll/EpollReuseAddrTest.java
new file mode 100644
index 0000000000..5b5fc5a5ff
--- /dev/null
+++ b/transport-native-epoll/src/test/java/io/netty/channel/epoll/EpollReuseAddrTest.java
@@ -0,0 +1,132 @@
+/*
+ * Copyright 2014 The Netty Project
+ *
+ * The Netty Project licenses this file to you under the Apache License,
+ * version 2.0 (the ""License""); you may not use this file except in compliance
+ * with the License. You may obtain a copy of the License at:
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations
+ * under the License.
+ */
+package io.netty.channel.epoll;
+
+import io.netty.bootstrap.ServerBootstrap;
+import io.netty.channel.ChannelFuture;
+import io.netty.channel.ChannelHandler;
+import io.netty.channel.ChannelHandlerAdapter;
+import io.netty.channel.ChannelHandlerContext;
+import io.netty.channel.ChannelInboundHandlerAdapter;
+import io.netty.channel.ChannelOption;
+import io.netty.testsuite.util.TestUtils;
+import org.junit.Assert;
+import org.junit.Assume;
+import org.junit.Test;
+
+import java.io.IOException;
+import java.net.InetSocketAddress;
+import java.net.Socket;
+import java.util.concurrent.atomic.AtomicBoolean;
+
+public class EpollReuseAddrTest {
+    private static final int MAJOR;
+    private static final int MINOR;
+    private static final int BUGFIX;
+    static {
+        String kernelVersion = Native.kernelVersion();
+        int index = kernelVersion.indexOf(""-"");
+        if (index > -1) {
+            kernelVersion = kernelVersion.substring(0, index);
+        }
+        String[] versionParts = kernelVersion.split(""\\."");
+        if (versionParts.length == 3) {
+            MAJOR = Integer.parseInt(versionParts[0]);
+            MINOR = Integer.parseInt(versionParts[1]);
+            BUGFIX = Integer.parseInt(versionParts[2]);
+        } else {
+            throw new IllegalStateException();
+        }
+    }
+
+    @Test
+    public void testMultipleBindWithoutReusePortFails() {
+        Assume.assumeTrue(versionEqOrGt(3, 9, 0));
+        ServerBootstrap bootstrap = createBootstrap();
+        ChannelFuture future = bootstrap.bind().syncUninterruptibly();
+        try {
+            bootstrap.bind().syncUninterruptibly();
+            Assert.fail();
+        } catch (Exception e) {
+            Assert.assertTrue(e instanceof IOException);
+        }
+        future.channel().close().syncUninterruptibly();
+    }
+
+    @Test(timeout = 10000)
+    public void testMultipleBind() throws Exception {
+        Assume.assumeTrue(versionEqOrGt(3, 9, 0));
+        ServerBootstrap bootstrap = createBootstrap();
+        bootstrap.option(EpollChannelOption.SO_REUSEPORT, true);
+        final AtomicBoolean accepted1 = new AtomicBoolean();
+        bootstrap.childHandler(new TestHandler(accepted1));
+        ChannelFuture future = bootstrap.bind().syncUninterruptibly();
+
+        final AtomicBoolean accepted2 = new AtomicBoolean();
+        bootstrap.childHandler(new TestHandler(accepted2));
+        ChannelFuture future2 = bootstrap.bind().syncUninterruptibly();
+        InetSocketAddress address = (InetSocketAddress) future2.channel().localAddress();
+
+        while (!accepted1.get() || !accepted2.get()) {
+            Socket socket = new Socket(address.getAddress(), address.getPort());
+            socket.setReuseAddress(true);
+            socket.close();
+        }
+        future.channel().close().syncUninterruptibly();
+        future2.channel().close().syncUninterruptibly();
+    }
+
+    private ServerBootstrap createBootstrap() {
+        ServerBootstrap bootstrap = new ServerBootstrap();
+        bootstrap.group(EpollSocketTestPermutation.EPOLL_BOSS_GROUP, EpollSocketTestPermutation.EPOLL_WORKER_GROUP);
+        bootstrap.channel(EpollServerSocketChannel.class);
+        bootstrap.childHandler(new ChannelHandlerAdapter() { });
+        bootstrap.option(ChannelOption.SO_REUSEADDR, true);
+        InetSocketAddress address = new InetSocketAddress(TestUtils.getFreePort());
+        bootstrap.localAddress(address);
+        return bootstrap;
+    }
+
+    private static boolean versionEqOrGt(int major, int minor, int bugfix)  {
+        if (MAJOR > major) {
+            return true;
+        } else if (MAJOR == major) {
+            if (MINOR > minor) {
+                return true;
+            } else if (MINOR == minor) {
+                if (BUGFIX >= bugfix) {
+                    return true;
+                }
+            }
+        }
+        return false;
+    }
+
+    @ChannelHandler.Sharable
+    private static class TestHandler extends ChannelInboundHandlerAdapter {
+        private final AtomicBoolean accepted;
+
+        TestHandler(AtomicBoolean accepted) {
+            this.accepted = accepted;
+        }
+
+        @Override
+        public void channelActive(ChannelHandlerContext ctx) throws Exception {
+            accepted.set(true);
+            ctx.close();
+        }
+    }
+}
diff --git a/transport-native-epoll/src/test/java/io/netty/channel/epoll/EpollSocketTestPermutation.java b/transport-native-epoll/src/test/java/io/netty/channel/epoll/EpollSocketTestPermutation.java
index a452a956e4..e08562e5e6 100644
--- a/transport-native-epoll/src/test/java/io/netty/channel/epoll/EpollSocketTestPermutation.java
+++ b/transport-native-epoll/src/test/java/io/netty/channel/epoll/EpollSocketTestPermutation.java
@@ -32,9 +32,9 @@ class EpollSocketTestPermutation extends SocketTestPermutation {
 
     static final SocketTestPermutation INSTANCE = new EpollSocketTestPermutation();
 
-    private final EventLoopGroup epollBossGroup =
+    static final EventLoopGroup EPOLL_BOSS_GROUP =
             new EpollEventLoopGroup(BOSSES, new DefaultThreadFactory(""testsuite-epoll-boss"", true));
-    private final EventLoopGroup epollWorkerGroup =
+    static final EventLoopGroup EPOLL_WORKER_GROUP =
             new EpollEventLoopGroup(WORKERS, new DefaultThreadFactory(""testsuite-epoll-worker"", true));
 
     @Override
@@ -54,7 +54,7 @@ class EpollSocketTestPermutation extends SocketTestPermutation {
                 new BootstrapFactory<ServerBootstrap>() {
                     @Override
                     public ServerBootstrap newInstance() {
-                        return new ServerBootstrap().group(epollBossGroup, epollWorkerGroup)
+                        return new ServerBootstrap().group(EPOLL_BOSS_GROUP, EPOLL_WORKER_GROUP)
                                 .channel(EpollServerSocketChannel.class);
                     }
                 },
@@ -74,7 +74,7 @@ class EpollSocketTestPermutation extends SocketTestPermutation {
                 new BootstrapFactory<Bootstrap>() {
                     @Override
                     public Bootstrap newInstance() {
-                        return new Bootstrap().group(epollWorkerGroup).channel(EpollSocketChannel.class);
+                        return new Bootstrap().group(EPOLL_WORKER_GROUP).channel(EpollSocketChannel.class);
                     }
                 },
                 new BootstrapFactory<Bootstrap>() {",Add support for SO_REUSEPORT in native transport .,"""Added support for SO_REUSEPORT option on EpollServerSocketChannel""","""Added support for SO_REUSEPORT option and kernel version retrieval""","""Added SO_REUSEPORT option to EpollChannelOption and EpollServerSocketChannelConfig, and a new JNI method to set it. Also added a new JNI method to retrieve the kernel version.""

Explanation:

* In `EpollChannelOption.java`, a new constant `SO_REUSEPORT` has been added.
* In `EpollServerSocketChannelConfig.java`, a new method `setReusePort(boolean)` has been added, as well as a new condition in the `getOptions()` method to include `EpollChannelOption.SO_REUSEPORT`.
* In `Native.java`, two new native methods `setReusePort(int, int)` and `isReusePort(int)` have been added, as well as a new method `kernelVersion()`.
* In `io_netty_channel_epoll_Native.c`, two new JNI methods `Java_io_netty_channel_epoll_Native_setReusePort` and `Java_io_netty_channel_epoll_Native_isReusePort` have been added, as well as a new method `Java_io_netty_channel_epoll_Native_kernelVersion`.
* In `io_netty_channel_epoll_Native.h`, the declarations for the new JNI methods have been added.

This commit adds the ability to set the `SO_REUSEPORT` socket option for Epoll Server Socket Channels, as well as a new JNI method to retrieve the kernel version. The `SO_REUSEPORT` option allows multiple sockets to bind to the same address and port, which can be useful for load balancing incoming connections across multiple processes or threads. The kernel version method is used to check the version of the Linux kernel, which can be useful for determining whether certain features or bug fixes are present.",Add support for SO_REUSEPORT and kernel version fetching in Epoll transport.,Model 3
"diff --git a/AnkiDroid/src/main/java/com/ichi2/utils/JSONException.java b/AnkiDroid/src/main/java/com/ichi2/utils/JSONException.java
new file mode 100644
index 0000000000..1d4bef5a7e
--- /dev/null
+++ b/AnkiDroid/src/main/java/com/ichi2/utils/JSONException.java
@@ -0,0 +1,39 @@
+package com.ichi2.utils;
+
+
+
+/**
+   Similar to JSONException in meaning, but unchecked */
+public class JSONException extends RuntimeException {
+
+    private JSONException exc = null;
+
+    public JSONException(String s) {
+        super(s);
+    }
+
+    public JSONException() {
+        super();
+    }
+
+    public JSONException(Throwable e) {
+        super(e);
+    }
+
+    public JSONException(JSONException e) {
+        super(e);
+        exc = e;
+    }
+
+    public JSONException asException() {
+        if (exc!=null) {
+            return exc;
+        } else {
+            return new JSONException(toString());
+        }
+    }
+
+    public void throwAsException() throws JSONException {
+        throw asException();
+    }
+}",Add an unchecked exception for JSON .,"""Added unchecked JSONException class to com.ichi2.utils package""","""Added JSONException utility class for unchecked JSON exceptions.""","""Added new unchecked JSONException class to com.ichi2.utils package""",Add JSONException class to utils package: an unchecked exception for handling JSON errors similar to RuntimeException.,Model 1
"diff --git a/logback-examples/src/main/java/chapters/appenders/socket/ssl/SocketClient.java b/logback-examples/src/main/java/chapters/appenders/socket/ssl/SocketClient.java
new file mode 100644
index 000000000..f3da32c52
--- /dev/null
+++ b/logback-examples/src/main/java/chapters/appenders/socket/ssl/SocketClient.java
@@ -0,0 +1,73 @@
+/**
+ * Logback: the reliable, generic, fast and flexible logging framework.
+ * Copyright (C) 1999-2011, QOS.ch. All rights reserved.
+ *
+ * This program and the accompanying materials are dual-licensed under
+ * either the terms of the Eclipse Public License v1.0 as published by
+ * the Eclipse Foundation
+ *
+ *   or (per the licensee's choosing)
+ *
+ * under the terms of the GNU Lesser General Public License version 2.1
+ * as published by the Free Software Foundation.
+ */
+package chapters.appenders.socket.ssl;
+
+import java.io.BufferedReader;
+import java.io.InputStreamReader;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import ch.qos.logback.classic.LoggerContext;
+import ch.qos.logback.classic.joran.JoranConfigurator;
+
+
+/**
+ * This application uses an SSLSocketAppender that log messages to a
+ * server on a host and port specified by the user. It waits for the
+ * user to type a message which will be sent to the server.
+ * */
+public class SocketClient {
+  static void usage(String msg) {
+    System.err.println(msg);
+    System.err.println(""Usage: java "" + SocketClient.class.getName() +
+      "" configFile\n"" +
+      ""   configFile a logback configuration file"" +
+      ""   in XML format."");
+    System.exit(1);
+  }
+
+  static public void main(String[] args) throws Exception {
+    if (args.length != 1) {
+      usage(""Wrong number of arguments."");
+    }
+
+    String configFile = args[0];
+
+    if (configFile.endsWith("".xml"")) {
+      LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory();
+      JoranConfigurator configurator = new JoranConfigurator();
+      lc.stop();
+      configurator.setContext(lc);
+      configurator.doConfigure(configFile);
+    }
+
+    Logger logger = LoggerFactory.getLogger(SocketClient.class);
+
+    BufferedReader reader = new BufferedReader(new InputStreamReader(System.in));
+
+    while (true) {
+      System.out.println(
+        ""Type a message to send to log server. Type 'q' to quit."");
+
+      String s = reader.readLine();
+
+      if (s.equals(""q"")) {
+        break;
+      } else {
+        logger.debug(s);
+      }
+    }
+  }
+}
diff --git a/logback-examples/src/main/java/chapters/appenders/socket/ssl/SocketServer.java b/logback-examples/src/main/java/chapters/appenders/socket/ssl/SocketServer.java
new file mode 100644
index 000000000..66e8a0355
--- /dev/null
+++ b/logback-examples/src/main/java/chapters/appenders/socket/ssl/SocketServer.java
@@ -0,0 +1,54 @@
+/**
+ * Logback: the reliable, generic, fast and flexible logging framework.
+ * Copyright (C) 1999-2011, QOS.ch. All rights reserved.
+ *
+ * This program and the accompanying materials are dual-licensed under
+ * either the terms of the Eclipse Public License v1.0 as published by
+ * the Eclipse Foundation
+ *
+ *   or (per the licensee's choosing)
+ *
+ * under the terms of the GNU Lesser General Public License version 2.1
+ * as published by the Free Software Foundation.
+ */
+package chapters.appenders.socket.ssl;
+
+import org.slf4j.LoggerFactory;
+
+import ch.qos.logback.classic.LoggerContext;
+import ch.qos.logback.classic.joran.JoranConfigurator;
+
+
+/**
+ * This application uses an SSLSocketServer that log messages to a
+ * server on a host and port specified by the user. It waits for the
+ * user to type a message which will be sent to the server.
+ * */
+public class SocketServer {
+  static void usage(String msg) {
+    System.err.println(msg);
+    System.err.println(""Usage: java "" + SocketServer.class.getName() +
+      "" configFile\n"" +
+      ""   configFile a logback configuration file"" +
+      ""   in XML format."");
+    System.exit(1);
+  }
+
+  static public void main(String[] args) throws Exception {
+    if (args.length != 1) {
+      usage(""Wrong number of arguments."");
+    }
+
+    String configFile = args[0];
+
+    if (configFile.endsWith("".xml"")) {
+      LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory();
+      JoranConfigurator configurator = new JoranConfigurator();
+      lc.stop();
+      configurator.setContext(lc);
+      configurator.doConfigure(configFile);
+    }
+
+    Thread.sleep(Long.MAX_VALUE);
+  }
+}
diff --git a/logback-examples/src/main/java/chapters/appenders/socket/ssl/client.xml b/logback-examples/src/main/java/chapters/appenders/socket/ssl/client.xml
new file mode 100644
index 000000000..0dbc8fc8e
--- /dev/null
+++ b/logback-examples/src/main/java/chapters/appenders/socket/ssl/client.xml
@@ -0,0 +1,28 @@
+<?xml version=""1.0"" encoding=""UTF-8"" ?>
+
+<!-- ==================================================================== -->
+<!-- Sample SSLSocketAppender configuration.                                 -->
+<!-- ==================================================================== -->
+
+<configuration debug=""true"">
+	  
+  <appender name=""SOCKET"" class=""ch.qos.logback.classic.net.SSLSocketAppender"">
+    <remoteHost>${host}</remoteHost>
+    <port>${port}</port>
+    <reconnectionDelay>10000</reconnectionDelay>
+    <ssl>
+      <trustStore>
+        <location>${truststore}</location>
+        <passphrase>${passphrase}</passphrase>
+      </trustStore>
+    </ssl>
+  </appender>
+
+  <root level=""debug"">
+    <appender-ref ref=""SOCKET"" />
+  </root>  
+
+</configuration>
+
+
+
diff --git a/logback-examples/src/main/java/chapters/appenders/socket/ssl/keystore.jks b/logback-examples/src/main/java/chapters/appenders/socket/ssl/keystore.jks
new file mode 100644
index 000000000..274e4d159
Binary files /dev/null and b/logback-examples/src/main/java/chapters/appenders/socket/ssl/keystore.jks differ
diff --git a/logback-examples/src/main/java/chapters/appenders/socket/ssl/server.xml b/logback-examples/src/main/java/chapters/appenders/socket/ssl/server.xml
new file mode 100644
index 000000000..aa7fe3757
--- /dev/null
+++ b/logback-examples/src/main/java/chapters/appenders/socket/ssl/server.xml
@@ -0,0 +1,32 @@
+<?xml version=""1.0"" encoding=""UTF-8"" ?>
+
+<!-- ==================================================================== -->
+<!-- Sample SSLSocketServer configuration.                                 -->
+<!-- ==================================================================== -->
+
+<configuration debug=""true"">
+
+  <server class=""ch.qos.logback.classic.net.server.SSLSocketServer"">
+    <port>${port}</port>
+    <ssl>
+      <keyStore>
+        <location>${keystore}</location>
+        <passphrase>${passphrase}</passphrase>
+      </keyStore>
+    </ssl>
+  </server>
+  
+  <appender name=""CONSOLE"" class=""ch.qos.logback.core.ConsoleAppender"">
+    <encoder>
+      <pattern>%d{HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n</pattern>
+    </encoder>
+  </appender>
+  
+  <root level=""debug"">
+    <appender-ref ref=""CONSOLE"" />
+  </root>
+  
+</configuration>
+
+
+
diff --git a/logback-examples/src/main/java/chapters/appenders/socket/ssl/truststore.jks b/logback-examples/src/main/java/chapters/appenders/socket/ssl/truststore.jks
new file mode 100644
index 000000000..93498fb44
Binary files /dev/null and b/logback-examples/src/main/java/chapters/appenders/socket/ssl/truststore.jks differ",added an example of using the SSL enabled components,"""Added SSL socket client and server examples to logback-examples""","Added examples for SSLSocketAppender and SSLSocketServer in Logback. 

This commit includes the addition of two new classes, SocketClient and SocketServer, which demonstrate the use of SSLSocketAppender and SSLSocketServer respectively. It also includes the creation of two new configuration files, client.xml and server.xml, which are used to configure the SSLSocketAppender and SSLSocketServer. Additionally, two new keystore files, keystore.jks and truststore.jks, are added to the project.","""Added SSL socket appender and server examples in logback-examples""

This commit adds two new Java classes, `SocketClient` and `SocketServer`, which demonstrate how to use the SSLSocketAppender and SSLSocketServer in Logback. It also includes configuration files and security certificates needed to run the examples. The code is licensed under the Eclipse Public License v1.0 or the GNU Lesser General Public License version 2.1.","Added SSL socket client and server examples with corresponding XML configurations, keystore, and truststore files.",Model 1
"diff --git a/sopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/jsondatamodel/JsonNodeTest.java b/sopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/jsondatamodel/JsonNodeTest.java
new file mode 100644
index 00000000000..2be4985fbdf
--- /dev/null
+++ b/sopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/jsondatamodel/JsonNodeTest.java
@@ -0,0 +1,5 @@
+package eu.stratosphere.sopremo.jsondatamodel;
+
+public class JsonNodeTest {
+	//generic tests for every JsonNode
+}
diff --git a/sopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/jsondatamodel/TextNodeTest.java b/sopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/jsondatamodel/TextNodeTest.java
new file mode 100644
index 00000000000..01c4c779f4b
--- /dev/null
+++ b/sopremo/sopremo-common/src/test/java/eu/stratosphere/sopremo/jsondatamodel/TextNodeTest.java
@@ -0,0 +1,5 @@
+package eu.stratosphere.sopremo.jsondatamodel;
+
+public class TextNodeTest extends JsonNodeTest {
+
+}",added teststubs,"""Added JsonNodeTest and TextNodeTest classes for testing JSON data model""","Added test classes for JsonNode and TextNode.

Or, in a more conventional commit message format:

`Add JsonNode and TextNode test classes`

This commit message is concise and accurately describes the changes made in the commit.","""Added test classes for JsonNode and TextNode in sopremo-common""

This commit contains two new files:

1. JsonNodeTest.java: This is a new test class for the package eu.stratosphere.sopremo.jsondatamodel. The class doesn't contain any tests yet, but it's a placeholder for future generic tests for every JsonNode.

2. TextNodeTest.java: This is another new test class for the same package that extends JsonNodeTest. This class also doesn't contain any tests yet.

The changes made in this commit are related to testing functionality in the sopremo-common project, specifically for the JsonNode and TextNode classes. The commit message should reflect these changes.","""Add initial test classes for JsonNode and TextNode in sopremo-common module.""",Model 2
"diff --git a/sql/jdbc/src/test/java/org/elasticsearch/xpack/sql/jdbc/DebugCsvSpec.java b/sql/jdbc/src/test/java/org/elasticsearch/xpack/sql/jdbc/DebugCsvSpecIT.java
similarity index 88%
rename from sql/jdbc/src/test/java/org/elasticsearch/xpack/sql/jdbc/DebugCsvSpec.java
rename to sql/jdbc/src/test/java/org/elasticsearch/xpack/sql/jdbc/DebugCsvSpecIT.java
index cd061a5d0a6..ae567fe3bb9 100644
--- a/sql/jdbc/src/test/java/org/elasticsearch/xpack/sql/jdbc/DebugCsvSpec.java
+++ b/sql/jdbc/src/test/java/org/elasticsearch/xpack/sql/jdbc/DebugCsvSpecIT.java
@@ -16,7 +16,7 @@ import java.sql.SQLException;
 import java.util.List;
 
 @TestLogging(""org.elasticsearch.xpack.sql:TRACE"")
-public class DebugCsvSpec extends CsvSpecIT {
+public class DebugCsvSpecIT extends CsvSpecIT {
 
     @ParametersFactory(shuffle = false, argumentFormatting = SqlSpecIT.PARAM_FORMATTING) // NOCOMMIT are we sure?!
     public static List<Object[]> readScriptSpec() throws Exception {
@@ -26,7 +26,7 @@ public class DebugCsvSpec extends CsvSpecIT {
         return readScriptSpec(""/debug.csv-spec"", parser);
     }
 
-    public DebugCsvSpec(String groupName, String testName, Integer lineNumber, Path source, CsvTestCase testCase) {
+    public DebugCsvSpecIT(String groupName, String testName, Integer lineNumber, Path source, CsvTestCase testCase) {
         super(groupName, testName, lineNumber, source, testCase);
     }
 ",Rename DebugCsvSpec to match test naming convention .,"""Rename DebugCsvSpec to DebugCsvSpecIT""",Rename DebugCsvSpec to DebugCsvSpecIT to match the test class suffix convention.,"""Rename DebugCsvSpec.java to DebugCsvSpecIT.java and update class name accordingly""",Renamed `DebugCsvSpec` to `DebugCsvSpecIT` to follow the integration test naming convention.,Model 2
"diff --git a/app/src/main/res/layout/fragment_options_notifications.xml b/app/src/main/res/layout/fragment_options_notifications.xml
index 909a0afdec..637b256c74 100644
--- a/app/src/main/res/layout/fragment_options_notifications.xml
+++ b/app/src/main/res/layout/fragment_options_notifications.xml
@@ -144,6 +144,18 @@
                 app:layout_constraintStart_toStartOf=""parent""
                 app:layout_constraintTop_toBottomOf=""@id/tvNotifyActionsPro"" />
 
+            <TextView
+                android:id=""@+id/tvManageHint""
+                android:layout_width=""0dp""
+                android:layout_height=""wrap_content""
+                android:layout_marginEnd=""48dp""
+                android:text=""@string/title_advanced_notify_manage_hint""
+                android:textAppearance=""@style/TextAppearance.AppCompat.Small""
+                android:textStyle=""italic""
+                app:layout_constraintEnd_toEndOf=""parent""
+                app:layout_constraintStart_toStartOf=""parent""
+                app:layout_constraintTop_toBottomOf=""@id/btnManage"" />
+
             <androidx.appcompat.widget.SwitchCompat
                 android:id=""@+id/swLight""
                 android:layout_width=""match_parent""
@@ -151,7 +163,7 @@
                 android:layout_marginTop=""12dp""
                 android:text=""@string/title_advanced_light""
                 app:layout_constraintStart_toStartOf=""parent""
-                app:layout_constraintTop_toBottomOf=""@id/btnManage""
+                app:layout_constraintTop_toBottomOf=""@id/tvManageHint""
                 app:switchPadding=""12dp"" />
 
             <Button
diff --git a/app/src/main/res/values/strings.xml b/app/src/main/res/values/strings.xml
index 5ccfe79597..b4be65537d 100644
--- a/app/src/main/res/values/strings.xml
+++ b/app/src/main/res/values/strings.xml
@@ -222,6 +222,7 @@
     <string name=""title_advanced_notify_action_flag"">Star</string>
     <string name=""title_advanced_notify_action_seen"">Read</string>
     <string name=""title_advanced_notify_action_hint"">At",Added hint about notification channel settings,"""Added notification management hint in fragment options notifications""","""Added hint for managing notifications and updated layout constraints""","""Added manage hint textview and adjusted layout constraints in fragment_options_notifications.xml. Also added a new string resource in strings.xml.""

This commit seems to have added a new TextView with the id ""tvManageHint"" in the layout file ""fragment_options_notifications.xml"". The layout constraints of an existing SwitchCompat with the id ""swLight"" have also been adjusted to accommodate the new TextView. Additionally, a new string resource has been added in ""strings.xml"" which is likely used in the new TextView.","""Added a TextView to provide a hint below the 'Manage' button in the notification options fragment.""",Model 1
"diff --git a/app/src/processing/app/Base.java b/app/src/processing/app/Base.java
index 112c96193..df06857e6 100644
--- a/app/src/processing/app/Base.java
+++ b/app/src/processing/app/Base.java
@@ -55,9 +55,9 @@ import processing.data.StringList;
 public class Base {
   // Added accessors for 0218 because the UpdateCheck class was not properly
   // updating the values, due to javac inlining the static final values.
-  static private final int REVISION = 246;
+  static private final int REVISION = 247;
   /** This might be replaced by main() if there's a lib/version.txt file. */
-  static private String VERSION_NAME = ""0246""; //$NON-NLS-1$
+  static private String VERSION_NAME = ""0247""; //$NON-NLS-1$
   /** Set true if this a proper release rather than a numbered revision. */
 
   /** True if heavy debugging error/log messages are enabled */
diff --git a/build/shared/revisions.txt b/build/shared/revisions.txt
index 64143b349..11a3ded0a 100644
--- a/build/shared/revisions.txt
+++ b/build/shared/revisions.txt
@@ -1,4 +1,4 @@
-PROCESSING 3.0 (REV 0246) - 30 September 2015
+PROCESSING 3.0 (REV 0246) - 30 September 2015, 3pm ET
 
 This one is huge. 
 
diff --git a/core/done.txt b/core/done.txt
index edd46e6af..6e4efb735 100644
--- a/core/done.txt
+++ b/core/done.txt
@@ -1,3 +1,38 @@
+0246 the papal visit (3.0)
+X implement high-performance/async image saving
+X   Use PBOs for async texture copy
+X   https://github.com/processing/processing/issues/3569
+X   https://github.com/processing/processing/pull/3863
+X   https://github.com/processing/processing/pull/3869
+X Textures disappearing in beta 7 (might be WeakReference regression)
+X   https://github.com/processing/processing/issues/3858
+X   https://github.com/processing/processing/pull/3874
+X   https://github.com/processing/processing/pull/3875
+X Convert all documented hacky keys in OpenGL
+X   https://github.com/processing/processing/pull/3888
+X Frame size displays incorrectly if surface.setResizable(true)
+X   https://github.com/processing/processing/issues/3868
+X   https://github.com/processing/processing/pull/3880
+X displayWidth, displayHeight, full screen, display number
+X   https://github.com/processing/processing/pull/3893
+X   https://github.com/processing/processing/issues/3865
+X OpenGL with fullScreen() always opens on default display
+X   https://github.com/processing/processing/issues/3889
+X   https://github.com/processing/processing/issues/3797
+X   https://github.com/processing/processing/pull/3892
+
+cleaning
+o move AWT image loading into PImageAWT
+o   look into how GL and FX will handle from there
+o run only the necessary pieces on the EDT
+o   in part because FX doesn't even use the EDT
+o   re-check the Linux frame visibility stuff
+X   cleaned most of this as far as we can go
+o Ubuntu Unity prevents full screen from working properly
+X   https://github.com/processing/processing/issues/3158
+X   can't fix; upstream problem, added to the wiki
+
+
 0245 core (3.0b7)
 X surface.setLocation(x,y) not working with the default renderer
 X   https://github.com/processing/processing/issues/3821
diff --git a/core/todo.txt b/core/todo.txt
index 2ec573242..c230e295d 100644
--- a/core/todo.txt
+++ b/core/todo.txt
@@ -1,36 +1,4 @@
-0246 the papal visit (3.0)
-X implement high-performance/async image saving
-X   Use PBOs for async texture copy
-X   https://github.com/processing/processing/issues/3569
-X   https://github.com/processing/processing/pull/3863
-X   https://github.com/processing/processing/pull/3869
-X Textures disappearing in beta 7 (might be WeakReference regression)
-X   https://github.com/processing/processing/issues/3858
-X   https://github.com/processing/processing/pull/3874
-X   https://github.com/processing/processing/pull/3875
-X Convert all documented hacky keys in OpenGL
-X   https://github.com/processing/processing/pull/3888
-X Frame size displays incorrectly if surface.setResizable(true)
-X   https://github.com/processing/processing/issues/3868
-X   https://github.com/processing/processing/pull/3880
-X displayWidth, displayHeight, full screen, display number
-X   https://github.com/processing/processing/pull/3893
-X   https://github.com/processing/processing/issues/3865
-X OpenGL with fullScreen() always opens on default display
-X   https://github.com/processing/processing/issues/3889
-X   https://github.com/processing/processing/issues/3797
-X   https://github.com/processing/processing/pull/3892
-
-cleaning
-o move AWT image loading into PImageAWT
-o   look into how GL and FX will handle from there
-o run only the necessary pieces on the EDT
-o   in part because FX doesn't even use the EDT
-o   re-check the Linux frame visibility stuff
-X   cleaned most of this as far as we can go
-o Ubuntu Unity prevents full screen from working properly
-X   https://github.com/processing/processing/issues/3158
-X   can't fix; upstream problem, added to the wiki
+0247 (3.0.1)
 
 
 known
diff --git a/done.txt b/done.txt
index cde20c1b0..26cc9862c 100644
--- a/done.txt
+++ b/done.txt
@@ -1,3 +1,114 @@
+0246 the holy land (3.0)
+X ""Saving"" messages never clear on ""Save As""
+X   https://github.com/processing/processing/issues/3861
+X error checker/suggestions fixes
+X   https://github.com/processing/processing/pull/3871
+X   https://github.com/processing/processing/pull/3879
+X contributions filter is ignored after clicking Install
+X   https://github.com/processing/processing/issues/3826
+X   https://github.com/processing/processing/pull/3872
+X   https://github.com/processing/processing/pull/3883
+X Exception in thread ""Contribution List Downloader""
+X   https://github.com/processing/processing/issues/3882
+X   https://github.com/processing/processing/pull/3884
+X Hide useless error in error checker
+X   https://github.com/processing/processing/pull/3887
+X grab bag of CM work from Jakub
+X   https://github.com/processing/processing/issues/3895
+X   https://github.com/processing/processing/pull/3897
+X Clean up delete dir function
+X   https://github.com/processing/processing/pull/3910
+X don't follow symlinks when deleting directories
+X   https://github.com/processing/processing/pull/3916
+X show number of updates available in the footer
+X   https://github.com/processing/processing/issues/3518
+X   https://github.com/processing/processing/pull/3896
+X   https://github.com/processing/processing/pull/3901
+o   total number of updates available is not correct? (may be fixed)
+o ArrayIndexOutOfBoundsException freak out when clicking the header line
+o   think this was on name, with libraries, but not sure
+X   should be fixed with the updates from Jakub
+X error checker updates for toggle and listeners
+X   https://github.com/processing/processing/pull/3915
+X file file counting in the change detector
+X   https://github.com/processing/processing/pull/3917
+X   https://github.com/processing/processing/issues/3898
+X   https://github.com/processing/processing/issues/3387
+X Windows suggests ""Documents"" as a new location for the 3.0 sketchbook
+X   maybe prevent users from accepting that?
+X   https://github.com/processing/processing/issues/3920
+
+gui
+X distinguish errors and warnings
+X   https://github.com/processing/processing/issues/3406
+X make breakpoints more prominent
+X   https://github.com/processing/processing/issues/3307 (comp is set)
+X clean up statusMessage() inside JavaEditor
+o   do we want to bring back the delays?
+X implement side gradient on the editor
+X if fewer lines in sketch than can be shown in window, show ticks adjacent
+X   error/warning location is awkward when no scroll bar is in use
+X   when only one screen-full, show ticks at exact location
+X   simpler/less confusing to not show at all? 
+X   MarkerColumn.recalculateMarkerPositions()
+X   https://github.com/processing/processing/pull/3903
+X Update status error/warning when changing the line
+X   https://github.com/processing/processing/pull/3907
+X Update status error/warning when changing the line
+X   when moving away from an error/warning line, de-select it below
+X   selecting a warning should also show the warning in the status area
+X   https://github.com/processing/processing/pull/3907
+X clicking an error or warning should give the focus back to the editor
+X   https://github.com/processing/processing/pull/3905
+X replace startup/about screen (1x and 2x versions)
+X   change 'alpha' to correct name
+X   also change the revision in the ""about processing"" dialog
+X   https://github.com/processing/processing/issues/3665
+X implement splash screen on OS X
+X   http://www.randelshofer.ch/oop/javasplash/javasplash.html
+X   also implement special retina version
+X Fix placement and visual design when showing error on hover
+X   https://github.com/processing/processing/issues/3173
+X   implement custom tooltip for error/warning hover
+X   applies to both MarkerColumn and JavaTextAreaPainter
+X make gutter of console match error list
+X   https://github.com/processing/processing/issues/3904
+o bring back the # of updates on the update tab
+o   use this instead of the 'icon' stuff?
+o   or in addition, since only the 'updates' tab has it
+X   https://github.com/processing/processing/issues/3855
+X for updates available, have it be clickable to open the manager
+X fix the design of the completions window
+X   remove extra border around the outside
+X   change font
+X   add 2x version of the icons
+X   change selection highlight color
+o   put some margin around it
+X   https://github.com/processing/processing/issues/3906
+X completion panel
+X   what should the background color be? 
+X   test fg/bg color on other operating systems
+J   fix icon sizes/design
+X set a better minimum size for the number of updates available
+
+earlier/cleaning
+X list with contrib types separated is really wonky
+o   do we keep the list?
+o   does it even work for different contrib types?
+X   cleaned this up in the last release
+X remove the dated releases from download.processing.org
+X new Android release (EditorButton constructor changed)
+o JavaEditor has several null colors, remove color support
+o   once the design is complete and we for sure do not need color
+X remove deprecated methods
+X do the right thing on passing around List vs ArrayList and others
+o wonder if ""Save As"" is causing the problems with auto-reload
+X   found and fixed
+X look at the sound library https://github.com/wirsing/ProcessingSound
+o   sound is not yet supported on Windows
+X implement the new gui
+
+
 0245 (3.0b7)
 X add jar files from 'code' folder to the library path
 X   Code editor wrongly detects errors for libraries in code folder
diff --git a/todo.txt b/todo.txt
index 6d4db7b94..e27b2b5f7 100644
--- a/todo.txt
+++ b/todo.txt
@@ -1,112 +1,4 @@
-0246 the holy land (3.0)
-X ""Saving"" messages never clear on ""Save As""
-X   https://github.com/processing/processing/issues/3861
-X error checker/suggestions fixes
-X   https://github.com/processing/processing/pull/3871
-X   https://github.com/processing/processing/pull/3879
-X contributions filter is ignored after clicking Install
-X   https://github.com/processing/processing/issues/3826
-X   https://github.com/processing/processing/pull/3872
-X   https://github.com/processing/processing/pull/3883
-X Exception in thread ""Contribution List Downloader""
-X   https://github.com/processing/processing/issues/3882
-X   https://github.com/processing/processing/pull/3884
-X Hide useless error in error checker
-X   https://github.com/processing/processing/pull/3887
-X grab bag of CM work from Jakub
-X   https://github.com/processing/processing/issues/3895
-X   https://github.com/processing/processing/pull/3897
-X Clean up delete dir function
-X   https://github.com/processing/processing/pull/3910
-X don't follow symlinks when deleting directories
-X   https://github.com/processing/processing/pull/3916
-X show number of updates available in the footer
-X   https://github.com/processing/processing/issues/3518
-X   https://github.com/processing/processing/pull/3896
-X   https://github.com/processing/processing/pull/3901
-o   total number of updates available is not correct? (may be fixed)
-o ArrayIndexOutOfBoundsException freak out when clicking the header line
-o   think this was on name, with libraries, but not sure
-X   should be fixed with the updates from Jakub
-X error checker updates for toggle and listeners
-X   https://github.com/processing/processing/pull/3915
-X file file counting in the change detector
-X   https://github.com/processing/processing/pull/3917
-X   https://github.com/processing/processing/issues/3898
-X   https://github.com/processing/processing/issues/3387
-X Windows suggests ""Documents"" as a new location for the 3.0 sketchbook
-X   maybe prevent users from accepting that?
-X   https://github.com/processing/processing/issues/3920
-
-gui
-X distinguish errors and warnings
-X   https://github.com/processing/processing/issues/3406
-X make breakpoints more prominent
-X   https://github.com/processing/processing/issues/3307 (comp is set)
-X clean up statusMessage() inside JavaEditor
-o   do we want to bring back the delays?
-X implement side gradient on the editor
-X if fewer lines in sketch than can be shown in window, show ticks adjacent
-X   error/warning location is awkward when no scroll bar is in use
-X   when only one screen-full, show ticks at exact location
-X   simpler/less confusing to not show at all? 
-X   MarkerColumn.recalculateMarkerPositions()
-X   https://github.com/processing/processing/pull/3903
-X Update status error/warning when changing the line
-X   https://github.com/processing/processing/pull/3907
-X Update status error/warning when changing the line
-X   when moving away from an error/warning line, de-select it below
-X   selecting a warning should also show the warning in the status area
-X   https://github.com/processing/processing/pull/3907
-X clicking an error or warning should give the focus back to the editor
-X   https://github.com/processing/processing/pull/3905
-X replace startup/about screen (1x and 2x versions)
-X   change 'alpha' to correct name
-X   also change the revision in the ""about processing"" dialog
-X   https://github.com/processing/processing/issues/3665
-X implement splash screen on OS X
-X   http://www.randelshofer.ch/oop/javasplash/javasplash.html
-X   also implement special retina version
-X Fix placement and visual design when showing error on hover
-X   https://github.com/processing/processing/issues/3173
-X   implement custom tooltip for error/warning hover
-X   applies to both MarkerColumn and JavaTextAreaPainter
-X make gutter of console match error list
-X   https://github.com/processing/processing/issues/3904
-o bring back the # of updates on the update tab
-o   use this instead of the 'icon' stuff?
-o   or in addition, since only the 'updates' tab has it
-X   https://github.com/processing/processing/issues/3855
-X for updates available, have it be clickable to open the manager
-X fix the design of the completions window
-X   remove extra border around the outside
-X   change font
-X   add 2x version of the icons
-X   change selection highlight color
-o   put some margin around it
-X   https://github.com/processing/processing/issues/3906
-X completion panel
-X   what should the background color be? 
-X   test fg/bg color on other operating systems
-J   fix icon sizes/design
-X set a better minimum size for the number of updates available
-
-earlier/cleaning
-X list with contrib types separated is really wonky
-o   do we keep the list?
-o   does it even work for different contrib types?
-X   cleaned this up in the last release
-X remove the dated releases from download.processing.org
-X new Android release (EditorButton constructor changed)
-o JavaEditor has several null colors, remove color support
-o   once the design is complete and we for sure do not need color
-X remove deprecated methods
-X do the right thing on passing around List vs ArrayList and others
-o wonder if ""Save As"" is causing the problems with auto-reload
-X   found and fixed
-X look at the sound library https://github.com/wirsing/ProcessingSound
-o   sound is not yet supported on Windows
-X implement the new gui
+0247 (3.0.1)
 
 
 known issues",starting the next release,"""Bump version to 3.0.1 (REV 0247)""","""Release Processing 3.0.1 (revision 0247)""","It seems like you're sharing some version control diff outputs and change logs for a software project named Processing. From the information provided, it appears that the project has gone through several changes and revisions, with the most recent one being 0246.

The changes seem to be related to various aspects of the project, including the core, GUI, error handling, and cleaning. Some of the changes include implementing high-performance/async image saving, fixing various bugs related to textures and frames, and updating the error checker. Additionally, there have been changes to the GUI, such as distinguishing errors and warnings, making breakpoints more prominent, and updating the status message in the JavaEditor.

The project also seems to have addressed some issues related to file handling, such as not following symlinks when deleting directories and fixing file counting in the change detector. Furthermore, there have been contributions from other developers, and the project has updated the number of updates available in the footer.

The next planned version appears to be 0247, but the specific changes for that version have not been detailed yet.",Update version number to 0247 and revise related files for release 3.0.1.,Model 3
"diff --git a/src/main/java/reactor/core/publisher/EventLoopProcessor.java b/src/main/java/reactor/core/publisher/EventLoopProcessor.java
index cb830ea52..ddd43abea 100644
--- a/src/main/java/reactor/core/publisher/EventLoopProcessor.java
+++ b/src/main/java/reactor/core/publisher/EventLoopProcessor.java
@@ -23,7 +23,6 @@ import java.util.concurrent.ThreadFactory;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;
-import java.util.concurrent.atomic.AtomicLong;
 import java.util.function.Supplier;
 
 import org.reactivestreams.Processor;
@@ -33,6 +32,7 @@ import reactor.core.flow.Cancellation;
 import reactor.core.flow.Loopback;
 import reactor.core.flow.MultiProducer;
 import reactor.core.flow.Receiver;
+import reactor.core.queue.QueueSupplier;
 import reactor.core.queue.RingBuffer;
 import reactor.core.queue.Slot;
 import reactor.core.scheduler.Scheduler;
@@ -104,7 +104,7 @@ abstract class EventLoopProcessor<IN> extends FluxProcessor<IN, IN>
 			Supplier<Slot<IN>> factory,
 			WaitStrategy strategy) {
 
-		if (!RingBuffer.isPowerOfTwo(bufferSize)) {
+		if (!QueueSupplier.isPowerOfTwo(bufferSize)) {
 			throw new IllegalArgumentException(""bufferSize must be a power of 2 : "" + bufferSize);
 		}
 		
diff --git a/src/main/java/reactor/core/queue/MultiProducer.java b/src/main/java/reactor/core/queue/MultiProducer.java
index 451f83eb0..a269d7fc6 100644
--- a/src/main/java/reactor/core/queue/MultiProducer.java
+++ b/src/main/java/reactor/core/queue/MultiProducer.java
@@ -54,7 +54,7 @@ final class MultiProducer extends RingBufferProducer
     MultiProducer(int bufferSize, final WaitStrategy waitStrategy, Runnable spinObserver) {
         super(bufferSize, waitStrategy, spinObserver);
 
-        if (!RingBuffer.isPowerOfTwo(bufferSize)) {
+        if (!QueueSupplier.isPowerOfTwo(bufferSize)) {
             throw new IllegalArgumentException(""bufferSize must be a power of 2"");
         }
 
diff --git a/src/main/java/reactor/core/queue/QueueSupplier.java b/src/main/java/reactor/core/queue/QueueSupplier.java
index 96657e3c5..c4bd11804 100644
--- a/src/main/java/reactor/core/queue/QueueSupplier.java
+++ b/src/main/java/reactor/core/queue/QueueSupplier.java
@@ -28,17 +28,17 @@ import reactor.core.util.PlatformDependent;
  */
 public final class QueueSupplier<T> implements Supplier<Queue<T>> {
 
-	static final Supplier CLQ_SUPPLIER             = new QueueSupplier<>(Long.MAX_VALUE, false, false);
-	static final Supplier ONE_SUPPLIER             = new QueueSupplier<>(1, false, true);
-	static final Supplier XSRB_SUPPLIER            = new QueueSupplier<>(PlatformDependent.XS_BUFFER_SIZE, false, false);
-	static final Supplier SMALLRB_SUPPLIER         = new QueueSupplier<>(PlatformDependent.SMALL_BUFFER_SIZE, false, false);
-	static final Supplier WAITING_XSRB_SUPPLIER    = new QueueSupplier<>(PlatformDependent.XS_BUFFER_SIZE, true, false);
-	static final Supplier WAITING_SMALLRB_SUPPLIER = new QueueSupplier<>(PlatformDependent.SMALL_BUFFER_SIZE, true, false);
-
-	final long    batchSize;
-	final boolean waiting;
-	final boolean multiproducer;
-
+	/**
+	 * Calculate the next power of 2, greater than or equal to x.<p> From Hacker's Delight, Chapter 3, Harry S. Warren
+	 * Jr.
+	 *
+	 * @param x Value to round up
+	 *
+	 * @return The next power of 2 from x inclusive
+	 */
+	public static int ceilingNextPowerOfTwo(final int x) {
+		return 1 << (32 - Integer.numberOfLeadingZeros(x - 1));
+	}
 
 	/**
 	 *
@@ -84,7 +84,16 @@ public final class QueueSupplier<T> implements Supplier<Queue<T>> {
 		}
 		return new QueueSupplier<>(batchSize, waiting, multiproducer);
 	}
-	
+
+	/**
+	 * @param x the int to test
+	 *
+	 * @return true if x is a power of 2
+	 */
+	public static boolean isPowerOfTwo(final int x) {
+		return Integer.bitCount(x) == 1;
+	}
+
 	/**
 	 *
 	 * @param <T> the reified {@link Queue} generic type
@@ -166,6 +175,9 @@ public final class QueueSupplier<T> implements Supplier<Queue<T>> {
 			return (Supplier<Queue<T>>) WAITING_XSRB_SUPPLIER;
 		}
 	}
+	final long    batchSize;
+	final boolean waiting;
+	final boolean multiproducer;
 
 	QueueSupplier(long batchSize, boolean waiting, boolean multiproducer) {
 		this.batchSize = batchSize;
@@ -198,17 +210,49 @@ public final class QueueSupplier<T> implements Supplier<Queue<T>> {
 	}
 
 	static final class OneQueue<T> extends AtomicReference<T> implements Queue<T> {
-		/** */
-        private static final long serialVersionUID = -6079491923525372331L;
-
         @Override
 		public boolean add(T t) {
 
 		    while (!offer(t));
-		    
+
 		    return true;
 		}
 
+		@Override
+		public boolean addAll(Collection<? extends T> c) {
+			return false;
+		}
+
+		@Override
+		public void clear() {
+			set(null);
+		}
+
+		@Override
+		public boolean contains(Object o) {
+			return Objects.equals(get(), o);
+		}
+
+		@Override
+		public boolean containsAll(Collection<?> c) {
+			return false;
+		}
+
+		@Override
+		public T element() {
+			return get();
+		}
+
+		@Override
+		public boolean isEmpty() {
+			return get() == null;
+		}
+
+		@Override
+		public Iterator<T> iterator() {
+			return new QueueIterator<>(this);
+		}
+
 		@Override
 		public boolean offer(T t) {
 			if (get() != null) {
@@ -219,8 +263,8 @@ public final class QueueSupplier<T> implements Supplier<Queue<T>> {
 		}
 
 		@Override
-		public T remove() {
-			return getAndSet(null);
+		public T peek() {
+			return get();
 		}
 
 		@Override
@@ -233,33 +277,28 @@ public final class QueueSupplier<T> implements Supplier<Queue<T>> {
 		}
 
 		@Override
-		public T element() {
-			return get();
-		}
-
-		@Override
-		public T peek() {
-			return get();
+		public T remove() {
+			return getAndSet(null);
 		}
 
 		@Override
-		public int size() {
-			return get() == null ? 0 : 1;
+		public boolean remove(Object o) {
+			return false;
 		}
 
 		@Override
-		public boolean isEmpty() {
-			return get() == null;
+		public boolean removeAll(Collection<?> c) {
+			return false;
 		}
 
 		@Override
-		public boolean contains(Object o) {
-			return Objects.equals(get(), o);
+		public boolean retainAll(Collection<?> c) {
+			return false;
 		}
 
 		@Override
-		public Iterator<T> iterator() {
-			return new QueueIterator<>(this);
+		public int size() {
+			return get() == null ? 0 : 1;
 		}
 
 		@Override
@@ -283,36 +322,8 @@ public final class QueueSupplier<T> implements Supplier<Queue<T>> {
 			}
 			return (T1[])toArray();
 		}
-
-		@Override
-		public boolean remove(Object o) {
-			return false;
-		}
-
-		@Override
-		public boolean containsAll(Collection<?> c) {
-			return false;
-		}
-
-		@Override
-		public boolean addAll(Collection<? extends T> c) {
-			return false;
-		}
-
-		@Override
-		public boolean removeAll(Collection<?> c) {
-			return false;
-		}
-
-		@Override
-		public boolean retainAll(Collection<?> c) {
-			return false;
-		}
-
-		@Override
-		public void clear() {
-			set(null);
-		}
+		/** */
+        private static final long serialVersionUID = -6079491923525372331L;
 	}
 
 	static class QueueIterator<T> implements Iterator<T> {
@@ -338,4 +349,10 @@ public final class QueueSupplier<T> implements Supplier<Queue<T>> {
 			queue.remove();
 		}
 	}
+	static final Supplier CLQ_SUPPLIER          = new QueueSupplier<>(Long.MAX_VALUE, false, false);
+	static final Supplier ONE_SUPPLIER          = new QueueSupplier<>(1, false, true);
+	static final Supplier XSRB_SUPPLIER         = new QueueSupplier<>(PlatformDependent.XS_BUFFER_SIZE, false, false);
+	static final Supplier SMALLRB_SUPPLIER      = new QueueSupplier<>(PlatformDependent.SMALL_BUFFER_SIZE, false, false);
+	static final Supplier WAITING_XSRB_SUPPLIER = new QueueSupplier<>(PlatformDependent.XS_BUFFER_SIZE, true, false);
+	static final Supplier WAITING_SMALLRB_SUPPLIER = new QueueSupplier<>(PlatformDependent.SMALL_BUFFER_SIZE, true, false);
 }
diff --git a/src/main/java/reactor/core/queue/RingBuffer.java b/src/main/java/reactor/core/queue/RingBuffer.java
index 868b809c1..01ab7a23c 100644
--- a/src/main/java/reactor/core/queue/RingBuffer.java
+++ b/src/main/java/reactor/core/queue/RingBuffer.java
@@ -50,18 +50,6 @@ public abstract class RingBuffer<E> implements LongSupplier, Backpressurable {
 	 */
 	public static final long     INITIAL_CURSOR_VALUE = -1L;
 
-	/**
-	 * Calculate the next power of 2, greater than or equal to x.<p> From Hacker's Delight, Chapter 3, Harry S. Warren
-	 * Jr.
-	 *
-	 * @param x Value to round up
-	 *
-	 * @return The next power of 2 from x inclusive
-	 */
-	public static int ceilingNextPowerOfTwo(final int x) {
-		return 1 << (32 - Integer.numberOfLeadingZeros(x - 1));
-	}
-
 	/**
 	 *
 	 * Create a
@@ -106,17 +94,6 @@ public abstract class RingBuffer<E> implements LongSupplier, Backpressurable {
 		return createMultiProducer(EMITTED, bufferSize, WaitStrategy.blocking());
 	}
 
-	/**
-	 * Create a new multiple producer RingBuffer using the default wait strategy   {@link WaitStrategy#busySpin()}.
-	 * @param factory used to create the events within the ring buffer.
-	 * @param bufferSize number of elements to create within the ring buffer.
-	 * @throws IllegalArgumentException if <tt>bufferSize</tt> is less than 1 or not a power of 2
-	 * @see MultiProducer
-	 */
-	public static <E> RingBuffer<E> createMultiProducer(Supplier<E> factory, int bufferSize) {
-		return createMultiProducer(factory, bufferSize, WaitStrategy.busySpin());
-	}
-
 	/**
 	 * Create a new multiple producer RingBuffer with the specified wait strategy.
 	 * @param factory used to create the events within the ring buffer.
@@ -143,7 +120,7 @@ public abstract class RingBuffer<E> implements LongSupplier, Backpressurable {
 			int bufferSize,
 			WaitStrategy waitStrategy, Runnable spinObserver) {
 
-		if (PlatformDependent.hasUnsafe() && isPowerOfTwo(bufferSize)) {
+		if (PlatformDependent.hasUnsafe() && QueueSupplier.isPowerOfTwo(bufferSize)) {
 			MultiProducer sequencer = new MultiProducer(bufferSize, waitStrategy, spinObserver);
 
 			return new UnsafeRingBuffer<E>(factory, sequencer);
@@ -195,16 +172,6 @@ public abstract class RingBuffer<E> implements LongSupplier, Backpressurable {
 		return createSingleProducer(EMITTED, bufferSize, WaitStrategy.busySpin());
 	}
 
-	/**
-	 * Create a new single producer RingBuffer using the default wait strategy  {@link WaitStrategy#busySpin()}.
-	 * @param bufferSize number of elements to create within the ring buffer.
-	 * @see MultiProducer
-	 */
-	@SuppressWarnings(""unchecked"")
-	public static <E> RingBuffer<Slot<E>> createSingleProducer(int bufferSize, Runnable spinObserver) {
-		return createSingleProducer(EMITTED, bufferSize, WaitStrategy.busySpin(), spinObserver);
-	}
-
 	/**
 	 * Create a new single producer RingBuffer using the default wait strategy   {@link WaitStrategy#busySpin()}.
 	 * @param factory used to create the events within the ring buffer.
@@ -244,7 +211,7 @@ public abstract class RingBuffer<E> implements LongSupplier, Backpressurable {
 			Runnable spinObserver) {
 		SingleProducerSequencer sequencer = new SingleProducerSequencer(bufferSize, waitStrategy, spinObserver);
 
-		if (PlatformDependent.hasUnsafe() && isPowerOfTwo(bufferSize)) {
+		if (PlatformDependent.hasUnsafe() && QueueSupplier.isPowerOfTwo(bufferSize)) {
 			return new UnsafeRingBuffer<>(factory, sequencer);
 		}
 		else {
@@ -289,15 +256,6 @@ public abstract class RingBuffer<E> implements LongSupplier, Backpressurable {
 		return minimum;
 	}
 
-	/**
-	 * @param x the int to test
-	 *
-	 * @return true if x is a power of 2
-	 */
-	public static boolean isPowerOfTwo(final int x) {
-		return Integer.bitCount(x) == 1;
-	}
-
 	/**
 	 * Calculate the log base 2 of the supplied integer, essentially reports the location of the highest bit.
 	 *
diff --git a/src/main/java/reactor/core/queue/SpscArrayQueue.java b/src/main/java/reactor/core/queue/SpscArrayQueue.java
index ad1e7bb21..48cb0d627 100644
--- a/src/main/java/reactor/core/queue/SpscArrayQueue.java
+++ b/src/main/java/reactor/core/queue/SpscArrayQueue.java
@@ -39,7 +39,7 @@ final class SpscArrayQueue<T> extends SpscArrayQueueP3<T> implements Queue<T> {
     private static final long serialVersionUID = 494623116936946976L;
 
     public SpscArrayQueue(int capacity) {
-        super(RingBuffer.ceilingNextPowerOfTwo(capacity));
+        super(QueueSupplier.ceilingNextPowerOfTwo(capacity));
     }
     
     @Override
diff --git a/src/main/java/reactor/core/queue/SpscLinkedArrayQueue.java b/src/main/java/reactor/core/queue/SpscLinkedArrayQueue.java
index 413d204b6..b265cf6e6 100644
--- a/src/main/java/reactor/core/queue/SpscLinkedArrayQueue.java
+++ b/src/main/java/reactor/core/queue/SpscLinkedArrayQueue.java
@@ -45,7 +45,7 @@ final class SpscLinkedArrayQueue<T> extends AbstractQueue<T> {
     static final Object NEXT = new Object();
     
     public SpscLinkedArrayQueue(int linkSize) {
-        int c = RingBuffer.ceilingNextPowerOfTwo(Math.min(2, linkSize));
+        int c = QueueSupplier.ceilingNextPowerOfTwo(Math.min(2, linkSize));
         this.producerArray = this.consumerArray = new AtomicReferenceArray<>(c + 1);
         this.mask = c - 1;
     }
diff --git a/src/main/java/reactor/core/queue/UnsafeRingBuffer.java b/src/main/java/reactor/core/queue/UnsafeRingBuffer.java
index 34f1653df..b7dfc4307 100644
--- a/src/main/java/reactor/core/queue/UnsafeRingBuffer.java
+++ b/src/main/java/reactor/core/queue/UnsafeRingBuffer.java
@@ -61,7 +61,7 @@ abstract class RingBufferFields<E> extends RingBufferPad<E>
         if (bufferSize < 1) {
             throw new IllegalArgumentException(""bufferSize must not be less than 1"");
         }
-        if (!RingBuffer.isPowerOfTwo(bufferSize))
+        if (!QueueSupplier.isPowerOfTwo(bufferSize))
         {
             throw new IllegalArgumentException(""bufferSize must be a power of 2"");
         }
diff --git a/src/main/java/reactor/core/scheduler/OpenHashSet.java b/src/main/java/reactor/core/scheduler/OpenHashSet.java
index 456a11aca..2e2b09597 100644
--- a/src/main/java/reactor/core/scheduler/OpenHashSet.java
+++ b/src/main/java/reactor/core/scheduler/OpenHashSet.java
@@ -25,7 +25,7 @@ package reactor.core.scheduler;
 import java.util.Arrays;
 import java.util.function.Consumer;
 
-import reactor.core.queue.RingBuffer;
+import reactor.core.queue.QueueSupplier;
 
 /**
  * A simple open hash set with add, remove and clear capabilities only.
@@ -55,7 +55,7 @@ final class OpenHashSet<T> {
     @SuppressWarnings(""unchecked"")
     public OpenHashSet(int capacity, float loadFactor) {
         this.loadFactor = loadFactor;
-        int c = RingBuffer.ceilingNextPowerOfTwo(capacity);
+        int c = QueueSupplier.ceilingNextPowerOfTwo(capacity);
         this.mask = c - 1;
         this.maxSize = (int)(loadFactor * c);
         this.keys = (T[])new Object[c];",tweaks QueueSupplier utils,"""Extract power of 2 checks and ceiling calculation to QueueSupplier""","""Replace RingBuffer.isPowerOfTwo with QueueSupplier.isPowerOfTwo""","""Update to use QueueSupplier for power of 2 checks and OneQueue implementation""

This commit makes several changes to the codebase:

* It introduces a new class `QueueSupplier` that provides a static method `isPowerOfTwo` for checking if a given integer is a power of 2. This method is used in several places throughout the codebase to replace similar checks that were previously implemented using `Integer.bitCount`.
* It updates the `EventLoopProcessor` and `MultiProducer` classes to use `QueueSupplier.isPowerOfTwo` instead of `RingBuffer.isPowerOfTwo`.
* It adds several new methods to the `OneQueue` class to make it a full implementation of the `Queue` interface. These methods include `addAll`, `clear`, `contains`, `containsAll`, `element`, `isEmpty`, `iterator`, `remove`, `removeAll`, `retainAll`, and `size`.
* It adds a `serialVersionUID` field to the `OneQueue` class to make it compatible with Java's serialization mechanism.
* It updates the `QueueSupplier` class to define several new constants for creating `Queue` instances with different characteristics, such as waiting or non-waiting, single-producer or multi-producer, and with different buffer sizes.

Overall, this commit seems to be focused on improving the consistency and flexibility of the codebase by introducing a new abstraction for creating `Queue` instances and updating existing code to use this abstraction. It also includes some minor improvements to the `OneQueue` class to make it a full implementation of the `Queue` interface.","Refactored to utilize `QueueSupplier`'s `isPowerOfTwo` and `ceilingNextPowerOfTwo` methods, removing duplicates from `RingBuffer`.",Model 2
"diff --git a/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/_operations.html.erb b/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/_operations.html.erb
index dec69e8c8f8..1236878d716 100644
--- a/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/_operations.html.erb
+++ b/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/_operations.html.erb
@@ -16,7 +16,7 @@
     <li><%= uninstall -%></li>
   <% end %>
   </ul>
-  <input type=""submit"" value=""Cancel uninstalls""/>
+  <input type=""submit"" value=""Cancel uninstalls"" id=""cancel-uninstall""/>
 </p>
 </form>
 <% end %>
@@ -28,7 +28,7 @@
     <li><%= download -%></li>
   <% end %>
   </ul>
-  <input type=""submit"" value=""Cancel pending installations""/>
+  <input type=""submit"" value=""Cancel pending installations"" id=""cancel-pending-installations""/>
 </p>
 </form>
 <% end %>
diff --git a/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/available.html.erb b/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/available.html.erb
index 6bc0f196fc7..9487480fb5a 100644
--- a/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/available.html.erb
+++ b/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/available.html.erb
@@ -35,7 +35,7 @@ function installPlugin(key) {
         plugin = update.plugin
         release = update.release
     %>
-      <tr class=""<%= cycle('even','odd', :name => category) -%>"">
+      <tr class=""<%= cycle('even','odd', :name => category) -%>"" id=""select-<%= plugin.getKey() -%>"">
         <td width=""150"" nowrap>
           <b><a href=""#plugin"" onClick=""showPlugin('<%= plugin.getKey() -%>');""><%= h(plugin.getName()) -%></a></b>
         </td>
diff --git a/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/index.html.erb b/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/index.html.erb
index 4d5f853e752..31d566f9073 100644
--- a/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/index.html.erb
+++ b/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/index.html.erb
@@ -85,7 +85,7 @@
           <tr>
             <td colspan=""2"">
              <form method=""post"" action=""<%= ApplicationController.root_context -%>/updatecenter/uninstall?key=<%= plugin.getKey() -%>"" style=""display: inline-block"">
-               <input type=""submit"" value=""Uninstall"" class=""red-button""/>
+               <input type=""submit"" value=""Uninstall"" class=""red-button"" id=""uninstall-<%= plugin.getKey() -%>""/>
              </form>
               </td>
             </tr>
diff --git a/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/updates.html.erb b/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/updates.html.erb
index 05a59b023a3..ad2891711b6 100644
--- a/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/updates.html.erb
+++ b/sonar-server/src/main/webapp/WEB-INF/app/views/updatecenter/updates.html.erb
@@ -31,7 +31,7 @@ function upgradePlugin(key) {
            updates.each_with_index do |update, index|
             release=update.release
        %>
-        <tr class=""<%= css -%>"">
+        <tr class=""<%= css -%>"" id=""select_<%= plugin.getKey() -%>"">
           <td width=""1%"" nowrap><% if index==0 %><b><%= h(plugin.getName()) -%></b> <%= @installed_plugins[plugin.getKey()] -%> -> <% end %></td>
           <td width=""1%"" nowrap><b><%= release.getVersion() -%></b></td>
           <td width=""1%"" nowrap><%= release_date(release.getDate()) if release.getDate() -%></td>",Add HTML Id,"""Add IDs to update center buttons and table rows for better accessibility and styling""","""Added unique IDs to UI elements for better accessibility and identification""","This commit contains changes to the Sonar server's update center view files.

1. In `_operations.html.erb`, IDs have been added to the ""Cancel uninstalls"" and ""Cancel pending installations"" buttons.
2. In `available.html.erb`, an ID has been added to the table row for plugin selection.
3. In `index.html.erb`, an ID has been added to the ""Uninstall"" button for each plugin.
4. In `updates.html.erb`, an ID has been added to the table row for plugin selection.

These changes may be used for referencing these elements in JavaScript or CSS.",Added unique IDs to input buttons and table rows for better DOM element selection and manipulation.,Model 2
"diff --git a/spring-security-oauth2/src/main/java/org/springframework/security/oauth2/config/ResourceServerBeanDefinitionParser.java b/spring-security-oauth2/src/main/java/org/springframework/security/oauth2/config/ResourceServerBeanDefinitionParser.java
index adada9a5..0221fcfa 100755
--- a/spring-security-oauth2/src/main/java/org/springframework/security/oauth2/config/ResourceServerBeanDefinitionParser.java
+++ b/spring-security-oauth2/src/main/java/org/springframework/security/oauth2/config/ResourceServerBeanDefinitionParser.java
@@ -47,7 +47,7 @@ public class ResourceServerBeanDefinitionParser extends ProviderBeanDefinitionPa
 		}
 		protectedResourceFilterBean.addPropertyValue(""authenticationManager"", authenticationManagerBean.getBeanDefinition());
 		if (StringUtils.hasText(entryPointRef)) {
-			protectedResourceFilterBean.addPropertyValue(""authenticationEntryPoint"", entryPointRef);
+			protectedResourceFilterBean.addPropertyReference(""authenticationEntryPoint"", entryPointRef);
 		}
 
 		return protectedResourceFilterBean.getBeanDefinition();
diff --git a/spring-security-oauth2/src/main/resources/org/springframework/security/oauth2/spring-security-oauth2-1.0.xsd b/spring-security-oauth2/src/main/resources/org/springframework/security/oauth2/spring-security-oauth2-1.0.xsd
index f2802bdd..0fca0112 100644
--- a/spring-security-oauth2/src/main/resources/org/springframework/security/oauth2/spring-security-oauth2-1.0.xsd
+++ b/spring-security-oauth2/src/main/resources/org/springframework/security/oauth2/spring-security-oauth2-1.0.xsd
@@ -339,16 +339,11 @@
 						</xs:annotation>
 					</xs:attribute>
 
-					<xs:attribute name=""serialization-service-ref"" type=""xs:string"">
+					<xs:attribute name=""entry-point-ref"" type=""xs:string"">
 						<xs:annotation>
 							<xs:documentation>
-								The reference to the bean that defines the
-								serialization service for
-								an OAuth 2 response
-								Default
-								value is an
-								instance of
-								""org.springframework.security.oauth2.common.DefaultOAuth2SerializationService"".
+								The reference to the bean that defines the entry point for failed authentications.  Defaults to a vanilla
+								org.springframework.security.oauth2.provider.error.OAuth2AuthenticationEntryPoint.
 							</xs:documentation>
 						</xs:annotation>
 					</xs:attribute>",add entry point to xsd !,"""Change ResourceServerBeanDefinitionParser to use property reference for authenticationEntryPoint and update XSD to reflect entry-point-ref attribute""","""Update ResourceServerBeanDefinitionParser to use addPropertyReference for authenticationEntryPoint and update xsd to reflect the change in attribute name from serialization-service-ref to entry-point-ref""","""Updated ResourceServerBeanDefinitionParser to use addPropertyReference instead of addPropertyValue for authenticationEntryPoint, and removed serialization-service-ref attribute from spring-security-oauth2-1.0.xsd""",Fix bean attribute reference and update XSD documentation for authentication entry point in ResourceServer configuration.,Model 3
"diff --git a/src/main/java/hex/deeplearning/DeepLearningModel.java b/src/main/java/hex/deeplearning/DeepLearningModel.java
index 8e03aeca1..c193189a5 100644
--- a/src/main/java/hex/deeplearning/DeepLearningModel.java
+++ b/src/main/java/hex/deeplearning/DeepLearningModel.java
@@ -1188,7 +1188,8 @@ public class DeepLearningModel extends Model implements Comparable<DeepLearningM
             + water.api.Predict.link(_key, ""Score on dataset"") + "", ""
             + DeepLearning.link(_dataKey, ""Compute new model"", null, responseName(), val_key)
             + (actual_best_model_key != null && UKV.get(actual_best_model_key) != null && actual_best_model_key != _key ? "", "" + DeepLearningModelView.link(""Go to best model"", actual_best_model_key) : """")
-            + (jobKey == null || ((jobKey != null && UKV.get(jobKey) == null)) || (jobKey != null && UKV.get(jobKey) != null && Job.isEnded(jobKey)) ? "", <i class=\""icon-play\""></i>"" + DeepLearning.link(_dataKey, ""Continue training this model"", _key, responseName(), val_key) : """")
+            + (jobKey == null || ((jobKey != null && UKV.get(jobKey) == null)) || (jobKey != null && UKV.get(jobKey) != null && Job.isEnded(jobKey)) ? "", <i class=\""icon-play\""></i>"" + DeepLearning.link(_dataKey, ""Continue training this model"", _key, responseName(), val_key) : """") + "", ""
+            + UIUtils.qlink(SaveModel.class, ""model"", _key, ""Save model"") + "", ""
             + ""</div>"");
 
     DocGen.HTML.paragraph(sb, ""Model Key: "" + _key);",Add saveModel link to DL Model web page .,"""Added 'Save model' link to DeepLearningModel""","Added ""Save model"" option to DeepLearningModel view.","""Added a 'Save model' link to the DeepLearningModel view""","Added ""Save model"" and its corresponding link in the DeepLearningModel view for saving models.",Model 4
"diff --git a/build/build_release.sh b/build/build_release.sh
index ed539dcef5..8fa8441c87 100755
--- a/build/build_release.sh
+++ b/build/build_release.sh
@@ -95,10 +95,6 @@ echo ""  geowebcache = $gwc_ver""
 echo ""maven/java settings:""
 mvn -version
 
-if [ ! -z $git_user ] && [ ! -z $git_email ]; then
-  git_opts=""--author='$git_user <$git_email>'""
-fi
-
 # move to root of source tree
 pushd .. > /dev/null
 
@@ -364,6 +360,16 @@ fi
 
 # git commit changes on the release branch
 pushd .. > /dev/null
+
+# setup the author, for some reason I can;t for the life of me get to this
+# to work properly from a script using the --author option to git commit
+git config --unset user.name
+git config --unset user.email
+if [ ! -z $git_user ] && [ ! -z $git_email ]; then
+  git config user.name $git_user
+  git config user.email $git_email
+fi
+
 git add . 
 git commit $git_opts -m ""updating version numbers and release notes for $tag"" .
 popd > /dev/null",using git config to set author for release commits rather than - - author option,"""Fix setting author for release commits""","""Fix author configuration for git commit on release branch""

However, considering the commit message is already specified in the code, a more accurate commit message would be:

""update git commit author configuration""

This commit message directly reflects the changes made in the code.","""updating version numbers and release notes for $tag""

This commit message indicates that the purpose of the commit is to update version numbers and release notes for a specific tag (represented by the variable $tag). This commit is likely part of a release process for a software project.

The changes in the code also suggest that the script has been updated to remove some code related to setting the Git author and email configuration, and instead configure the user name and email using Git config commands directly in the script. This change may have been made to ensure that the correct author and email are used for the commit, regardless of the user's local Git configuration.","""Moved git author config setup from initial check to commit step for setting author details dynamically during release.""",Model 2
"diff --git a/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_constants.bal b/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_constants.bal
index 3b7e816b94c..45bee4b4591 100644
--- a/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_constants.bal
+++ b/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_constants.bal
@@ -193,10 +193,12 @@ const string MAP_VALUE = ""org/ballerinalang/jvm/values/MapValue"";
 const string ARRAY_VALUE = ""org/ballerinalang/jvm/values/ArrayValue"";
 const string OBJECT_VALUE = ""org/ballerinalang/jvm/values/ObjectValue"";
 const string STRING_VALUE = ""java/lang/String"";
-const string OBJECT = ""java/lang/Object"";
 const string LONG_VALUE = ""java/lang/Long"";
 const string BOOLEAN_VALUE = ""java/lang/Boolean"";
+const string DOUBLE_VALUE = ""java/lang/Double"";
+const string BYTE_VALUE = ""java/lang/Byte"";
 
+const string OBJECT = ""java/lang/Object"";
 const string MAP = ""java/util/Map"";
 const string LINKED_HASH_MAP = ""java/util/LinkedHashMap"";
 
diff --git a/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_instruction_gen.bal b/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_instruction_gen.bal
index 37812f77e1b..0c28b5f1a12 100644
--- a/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_instruction_gen.bal
+++ b/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_instruction_gen.bal
@@ -27,6 +27,10 @@ type InstructionGenerator object {
             int index = self.getJVMIndexOfVarRef(loadIns.lhsOp.variableDcl);
             //io:println(""Const Store Index is :::::::::::"", index);
             self.mv.visitVarInsn(ASTORE, index);
+        } else if (bType is bir:BTypeNil) {
+            self.mv.visitInsn(ACONST_NULL);
+            int index = self.getJVMIndexOfVarRef(loadIns.lhsOp.variableDcl);
+            self.mv.visitVarInsn(ASTORE, index);
         } else {
             error err = error( ""JVM generation is not supported for type : "" + io:sprintf(""%s"", bType));
             panic err;
@@ -44,16 +48,22 @@ type InstructionGenerator object {
         if (bType is bir:BTypeInt) {
             self.mv.visitVarInsn(LLOAD, rhsIndex);
             self.mv.visitVarInsn(LSTORE, lhsLndex);
-        } else if (bType is bir:BTypeBoolean) {
-            self.mv.visitVarInsn(ILOAD, rhsIndex);
-            self.mv.visitVarInsn(ISTORE, lhsLndex);
+        } else if (bType is bir:BTypeFloat) {
+            self.mv.visitVarInsn(DLOAD, rhsIndex);
+            self.mv.visitVarInsn(DSTORE, lhsLndex);
         } else if (bType is bir:BTypeString) {
             self.mv.visitVarInsn(ALOAD, rhsIndex);
             self.mv.visitVarInsn(ASTORE, lhsLndex);
-        } else if (bType is bir:BArrayType) {
-            self.mv.visitVarInsn(ALOAD, rhsIndex);
-            self.mv.visitVarInsn(ASTORE, lhsLndex);
-        } else if (bType is bir:BMapType) {
+        } else if (bType is bir:BTypeBoolean) {
+            self.mv.visitVarInsn(ILOAD, rhsIndex);
+            self.mv.visitVarInsn(ISTORE, lhsLndex);
+        } else if (bType is bir:BTypeByte) {
+            self.mv.visitVarInsn(ILOAD, rhsIndex);
+            self.mv.visitVarInsn(ISTORE, lhsLndex);
+        } else if (bType is bir:BArrayType ||
+                        bType is bir:BMapType ||
+                        bType is bir:BTypeAny ||
+                        bType is bir:BTypeNil) {
             self.mv.visitVarInsn(ALOAD, rhsIndex);
             self.mv.visitVarInsn(ASTORE, lhsLndex);
         } else {
diff --git a/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_method_gen.bal b/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_method_gen.bal
index afef2790e21..f2b35e4afdf 100644
--- a/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_method_gen.bal
+++ b/compiler/ballerina-backend-jvm/src/main/ballerina/compiler_backend_jvm/jvm_method_gen.bal
@@ -1,14 +1,11 @@
 function generateMethod(bir:Function func, jvm:ClassWriter cw) {
     BalToJVMIndexMap indexMap = new;
     string funcName = untaint func.name.value;
-
     int returnVarRefIndex = -1;
 
     // generate method desc
     string desc = getMethodDesc(func);
-
     jvm:MethodVisitor mv = cw.visitMethod(ACC_PUBLIC + ACC_STATIC, funcName, desc, null, null);
-
     mv.visitCode();
 
     // generate method body
@@ -29,26 +26,7 @@ function generateMethod(bir:Function func, jvm:ClassWriter cw) {
         var index = indexMap.getIndex(localVar);
         if(localVar.kind != ""ARG""){
             bir:BType bType = localVar.typeValue;
-            if (bType is bir:BTypeInt) {
-                mv.visitInsn(LCONST_0);
-                mv.visitVarInsn(LSTORE, index);
-            } else if (bType is bir:BTypeBoolean) {
-                mv.visitInsn(ICONST_0);
-                mv.visitVarInsn(ISTORE, index);
-            } else if (bType is bir:BTypeString) {
-                mv.visitInsn(ACONST_NULL);
-                mv.visitVarInsn(ASTORE, index);
-            } else if (bType is bir:BMapType) {
-                mv.visitInsn(ACONST_NULL);
-                mv.visitVarInsn(ASTORE, index);
-            } else if (bType is bir:BArrayType) {
-                mv.visitInsn(ACONST_NULL);
-                mv.visitVarInsn(ASTORE, index);
-            } else {
-                error err = error( ""JVM generation is not supported for type "" +
-                                            io:sprintf(""%s"", bType));
-                panic err;
-            }
+            genDefaultValue(mv, bType, index);
         }
         k += 1;
     }
@@ -72,26 +50,7 @@ function generateMethod(bir:Function func, jvm:ClassWriter cw) {
     if (!isVoidFunc) {
         returnVarRefIndex = indexMap.getIndex(localVars[0]);
         bir:BType returnType = func.typeValue.retType;
-        if (returnType is bir:BTypeInt) {
-            mv.visitInsn(LCONST_0);
-            mv.visitVarInsn(LSTORE, returnVarRefIndex);
-        } else if (returnType is bir:BTypeBoolean) {
-            mv.visitInsn(ICONST_0);
-            mv.visitVarInsn(ISTORE, returnVarRefIndex);
-        } else if (returnType is bir:BTypeString) {
-            mv.visitInsn(ACONST_NULL);
-            mv.visitVarInsn(ASTORE, returnVarRefIndex);
-        } else if (returnType is bir:BMapType) {
-            mv.visitInsn(ACONST_NULL);
-            mv.visitVarInsn(ASTORE, returnVarRefIndex);
-        } else if (returnType is bir:BArrayType) {
-            mv.visitInsn(ACONST_NULL);
-            mv.visitVarInsn(ASTORE, returnVarRefIndex);
-        } else {
-            error err = error( ""JVM generation is not supported for type "" +
-                                            io:sprintf(""%s"", returnType));
-            panic err;
-        }
+        genDefaultValue(mv, returnType, returnVarRefIndex);
     }
 
     // uncomment to test yield
@@ -222,13 +181,19 @@ function generateMethod(bir:Function func, jvm:ClassWriter cw) {
         if (bType is bir:BTypeInt) {
             mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""J"");
             mv.visitVarInsn(LSTORE, index);
-        } else if (bType is bir:BTypeBoolean) {
-            mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""Z"");
-            mv.visitVarInsn(ISTORE, index);
+        } else if (bType is bir:BTypeFloat) {
+            mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""D"");
+            mv.visitVarInsn(DSTORE, index);
         } else if (bType is bir:BTypeString) {
             mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), 
                     io:sprintf(""L%s;"", STRING_VALUE));
             mv.visitVarInsn(ASTORE, index);
+        } else if (bType is bir:BTypeBoolean) {
+            mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""Z"");
+            mv.visitVarInsn(ISTORE, index);
+        } else if (bType is bir:BTypeByte) {
+            mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""B"");
+            mv.visitVarInsn(ISTORE, index);
         } else if (bType is bir:BMapType) {
             mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), 
                     io:sprintf(""L%s;"", MAP_VALUE));
@@ -237,6 +202,10 @@ function generateMethod(bir:Function func, jvm:ClassWriter cw) {
             mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), 
                     io:sprintf(""L%s;"", ARRAY_VALUE));
             mv.visitVarInsn(ASTORE, index);
+        } else if (bType is bir:BTypeNil || bType is bir:BTypeAny) {
+            mv.visitFieldInsn(GETFIELD, frameName, localVar.name.value.replace(""%"",""_""), 
+                    io:sprintf(""L%s;"", OBJECT));
+            mv.visitVarInsn(ASTORE, index);
         } else {
             error err = error( ""JVM generation is not supported for type "" +
                                         io:sprintf(""%s"", bType));
@@ -266,13 +235,19 @@ function generateMethod(bir:Function func, jvm:ClassWriter cw) {
         if (bType is bir:BTypeInt) {
             mv.visitVarInsn(LLOAD, index);
             mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""J"");
-        } else if (bType is bir:BTypeBoolean) {
-            mv.visitVarInsn(ILOAD, index);
-            mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""Z"");
+        } else if (bType is bir:BTypeFloat) {
+            mv.visitVarInsn(DLOAD, index);
+            mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""D"");
         } else if (bType is bir:BTypeString) {
             mv.visitVarInsn(ALOAD, index);
             mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""),
                     io:sprintf(""L%s;"", STRING_VALUE));
+        } else if (bType is bir:BTypeBoolean) {
+            mv.visitVarInsn(ILOAD, index);
+            mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""Z"");
+        } else if (bType is bir:BTypeByte) {
+            mv.visitVarInsn(ILOAD, index);
+            mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""), ""B"");
         } else if (bType is bir:BMapType) {
             mv.visitVarInsn(ALOAD, index);
             mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""),
@@ -281,6 +256,10 @@ function generateMethod(bir:Function func, jvm:ClassWriter cw) {
             mv.visitVarInsn(ALOAD, index);
             mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""),
                     io:sprintf(""L%s;"", ARRAY_VALUE));
+        } else if (bType is bir:BTypeNil || bType is bir:BTypeAny) {
+            mv.visitVarInsn(ALOAD, index);
+            mv.visitFieldInsn(PUTFIELD, frameName, localVar.name.value.replace(""%"",""_""),
+                    io:sprintf(""L%s;"", OBJECT));
         } else {
             error err = error( ""JVM generation is not supported for type "" +
                                         io:sprintf(""%s"", bType));
@@ -319,6 +298,38 @@ function generateMethod(bir:Function func, jvm:ClassWriter cw) {
     mv.visitEnd();
 }
 
+function genDefaultValue(jvm:MethodVisitor mv, bir:BType bType, int index) {
+    if (bType is bir:BTypeInt) {
+        mv.visitInsn(LCONST_0);
+        mv.visitVarInsn(LSTORE, index);
+    } else if (bType is bir:BTypeFloat) {
+        mv.visitInsn(DCONST_0);
+        mv.visitVarInsn(DSTORE, index);
+    } else if (bType is bir:BTypeString) {
+        mv.visitInsn(ACONST_NULL);
+        mv.visitVarInsn(ASTORE, index);
+    } else if (bType is bir:BTypeBoolean) {
+        mv.visitInsn(ICONST_0);
+        mv.visitVarInsn(ISTORE, index);
+    } else if (bType is bir:BTypeByte) {
+        mv.visitInsn(ICONST_0);
+        mv.visitVarInsn(ISTORE, index);
+    } else if (bType is bir:BMapType) {
+        mv.visitInsn(ACONST_NULL);
+        mv.visitVarInsn(ASTORE, index);
+    } else if (bType is bir:BArrayType) {
+        mv.visitInsn(ACONST_NULL);
+        mv.visitVarInsn(ASTORE, index);
+    } else if (bType is bir:BTypeNil || bType is bir:BTypeAny) {
+        mv.visitInsn(ACONST_NULL);
+        mv.visitVarInsn(ASTORE, index);
+    } else {
+        error err = error( ""JVM generation is not supported for type "" +
+                                        io:sprintf(""%s"", bType));
+        panic err;
+    }
+}
+
 function getMethodDesc(bir:Function func) returns string {
     string desc = ""(Lorg/ballerina/jvm/Strand;"";
     int i = 0;
@@ -335,14 +346,22 @@ function getMethodDesc(bir:Function func) returns string {
 function getTypeDesc(bir:BType bType) returns string {
     if (bType is bir:BTypeInt) {
         return ""J"";
+    } else if (bType is bir:BTypeFloat) {
+        return ""D"";
     } else if (bType is bir:BTypeString) {
-        return ""Ljava/lang/String;"";
+        return io:sprintf(""L%s;"", STRING_VALUE);
     } else if (bType is bir:BTypeBoolean) {
         return ""Z"";
+    } else if (bType is bir:BTypeByte) {
+        return ""B"";
+    } else if (bType is bir:BTypeNil) {
+        return io:sprintf(""L%s;"", OBJECT);
     } else if (bType is bir:BMapType) {
         return io:sprintf(""L%s;"", OBJECT_VALUE);
     } else if (bType is bir:BArrayType) {
         return io:sprintf(""L%s;"", ARRAY_VALUE);
+    } else if (bType is bir:BTypeAny) {
+        return io:sprintf(""L%s;"", OBJECT);
     } else {
         error err = error( ""JVM generation is not supported for type "" + io:sprintf(""%s"", bType));
         panic err;
@@ -350,18 +369,24 @@ function getTypeDesc(bir:BType bType) returns string {
 }
 
 function generateReturnType(bir:BType? bType) returns string {
-    if (bType is bir:BTypeNil) {
-        return "")V"";
-    } else if (bType is bir:BTypeInt) {
+    if (bType is bir:BTypeInt) {
         return "")J"";
+    } else if (bType is bir:BTypeFloat) {
+        return "")D"";
     } else if (bType is bir:BTypeString) {
-        return "")Ljava/lang/String;"";
+        return io:sprintf("")L%s;"", STRING_VALUE);
     } else if (bType is bir:BTypeBoolean) {
         return "")Z"";
+    } else if (bType is bir:BTypeByte) {
+        return "")B"";
+    } else if (bType is bir:BTypeNil) {
+        return "")V"";
     } else if (bType is bir:BArrayType) {
         return io:sprintf("")L%s;"", ARRAY_VALUE);
     } else if (bType is bir:BMapType) {
         return io:sprintf("")L%s;"", OBJECT_VALUE);
+    } else if (bType is bir:BTypeAny) {
+        return io:sprintf("")L%s;"", OBJECT);
     } else {
         error err = error( ""JVM generation is not supported for type "" + io:sprintf(""%s"", bType));
         panic err;
@@ -420,8 +445,12 @@ function generateMainMethod(bir:Function userMainFunc, jvm:ClassWriter cw, bir:P
         bir:BType returnType = userMainFunc.typeValue.retType;
         if (returnType is bir:BTypeInt) {
             mv.visitMethodInsn(INVOKEVIRTUAL, ""java/io/PrintStream"", ""println"", ""(J)V"", false);
+        } else if (returnType is bir:BTypeFloat) {
+            mv.visitMethodInsn(INVOKEVIRTUAL, ""java/io/PrintStream"", ""println"", ""(D)V"", false);
         } else if (returnType is bir:BTypeBoolean) {
             mv.visitMethodInsn(INVOKEVIRTUAL, ""java/io/PrintStream"", ""println"", ""(Z)V"", false);
+        } else if (returnType is bir:BTypeByte) {
+            mv.visitMethodInsn(INVOKEVIRTUAL, ""java/io/PrintStream"", ""println"", ""(I)V"", false);
         } else {
             mv.visitMethodInsn(INVOKEVIRTUAL, ""java/io/PrintStream"", ""println"", ""(Ljava/lang/Object;)V"", false);
         }
@@ -443,12 +472,24 @@ function generateCast(int paramIndex, bir:BType targetType, jvm:MethodVisitor mv
 
     if (targetType is bir:BTypeInt) {
         mv.visitMethodInsn(INVOKESTATIC, LONG_VALUE, ""parseLong"", ""(Ljava/lang/String;)J"", false);
-    } if (targetType is bir:BTypeBoolean) {
-        mv.visitMethodInsn(INVOKESTATIC, BOOLEAN_VALUE, ""parseBoolean"", ""(Ljava/lang/String;)Z"", false);
+    } else if (targetType is bir:BTypeFloat) {
+        mv.visitMethodInsn(INVOKESTATIC, DOUBLE_VALUE, ""parseDouble"", ""(Ljava/lang/String;)D"", false);
     } else if (targetType is bir:BTypeString) {
         mv.visitTypeInsn(CHECKCAST, STRING_VALUE);
+    } else if (targetType is bir:BTypeBoolean) {
+        mv.visitMethodInsn(INVOKESTATIC, BOOLEAN_VALUE, ""parseBoolean"", ""(Ljava/lang/String;)Z"", false);
+    } else if (targetType is bir:BTypeByte) {
+        mv.visitMethodInsn(INVOKESTATIC, BYTE_VALUE, ""parseByte"", ""(Ljava/lang/String;)B"", false);
+    } else if (targetType is bir:BTypeNil) {
+        // do nothing
+        return;
     } else if (targetType is bir:BArrayType) {
         mv.visitTypeInsn(CHECKCAST, ARRAY_VALUE);
+    } else if (targetType is bir:BMapType) {
+        mv.visitTypeInsn(CHECKCAST, MAP_VALUE);
+    } else if (targetType is bir:BTypeAny) {
+        // do nothing
+        return;
     } else {
         error err = error(""JVM generation is not supported for type "" + io:sprintf(""%s"", targetType));
         panic err;
@@ -503,18 +544,30 @@ function generateFrameClasses(bir:Package pkg, map<byte[]> pkgEntries) {
             if (bType is bir:BTypeInt) {
                 jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, ""J"");
                 fv.visitEnd();
-            } else if (bType is bir:BTypeBoolean) {
+            } else if (bType is bir:BTypeFloat) {
                 jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, ""Z"");
                 fv.visitEnd();
             } else if (bType is bir:BTypeString) {
                 jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, io:sprintf(""L%s;"", STRING_VALUE));
                 fv.visitEnd();
+            } else if (bType is bir:BTypeBoolean) {
+                jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, ""D"");
+                fv.visitEnd();
+            } else if (bType is bir:BTypeByte) {
+                jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, ""B"");
+                fv.visitEnd();
+            } else if (bType is bir:BTypeNil) {
+                jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, io:sprintf(""L%s;"", OBJECT));
+                fv.visitEnd();
             } else if (bType is bir:BMapType) {
                 jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, io:sprintf(""L%s;"", MAP_VALUE));
                 fv.visitEnd();
             } else if (bType is bir:BArrayType) {
                 jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, io:sprintf(""L%s;"", ARRAY_VALUE));
                 fv.visitEnd();
+            } else if (bType is bir:BTypeAny) {
+                jvm:FieldVisitor fv = cw.visitField(ACC_PUBLIC, fieldName, io:sprintf(""L%s;"", OBJECT));
+ ","Add support for float , byte , nil and any","""Added support for float and byte types in JVM backend""","Added support for Float, Byte, and Any types in JVM backend.

This commit message is concise and accurately reflects the changes made in the code. It mentions the specific types that are now supported, which is Float, Byte, and Any.","""Adding support for byte and double types in JVM backend""

The changes in the code seem to be adding support for byte and double types in the JVM backend for Ballerina, a programming language. The changes include adding new constants for byte and double types, updating the instruction generator to handle these types, and updating the method generator to handle these types as well. The changes also include updating the code to handle nil and any types. The changes appear to be well-structured and follow the existing coding style.","""Add JVM support for Float and Byte types, and refactor common code into genDefaultValue function.""",Model 3
"diff --git a/stdlib/streams/src/main/ballerina/streams/windows.bal b/stdlib/streams/src/main/ballerina/streams/windows.bal
index 10b77e8b843..06dc2c10cf9 100644
--- a/stdlib/streams/src/main/ballerina/streams/windows.bal
+++ b/stdlib/streams/src/main/ballerina/streams/windows.bal
@@ -24,7 +24,7 @@ public type Window abstract object {
 
     public function getCandidateEvents(
                         StreamEvent originEvent,
-                        (function (map<any> e1Data, map<any> e2Data) returns boolean)? conditionFunc,
+                        (function (map<anydata> e1Data, map<anydata> e2Data) returns boolean)? conditionFunc,
                         boolean isLHSTrigger = true)
                         returns (StreamEvent?, StreamEvent?)[];
 };
@@ -36,20 +36,22 @@ public type LengthWindow object {
     public any[] windowParameters;
     public function (StreamEvent[])? nextProcessPointer;
 
-    public new(nextProcessPointer, windowParameters) {
+    public function __init(function (StreamEvent[])? nextProcessPointer, any[] windowParameters) {
+        self.nextProcessPointer = nextProcessPointer;
+        self.windowParameters = windowParameters;
         self.linkedList = new;
         self.initParameters(windowParameters);
         self.size = 0;
     }
 
     public function initParameters(any[] parameters) {
-        if(parameters.length() == 1) {
-            match parameters[0] {
-                int value => self.size = value;
-                any anyValue => {
-                    error err = error(""Length window expects an int parameter"");
-                    panic err;
-                }
+        if (parameters.length() == 1) {
+            any value = parameters[0];
+            if (value is int) {
+                self.size = value;
+            } else {
+                error err = error(""Length window expects an int parameter"");
+                panic err;
             }
         } else {
             error err = error(""Length window should only have one parameter (<int> "" +
@@ -62,18 +64,10 @@ public type LengthWindow object {
         StreamEvent[] outputEvents = [];
         foreach event in streamEvents {
             if (self.linkedList.getSize() == self.size) {
-                match self.linkedList.removeFirst() {
-                    StreamEvent streamEvent => {
-                        outputEvents[outputEvents.length()] = streamEvent;
-                    }
 
-                    () => {
-                        // do nothing
-                    }
-
-                    any anyValue => {
-                        // do nothing
-                    }
+                any? anyValue = self.linkedList.removeFirst();
+                if (anyValue is StreamEvent) {
+                    outputEvents[outputEvents.length()] = anyValue;
                 }
             }
 
@@ -82,42 +76,33 @@ public type LengthWindow object {
             expiredVeresionOfEvent.eventType = ""EXPIRED"";
             self.linkedList.addLast(expiredVeresionOfEvent);
         }
-        match (self.nextProcessPointer) {
-            function (StreamEvent[]) nxtProc => {
-                nxtProc(outputEvents);
-            }
-            () => {
-                //do nothing
-            }
+
+        any nextProcessFuncPointer = self.nextProcessPointer;
+        if (nextProcessFuncPointer is function (StreamEvent[])) {
+            nextProcessFuncPointer.call(outputEvents);
         }
     }
 
     public function getCandidateEvents(
                         StreamEvent originEvent,
-                        (function (map<any> e1Data, map<any> e2Data) returns boolean)? conditionFunc,
+                        (function (map<anydata> e1Data, map<anydata> e2Data) returns boolean)? conditionFunc,
                         boolean isLHSTrigger = true)
                         returns (StreamEvent?, StreamEvent?)[] {
         (StreamEvent?, StreamEvent?)[] events = [];
         int i = 0;
         foreach e in self.linkedList.asArray() {
-            match e {
-                StreamEvent s => {
-                    StreamEvent lshEvent = (isLHSTrigger) ? originEvent : s;
-                    StreamEvent rhsEvent = (isLHSTrigger) ? s : originEvent;
-                    match (conditionFunc) {
-                        function (map<any> e1Data, map<any> e2Data) returns boolean conditionCheckFunc => {
-                            if (conditionCheckFunc(lshEvent.data, rhsEvent.data)) {
-                                events[i] = (lshEvent, rhsEvent);
-                                i += 1;
-                            }
-                        }
-                        () => {
-                            events[i] = (lshEvent, rhsEvent);
-                            i += 1;
-                        }
+            if (e is StreamEvent) {
+                StreamEvent lshEvent = (isLHSTrigger) ? originEvent : e;
+                StreamEvent rhsEvent = (isLHSTrigger) ? e : originEvent;
+
+                if (conditionFunc is function (map<anydata> e1Data, map<anydata> e2Data) returns boolean) {
+                    if (conditionFunc.call(lshEvent.data, rhsEvent.data)) {
+                        events[i] = (lshEvent, rhsEvent);
+                        i += 1;
                     }
-                }
-                any a => {
+                } else if (conditionFunc is ()) {
+                    events[i] = (lshEvent, rhsEvent);
+                    i += 1;
                 }
             }
         }
@@ -140,7 +125,9 @@ public type TimeWindow object {
     public function (StreamEvent[])? nextProcessPointer;
     public int lastTimestamp = -0x8000000000000000;
 
-    public new(nextProcessPointer, windowParameters) {
+    public function __init(function (StreamEvent[])? nextProcessPointer, any[] windowParameters) {
+        self.nextProcessPointer = nextProcessPointer;
+        self.windowParameters = windowParameters;
         self.timeInMillis = 0;
         self.expiredEventQueue = new;
         self.timerQueue = new;
@@ -148,13 +135,13 @@ public type TimeWindow object {
     }
 
     public function initParameters(any[] parameters) {
-        if(parameters.length() == 1) {
-            match parameters[0] {
-                int value => self.timeInMillis = value;
-                any anyValue => {
-                    error err = error(""Time window expects an int parameter"");
-                    panic err;
-                }
+        if (parameters.length() == 1) {
+            any parameter0 = parameters[0];
+            if (parameter0 is int) {
+                self.timeInMillis = parameter0;
+            } else {
+                error err = error(""Time window expects an int parameter"");
+                panic err;
             }
         } else {
             error err = error(""Time window should only have one parameter (<int> "" +
@@ -173,14 +160,7 @@ public type TimeWindow object {
             streamEventChunk.resetToFront();
 
             while (streamEventChunk.hasNext()) {
-                StreamEvent streamEvent;
-                any? next = streamEventChunk.next();
-                if (next is StreamEvent) {
-                    streamEvent = next;
-                } else {
-                    return;
-                }
-
+                StreamEvent streamEvent = <StreamEvent>streamEventChunk.next();
                 int currentTime = time:currentTime().time;
                 self.expiredEventQueue.resetToFront();
 
@@ -202,7 +182,8 @@ public type TimeWindow object {
                     self.expiredEventQueue.addLast(clonedEvent);
 
                     if (self.lastTimestamp < clonedEvent.timestamp) {
-                        task:Timer timer = new task:Timer(self.invokeProcess, self.handleError, self.timeInMillis,
+                        task:Timer timer = new task:Timer(function () returns error? {return self.invokeProcess();},
+                            function (error e) {self.handleError(e);}, self.timeInMillis,
                             delay = self.timeInMillis - (time:currentTime().time - clonedEvent.timestamp));
                         _ = timer.start();
                         self.timerQueue.addLast(timer);
@@ -214,31 +195,29 @@ public type TimeWindow object {
             }
             self.expiredEventQueue.resetToFront();
         }
-        match (self.nextProcessPointer) {
-            function (StreamEvent[]) nxtProc => {
-                if (streamEventChunk.getSize() != 0) {
-                    StreamEvent[] events = [];
-                    streamEventChunk.resetToFront();
-                    while (streamEventChunk.hasNext()) {
-                        StreamEvent streamEvent = getStreamEvent(streamEventChunk.next());
-                        events[events.length()] = streamEvent;
-                    }
-                    nxtProc(events);
+
+        any nextProcessFuncPointer = self.nextProcessPointer;
+        if (nextProcessFuncPointer is function (StreamEvent[])) {
+            if (streamEventChunk.getSize() != 0) {
+                StreamEvent[] events = [];
+                streamEventChunk.resetToFront();
+                while (streamEventChunk.hasNext()) {
+                    StreamEvent streamEvent = getStreamEvent(streamEventChunk.next());
+                    events[events.length()] = streamEvent;
                 }
-            }
-            () => {
-                //do nothing
+                nextProcessFuncPointer.call(events);
             }
         }
     }
 
     public function invokeProcess() returns error? {
-        StreamEvent timerEvent = new((""timer"", {}), ""TIMER"", time:currentTime().time);
+        map<anydata> data = {};
+        StreamEvent timerEvent = new((""timer"", data), ""TIMER"", time:currentTime().time);
         StreamEvent[] timerEventWrapper = [];
         timerEventWrapper[0] = timerEvent;
         self.process(timerEventWrapper);
         if (!self.timerQueue.isEmpty()) {
-            task:Timer timer = check trap <task:Timer>self.timerQueue.removeFirst();
+            task:Timer timer = <task:Timer>self.timerQueue.removeFirst();
             _ = timer.stop();
         }
         return ();
@@ -250,30 +229,24 @@ public type TimeWindow object {
 
     public function getCandidateEvents(
                         StreamEvent originEvent,
-                        (function (map<any> e1Data, map<any> e2Data) returns boolean)? conditionFunc,
+                        (function (map<anydata> e1Data, map<anydata> e2Data) returns boolean)? conditionFunc,
                         boolean isLHSTrigger = true)
                         returns (StreamEvent?, StreamEvent?)[] {
         (StreamEvent?, StreamEvent?)[] events = [];
         int i = 0;
         foreach e in self.expiredEventQueue.asArray() {
-            match e {
-                StreamEvent s => {
-                    StreamEvent lshEvent = (isLHSTrigger) ? originEvent : s;
-                    StreamEvent rhsEvent = (isLHSTrigger) ? s : originEvent;
-                    match (conditionFunc) {
-                        function (map<any> e1Data, map<any> e2Data) returns boolean conditionCheckFunc => {
-                            if (conditionCheckFunc(lshEvent.data, rhsEvent.data)) {
-                                events[i] = (lshEvent, rhsEvent);
-                                i += 1;
-                            }
-                        }
-                        () => {
-                            events[i] = (lshEvent, rhsEvent);
-                            i += 1;
-                        }
+            if (e is StreamEvent) {
+                StreamEvent lshEvent = (isLHSTrigger) ? originEvent : e;
+                StreamEvent rhsEvent = (isLHSTrigger) ? e : originEvent;
+
+                if (conditionFunc is function (map<anydata> e1Data, map<anydata> e2Data) returns boolean) {
+                    if (conditionFunc.call(lshEvent.data, rhsEvent.data)) {
+                        events[i] = (lshEvent, rhsEvent);
+                        i += 1;
                     }
-                }
-                any a => {
+                } else if (conditionFunc is ()) {
+                    events[i] = (lshEvent, rhsEvent);
+                    i += 1;
                 }
             }
   ",Add improved streams bal files and tests based on updated grammar,"""Refactor window objects to use type narrowing and simplify match expressions""","The commit message should be:

""Update Ballerina streams to use anydata instead of any for map keys""

This commit message accurately reflects the changes made in the code, which involve replacing `any` with `anydata` in various places to ensure type safety and consistency with Ballerina's type system.","This commit updates the Ballerina code in the `stdlib/streams/src/main/ballerina/streams/windows.bal` file. The changes include:

1. Modifying the `getCandidateEvents` function signature in the `Window` type to use `map<anydata>` instead of `map<any>` for the `e1Data` and `e2Data` parameters of the `conditionFunc` function.
2. Updating the constructor of the `LengthWindow` type to use the `__init` function name and assigning the `nextProcessPointer` and `windowParameters` fields directly.
3. Simplifying the code in the `process` function of the `LengthWindow` type by removing unnecessary match cases and using an `if` statement to check the type of the removed item from the linked list.
4. Simplifying the code in the `getCandidateEvents` function of the `LengthWindow` type by removing unnecessary match cases and using `if` statements to check the type of the `conditionFunc` parameter and the items in the linked list.
5. Updating the constructor of the `TimeWindow` type to use the `__init` function name and assigning the `nextProcessPointer` and `windowParameters` fields directly.
6. Simplifying the code in the `process` function of the `TimeWindow` type by removing unnecessary match cases and using an `if` statement to check the type of the items in the `streamEventChunk`.
7. Simplifying the code in the `getCandidateEvents` function of the `TimeWindow` type by removing unnecessary match cases and using `if` statements to check the type of the `conditionFunc` parameter and the items in the `expiredEventQueue`.

Overall, the changes seem to be focused on simplifying the code and using more idiomatic Ballerina constructs. However, the commit message does not provide any context or explanation for these changes.","""Refactor window functions, improve type handling, and replace match statements with type checks, reducing redundant code.""",Model 2
"diff --git a/gdx/src/com/badlogic/gdx/graphics/g2d/tiled/TileAtlas.java b/gdx/src/com/badlogic/gdx/graphics/g2d/tiled/TileAtlas.java
index b5e0647a4..fa32922ea 100644
--- a/gdx/src/com/badlogic/gdx/graphics/g2d/tiled/TileAtlas.java
+++ b/gdx/src/com/badlogic/gdx/graphics/g2d/tiled/TileAtlas.java
@@ -121,4 +121,15 @@ public class TileAtlas implements Disposable {
 
 		return child;
 	}
+
+	/**
+	 * Flips all regions in the atlas on the specified axis.
+	 * @param x - if <code>true</code> region is flipped on the <b>x</b> axis 
+	 * @param y - if <code>true</code> region is flipped on the <b>y</b> axis 
+	 */
+	public void flipRegions(boolean x, boolean y) {
+		for (TextureRegion region : regionsMap.values()) {
+			region.flip(x, y);
+		}
+	}
 }",Added flipRegions method .,"""Added method to flip all regions in a TileAtlas""",Added method to flip all regions in the atlas on specified axis.,"This commit adds a new method `flipRegions(boolean x, boolean y)` to the `TileAtlas` class in the `com.badlogic.gdx.graphics.g2d.tiled` package. This method takes two boolean parameters `x` and `y` and flips all regions in the atlas on the specified axis. The method iterates through all the regions in the `regionsMap` and calls the `flip(x, y)` method on each region. The commit also includes a corresponding Javadoc comment for the new method.",Added flipRegions method to TileAtlas for flipping regions on the x and y axis.,Model 4
"diff --git a/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/FeatureImpl.java b/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/FeatureImpl.java
index bf67d27d02d..ce7a943bc65 100644
--- a/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/FeatureImpl.java
+++ b/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/FeatureImpl.java
@@ -46,6 +46,7 @@ import java.util.function.Predicate;
 import java.util.stream.Collectors;
 
 import com.oracle.svm.hosted.code.CEntryPointData;
+import com.oracle.svm.hosted.code.CompileQueue;
 import org.graalvm.collections.Pair;
 import org.graalvm.compiler.debug.DebugContext;
 import org.graalvm.nativeimage.hosted.Feature;
@@ -563,9 +564,16 @@ public class FeatureImpl {
     }
 
     public static class AfterCompilationAccessImpl extends CompilationAccessImpl implements Feature.AfterCompilationAccess {
+        private Collection<CompileQueue.CompileTask> compilationTasks;
+
         AfterCompilationAccessImpl(FeatureHandler featureHandler, ImageClassLoader imageClassLoader, AnalysisUniverse aUniverse, HostedUniverse hUniverse, HostedMetaAccess hMetaAccess,
-                        NativeImageHeap heap, DebugContext debugContext) {
+                                   Collection<CompileQueue.CompileTask> compilationTasks, NativeImageHeap heap, DebugContext debugContext) {
             super(featureHandler, imageClassLoader, aUniverse, hUniverse, hMetaAccess, heap, debugContext);
+            this.compilationTasks = compilationTasks;
+        }
+
+        public Collection<CompileQueue.CompileTask> getCompilationTasks() {
+            return compilationTasks;
         }
     }
 
diff --git a/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/NativeImageGenerator.java b/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/NativeImageGenerator.java
index d8d8428251e..2face1e80e4 100644
--- a/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/NativeImageGenerator.java
+++ b/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/NativeImageGenerator.java
@@ -613,7 +613,7 @@ public class NativeImageGenerator {
                 codeCache.layoutConstants();
                 codeCache.layoutMethods(debug, imageName, bigbang, compilationExecutor);
 
-                AfterCompilationAccessImpl config = new AfterCompilationAccessImpl(featureHandler, loader, aUniverse, hUniverse, hMetaAccess, heap, debug);
+                AfterCompilationAccessImpl config = new AfterCompilationAccessImpl(featureHandler, loader, aUniverse, hUniverse, hMetaAccess, compileQueue.getCompilationTasks(), heap, debug);
                 featureHandler.forEachFeature(feature -> feature.afterCompilation(config));
             }
             CodeCacheProvider codeCacheProvider = runtime.getRuntimeConfig().getBackendForNormalMethod().getProviders().getCodeCache();
diff --git a/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/code/CompileQueue.java b/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/code/CompileQueue.java
index f9099678535..814f3a7e141 100644
--- a/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/code/CompileQueue.java
+++ b/substratevm/src/com.oracle.svm.hosted/src/com/oracle/svm/hosted/code/CompileQueue.java
@@ -28,6 +28,7 @@ import java.lang.annotation.Annotation;
 import java.lang.reflect.Modifier;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collection;
 import java.util.Collections;
 import java.util.Comparator;
 import java.util.HashMap;
@@ -391,6 +392,10 @@ public class CompileQueue {
         return phaseSuite;
     }
 
+    public Collection<CompileTask> getCompilationTasks() {
+        return compilations.values();
+    }
+
     private void printMethodHistogram() {
         long sizeAllMethods = 0;
         long sizeDeoptMethods = 0;",Expose compilation tasks in the afterCompilation handler .,"""Added compilation tasks to AfterCompilationAccessImpl and exposed them through NativeImageGenerator""","""Added support for compile queue tasks in AfterCompilationAccessImpl and NativeImageGenerator""","""Add compilation tasks to AfterCompilationAccessImpl and expose them via getCompilationTasks()""

This commit introduces the following changes:

1. In `FeatureImpl.java`, a new field `compilationTasks` is added to `AfterCompilationAccessImpl` class. The constructor is updated to accept this new field, and a getter method `getCompilationTasks()` is added.

2. In `NativeImageGenerator.java`, the `AfterCompilationAccessImpl` object is now created with the `compileQueue.getCompilationTasks()` as an argument.

3. In `CompileQueue.java`, a new method `getCompilationTasks()` is added to return the compilations.

These changes seem to be related to managing and accessing compilation tasks in the native image generation process.",Add access to compile tasks in AfterCompilationAccessImpl and expose compilation tasks collection in CompileQueue.,Model 2
"diff --git a/test/org/apache/tomcat/util/http/TestParametersPerformance.java b/test/org/apache/tomcat/util/http/TestParametersPerformance.java
new file mode 100644
index 0000000000..9b6d4acb8a
--- /dev/null
+++ b/test/org/apache/tomcat/util/http/TestParametersPerformance.java
@@ -0,0 +1,133 @@
+/*
+ *  Licensed to the Apache Software Foundation (ASF) under one or more
+ *  contributor license agreements.  See the NOTICE file distributed with
+ *  this work for additional information regarding copyright ownership.
+ *  The ASF licenses this file to You under the Apache License, Version 2.0
+ *  (the ""License""); you may not use this file except in compliance with
+ *  the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing, software
+ *  distributed under the License is distributed on an ""AS IS"" BASIS,
+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+package org.apache.tomcat.util.http;
+
+import java.io.UnsupportedEncodingException;
+import java.nio.charset.Charset;
+import java.util.logging.Level;
+import java.util.logging.LogManager;
+
+import static org.junit.Assert.assertEquals;
+import org.junit.Test;
+
+import org.apache.tomcat.util.buf.B2CConverter;
+
+public class TestParametersPerformance {
+
+    @Test
+    public void testProcessParametersByteArrayIntInt() {
+        LogManager.getLogManager().getLogger("""").setLevel(Level.OFF);
+        doTestProcessParametersMultiple(""foo"".getBytes());
+    }
+
+    private void doTestProcessParametersMultiple(byte[] input) {
+        System.out.println(doTestProcessParameters(input, 10000));
+        System.out.println(doTestProcessParameters(input, 20000));
+        System.out.println(doTestProcessParameters(input, 40000));
+        System.out.println(doTestProcessParameters(input, 80000));
+        System.out.println(doTestProcessParameters(input, 160000));
+        System.out.println(doTestProcessParameters(input, 320000));
+        System.out.println(doTestProcessParameters(input, 640000));
+        System.out.println(doTestProcessParameters(input, 1280000));
+    }
+
+    private long doTestProcessParameters(byte[] input, int size) {
+        assertEquals(input.length, 3);
+
+        Parameters p = new Parameters();
+
+        byte[] params = createParams(input, size);
+        //byte[] input = createParams(8);
+        p.setEncoding(""ISO-8859-1"");
+        long start = System.nanoTime();
+        p.processParameters(params, 0, params.length);
+        return System.nanoTime() - start;
+    }
+
+    private byte[] createParams(byte[] input, int len) {
+        byte[] result = new byte[len * 4 - 1];
+
+        for (int i = 0; i < len; i++) {
+            result[i * 4] = input[0];
+            result[i * 4 + 1] = input[1];
+            result[i * 4 + 2] = input[2];
+            if (i < len -1) {
+                result[i * 4 + 3] = 38;
+            }
+        }
+        return result;
+    }
+
+    @Test
+    public void testCreateString() throws UnsupportedEncodingException {
+        B2CConverter.getCharset(""ISO-8859-1"");
+        doCreateStringMultiple(""foo"");
+    }
+
+    private void doCreateStringMultiple(String input) {
+        System.out.println(doCreateString(input, 10, true));
+        System.out.println(doCreateString(input, 100, true));
+        System.out.println(doCreateString(input, 1000, true));
+        System.out.println(doCreateString(input, 10000, true));
+        System.out.println(doCreateString(input, 100000, true));
+        System.out.println(doCreateString(input, 1000000, true));
+        System.out.println(doCreateString(input, 2000000, true));
+        //System.out.println(doCreateString(input, 4000000, true));
+        //System.out.println(doCreateString(input, 8000000, true));
+        System.out.println(doCreateString(input, 10, false));
+        System.out.println(doCreateString(input, 100, false));
+        System.out.println(doCreateString(input, 1000, false));
+        System.out.println(doCreateString(input, 10000, false));
+        System.out.println(doCreateString(input, 100000, false));
+        System.out.println(doCreateString(input, 1000000, false));
+        System.out.println(doCreateString(input, 2000000, false));
+        //System.out.println(doCreateString(input, 4000000, false));
+        //System.out.println(doCreateString(input, 8000000, false));
+    }
+
+    private long doCreateString(String input, int size,
+            boolean defensiveCopyWorkAround) {
+        int loops = 10000;
+        byte[] inputBytes = input.getBytes();
+        byte[] bytes = new byte[size];
+        int inputLength = inputBytes.length;
+
+        System.arraycopy(inputBytes, 0, bytes, 0, inputLength);
+
+        String[] result = new String[loops];
+        Charset charset = null;
+        try {
+            charset = B2CConverter.getCharset(""ISO-8859-1"");
+        } catch (UnsupportedEncodingException e) {
+            // TODO Auto-generated catch block
+            e.printStackTrace();
+        }
+
+        long start = System.nanoTime();
+        for (int i = 0; i < loops; i++) {
+            if (defensiveCopyWorkAround) {
+                byte[] tmp = new byte[inputLength];
+                System.arraycopy(bytes, 0, tmp, 0, inputLength);
+                result[i] = new String(tmp, 0, inputLength, charset);
+            } else {
+                result[i] = new String(bytes, 0, inputLength, charset);
+            }
+        }
+
+        return System.nanoTime() - start;
+    }
+}",Add some tests used to help track down performance issues . . git - svn - id : https : / / svn . apache . org / repos / asf / tomcat / trunk @ 1190383 13f79535 - 47bb - 0310 - 9956 - ffa450edef68,"""Added test class TestParametersPerformance to measure performance of Parameters class""","Added performance test for Parameters class and B2CConverter class.

This commit message is concise and accurately describes the changes made in the commit. It mentions the specific classes that are being tested for performance, which is useful for understanding the context of the changes.","""Add TestParametersPerformance.java""

The file TestParametersPerformance.java has been added with a complete code for a JUnit test class. The class contains several test methods for testing the performance of processing parameters and creating strings in the org.apache.tomcat.util.http package. The class uses the Apache License, Version 2.0.","""Add performance tests for processing parameters and creating strings in Tomcat HTTP utility.""",Model 1
"diff --git a/core/pom.xml b/core/pom.xml
index f90b7d7e8e..da843c813f 100644
--- a/core/pom.xml
+++ b/core/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.jvnet.hudson.main</groupId>
     <artifactId>pom</artifactId>
-    <version>1.110-SNAPSHOT</version>
+    <version>1.110</version>
     <relativePath>../pom.xml</relativePath>
   </parent>
   
diff --git a/jnlp-agent/pom.xml b/jnlp-agent/pom.xml
index 0f4e841c7a..bab6fdce6c 100644
--- a/jnlp-agent/pom.xml
+++ b/jnlp-agent/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.jvnet.hudson.main</groupId>
     <artifactId>pom</artifactId>
-    <version>1.110-SNAPSHOT</version>
+    <version>1.110</version>
     <relativePath>../pom.xml</relativePath>
   </parent>
   
diff --git a/maven-agent/pom.xml b/maven-agent/pom.xml
index a0680767dc..0cb093b1e0 100644
--- a/maven-agent/pom.xml
+++ b/maven-agent/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.jvnet.hudson.main</groupId>
     <artifactId>pom</artifactId>
-    <version>1.110-SNAPSHOT</version>
+    <version>1.110</version>
     <relativePath>../pom.xml</relativePath>
   </parent>
   
diff --git a/maven-interceptor/pom.xml b/maven-interceptor/pom.xml
index cab7beef52..ecc99e5c0b 100644
--- a/maven-interceptor/pom.xml
+++ b/maven-interceptor/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.jvnet.hudson.main</groupId>
     <artifactId>pom</artifactId>
-    <version>1.110-SNAPSHOT</version>
+    <version>1.110</version>
     <relativePath>../pom.xml</relativePath>
   </parent>
   
diff --git a/pom.xml b/pom.xml
index 129e310307..032f399853 100644
--- a/pom.xml
+++ b/pom.xml
@@ -9,7 +9,7 @@
   
   <groupId>org.jvnet.hudson.main</groupId>
   <artifactId>pom</artifactId>
-  <version>1.110-SNAPSHOT</version>
+  <version>1.110</version>
   <packaging>pom</packaging>
   
   <name>Hudson main module</name>
@@ -28,6 +28,7 @@
     <connection>scm:cvs:pserver:guest@cvs.dev.java.net:/cvs:hudson/hudson/main</connection>
     <developerConnection>scm:cvs:pserver:kohsuke@cvs.dev.java.net:/cvs:hudson/hudson/main</developerConnection>
     <url>https://hudson.dev.java.net/source/browse/hudson/hudson/main</url>
+    <tag>hudson-1_110</tag>
   </scm>
   
   <build>
diff --git a/remoting/pom.xml b/remoting/pom.xml
index 1bf847a2ba..9adc742c2e 100644
--- a/remoting/pom.xml
+++ b/remoting/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.jvnet.hudson.main</groupId>
     <artifactId>pom</artifactId>
-    <version>1.110-SNAPSHOT</version>
+    <version>1.110</version>
     <relativePath>../pom.xml</relativePath>
   </parent>
   
diff --git a/war/pom.xml b/war/pom.xml
index a0f7a0053e..816f686976 100644
--- a/war/pom.xml
+++ b/war/pom.xml
@@ -3,7 +3,7 @@
   <parent>
     <groupId>org.jvnet.hudson.main</groupId>
     <artifactId>pom</artifactId>
-    <version>1.110-SNAPSHOT</version>
+    <version>1.110</version>
     <relativePath>../pom.xml</relativePath>
   </parent>
   ",prepare release hudson - 1_110 .,"""Release Hudson 1.110: Update version numbers from 1.110-SNAPSHOT to 1.110 and add release tag""",Bump Hudson main module version to 1.110 from 1.110-SNAPSHOT.,"""Updating parent version from 1.110-SNAPSHOT to 1.110 in various pom.xml files and adding tag hudson-1_110 in pom.xml""","""Update all modules to version 1.110, changing from 1.110-SNAPSHOT and adding SCM tag in parent POM.""",Model 1
"diff --git a/hotspot/.hgtags b/hotspot/.hgtags
index b9ee766f1a..3f843994e7 100644
--- a/hotspot/.hgtags
+++ b/hotspot/.hgtags
@@ -1014,3 +1014,4 @@ cdfe7ec6f29293d7c2f64239518e8947733ad85c jdk8u152-b12
 3dd92151df1b3b7c21756f241b49607024b6fe5a jdk8u152-b13
 0a9d8db98fc5f0302da6520ba329f41baa092ae0 jdk8u152-b14
 c1bf165d3b27e864a9f8eec5bb0c1e746a972ad5 jdk8u152-b15
+98b4b0661837817cc39047000e1a7efa6015af7c jdk8u152-b16",Added tag jdk8u152 - b16 for changeset eade057fd8d0,"""Added tag jdk8u152-b16""","""Update .hgtags to include jdk8u152-b16""","Based on the diff you provided, it seems like a new line has been added to the .hgtags file in the hotspot directory. The new line is:

`98b4b0661837817cc39047000e1a7efa6015af7c jdk8u152-b16`

This line represents a new commit with the commit hash `98b4b0661837817cc39047000e1a7efa6015af7c` and the tag `jdk8u152-b16`. However, the diff does not provide any information about the changes made in this commit.

If you want to create a commit message, you might need more context about what changes were made in this commit. A commit message typically includes a summary of the changes and a more detailed description if necessary.

If you want to see the changes made in this commit, you can use the command `git show 98b4b0661837817cc39047000e1a7efa6015af7c` (or the shorter `git show jdk8u152-b16`, if the tag is unique) in a terminal. This will show you the changes made in this commit, which you can use to write an appropriate commit message.",Added new tag `jdk8u152-b16` to the `.hgtags` file.,Model 3
"diff --git a/CHANGELOG.md b/CHANGELOG.md
index 1a5f08962a..ae38b20a7a 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -1,7 +1,8 @@
 3.5.0 (in progress)
 ================
 * [#446](https://github.com/oshi/oshi/pull/446): Add getChildProcesses to OperatingSystem. - [@jsimomaa](https://github.com/jsimomaa)
-* [#447](https://github.com/oshi/oshi/pull/447): Added context switches and interrupts (linux/windows) - [@jpbempel](https://github.com/jpbempel).
+* [#447](https://github.com/oshi/oshi/pull/447), [#471](https://github.com/oshi/oshi/pull/471): Added context switches and interrupts - [@jpbempel](https://github.com/jpbempel), [@dbwiddis](https://github.com/dbwiddis).
+* Updated to JNA 4.5.1
 * Your contribution here.
 
 3.4.5 (4/11/18)
diff --git a/oshi-core/pom.xml b/oshi-core/pom.xml
index f93a30de69..9b504939b8 100644
--- a/oshi-core/pom.xml
+++ b/oshi-core/pom.xml
@@ -45,7 +45,7 @@
 		<dependency>
 			<groupId>net.java.dev.jna</groupId>
 			<artifactId>jna-platform</artifactId>
-			<version>4.5.0</version>
+			<version>4.5.1</version>
 		</dependency>
 		<dependency>
 			<groupId>org.threeten</groupId>
diff --git a/oshi-core/src/main/java/oshi/hardware/CentralProcessor.java b/oshi-core/src/main/java/oshi/hardware/CentralProcessor.java
index ecb4617288..3d95b486fc 100644
--- a/oshi-core/src/main/java/oshi/hardware/CentralProcessor.java
+++ b/oshi-core/src/main/java/oshi/hardware/CentralProcessor.java
@@ -69,7 +69,8 @@ public interface CentralProcessor extends Serializable {
          */
         SOFTIRQ(6),
         /**
-         * Time which the hypervisor dedicated for other guests in the system. Only supported on Linux.
+         * Time which the hypervisor dedicated for other guests in the system.
+         * Only supported on Linux.
          */
         STEAL(7);
 
@@ -239,19 +240,19 @@ public interface CentralProcessor extends Serializable {
      * Get System-wide CPU Load tick counters. Returns an array with seven
      * elements representing either clock ticks or milliseconds (platform
      * dependent) spent in User (0), Nice (1), System (2), Idle (3), IOwait (4),
-     * Hardware interrupts (IRQ) (5), Software interrupts/DPC (SoftIRQ) (6), or Steal (7)
-     * states. Use {@link TickType#getIndex()} to retrieve the appropriate
-     * index. By measuring the difference between ticks across a time interval,
-     * CPU load over that interval may be calculated.
+     * Hardware interrupts (IRQ) (5), Software interrupts/DPC (SoftIRQ) (6), or
+     * Steal (7) states. Use {@link TickType#getIndex()} to retrieve the
+     * appropriate index. By measuring the difference between ticks across a
+     * time interval, CPU load over that interval may be calculated.
      *
      * Nice and IOWait information is not available on Windows, and IOwait and
      * IRQ information is not available on macOS, so these ticks will always be
      * zero.
      *
      * To calculate overall Idle time using this method, include both Idle and
-     * IOWait ticks. Similarly, IRQ, SoftIRQ, and Steal ticks should be added to the
-     * System value to get the total. System ticks also include time executing
-     * other virtual hosts (steal).
+     * IOWait ticks. Similarly, IRQ, SoftIRQ, and Steal ticks should be added to
+     * the System value to get the total. System ticks also include time
+     * executing other virtual hosts (steal).
      *
      * @return An array of 7 long values representing time spent in User, Nice,
      *         System, Idle, IOwait, IRQ, SoftIRQ, and Steal states.
@@ -317,10 +318,9 @@ public interface CentralProcessor extends Serializable {
      * than 1 second. If less than one second has elapsed since the last call of
      * this method, it will return a calculation based on the tick counts and
      * times of the previous two calls. If at least a second has elapsed, it
-     * will return the average CPU load for the interval and update the
-     * ""last called"" times. This method is intended to be used for periodic
-     * polling (iterating over all processors) at intervals of 1 second or
-     * longer.
+     * will return the average CPU load for the interval and update the ""last
+     * called"" times. This method is intended to be used for periodic polling
+     * (iterating over all processors) at intervals of 1 second or longer.
      *
      * @return array of CPU load between 0 and 1 (100%) for each logical
      *         processor
@@ -332,23 +332,23 @@ public interface CentralProcessor extends Serializable {
      * with {@link #getLogicalProcessorCount()} arrays, each containing seven
      * elements representing either clock ticks or milliseconds (platform
      * dependent) spent in User (0), Nice (1), System (2), Idle (3), IOwait (4),
-     * Hardware interrupts (IRQ) (5), Software interrupts/DPC (SoftIRQ) (6), or Steal (7)
-     * states. Use {@link TickType#getIndex()} to retrieve the appropriate
-     * index. By measuring the difference between ticks across a time interval,
-     * CPU load over that interval may be calculated.
+     * Hardware interrupts (IRQ) (5), Software interrupts/DPC (SoftIRQ) (6), or
+     * Steal (7) states. Use {@link TickType#getIndex()} to retrieve the
+     * appropriate index. By measuring the difference between ticks across a
+     * time interval, CPU load over that interval may be calculated.
      *
      * Nice and IOwait per processor information is not available on Windows,
      * and IOwait and IRQ information is not available on macOS, so these ticks
      * will always be zero.
      *
      * To calculate overall Idle time using this method, include both Idle and
-     * IOWait ticks. Similarly, IRQ, SoftIRQ and Steal ticks should be added to the
-     * System value to get the total. System ticks also include time executing
-     * other virtual hosts (steal).
+     * IOWait ticks. Similarly, IRQ, SoftIRQ and Steal ticks should be added to
+     * the System value to get the total. System ticks also include time
+     * executing other virtual hosts (steal).
      *
      * @return A 2D array of logicalProcessorCount x 7 long values representing
-     *         time spent in User, Nice, System, Idle, IOwait, IRQ, SoftIRQ, and Steal
-     *         states.
+     *         time spent in User, Nice, System, Idle, IOwait, IRQ, SoftIRQ, and
+     *         Steal states.
      */
     long[][] getProcessorCpuLoadTicks();
 
@@ -390,13 +390,15 @@ public interface CentralProcessor extends Serializable {
     int getPhysicalProcessorCount();
 
     /**
-     *  Get the number of context switches happened
+     * Get the number of context switches which have occurred
+     * 
      * @return The number of context switches
      */
     long getContextSwitches();
 
     /**
-     * Get the number of interrupts happened
+     * Get the number of interrupts which have occurred
+     * 
      * @return The number of interrupts
      */
     long getInterrupts();
diff --git a/oshi-core/src/main/java/oshi/hardware/platform/mac/MacCentralProcessor.java b/oshi-core/src/main/java/oshi/hardware/platform/mac/MacCentralProcessor.java
index 2a9710bbb5..cfa0703ffd 100644
--- a/oshi-core/src/main/java/oshi/hardware/platform/mac/MacCentralProcessor.java
+++ b/oshi-core/src/main/java/oshi/hardware/platform/mac/MacCentralProcessor.java
@@ -28,6 +28,7 @@ import com.sun.jna.ptr.PointerByReference;
 
 import oshi.hardware.common.AbstractCentralProcessor;
 import oshi.jna.platform.mac.SystemB;
+import oshi.jna.platform.mac.SystemB.VMMeter;
 import oshi.jna.platform.unix.CLibrary.Timeval;
 import oshi.util.ExecutingCommand;
 import oshi.util.FormatUtil;
@@ -194,7 +195,14 @@ public class MacCentralProcessor extends AbstractCentralProcessor {
      */
     @Override
     public long getContextSwitches() {
-        return -1;
+        int machPort = SystemB.INSTANCE.mach_host_self();
+        VMMeter vmstats = new VMMeter();
+        if (0 != SystemB.INSTANCE.host_statistics(machPort, SystemB.HOST_VM_INFO, vmstats,
+                new IntByReference(vmstats.size()))) {
+            LOG.error(""Failed to update vmstats. Error code: "" + Native.getLastError());
+            return -1;
+        }
+        return ParseUtil.unsignedIntToLong(vmstats.v_swtch);
     }
 
     /**
@@ -202,6 +210,13 @@ public class MacCentralProcessor extends AbstractCentralProcessor {
      */
     @Override
     public long getInterrupts() {
-        return -1;
+        int machPort = SystemB.INSTANCE.mach_host_self();
+        VMMeter vmstats = new VMMeter();
+        if (0 != SystemB.INSTANCE.host_statistics(machPort, SystemB.HOST_VM_INFO, vmstats,
+                new IntByReference(vmstats.size()))) {
+            LOG.error(""Failed to update vmstats. Error code: "" + Native.getLastError());
+            return -1;
+        }
+        return ParseUtil.unsignedIntToLong(vmstats.v_intr);
     }
 }
diff --git a/oshi-core/src/main/java/oshi/hardware/platform/unix/freebsd/FreeBsdCentralProcessor.java b/oshi-core/src/main/java/oshi/hardware/platform/unix/freebsd/FreeBsdCentralProcessor.java
index 33cfe01256..4c5346f389 100644
--- a/oshi-core/src/main/java/oshi/hardware/platform/unix/freebsd/FreeBsdCentralProcessor.java
+++ b/oshi-core/src/main/java/oshi/hardware/platform/unix/freebsd/FreeBsdCentralProcessor.java
@@ -264,7 +264,13 @@ public class FreeBsdCentralProcessor extends AbstractCentralProcessor {
      */
     @Override
     public long getContextSwitches() {
-        return -1;
+        String name = ""vm.stats.sys.v_swtch"";
+        IntByReference size = new IntByReference(Libc.INT_SIZE);
+        Pointer p = new Memory(size.getValue());
+        if (0 != Libc.INSTANCE.sysctlbyname(name, p, size, null, 0)) {
+            return -1;
+        }
+        return ParseUtil.unsignedIntToLong(p.getInt(0));
     }
 
     /**
@@ -272,6 +278,12 @@ public class FreeBsdCentralProcessor extends AbstractCentralProcessor {
      */
     @Override
     public long getInterrupts() {
-        return -1;
+        String name = ""vm.stats.sys.v_intr"";
+        IntByReference size = new IntByReference(Libc.INT_SIZE);
+        Pointer p = new Memory(size.getValue());
+        if (0 != Libc.INSTANCE.sysctlbyname(name, p, size, null, 0)) {
+            return -1;
+        }
+        return ParseUtil.unsignedIntToLong(p.getInt(0));
     }
 }
diff --git a/oshi-core/src/main/java/oshi/hardware/platform/unix/solaris/SolarisCentralProcessor.java b/oshi-core/src/main/java/oshi/hardware/platform/unix/solaris/SolarisCentralProcessor.java
index 20ea2923b1..702e1ae622 100644
--- a/oshi-core/src/main/java/oshi/hardware/platform/unix/solaris/SolarisCentralProcessor.java
+++ b/oshi-core/src/main/java/oshi/hardware/platform/unix/solaris/SolarisCentralProcessor.java
@@ -206,7 +206,12 @@ public class SolarisCentralProcessor extends AbstractCentralProcessor {
      */
     @Override
     public long getContextSwitches() {
-        return -1;
+        long swtch = 0;
+        List<String> kstat = ExecutingCommand.runNative(""kstat -p cpu_stat:::/pswitch\\\\|inv_swtch/"");
+        for (String s : kstat) {
+            swtch += ParseUtil.parseLastLong(s, 0L);
+        }
+        return swtch > 0 ? swtch : -1L;
     }
 
     /**
@@ -214,6 +219,11 @@ public class SolarisCentralProcessor extends AbstractCentralProcessor {
      */
     @Override
     public long getInterrupts() {
-        return -1;
+        long intr = 0;
+        List<String> kstat = ExecutingCommand.runNative(""kstat -p cpu_stat:::/intr/"");
+        for (String s : kstat) {
+            intr += ParseUtil.parseLastLong(s, 0L);
+        }
+        return intr > 0 ? intr : -1L;
     }
 }
diff --git a/oshi-core/src/main/java/oshi/jna/platform/mac/SystemB.java b/oshi-core/src/main/java/oshi/jna/platform/mac/SystemB.java
index f0facbe1a2..10e748bc7c 100644
--- a/oshi-core/src/main/java/oshi/jna/platform/mac/SystemB.java
+++ b/oshi-core/src/main/java/oshi/jna/platform/mac/SystemB.java
@@ -135,6 +135,65 @@ public interface SystemB extends CLibrary, com.sun.jna.platform.mac.SystemB {
         }
     }
 
+    class VMMeter extends Structure {
+        /*
+         * General system activity.
+         */
+        public int v_swtch; /* context switches */
+        public int v_trap; /* calls to trap */
+        public int v_syscall; /* calls to syscall() */
+        public int v_intr; /* device interrupts */
+        public int v_soft; /* software interrupts */
+        public int v_faults; /* total faults taken */
+        /*
+         * Virtual memory activity.
+         */
+        public int v_lookups; /* object cache lookups */
+        public int v_hits; /* object cache hits */
+        public int v_vm_faults; /* number of address memory faults */
+        public int v_cow_faults; /* number of copy-on-writes */
+        public int v_swpin; /* swapins */
+        public int v_swpout; /* swapouts */
+        public int v_pswpin; /* pages swapped in */
+        public int v_pswpout; /* pages swapped out */
+        public int v_pageins; /* number of pageins */
+        public int v_pageouts; /* number of pageouts */
+        public int v_pgpgin; /* pages paged in */
+        public int v_pgpgout; /* pages paged out */
+        public int v_intrans; /* intransit blocking page faults */
+        public int v_reactivated; /*
+                                   * number of pages reactivated from free list
+                                   */
+        public int v_rev; /* revolutions of the hand */
+        public int v_scan; /* scans in page out daemon */
+        public int v_dfree; /* pages freed by daemon */
+        public int v_pfree; /* pages freed by exiting processes */
+        public int v_zfod; /* pages zero filled on demand */
+        public int v_nzfod; /* number of zfod's created */
+        /*
+         * Distribution of page usages.
+         */
+        public int v_page_size; /* page size in bytes */
+        public int v_kernel_pages; /* number of pages in use by kernel */
+        public int v_free_target; /* number of pages desired free */
+        public int v_free_min; /* minimum number of pages desired free */
+        public int v_free_count; /* number of pages free */
+        public int v_wire_count; /* number of pages wired down */
+        public int v_active_count; /* number of pages active */
+        public int v_inactive_target; /* number of pages desired inactive */
+        public int v_inactive_count; /* number of pages inactive */
+
+        @Override
+        protected List<String> getFieldOrder() {
+            return Arrays.asList(new String[] { ""v_swtch"", ""v_trap"", ""v_syscall"", ""v_intr"", ""v_soft"", ""v_faults"",
+                    ""v_lookups"", ""v_hits"", ""v_vm_faults"", ""v_cow_faults"", ""v_swpin"", ""v_swpout"", ""v_pswpin"",
+                    ""v_pswpout"", ""v_pageins"", ""v_pageouts"", ""v_pgpgin"", ""v_pgpgout"", ""v_intrans"", ""v_reactivated"",
+                    ""v_rev"", ""v_scan"", ""v_dfree"", ""v_pfree"", ""v_zfod"", ""v_nzfod"", ""v_page_size"", ""v_kernel_pages"",
+                    ""v_free_target"", ""v_free_min"", ""v_free_count"", ""v_wire_count"", ""v_active_count"",
+                    ""v_inactive_target"", ""v_inactive_count"" });
+        }
+    }
+
     class RUsageInfoV2 extends Structure {
         public byte[] ri_uuid = new byte[16];
         public long ri_user_time;
diff --git a/oshi-core/src/main/java/oshi/util/ParseUtil.java b/oshi-core/src/main/java/oshi/util/ParseUtil.java
index 01eceff145..4a5db9abaa 100644
--- a/oshi-core/src/main/java/oshi/util/ParseUtil.java
+++ b/oshi-core/src/main/java/oshi/util/ParseUtil.java
@@ -139,6 +139,24 @@ public class ParseUtil {
         }
     }
 
+    /**
+     * Parse the last element of a space-delimited string to a value
+     *
+     * @param s
+     *            The string to parse
+     * @param li
+     *            Default long integer if not parsable
+     * @return value or the given default if not parsable
+     */
+    public static long parseLastLong(String s, long li) {
+        try {
+            return Long.parseLong(parseLastString(s));
+        } catch (NumberFormatException e) {
+            LOG.trace(DEFAULT_LOG_MSG, s, e);
+            return li;
+        }
+    }
+
     /**
      * Parse the last element of a space-delimited string to a string
      *
@@ -548,5 +566,4 @@ public class ParseUtil {
         buffer.append(original.substring(currIndex));
         return buffer.toString();
     }
-
 }
diff --git a/oshi-core/src/test/java/oshi/hardware/CentralProcessorTest.java b/oshi-core/src/test/java/oshi/hardware/CentralProcessorTest.java
index ff27124ad7..bfcad08517 100644
--- a/oshi-core/src/test/java/oshi/hardware/CentralProcessorTest.java
+++ b/oshi-core/src/test/java/oshi/hardware/CentralProcessorTest.java
@@ -100,10 +100,7 @@ public class CentralProcessorTest {
         assertNotNull(p.getSystemSerialNumber());
         assertTrue(p.getLogicalProcessorCount() >= p.getPhysicalProcessorCount());
         assertTrue(p.getPhysicalProcessorCount() > 0);
-
-        if (Platform.isLinux() || Platform.isWindows()) {
-            assertTrue(p.getContextSwitches() >= 0);
-            assertTrue(p.getInterrupts() >= 0);
-        }
+        assertTrue(p.getContextSwitches() >= 0);
+        assertTrue(p.getInterrupts() >= 0);
     }
 }
diff --git a/oshi-core/src/test/java/oshi/util/ParseUtilTest.java b/oshi-core/src/test/java/oshi/util/ParseUtilTest.java
index 944944d39a..2d5539a6f2 100644
--- a/oshi-core/src/test/java/oshi/util/ParseUtilTest.java
+++ b/oshi-core/src/test/java/oshi/util/ParseUtilTest.java
@@ -55,6 +55,12 @@ public class ParseUtilTest {
         assertEquals(-1, ParseUtil.parseLastInt(""foo : bar"", -1));
         assertEquals(1, ParseUtil.parseLastInt(""foo : 1"", 0));
         assertEquals(2, ParseUtil.parseLastInt(""foo"", 2));
+        assertEquals(3, ParseUtil.parseLastInt(""max_int plus one is 2147483648"", 3));
+
+        assertEquals(-1L, ParseUtil.parseLastLong(""foo : bar"", -1L));
+        assertEquals(1L, ParseUtil.parseLastLong(""foo : 1"", 0L));
+        assertEquals(2L, ParseUtil.parseLastLong(""foo"", 2L));
+        assertEquals(2147483648L, ParseUtil.parseLastLong(""max_int plus one is 2147483648"", 3L));
     }
 
     /**
diff --git a/oshi-json/src/main/java/oshi/json/hardware/CentralProcessor.java b/oshi-json/src/main/java/oshi/json/hardware/CentralProcessor.java
index 14c2980515..f58dea1aa1 100644
--- a/oshi-json/src/main/java/oshi/json/hardware/CentralProcessor.java
+++ b/oshi-json/src/main/java/oshi/json/hardware/CentralProcessor.java
@@ -259,10 +259,9 @@ public interface CentralProcessor extends OshiJsonObject {
      * than 1 second. If less than one second has elapsed since the last call of
      * this method, it will return a calculation based on the tick counts and
      * times of the previous two calls. If at least a second has elapsed, it
-     * will return the average CPU load for the interval and update the
-     * ""last called"" times. This method is intended to be used for periodic
-     * polling (iterating over all processors) at intervals of 1 second or
-     * longer.
+     * will return the average CPU load for the interval and update the ""last
+     * called"" times. This method is intended to be used for periodic polling
+     * (iterating over all processors) at intervals of 1 second or longer.
      *
      * @return array of CPU load between 0 and 1 (100%) for each logical
      *         processor
@@ -337,13 +336,15 @@ public interface CentralProcessor extends OshiJsonObject {
     int getPhysicalProcessorCount();
 
     /**
-     *  Get the number of context switches happened
+     * Get the number of context switches which have occurred
+     * 
      * @return The number of context switches
      */
     long getContextSwitches();
 
     /**
-     * Get the number of interrupts happened
+     * Get the number of interrupts which have occurred
+     * 
      * @return The number of interrupts
      */
     long getInterrupts();
diff --git a/oshi-json/src/test/java/oshi/json/hardware/CentralProcessorTest.java b/oshi-json/src/test/java/oshi/json/hardware/CentralProcessorTest.java
index 38d6c2667b..655553559e 100644
--- a/oshi-json/src/test/java/oshi/json/hardware/CentralProcessorTest.java
+++ b/oshi-json/src/test/java/oshi/json/hardware/CentralProcessorTest.java
@@ -100,10 +100,7 @@ public class CentralProcessorTest {
         assertNotNull(p.getSystemSerialNumber());
         assertTrue(p.getLogicalProcessorCount() >= p.getPhysicalProcessorCount());
         assertTrue(p.getPhysicalProcessorCount() > 0);
-
-        if (Platform.isLinux() || Platform.isWindows()) {
-            assertTrue(p.getContextSwitches() >= 0);
-            assertTrue(p.getInterrupts() >= 0);
-        }
+        assertTrue(p.getContextSwitches() >= 0);
+        assertTrue(p.getInterrupts() >= 0);
     }
 }
diff --git a/oshi-json/src/test/resources/oshi.json.properties b/oshi-json/src/test/resources/oshi.json.properties
index 3d9d673c0c..634ee24b06 100644
--- a/oshi-json/src/test/resources/oshi.json.properties
+++ b/oshi-json/src/test/resources/oshi.json.properties
@@ -141,6 +141,8 @@
 #    hardware.processor.processorCpuLoadBetweenTicks     = false
 #    hardware.processor.processorCpuLoadTicks            = false
 #    hardware.processor.systemUptime                     = false
+#    hardware.processor.contextSwitches                  = false
+#    hardware.processor.interrupts                       = false
 #  hardware.memory                                       = false
 #    hardware.memory.available                           = false
 #    hardware.memory.total                               = false","Implement context switches and interrupts on macOS , FreeBSD , Solaris ( <issue_id> ) .","""Added context switches and interrupts for macOS, FreeBSD, and Solaris, and updated JNA to 4.5.1""","""Added context switches and interrupts for Linux, Windows, and macOS, and updated JNA version to 4.5.1""","This commit updates OSHI to version 3.5.0 and includes the following changes:

* Adds support for retrieving child processes in the OperatingSystem class (#446)
* Adds support for context switches and interrupts on Linux and Windows (#447, #471)
* Updates JNA dependency to version 4.5.1

The changes to the code include modifications to the CHANGELOG.md, pom.xml, and various Java files. The specific changes include adding new methods to the CentralProcessor interface and implementing them in the platform-specific classes, as well as updating the JNA dependency in the pom.xml file.

This commit also includes a change to the MacCentralProcessor class to use the host\_statistics() function from the SystemB library instead of the sysctlbyname() function from the Libc library to retrieve context switch and interrupt counts. This change was made to fix an issue where the previous implementation was not working correctly on macOS.

Finally, this commit includes a change to the ParseUtil class to add a new method for parsing the last element of a space-delimited string to a long value. This method is used in the implementation of the getContextSwitches() and getInterrupts() methods in the CentralProcessor interface.","""Add support for context switches and interrupts on Mac, FreeBSD, and Solaris. Updated to JNA 4.5.1. Various documentation and test updates.""",Model 4
"diff --git a/client/rest-high-level/src/main/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformProgress.java b/client/rest-high-level/src/main/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformProgress.java
new file mode 100644
index 00000000000..a4177a33487
--- /dev/null
+++ b/client/rest-high-level/src/main/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformProgress.java
@@ -0,0 +1,94 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the ""License""); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.client.dataframe.transforms;
+
+import org.elasticsearch.common.ParseField;
+import org.elasticsearch.common.xcontent.ConstructingObjectParser;
+import org.elasticsearch.common.xcontent.XContentParser;
+
+import java.util.Objects;
+
+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;
+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.optionalConstructorArg;
+
+public class DataFrameTransformProgress {
+
+    public static final ParseField TOTAL_DOCS = new ParseField(""total_docs"");
+    public static final ParseField DOCS_REMAINING = new ParseField(""docs_remaining"");
+    public static final ParseField PERCENT_COMPLETE = new ParseField(""percent_complete"");
+
+    public static final ConstructingObjectParser<DataFrameTransformProgress, Void> PARSER = new ConstructingObjectParser<>(
+        ""data_frame_transform_progress"",
+        true,
+        a -> new DataFrameTransformProgress((Long) a[0], (Long)a[1], (Double)a[2]));
+
+    static {
+        PARSER.declareLong(constructorArg(), TOTAL_DOCS);
+        PARSER.declareLong(optionalConstructorArg(), DOCS_REMAINING);
+        PARSER.declareDouble(optionalConstructorArg(), PERCENT_COMPLETE);
+    }
+
+    public static DataFrameTransformProgress fromXContent(XContentParser parser) {
+        return PARSER.apply(parser, null);
+    }
+
+    private final long totalDocs;
+    private final long remainingDocs;
+    private final double percentComplete;
+
+    public DataFrameTransformProgress(long totalDocs, Long remainingDocs, double percentComplete) {
+        this.totalDocs = totalDocs;
+        this.remainingDocs = remainingDocs == null ? totalDocs : remainingDocs;
+        this.percentComplete = percentComplete;
+    }
+
+    public double getPercentComplete() {
+        return percentComplete;
+    }
+
+    public long getTotalDocs() {
+        return totalDocs;
+    }
+
+    public long getRemainingDocs() {
+        return remainingDocs;
+    }
+
+    @Override
+    public boolean equals(Object other) {
+        if (other == this) {
+            return true;
+        }
+
+        if (other == null || other.getClass() != getClass()) {
+            return false;
+        }
+
+        DataFrameTransformProgress that = (DataFrameTransformProgress) other;
+        return Objects.equals(this.remainingDocs, that.remainingDocs)
+            && Objects.equals(this.totalDocs, that.totalDocs)
+            && Objects.equals(this.percentComplete, that.percentComplete);
+    }
+
+    @Override
+    public int hashCode(){
+        return Objects.hash(remainingDocs, totalDocs, percentComplete);
+    }
+}
diff --git a/client/rest-high-level/src/main/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformState.java b/client/rest-high-level/src/main/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformState.java
index 6bbc7a00b1b..352cbfb67fc 100644
--- a/client/rest-high-level/src/main/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformState.java
+++ b/client/rest-high-level/src/main/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformState.java
@@ -23,16 +23,14 @@ import org.elasticsearch.client.core.IndexerState;
 import org.elasticsearch.common.Nullable;
 import org.elasticsearch.common.ParseField;
 import org.elasticsearch.common.xcontent.ConstructingObjectParser;
-import org.elasticsearch.common.xcontent.ObjectParser;
+import org.elasticsearch.common.xcontent.ObjectParser.ValueType;
 import org.elasticsearch.common.xcontent.XContentParser;
 
 import java.io.IOException;
 import java.util.Collections;
-import java.util.HashMap;
+import java.util.LinkedHashMap;
 import java.util.Map;
 import java.util.Objects;
-import java.util.SortedMap;
-import java.util.TreeMap;
 
 import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;
 import static org.elasticsearch.common.xcontent.ConstructingObjectParser.optionalConstructorArg;
@@ -44,33 +42,25 @@ public class DataFrameTransformState {
     private static final ParseField CURRENT_POSITION = new ParseField(""current_position"");
     private static final ParseField CHECKPOINT = new ParseField(""checkpoint"");
     private static final ParseField REASON = new ParseField(""reason"");
+    private static final ParseField PROGRESS = new ParseField(""progress"");
 
     @SuppressWarnings(""unchecked"")
     public static final ConstructingObjectParser<DataFrameTransformState, Void> PARSER =
             new ConstructingObjectParser<>(""data_frame_transform_state"", true,
                     args -> new DataFrameTransformState((DataFrameTransformTaskState) args[0],
                         (IndexerState) args[1],
-                        (HashMap<String, Object>) args[2],
+                        (Map<String, Object>) args[2],
                         (long) args[3],
-                        (String) args[4]));
+                        (String) args[4],
+                        (DataFrameTransformProgress) args[5]));
 
     static {
-        PARSER.declareField(constructorArg(),
-            p -> DataFrameTransformTaskState.fromString(p.text()),
-            TASK_STATE,
-            ObjectParser.ValueType.STRING);
-        PARSER.declareField(constructorArg(), p -> IndexerState.fromString(p.text()), INDEXER_STATE, ObjectParser.ValueType.STRING);
-        PARSER.declareField(optionalConstructorArg(), p -> {
-            if (p.currentToken() == XContentParser.Token.START_OBJECT) {
-                return p.map();
-            }
-            if (p.currentToken() == XContentParser.Token.VALUE_NULL) {
-                return null;
-            }
-            throw new IllegalArgumentException(""Unsupported token ["" + p.currentToken() + ""]"");
-        }, CURRENT_POSITION, ObjectParser.ValueType.VALUE_OBJECT_ARRAY);
+        PARSER.declareField(constructorArg(), p -> DataFrameTransformTaskState.fromString(p.text()), TASK_STATE, ValueType.STRING);
+        PARSER.declareField(constructorArg(), p -> IndexerState.fromString(p.text()), INDEXER_STATE, ValueType.STRING);
+        PARSER.declareField(optionalConstructorArg(), (p, c) -> p.mapOrdered(), CURRENT_POSITION, ValueType.OBJECT);
         PARSER.declareLong(ConstructingObjectParser.optionalConstructorArg(), CHECKPOINT);
         PARSER.declareString(ConstructingObjectParser.optionalConstructorArg(), REASON);
+        PARSER.declareField(optionalConstructorArg(), DataFrameTransformProgress::fromXContent, PROGRESS, ValueType.OBJECT);
     }
 
     public static DataFrameTransformState fromXContent(XContentParser parser) throws IOException {
@@ -80,19 +70,22 @@ public class DataFrameTransformState {
     private final DataFrameTransformTaskState taskState;
     private final IndexerState indexerState;
     private final long checkpoint;
-    private final SortedMap<String, Object> currentPosition;
+    private final Map<String, Object> currentPosition;
     private final String reason;
+    private final DataFrameTransformProgress progress;
 
     public DataFrameTransformState(DataFrameTransformTaskState taskState,
                                    IndexerState indexerState,
                                    @Nullable Map<String, Object> position,
                                    long checkpoint,
-                                   @Nullable String reason) {
+                                   @Nullable String reason,
+                                   @Nullable DataFrameTransformProgress progress) {
         this.taskState = taskState;
         this.indexerState = indexerState;
-        this.currentPosition = position == null ? null : Collections.unmodifiableSortedMap(new TreeMap<>(position));
+        this.currentPosition = position == null ? null : Collections.unmodifiableMap(new LinkedHashMap<>(position));
         this.checkpoint = checkpoint;
         this.reason = reason;
+        this.progress = progress;
     }
 
     public IndexerState getIndexerState() {
@@ -117,6 +110,11 @@ public class DataFrameTransformState {
         return reason;
     }
 
+    @Nullable
+    public DataFrameTransformProgress getProgress() {
+        return progress;
+    }
+
     @Override
     public boolean equals(Object other) {
         if (this == other) {
@@ -132,13 +130,14 @@ public class DataFrameTransformState {
         return Objects.equals(this.taskState, that.taskState) &&
             Objects.equals(this.indexerState, that.indexerState) &&
             Objects.equals(this.currentPosition, that.currentPosition) &&
+            Objects.equals(this.progress, that.progress) &&
             this.checkpoint == that.checkpoint &&
             Objects.equals(this.reason, that.reason);
     }
 
     @Override
     public int hashCode() {
-        return Objects.hash(taskState, indexerState, currentPosition, checkpoint, reason);
+        return Objects.hash(taskState, indexerState, currentPosition, checkpoint, reason, progress);
     }
 
 }
diff --git a/client/rest-high-level/src/main/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformStateAndStats.java b/client/rest-high-level/src/main/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformStateAndStats.java
index 938563796ca..9914a0e6331 100644
--- a/client/rest-high-level/src/main/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformStateAndStats.java
+++ b/client/rest-high-level/src/main/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformStateAndStats.java
@@ -57,7 +57,7 @@ public class DataFrameTransformStateAndStats {
     private final DataFrameTransformCheckpointingInfo checkpointingInfo;
 
     public DataFrameTransformStateAndStats(String id, DataFrameTransformState state, DataFrameIndexerTransformStats stats,
-            DataFrameTransformCheckpointingInfo checkpointingInfo) {
+                                           DataFrameTransformCheckpointingInfo checkpointingInfo) {
         this.id = id;
         this.transformState = state;
         this.transformStats = stats;
diff --git a/client/rest-high-level/src/test/java/org/elasticsearch/client/DataFrameTransformIT.java b/client/rest-high-level/src/test/java/org/elasticsearch/client/DataFrameTransformIT.java
index 3e564a86207..3d7f5e3dbcb 100644
--- a/client/rest-high-level/src/test/java/org/elasticsearch/client/DataFrameTransformIT.java
+++ b/client/rest-high-level/src/test/java/org/elasticsearch/client/DataFrameTransformIT.java
@@ -71,6 +71,7 @@ import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;
 import static org.hamcrest.Matchers.containsString;
 import static org.hamcrest.Matchers.empty;
 import static org.hamcrest.Matchers.equalTo;
+import static org.hamcrest.Matchers.greaterThan;
 import static org.hamcrest.Matchers.hasSize;
 import static org.hamcrest.Matchers.is;
 
@@ -360,6 +361,10 @@ public class DataFrameTransformIT extends ESRestHighLevelClientTestCase {
             assertEquals(DataFrameTransformTaskState.STARTED, stateAndStats.getTransformState().getTaskState());
             assertEquals(null, stateAndStats.getTransformState().getReason());
             assertNotEquals(zeroIndexerStats, stateAndStats.getTransformStats());
+            assertNotNull(stateAndStats.getTransformState().getProgress());
+            assertThat(stateAndStats.getTransformState().getProgress().getPercentComplete(), equalTo(100.0));
+            assertThat(stateAndStats.getTransformState().getProgress().getTotalDocs(), greaterThan(0L));
+            assertThat(stateAndStats.getTransformState().getProgress().getRemainingDocs(), equalTo(0L));
         });
     }
 }
diff --git a/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformProgressTests.java b/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformProgressTests.java
new file mode 100644
index 00000000000..573e2ffdbb9
--- /dev/null
+++ b/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformProgressTests.java
@@ -0,0 +1,55 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the ""License""); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.client.dataframe.transforms;
+
+import org.elasticsearch.common.xcontent.XContentBuilder;
+import org.elasticsearch.test.ESTestCase;
+
+import java.io.IOException;
+
+import static org.elasticsearch.test.AbstractXContentTestCase.xContentTester;
+
+public class DataFrameTransformProgressTests extends ESTestCase {
+
+    public void testFromXContent() throws IOException {
+        xContentTester(this::createParser,
+            DataFrameTransformProgressTests::randomInstance,
+            DataFrameTransformProgressTests::toXContent,
+            DataFrameTransformProgress::fromXContent)
+           .supportsUnknownFields(true)
+           .randomFieldsExcludeFilter(field -> field.startsWith(""state""))
+           .test();
+    }
+
+    public static DataFrameTransformProgress randomInstance() {
+        long totalDocs = randomNonNegativeLong();
+        Long docsRemaining = randomBoolean() ? null : randomLongBetween(0, totalDocs);
+        double percentComplete = totalDocs == 0 ? 1.0 : docsRemaining == null ? 0.0 : 100.0*(double)(totalDocs - docsRemaining)/totalDocs;
+        return new DataFrameTransformProgress(totalDocs, docsRemaining, percentComplete);
+    }
+
+    public static void toXContent(DataFrameTransformProgress progress, XContentBuilder builder) throws IOException {
+        builder.startObject();
+        builder.field(DataFrameTransformProgress.TOTAL_DOCS.getPreferredName(), progress.getTotalDocs());
+        builder.field(DataFrameTransformProgress.DOCS_REMAINING.getPreferredName(), progress.getRemainingDocs());
+        builder.field(DataFrameTransformProgress.PERCENT_COMPLETE.getPreferredName(), progress.getPercentComplete());
+        builder.endObject();
+    }
+}
diff --git a/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformStateAndStatsTests.java b/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformStateAndStatsTests.java
index 88628699104..6ebdec5a690 100644
--- a/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformStateAndStatsTests.java
+++ b/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformStateAndStatsTests.java
@@ -40,9 +40,9 @@ public class DataFrameTransformStateAndStatsTests extends ESTestCase {
 
     public static DataFrameTransformStateAndStats randomInstance() {
         return new DataFrameTransformStateAndStats(randomAlphaOfLength(10),
-                DataFrameTransformStateTests.randomDataFrameTransformState(),
-                DataFrameIndexerTransformStatsTests.randomStats(),
-                DataFrameTransformCheckpointingInfoTests.randomDataFrameTransformCheckpointingInfo());
+            DataFrameTransformStateTests.randomDataFrameTransformState(),
+            DataFrameIndexerTransformStatsTests.randomStats(),
+            DataFrameTransformCheckpointingInfoTests.randomDataFrameTransformCheckpointingInfo());
     }
 
     public static void toXContent(DataFrameTransformStateAndStats stateAndStats, XContentBuilder builder) throws IOException {
diff --git a/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformStateTests.java b/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformStateTests.java
index 7d1d713a127..4ada50c20d2 100644
--- a/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformStateTests.java
+++ b/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/DataFrameTransformStateTests.java
@@ -24,7 +24,7 @@ import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.test.ESTestCase;
 
 import java.io.IOException;
-import java.util.HashMap;
+import java.util.LinkedHashMap;
 import java.util.Map;
 
 import static org.elasticsearch.test.AbstractXContentTestCase.xContentTester;
@@ -46,7 +46,8 @@ public class DataFrameTransformStateTests extends ESTestCase {
             randomFrom(IndexerState.values()),
             randomPositionMap(),
             randomLongBetween(0,10),
-            randomBoolean() ? null : randomAlphaOfLength(10));
+            randomBoolean() ? null : randomAlphaOfLength(10),
+            randomBoolean() ? null : DataFrameTransformProgressTests.randomInstance());
     }
 
     public static void toXContent(DataFrameTransformState state, XContentBuilder builder) throws IOException {
@@ -60,6 +61,10 @@ public class DataFrameTransformStateTests extends ESTestCase {
         if (state.getReason() != null) {
             builder.field(""reason"", state.getReason());
         }
+        if (state.getProgress() != null) {
+            builder.field(""progress"");
+            DataFrameTransformProgressTests.toXContent(state.getProgress(), builder);
+        }
         builder.endObject();
     }
 
@@ -68,7 +73,7 @@ public class DataFrameTransformStateTests extends ESTestCase {
             return null;
         }
         int numFields = randomIntBetween(1, 5);
-        Map<String, Object> position = new HashMap<>();
+        Map<String, Object> position = new LinkedHashMap<>();
         for (int i = 0; i < numFields; i++) {
             Object value;
             if (randomBoolean()) {
diff --git a/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/hlrc/DataFrameTransformProgressTests.java b/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/hlrc/DataFrameTransformProgressTests.java
new file mode 100644
index 00000000000..be589a63248
--- /dev/null
+++ b/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/hlrc/DataFrameTransformProgressTests.java
@@ -0,0 +1,57 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the ""License""); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.client.dataframe.transforms.hlrc;
+
+import org.elasticsearch.client.AbstractResponseTestCase;
+import org.elasticsearch.common.xcontent.XContentParser;
+import org.elasticsearch.xpack.core.dataframe.transforms.DataFrameTransformProgress;
+
+import static org.hamcrest.Matchers.equalTo;
+
+public class DataFrameTransformProgressTests extends AbstractResponseTestCase<
+        DataFrameTransformProgress,
+        org.elasticsearch.client.dataframe.transforms.DataFrameTransformProgress> {
+
+    public static DataFrameTransformProgress fromHlrc(
+            org.elasticsearch.client.dataframe.transforms.DataFrameTransformProgress instance) {
+        if (instance == null) {
+            return null;
+        }
+        return new DataFrameTransformProgress(instance.getTotalDocs(), instance.getRemainingDocs());
+    }
+
+    @Override
+    protected DataFrameTransformProgress createServerTestInstance() {
+        return DataFrameTransformStateTests.randomDataFrameTransformProgress();
+    }
+
+    @Override
+    protected org.elasticsearch.client.dataframe.transforms.DataFrameTransformProgress doParseToClientInstance(XContentParser parser) {
+        return org.elasticsearch.client.dataframe.transforms.DataFrameTransformProgress.fromXContent(parser);
+    }
+
+    @Override
+    protected void assertInstances(DataFrameTransformProgress serverTestInstance,
+                                   org.elasticsearch.client.dataframe.transforms.DataFrameTransformProgress clientInstance) {
+        assertThat(serverTestInstance.getTotalDocs(), equalTo(clientInstance.getTotalDocs()));
+        assertThat(serverTestInstance.getRemainingDocs(), equalTo(clientInstance.getRemainingDocs()));
+        assertThat(serverTestInstance.getPercentComplete(), equalTo(clientInstance.getPercentComplete()));
+    }
+}
diff --git a/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/hlrc/DataFrameTransformStateTests.java b/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/hlrc/DataFrameTransformStateTests.java
index 457c68d593e..4c80365bc53 100644
--- a/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/hlrc/DataFrameTransformStateTests.java
+++ b/client/rest-high-level/src/test/java/org/elasticsearch/client/dataframe/transforms/hlrc/DataFrameTransformStateTests.java
@@ -24,6 +24,7 @@ import org.elasticsearch.client.AbstractHlrcXContentTestCase;
 import org.elasticsearch.xpack.core.dataframe.transforms.DataFrameIndexerTransformStats;
 import org.elasticsearch.xpack.core.dataframe.transforms.DataFrameTransformCheckpointStats;
 import org.elasticsearch.xpack.core.dataframe.transforms.DataFrameTransformCheckpointingInfo;
+import org.elasticsearch.xpack.core.dataframe.transforms.DataFrameTransformProgress;
 import org.elasticsearch.xpack.core.dataframe.transforms.DataFrameTransformState;
 import org.elasticsearch.xpack.core.dataframe.transforms.DataFrameTransformStateAndStats;
 import org.elasticsearch.xpack.core.dataframe.transforms.DataFrameTransformTaskState;
@@ -40,7 +41,7 @@ public class DataFrameTransformStateTests extends AbstractHlrcXContentTestCase<D
     public static DataFrameTransformState fromHlrc(org.elasticsearch.client.dataframe.transforms.DataFrameTransformState instance) {
         return new DataFrameTransformState(DataFrameTransformTaskState.fromString(instance.getTaskState().value()),
                 IndexerState.fromString(instance.getIndexerState().value()), instance.getPosition(), instance.getCheckpoint(),
-                instance.getReason());
+                instance.getReason(), DataFrameTransformProgressTests.fromHlrc(instance.getProgress()));
     }
 
     @Override
@@ -90,6 +91,12 @@ public class DataFrameTransformStateTests extends AbstractHlrcXContentTestCase<D
         return new DataFrameTransformCheckpointStats(randomNonNegativeLong(), randomNonNegativeLong());
     }
 
+    public static DataFrameTransformProgress randomDataFrameTransformProgress() {
+        long totalDocs = randomNonNegativeLong();
+        Long remainingDocs = randomBoolean() ? null : randomLongBetween(0, totalDocs);
+        return new DataFrameTransformProgress(totalDocs, remainingDocs);
+    }
+
     public static DataFrameIndexerTransformStats randomStats(String transformId) {
         return new DataFrameIndexerTransformStats(transformId, randomLongBetween(10L, 10000L),
             randomLongBetween(0L, 10000L), randomLongBetween(0L, 10000L), randomLongBetween(0L, 10000L), randomLongBetween(0L, 10000L),
@@ -102,7 +109,8 @@ public class DataFrameTransformStateTests extends AbstractHlrcXContentTestCase<D
             randomFrom(IndexerState.values()),
             randomPosition(),
             randomLongBetween(0,10),
-            randomBoolean() ? null : randomAlphaOfLength(10));
+            randomBoolean() ? null : randomAlphaOfLength(10),
+            randomBoolean() ? null : randomDataFrameTransformProgress());
     }
 
     private static Map<String, Object> randomPosition() {
diff --git a/client/rest-high-level/src/test/java/org/elasticsearch/client/documentation/DataFrameTransformDocumentationIT.java b/client/rest-high-level/src/test/java/org/elasticsearch/client/documentation/DataFrameTransformDocumentationIT.java
index b7d6967206c..daa9dc06fee 100644
--- a/client/rest-high-level/src/test/java/org/elasticsearch/client/documentation/DataFrameTransformDocumentationIT.java
+++ b/client/rest-high-level/src/test/java/org/elasticsearch/client/documentation/DataFrameTransformDocumentationIT.java
@@ -40,6 +40,7 @@ import org.elasticsearch.client.dataframe.StopDataFrameTransformRequest;
 import org.elasticsearch.client.dataframe.StopDataFrameTransformResponse;
 import org.elasticsearch.client.dataframe.transforms.DataFrameIndexerTransformStats;
 import org.elasticsearch.client.dataframe.transforms.DataFrameTransformConfig;
+import org.elasticsearch.client.dataframe.transforms.DataFrameTransformProgress;
 import org.elasticsearch.client.dataframe.transforms.DataFrameTransformStateAndStats;
 import org.elasticsearch.client.dataframe.transforms.DataFrameTransformTaskState;
 import org.elasticsearch.client.dataframe.transforms.DestConfig;
@@ -465,18 +466,21 @@ public class DataFrameTransformDocumentationIT extends ESRestHighLevelClientTest
 
             // tag::get-data-frame-transform-stats-response
             DataFrameTransformStateAndStats stateAndStats =
-                    response.getTransformsStateAndStats().get(0);   // <1>
+                response.getTransformsStateAndStats().get(0);   // <1>
             DataFrameTransformTaskState taskState =
                 stateAndStats.getTransformState().getTaskState(); // <2>
             IndexerState indexerState =
-                    stateAndStats.getTransformState().getIndexerState();  // <3>
+                stateAndStats.getTransformState().getIndexerState();  // <3>
             DataFrameIndexerTransformStats transformStats =
-                    stateAndStats.getTransformStats();              // <4>
+                stateAndStats.getTransformStats();              // <4>
+            DataFrameTransformProgress progress =
+                stateAndStats.getTransformState().getProgress(); // <5>
             // end::get-data-frame-transform-stats-response
 
             assertEquals(IndexerState.STOPPED, indexerState);
             assertEquals(DataFrameTransformTaskState.STOPPED, taskState);
             assertNotNull(transformStats);
+            assertNull(progress);
         }
         {
             // tag::get-data-frame-transform-stats-execute-listener
diff --git a/docs/java-rest/high-level/dataframe/get_data_frame_stats.asciidoc b/docs/java-rest/high-level/dataframe/get_data_frame_stats.asciidoc
index 2b377d22c81..cdc6254a4e4 100644
--- a/docs/java-rest/high-level/dataframe/get_data_frame_stats.asciidoc
+++ b/docs/java-rest/high-level/dataframe/get_data_frame_stats.asciidoc
@@ -37,4 +37,6 @@ include-tagged::{doc-tests-file}[{api}-response]
 <1> The response contains a list of `DataFrameTransformStateAndStats` objects
 <2> The running state of the transform task e.g `started`
 <3> The running state of the transform indexer e.g `started`, `indexing`, etc.
-<4> The transform progress statistics recording the number of documents indexed etc
\ No newline at end of file
+<4> The overall transform statistics recording the number of documents indexed etc.
+<5> The progress of the current run in the transform. Supplies the number of docs left until the next checkpoint
+and the total number of docs expected.
\ No newline at end of file
diff --git a/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/dataframe/transforms/DataFrameTransformProgress.java b/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/dataframe/transforms/DataFrameTransformProgress.java
new file mode 100644
index 00000000000..5b7346bca2a
--- /dev/null
+++ b/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/dataframe/transforms/DataFrameTransformProgress.java
@@ -0,0 +1,135 @@
+/*
+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one
+ * or more contributor license agreements. Licensed under the Elastic License;
+ * you may not use this file except in compliance with the Elastic License.
+ */
+
+package org.elasticsearch.xpack.core.dataframe.transforms;
+
+import org.elasticsearch.common.ParseField;
+import org.elasticsearch.common.Strings;
+import org.elasticsearch.common.io.stream.StreamInput;
+import org.elasticsearch.common.io.stream.StreamOutput;
+import org.elasticsearch.common.io.stream.Writeable;
+import org.elasticsearch.common.xcontent.ConstructingObjectParser;
+import org.elasticsearch.common.xcontent.ToXContentObject;
+import org.elasticsearch.common.xcontent.XContentBuilder;
+
+import java.io.IOException;
+import java.util.Objects;
+
+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;
+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.optionalConstructorArg;
+
+public class DataFrameTransformProgress implements Writeable, ToXContentObject {
+
+    private static final ParseField TOTAL_DOCS = new ParseField(""total_docs"");
+    private static final ParseField DOCS_REMAINING = new ParseField(""docs_remaining"");
+    private static final String PERCENT_COMPLETE = ""percent_complete"";
+
+    public static final ConstructingObjectParser<DataFrameTransformProgress, Void> PARSER = new ConstructingObjectParser<>(
+        ""data_frame_transform_progress"",
+        true,
+        a -> new DataFrameTransformProgress((Long) a[0], (Long)a[1]));
+
+    static {
+        PARSER.declareLong(constructorArg(), TOTAL_DOCS);
+        PARSER.declareLong(optionalConstructorArg(), DOCS_REMAINING);
+    }
+
+    private final long totalDocs;
+    private long remainingDocs;
+
+    public DataFrameTransformProgress(long totalDocs, Long remainingDocs) {
+        if (totalDocs < 0) {
+            throw new IllegalArgumentException(""[total_docs] must be >0."");
+        }
+        this.totalDocs = totalDocs;
+        if (remainingDocs != null && remainingDocs < 0) {
+            throw new IllegalArgumentException(""[docs_remaining] must be >0."");
+        }
+        this.remainingDocs = remainingDocs == null ? totalDocs : remainingDocs;
+    }
+
+  ",Adds progress reporting for transforms ( <issue_id> ) ( <issue_id> ) .,"""Add DataFrameTransformProgress class to track progress of data frame transforms""",Added DataFrameTransformProgress class to track transform progress and updated related classes and tests to use it.,"This commit adds a new class `DataFrameTransformProgress` to the Elasticsearch client codebase. This class represents the progress of a data frame transform operation, which includes the total number of documents to be processed, the remaining number of documents to be processed, and the percentage of the operation that has been completed.

 The class includes a constructor that takes the total number of documents and the remaining number of documents as arguments, as well as getter methods for these properties. It also includes a `hashCode` method and an `equals` method for comparing `DataFrameTransformProgress` objects.

 The class also includes a static method `fromXContent` that can be used to parse a `DataFrameTransformProgress` object from an Elasticsearch response, using a `ConstructingObjectParser` to parse the JSON response. The `ConstructingObjectParser` is defined using a static block in the class, and includes fields for the total number of documents, the remaining number of documents, and the percentage complete.

 Finally, the commit also includes a test class `DataFrameTransformProgressTests` that includes tests for the `DataFrameTransformProgress` class, using the `ESTestCase` testing framework. These tests include randomized tests for the `fromXContent` method, using the `xContentTester` helper method.","""Add progress tracking for DataFrame transforms including total docs, docs remaining, and percent complete.""",Model 2
"diff --git a/jmh/src/main/java/org/roaringbitmap/needwork/RandomAccess.java b/jmh/src/main/java/org/roaringbitmap/needwork/RandomAccess.java
new file mode 100644
index 00000000..02bf1531
--- /dev/null
+++ b/jmh/src/main/java/org/roaringbitmap/needwork/RandomAccess.java
@@ -0,0 +1,89 @@
+package org.roaringbitmap.needwork;
+
+
+import java.util.ArrayList;
+import java.util.Random;
+import java.util.concurrent.TimeUnit;
+
+import org.openjdk.jmh.annotations.Benchmark;
+import org.openjdk.jmh.annotations.BenchmarkMode;
+import org.openjdk.jmh.annotations.Mode;
+import org.openjdk.jmh.annotations.OutputTimeUnit;
+import org.openjdk.jmh.annotations.Param;
+import org.openjdk.jmh.annotations.Scope;
+import org.openjdk.jmh.annotations.Setup;
+import org.openjdk.jmh.annotations.State;
+import org.roaringbitmap.RoaringBitmap;
+import org.roaringbitmap.ZipRealDataRetriever;
+
+@BenchmarkMode(Mode.AverageTime)
+@OutputTimeUnit(TimeUnit.MICROSECONDS)
+public class RandomAccess {
+
+    @Benchmark
+    public int RoaringWithRun(BenchmarkState benchmarkState) {
+        int answer = 0;
+        for(int k : benchmarkState.queries) {
+            if(benchmarkState.rc.contains(k))
+                answer++;
+        }
+        return answer;
+    }
+
+    @Benchmark
+    public int Roaring(BenchmarkState benchmarkState) {
+        int answer = 0;
+        for(int k : benchmarkState.queries) {
+            if(benchmarkState.ac.contains(k))
+                answer++;
+        }
+        return answer;
+    }
+    
+    @State(Scope.Benchmark)
+    public static class BenchmarkState {
+        @Param ({// putting the data sets in alpha. order
+            ""census-income"", ""census1881"",
+            ""dimension_008"", ""dimension_003"",
+            ""dimension_033"", ""uscensus2000"",
+            ""weather_sept_85"", ""wikileaks-noquotes""
+            ,""census-income_srt"",""census1881_srt"",
+            ""weather_sept_85_srt"",""wikileaks-noquotes_srt""
+        })
+        String dataset;
+        
+        int[] queries = new int[1024];
+        
+
+        ArrayList<RoaringBitmap> ac = new ArrayList<RoaringBitmap>();
+
+        ArrayList<RoaringBitmap> rc = new ArrayList<RoaringBitmap>();
+
+        public BenchmarkState() {
+        }
+                
+        @Setup
+        public void setup() throws Exception {
+            ZipRealDataRetriever dataRetriever = new ZipRealDataRetriever(dataset);
+            System.out.println();
+            System.out.println(""Loading files from "" + dataRetriever.getName());
+            int universe = 0;
+            
+
+            for (int[] data : dataRetriever.fetchBitPositions()) {
+                RoaringBitmap basic = RoaringBitmap.bitmapOf(data);
+                ac.add(basic.clone());
+                int lv =  basic.getReverseIntIterator().next();
+                if(lv > universe) universe = lv;
+
+                basic.runOptimize();
+                rc.add(basic);
+            }
+            Random rand = new Random(123);
+            for(int k = 0; k < queries.length; ++k)
+                queries[k] = rand.nextInt(universe+1);
+            System.out.println(""loaded ""+rc.size()+"" bitmaps"");
+        }
+
+    }
+}
diff --git a/src/main/java/org/roaringbitmap/Util.java b/src/main/java/org/roaringbitmap/Util.java
index 5cd6a404..55e7f64b 100644
--- a/src/main/java/org/roaringbitmap/Util.java
+++ b/src/main/java/org/roaringbitmap/Util.java
@@ -183,10 +183,43 @@ public final class Util {
      * @return count
      */
     public static int unsignedBinarySearch(final short[] array, final int begin,
-                                              final int end, final short k) {
+            final int end,  final short k) {
+        return branchlessUnsignedBinarySearch(array,begin,end, k);
+    }
+
+    protected static int branchlessUnsignedBinarySearch(final short[] array, final int begin,
+            final int end,  final short k) {
         int ikey = toIntUnsigned(k);
         // next line accelerates the possibly common case where the value would be inserted at the end
         if((end>0) && (toIntUnsigned(array[end-1]) < ikey)) return - end - 1;
+        int n = end - begin;
+        if(n == 0) return -1;
+        int pos = 0;
+        while (n > 1) {
+            final int half = n >>> 1;
+            n -= half;
+            final int index = pos + half;
+            final int val = array[index + begin] & 0xFFFF;
+            final int diff = val - ikey;
+            final int mask = diff >> 31;
+            final int addition = half & mask;
+            pos += addition;
+        }
+        // next  line is upper bound
+        if(toIntUnsigned(array[pos + begin]) < ikey) pos = pos + 1;
+        if ((pos +begin < end) && (toIntUnsigned(array[pos + begin]) == ikey)) {
+            return pos + begin;
+        }
+        return -(pos + begin + 1);
+    }
+
+    protected static int branchyUnsignedBinarySearch(final short[] array,
+            final int begin, final int end, final short k) {
+        int ikey = toIntUnsigned(k);
+        // next line accelerates the possibly common case where the value would
+        // be inserted at the end
+        if ((end > 0) && (toIntUnsigned(array[end - 1]) < ikey))
+            return -end - 1;
         int low = begin;
         int high = end - 1;
         while (low <= high) {
@@ -202,7 +235,7 @@ public final class Util {
         }
         return -(low + 1);
     }
-
+    
     /**
      * Compute the difference between two sorted lists and write the result to the provided
      * output array
diff --git a/src/main/java/org/roaringbitmap/buffer/BufferUtil.java b/src/main/java/org/roaringbitmap/buffer/BufferUtil.java
index 4749650b..d962faff 100644
--- a/src/main/java/org/roaringbitmap/buffer/BufferUtil.java
+++ b/src/main/java/org/roaringbitmap/buffer/BufferUtil.java
@@ -321,8 +321,54 @@ public final class BufferUtil {
     protected static int toIntUnsigned(short x) {
         return x & 0xFFFF;
     }
+    
+    /**
+     * Look for value k in buffer in the range [begin,end). If the value
+     * is found, return its index. If not, return -(i+1) where i is the
+     * index where the value would be inserted. 
+     * The buffer is assumed to contain sorted values where shorts are
+     * interpreted as unsigned integers.
+     * 
+     * @param array buffer where we search
+     * @param begin first index (inclusive)
+     * @param end last index (exclusive)
+     * @param k value we search for
+     * @return count
+     */
+    public static int unsignedBinarySearch(final ShortBuffer array, final int begin,
+            final int end,  final short k) {
+        return branchlessUnsignedBinarySearch(array,begin,end, k);
+    }
 
-    protected static int unsignedBinarySearch(final ShortBuffer array, final int begin,
+    
+    protected static int branchlessUnsignedBinarySearch(final ShortBuffer array, final int begin,
+            final int end,  final short k) {
+        int ikey = toIntUnsigned(k);
+        // next line accelerates the possibly common case where the value would be inserted at the end
+        if((end>0) && (toIntUnsigned(array.get(end-1)) < ikey)) return - end - 1;
+        int n = end - begin;
+        if(n == 0) return -1;
+        int pos = 0;
+        while (n > 1) {
+            final int half = n >>> 1;
+            n -= half;
+            final int index = pos + half;
+            final int val = array.get(index + begin) & 0xFFFF;
+            final int diff = val - ikey;
+            final int mask = diff >> 31;
+            final int addition = half & mask;
+            pos += addition;
+        }
+   ",Introducing branchless bin .,"""Optimize binary search in Util and BufferUtil classes, and add JMH benchmark for random access performance""","""Optimized binary search in Util and BufferUtil classes with branchless implementation""","Added RandomAccess.java benchmark for RoaringBitmap

Added branchlessUnsignedBinarySearch method to Util.java

Modified unsignedBinarySearch method in Util.java to call branchlessUnsignedBinarySearch

Added branchlessUnsignedBinarySearch method to BufferUtil.java

Modified unsignedBinarySearch method in BufferUtil.java to call branchlessUnsignedBinarySearch

The RandomAccess.java file is a new benchmark for RoaringBitmap, which is a compressed bitmap library. The benchmark tests the performance of RoaringBitmap when performing random access queries on a dataset.

The branchlessUnsignedBinarySearch method was added to Util.java and BufferUtil.java. This method is a branchless implementation of unsigned binary search, which is used to search for an unsigned integer value in a sorted array or buffer. The branchless implementation is faster than the branchy implementation in some cases, as it avoids branch mispredictions.

The unsignedBinarySearch method in Util.java was modified to call the branchlessUnsignedBinarySearch method instead of the branchyUnsignedBinarySearch method. Similarly, the unsignedBinarySearch method in BufferUtil.java was modified to call the branchlessUnsignedBinarySearch method. These changes were made to improve the performance of unsigned binary search in these classes.",Added `RandomAccess` benchmarking for RoaringBitmap and implemented branchless unsigned binary search for `short` and `ShortBuffer`.,Model 1
"diff --git a/README.md b/README.md
index 388d6da6..5af04420 100644
--- a/README.md
+++ b/README.md
@@ -58,7 +58,11 @@ Regarding to hwo to access the server you just started, please refer to the READ
 Almost every server component has a configuration file in JSON format and a default config file is located in resources/config.
 
 This allows all components can be used out of the box but that might not be ideal for you. If you want to change the config, you
-can create a folder in file system and use a system properties to point to that folder for your config.
+can create a folder resources/config in your project and overwrite the default config of each components. One example is the
+security.json in undertow-server-demo project to turn off the JWT token verification.
+
+For offcial deployment, you should copy your config files to a directory in file system and use a system properties to point
+to that folder for your config.
 
 For example, create a folder in /home/steve/config and put all updated config files there. In order to let your server to lookup
 that folder for config, you need to pass in -Dundertow-server-config-dir=/home/steve/config when you start the server. Another way
@@ -73,7 +77,37 @@ endpoints without putting token in the request header. In this case, you need to
 Note that you have to restart your terminal if you add JAVA_TOOL_OPTIONS to .bashrc and restart your IDE from the new terminal
 window.
 
-## 
+## Start Server
+
+### In IDE
+create a Java application that main class is com.networknt.server.Server and working
+directory is your project root folder. You can debug your server just like a single POJO application.
+
+### From Maven
+
+mvn exec:exec
+
+### Copmmand Line
+
+For testing
+```
+java -jar target/demo-0.1.0.jar
+```
+
+For production
+
+```
+setsid java -jar demo-0.1.0.jar < /dev/zero & > /dev/null &
+```
+
+## Stop Server
+
+you can use Ctrl+C to kill the server but for production use the following command
 
+```
+kill -s TERM <pid>
+```
 
+The server has a shutdown hook and the above command allow it to clean up. For example,
+complete in-flight requests and close the database connections etc.
 
diff --git a/server/src/main/java/com/networknt/server/Server.java b/server/src/main/java/com/networknt/server/Server.java
index 496261c4..3e4baabb 100644
--- a/server/src/main/java/com/networknt/server/Server.java
+++ b/server/src/main/java/com/networknt/server/Server.java
@@ -14,7 +14,6 @@ import io.undertow.Handlers;
 import io.undertow.Undertow;
 import io.undertow.UndertowOptions;
 import io.undertow.server.HttpHandler;
-import io.undertow.server.handlers.PathTemplateHandler;
 import io.undertow.util.Headers;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -32,7 +31,6 @@ public class Server {
     static protected boolean shutdownRequested = false;
     static Undertow server = null;
     static String configName = ""server"";
-    public static PathTemplateHandler handler;
 
     public static void main(final String[] args) {
         logger.info(""server starts"");",update readme,"""Update README with server configuration and startup/shutdown instructions""","""Update README.md and Server.java to improve documentation and add instructions for starting and stopping the server""","""Update README with server startup and shutdown instructions, and remove unused imports in Server.java""

This commit includes changes to the README.md file, adding instructions on how to start and stop the server in different environments (IDE, Maven, and command line). It also mentions the creation of a custom configuration directory and how to use it. Additionally, there is a change in the Server.java file where unused imports have been removed.","""Update config instructions in README, add server start/stop procedures, and remove unused PathTemplateHandler in Server class.""",Model 3
"diff --git a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/FieldAccessDescriptor.java b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/FieldAccessDescriptor.java
index ec83d92172..f61f49b2cb 100644
--- a/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/FieldAccessDescriptor.java
+++ b/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/FieldAccessDescriptor.java
@@ -192,6 +192,7 @@ public abstract class FieldAccessDescriptor implements Serializable {
     return union(fields);
   }
 
+  /** Return a descriptor that accesses the specified fields, renaming those fields. */
   public static FieldAccessDescriptor withFieldNamesAs(Map<String, String> fieldNamesAs) {
     List<FieldAccessDescriptor> fields = Lists.newArrayListWithCapacity(fieldNamesAs.size());
     for (Map.Entry<String, String> entry : fieldNamesAs.entrySet()) {
@@ -200,15 +201,29 @@ public abstract class FieldAccessDescriptor implements Serializable {
     return union(fields);
   }
 
+  /**
+   * Return a descriptor that accesses the specified field names as nested subfields of the
+   * baseDescriptor.
+   *
+   * <p>This is only supported when baseDescriptor refers to a single field.
+   */
   public static FieldAccessDescriptor withFieldNames(
       FieldAccessDescriptor baseDescriptor, String... fieldNames) {
     return withFieldNames(baseDescriptor, Arrays.asList(fieldNames));
   }
 
+  /**
+   * Return a descriptor that accesses the specified field names as nested subfields of the
+   * baseDescriptor.
+   *
+   * <p>This is only supported when baseDescriptor refers to a single field.
+   */
   public static FieldAccessDescriptor withFieldNames(
       FieldAccessDescriptor baseDescriptor, Iterable<String> fieldNames) {
     if (baseDescriptor.getFieldsAccessed().isEmpty()
         && baseDescriptor.getNestedFieldsAccessed().isEmpty()) {
+      // If baseDescriptor is empty, this is no different than calling
+      // withFieldNames(Iterable<String>);
       return withFieldNames(fieldNames);
     }
     if (!baseDescriptor.getFieldsAccessed().isEmpty()) {
@@ -226,11 +241,23 @@ public abstract class FieldAccessDescriptor implements Serializable {
     }
   }
 
+  /**
+   * Return a descriptor that accesses the specified field ids as nested subfields of the
+   * baseDescriptor.
+   *
+   * <p>This is only supported when baseDescriptor refers to a single field.
+   */
   public static FieldAccessDescriptor withFieldIds(
       FieldAccessDescriptor baseDescriptor, Integer... fieldIds) {
     return withFieldIds(baseDescriptor, Arrays.asList(fieldIds));
   }
 
+  /**
+   * Return a descriptor that accesses the specified field ids as nested subfields of the
+   * baseDescriptor.
+   *
+   * <p>This is only supported when baseDescriptor refers to a single field.
+   */
   public static FieldAccessDescriptor withFieldIds(
       FieldAccessDescriptor baseDescriptor, Iterable<Integer> fieldIds) {
     if (baseDescriptor.getFieldsAccessed().isEmpty()",add javadoc,"""Added FieldAccessDescriptor methods for accessing nested subfields with field names and IDs""","""Added support for nested field access in FieldAccessDescriptor""","""Add method comments for FieldAccessDescriptor.withFieldNamesAs, FieldAccessDescriptor.withFieldNames, FieldAccessDescriptor.withFieldIds methods in FieldAccessDescriptor.java""",Added documentation and validation to FieldAccessDescriptor methods handling field names and IDs.,Model 1
"diff --git a/sonar-server/src/main/java/org/sonar/server/db/migrations/MassUpdater.java b/sonar-server/src/main/java/org/sonar/server/db/migrations/MassUpdater.java
index 0a603ab3a4a..8ebb52612f6 100644
--- a/sonar-server/src/main/java/org/sonar/server/db/migrations/MassUpdater.java
+++ b/sonar-server/src/main/java/org/sonar/server/db/migrations/MassUpdater.java
@@ -37,7 +37,6 @@ import java.sql.*;
 public class MassUpdater {
 
   private static final Logger LOGGER = LoggerFactory.getLogger(MassUpdater.class);
-  private static final String FAILURE_MESSAGE = ""Fail to migrate data"";
   private static final int GROUP_SIZE = 1000;
   private final Database db;
 
@@ -104,14 +103,10 @@ public class MassUpdater {
       }
 
     } catch (SQLException e) {
-      LOGGER.error(FAILURE_MESSAGE, e);
       SqlUtil.log(LOGGER, e);
-      throw MessageException.of(FAILURE_MESSAGE);
-
+      throw processError(e);
     } catch (Exception e) {
-      LOGGER.error(FAILURE_MESSAGE, e);
-      throw MessageException.of(FAILURE_MESSAGE);
-
+      throw processError(e);
     } finally {
       DbUtils.closeQuietly(writeStatement);
       DbUtils.closeQuietly(writeConnection);
@@ -121,6 +116,12 @@ public class MassUpdater {
     }
   }
 
+  private static MessageException processError(Exception e) {
+    String message = String.format(""Fail to migrate data, error is : %s"", e.getMessage());
+    LOGGER.error(message, e);
+    throw MessageException.of(message);
+  }
+
   @VisibleForTesting
   static String convertSelectSql(String selectSql, Database db){
     String newSelectSql = selectSql;
diff --git a/sonar-server/src/test/java/org/sonar/server/db/migrations/MassUpdaterTest.java b/sonar-server/src/test/java/org/sonar/server/db/migrations/MassUpdaterTest.java
index 208c0d50687..f5aaeb81aed 100644
--- a/sonar-server/src/test/java/org/sonar/server/db/migrations/MassUpdaterTest.java
+++ b/sonar-server/src/test/java/org/sonar/server/db/migrations/MassUpdaterTest.java
@@ -20,25 +20,146 @@
 
 package org.sonar.server.db.migrations;
 
+import org.junit.ClassRule;
 import org.junit.Test;
 import org.junit.runner.RunWith;
-import org.mockito.Mock;
 import org.mockito.runners.MockitoJUnitRunner;
+import org.sonar.api.utils.MessageException;
 import org.sonar.core.persistence.Database;
+import org.sonar.core.persistence.TestDatabase;
 import org.sonar.core.persistence.dialect.Dialect;
 
+import java.sql.PreparedStatement;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+
 import static org.fest.assertions.Assertions.assertThat;
+import static org.fest.assertions.Fail.fail;
 import static org.mockito.Mockito.mock;
 import static org.mockito.Mockito.when;
 
 @RunWith(MockitoJUnitRunner.class)
 public class MassUpdaterTest {
 
-  @Mock
-  Database db;
+  @ClassRule
+  public static TestDatabase db = new TestDatabase().schema(MassUpdaterTest.class, ""schema.sql"");
+
+  static class Row {
+    private Long id;
+  }
+
+  @Test
+  public void execute() throws Exception {
+    db.prepareDbUnit(getClass(), ""migrate_data.xml"");
+
+    new MassUpdater(db.database()).execute(
+      new MassUpdater.InputLoader<Row>() {
+        @Override
+        public String selectSql() {
+          return ""SELECT i.id FROM issues i"";
+        }
+
+        @Override
+        public Row load(ResultSet rs) throws SQLException {
+          Row row = new Row();
+          row.id = SqlUtil.getLong(rs, 1);
+          return row;
+        }
+      },
+      new MassUpdater.InputConverter<Row>() {
+        @Override
+        public String updateSql() {
+          return ""UPDATE issues SET severity=? WHERE id=?"";
+        }
+
+        @Override
+        public boolean convert(Row row, PreparedStatement updateStatement) throws SQLException {
+          updateStatement.setString(1, ""MAJOR"");
+          updateStatement.setLong(2, row.id);
+          return true;
+        }
+      }
+    );
+
+    db.assertDbUnit(getClass(), ""migrate_data_result.xml"", ""issues"");
+  }
+
+  @Test
+  public void fail_on_bad_sql_request() throws Exception {
+    db.prepareDbUnit(getClass(), ""migrate_data.xml"");
+
+    try {
+      new MassUpdater(db.database()).execute(
+        new MassUpdater.InputLoader<Row>() {
+          @Override
+          public String selectSql() {
+            return ""<INVALID QUERY>"";
+          }
+
+          @Override
+          public Row load(ResultSet rs) throws SQLException {
+            return new Row();
+          }
+        },
+        new MassUpdater.InputConverter<Row>() {
+          @Override
+          public String updateSql() {
+            return ""<INVALID QUERY>"";
+          }
+
+          @Override
+          public boolean convert(Row row, PreparedStatement updateStatement) throws SQLException {
+            return true;
+          }
+        }
+      );
+      fail();
+    } catch (Exception e) {
+      assertThat(e).isInstanceOf(MessageException.class);
+    }
+  }
+
+  @Test
+  public void fail_on_unknown_error() throws Exception {
+    db.prepareDbUnit(getClass(), ""migrate_data.xml"");
+
+    try {
+      new MassUpdater(db.database()).execute(
+        new MassUpdater.InputLoader<Row>() {
+          @Override
+          public String selectSql() {
+            return ""SELECT i.id FROM issues i"";
+          }
+
+          @Override
+          public Row load(ResultSet rs) throws SQLException {
+            Row row = new Row();
+            row.id = SqlUtil.getLong(rs, 1);
+            return row;
+          }
+        },
+        new MassUpdater.InputConverter<Row>() {
+          @Override
+          public String updateSql() {
+            throw new RuntimeException(""Unknown error"");
+          }
+
+          @Override
+          public boolean convert(Row row, PreparedStatement updateStatement) throws SQLException {
+            return true;
+          }
+        }
+      );
+      fail();
+    } catch (Exception e) {
+      assertThat(e).isInstanceOf(MessageException.class);
+    }
+  }
 
   @Test
   public void convert_select_sql() throws Exception {
+    Database db = mock(Database.class);
+
     Dialect dialect = mock(Dialect.class);
     when(dialect.getTrueSqlValue()).thenReturn(""true"");
     when(dialect.getFalseSqlValue()).thenReturn(""false"");
diff --git a/sonar-server/src/test/resources/org/sonar/server/db/migrations/MassUpdaterTest/migrate_data.xml b/sonar-server/src/test/resources/org/sonar/server/db/migrations/MassUpdaterTest/migrate_data.xml
new file mode 100644
index 00000000000..5eb657bf6a2
--- /dev/null
+++ b/sonar-server/src/test/resources/org/sonar/server/db/migrations/MassUpdaterTest/migrate_data.xml
@@ -0,0 +1,10 @@
+<dataset>
+
+  <issues ID=""1"" COMPONENT_ID=""11"" ROOT_COMPONENT_ID=""10"" RULE_ID=""20"" SEVERITY=""MINOR"" KEE=""1""
+          ACTION_PLAN_KEY=""[null]"" ASSIGNEE=""[null]"" AUTHOR_LOGIN=""[null]"" CHECKSUM=""ABCDE""
+          EFFORT_TO_FIX=""3.14"" ISSUE_ATTRIBUTES=""[null]"" ISSUE_CLOSE_DATE=""[null]"" ISSUE_CREATION_DATE=""2012-01-05""
+          ISSUE_UPDATE_DATE=""2012-01-05"" LINE=""1234"" MANUAL_SEVERITY=""[false]"" MESSAGE=""the message"" REPORTER=""[null]""
+          RESOLUTION=""[null]"" STATUS=""OPEN"" CREATED_AT=""2012-01-05"" UPDATED_AT=""2012-01-05""
+          TECHNICAL_DEBT=""10""/>
+
+</dataset>
diff --git a/sonar-server/src/test/resources/org/sonar/server/db/migrations/MassUpdaterTest/migrate_data_result.xml b/sonar-server/src/test/resources/org/sonar/server/db/migrations/MassUpdaterTest/migrate_data_result.xml
new file mode 100644
index 00000000000..ec1ac69511f
--- /dev/null
+++ b/sonar-server/src/test/resources/org/sonar/server/db/migrations/MassUpdaterTest/migrate_data_result.xml
@@ -0,0 +1,10 @@
+<dataset>
+
+  <issues ID=""1"" COMPONENT_ID=""11"" ROOT_COMPONENT_ID=""10"" RULE_ID=""20"" SEVERITY=""MAJOR"" KEE=""1""
+          ACTION_PLAN_KEY=""[null]"" ASSIGNEE=""[null]"" AUTHOR_LOGIN=""[null]"" CHECKSUM=""ABCDE""
+          EFFORT_TO_FIX=""3.14"" ISSUE_ATTRIBUTES=""[null]"" ISSUE_CLOSE_DATE=""[null]"" ISSUE_CREATION_DATE=""2012-01-05""
+          ISSUE_UPDATE_DATE=""2012-01-05"" LINE=""1234"" MANUAL_SEVERITY=""[false]"" MESSAGE=""the message"" REPORTER=""[null]""
+          RESOLUTION=""[null]"" STATUS=""OPEN"" CREATED_AT=""2012-01-05"" UPDATED_AT=""2012-01-05""
+          TECHNICAL_DEBT=""10""/>
+
+</dataset>
diff --git a/sonar-server/src/test/resources/org/sonar/server/db/migrations/MassUpdaterTest/schema.sql b/sonar-server/src/test/resources/org/sonar/server/db/migrations/MassUpdaterTest/schema.sql
new file mode 100644
index 00000000000..f3f71cfa229
--- /dev/null
+++ b/sonar-server/src/test/resources/org/sonar/server/db/migrations/MassUpdaterTest/schema.sql
@@ -0,0 +1,28 @@
+-- 4.3
+
+CREATE TABLE ""ISSUES"" (
+  ""ID"" INTEGER NOT NULL GENERATED BY DEFAULT AS IDENTITY (START WITH 1, INCREMENT BY 1),
+  ""KEE"" VARCHAR(50) UNIQUE NOT NULL,
+  ""COMPONENT_ID"" INTEGER NOT NULL,
+  ""ROOT_COMPONENT_ID"" INTEGER,
+  ""RULE_ID"" INTEGER,
+  ""SEVERITY"" VARCHAR(10),
+  ""MANUAL_SEVERITY"" BOOLEAN NOT NULL,
+  ""MESSAGE"" VARCHAR(4000),
+  ""LINE"" INTEGER,
+  ""EFFORT_TO_FIX"" DOUBLE,
+  ""STATUS"" VARCHAR(20),
+  ""RESOLUTION"" VARCHAR(20),
+  ""CHECKSUM"" VARCHAR(1000),
+  ""REPORTER"" VARCHAR(40),
+  ""ASSIGNEE"" VARCHAR(40),
+  ""AUTHOR_LOGIN"" VARCHAR(100),
+  ""ACTION_PLAN_KEY"" VARCHAR(50) NULL,
+  ""ISSUE_ATTRIBUTES"" VARCHAR(4000),
+  ""ISSUE_CREATION_DATE"" TIMESTAMP,
+  ""ISSUE_CLOSE_DATE"" TIMESTAMP,
+  ""ISSUE_UPDATE_DATE"" TIMESTAMP,
+  ""CREATED_AT"" TIMESTAMP,
+  ""UPDATED_AT"" TIMESTAMP,
+  ""TECHNICAL_DEBT"" INTEGER
+);",Add unit test,"""Improve MassUpdater to handle errors and add tests for data migration""",Refactor MassUpdater to handle exceptions in a more centralized and informative way.,"""Refactor MassUpdater to use processError method and add tests""

Explanation:

* The MassUpdater class has been refactored to use a new processError method, which handles logging and throwing a MessageException when an error occurs during data migration.
* Several new tests have been added to the MassUpdaterTest class, including tests for successful data migration, bad SQL requests, and unknown errors.
* Two new XML files have been added to the test resources, containing data for testing data migration and expected results.
* A new schema.sql file has been added to the test resources, containing the schema for the ""ISSUES"" table used in the tests.",Refactor error handling in MassUpdater and add comprehensive tests for SQL migration and error scenarios.,Model 1
"diff --git a/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingSideInputDoFnRunner.java b/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingSideInputDoFnRunner.java
index 508fbaf697..4e4874bf8b 100644
--- a/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingSideInputDoFnRunner.java
+++ b/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/StreamingSideInputDoFnRunner.java
@@ -28,7 +28,6 @@ import com.google.cloud.dataflow.sdk.transforms.windowing.BoundedWindow;
 import com.google.cloud.dataflow.sdk.transforms.windowing.WindowFn;
 import com.google.cloud.dataflow.sdk.util.DoFnInfo;
 import com.google.cloud.dataflow.sdk.util.DoFnRunner;
-import com.google.cloud.dataflow.sdk.util.DoFnRunner.OutputManager;
 import com.google.cloud.dataflow.sdk.util.ExecutionContext.StepContext;
 import com.google.cloud.dataflow.sdk.util.SideInputReader;
 import com.google.cloud.dataflow.sdk.util.UserCodeException;",Remove unused import .,"""Remove unused import of DoFnRunner.OutputManager in StreamingSideInputDoFnRunner""","""Remove unused import: com.google.cloud.dataflow.sdk.util.DoFnRunner.OutputManager""","""Remove unused import com.google.cloud.dataflow.sdk.util.DoFnRunner.OutputManager from StreamingSideInputDoFnRunner.java""",Remove unused import statement for `DoFnRunner.OutputManager` in `StreamingSideInputDoFnRunner.java`.,Model 4
"diff --git a/runtime/compiler/aarch64/codegen/J9AheadOfTimeCompile.cpp b/runtime/compiler/aarch64/codegen/J9AheadOfTimeCompile.cpp
index 113a2b911..2df43dfca 100644
--- a/runtime/compiler/aarch64/codegen/J9AheadOfTimeCompile.cpp
+++ b/runtime/compiler/aarch64/codegen/J9AheadOfTimeCompile.cpp
@@ -1043,25 +1043,6 @@ uint8_t *J9::ARM64::AheadOfTimeCompile::initializeAOTRelocationHeader(TR::Iterat
          }
          break;
 
-      case TR_ValidateStaticField:
-         {
-         *(uintptr_t*)cursor = (uintptr_t)relocation->getTargetAddress(); // Inlined site index
-         cursor += SIZEPOINTER;
-
-         TR::AOTClassInfo *aotCI = (TR::AOTClassInfo*)relocation->getTargetAddress2();
-         *(uintptr_t*)cursor = (uintptr_t) aotCI->_constantPool;
-         cursor += SIZEPOINTER;
-
-         *(uintptr_t*)cursor = (uintptr_t) aotCI->_cpIndex;
-         cursor += SIZEPOINTER;
-
-         void *romClass = (void *)fej9->getPersistentClassPointerFromClassPointer(aotCI->_clazz);
-         uintptr_t romClassOffsetInSharedCache = self()->offsetInSharedCacheFromPointer(sharedCache, romClass);
-         *(uintptr_t *)cursor = romClassOffsetInSharedCache;
-         cursor += SIZEPOINTER;
-         }
-         break;
-
       case TR_ValidateArbitraryClass:
          {
          TR::AOTClassInfo *aotCI = (TR::AOTClassInfo*) relocation->getTargetAddress2();
diff --git a/runtime/compiler/arm/codegen/J9AheadOfTimeCompile.cpp b/runtime/compiler/arm/codegen/J9AheadOfTimeCompile.cpp
index 170fb4b0d..0e372691e 100644
--- a/runtime/compiler/arm/codegen/J9AheadOfTimeCompile.cpp
+++ b/runtime/compiler/arm/codegen/J9AheadOfTimeCompile.cpp
@@ -490,25 +490,6 @@ uint8_t *J9::ARM::AheadOfTimeCompile::initializeAOTRelocationHeader(TR::Iterated
          }
          break;
 
-      case TR_ValidateStaticField:
-         {
-         *(uintptr_t*)cursor = (uintptr_t)relocation->getTargetAddress(); // Inlined site index
-         cursor += SIZEPOINTER;
-
-         TR::AOTClassInfo *aotCI = (TR::AOTClassInfo*)relocation->getTargetAddress2();
-         *(uintptr_t*)cursor = (uintptr_t) aotCI->_constantPool;
-         cursor += SIZEPOINTER;
-
-         *(uintptr_t*)cursor = (uintptr_t) aotCI->_cpIndex;
-         cursor += SIZEPOINTER;
-
-         void *romClass = (void *)fej9->getPersistentClassPointerFromClassPointer(aotCI->_clazz);
-         uintptr_t romClassOffsetInSharedCache = self()->offsetInSharedCacheFromPointer(sharedCache, romClass);
-         *(uintptr_t *)cursor = romClassOffsetInSharedCache;
-         cursor += SIZEPOINTER;
-         }
-         break;
-
       case TR_ValidateArbitraryClass:
          {
          TR::AOTClassInfo *aotCI = (TR::AOTClassInfo*) relocation->getTargetAddress2();
diff --git a/runtime/compiler/codegen/J9AheadOfTimeCompile.cpp b/runtime/compiler/codegen/J9AheadOfTimeCompile.cpp
index 6829c7798..e26754841 100644
--- a/runtime/compiler/codegen/J9AheadOfTimeCompile.cpp
+++ b/runtime/compiler/codegen/J9AheadOfTimeCompile.cpp
@@ -399,6 +399,23 @@ J9::AheadOfTimeCompile::initializeCommonAOTRelocationHeader(TR::IteratedExternal
          }
          break;
 
+      case TR_ValidateStaticField:
+         {
+         TR_RelocationRecordValidateStaticField *vsfRecord = reinterpret_cast<TR_RelocationRecordValidateStaticField *>(reloRecord);
+
+         uintptr_t inlinedSiteIndex = reinterpret_cast<uintptr_t>(relocation->getTargetAddress());
+         TR::AOTClassInfo *aotCI = reinterpret_cast<TR::AOTClassInfo*>(relocation->getTargetAddress2());
+
+         void *romClass = reinterpret_cast<void *>(fej9->getPersistentClassPointerFromClassPointer(aotCI->_clazz));
+         uintptr_t romClassOffsetInSharedCache = self()->offsetInSharedCacheFromPointer(sharedCache, romClass);
+
+         vsfRecord->setInlinedSiteIndex(reloTarget, inlinedSiteIndex);
+         vsfRecord->setConstantPool(reloTarget, reinterpret_cast<uintptr_t>(aotCI->_constantPool));
+         vsfRecord->setCpIndex(reloTarget, aotCI->_cpIndex);
+         vsfRecord->setRomClassOffsetInSharedCache(reloTarget, romClassOffsetInSharedCache);
+         }
+         break;
+
       default:
          return cursor;
       }
@@ -603,6 +620,22 @@ J9::AheadOfTimeCompile::dumpRelocationHeaderData(uint8_t *cursor, bool isVerbose
          }
          break;
 
+      case TR_ValidateStaticField:
+         {
+         TR_RelocationRecordValidateStaticField *vsfRecord = reinterpret_cast<TR_RelocationRecordValidateStaticField *>(reloRecord);
+
+         self()->traceRelocationOffsets(cursor, offsetSize, endOfCurrentRecord, orderedPair);
+         if (isVerbose)
+            {
+            traceMsg(self()->comp(), ""\nValidation Relocation: InlineCallSite index = %d, Constant pool = %x, cpIndex = %d, ROM Class offset = %x"",
+                                       vsfRecord->inlinedSiteIndex(reloTarget),
+                                       vsfRecord->constantPool(reloTarget),
+                                       vsfRecord->cpIndex(reloTarget),
+                                       vsfRecord->romClassOffsetInSharedCache(reloTarget));
+            }
+         }
+         break;
+
       default:
          return cursor;
       }
@@ -1140,7 +1173,6 @@ J9::AheadOfTimeCompile::dumpRelocationData()
                }
             break;
          case TR_ValidateClass:
-         case TR_ValidateStaticField:
             {
             cursor++;        //unused field
             if (is64BitTarget)
diff --git a/runtime/compiler/p/codegen/J9AheadOfTimeCompile.cpp b/runtime/compiler/p/codegen/J9AheadOfTimeCompile.cpp
index 41951e7e1..f66d99813 100644
--- a/runtime/compiler/p/codegen/J9AheadOfTimeCompile.cpp
+++ b/runtime/compiler/p/codegen/J9AheadOfTimeCompile.cpp
@@ -1227,25 +1227,6 @@ uint8_t *J9::Power::AheadOfTimeCompile::initializeAOTRelocationHeader(TR::Iterat
          }
          break;
 
-      case TR_ValidateStaticField:
-         {
-         *(uintptr_t*)cursor = (uintptr_t)relocation->getTargetAddress(); // Inlined site index
-         cursor += SIZEPOINTER;
-
-         TR::AOTClassInfo *aotCI = (TR::AOTClassInfo*)relocation->getTargetAddress2();
-         *(uintptr_t*)cursor = (uintptr_t) aotCI->_constantPool;
-         cursor += SIZEPOINTER;
-
-         *(uintptr_t*)cursor = (uintptr_t) aotCI->_cpIndex;
-         cursor += SIZEPOINTER;
-
-         void *romClass = (void *)fej9->getPersistentClassPointerFromClassPointer(aotCI->_clazz);
-         uintptr_t romClassOffsetInSharedCache = self()->offsetInSharedCacheFromPointer(sharedCache, romClass);
-         *(uintptr_t *)cursor = romClassOffsetInSharedCache;
-         cursor += SIZEPOINTER;
-         }
-         break;
-
       case TR_ValidateArbitraryClass:
          {
          TR::AOTClassInfo *aotCI = (TR::AOTClassInfo*) relocation->getTargetAddress2();
diff --git a/runtime/compiler/x/codegen/J9AheadOfTimeCompile.cpp b/runtime/compiler/x/codegen/J9AheadOfTimeCompile.cpp
index cb3404dab..8b4ae04b4 100644
--- a/runtime/compiler/x/codegen/J9AheadOfTimeCompile.cpp
+++ b/runtime/compiler/x/codegen/J9AheadOfTimeCompile.cpp
@@ -1021,25 +1021,6 @@ uint8_t *J9::X86::AheadOfTimeCompile::initializeAOTRelocationHeader(TR::Iterated
          }
          break;
 
-      case TR_ValidateStaticField:
-         {
-         *(uintptr_t*)cursor = (uintptr_t) relocation->getTargetAddress(); // Inlined site index
-         cursor += SIZEPOINTER;
-
-         TR::AOTClassInfo *aotCI = (TR::AOTClassInfo*)relocation->getTargetAddress2();
-         *(uintptr_t*)cursor = (uintptr_t) aotCI->_constantPool;
-         cursor += SIZEPOINTER;
-
-         *(uintptr_t*)cursor = (uintptr_t) aotCI->_cpIndex;
-         cursor += SIZEPOINTER;
-
-         void *romClass = (void *)fej9->getPersistentClassPointerFromClassPointer(aotCI->_clazz);
-         uintptr_t romClassOffsetInSharedCache = self()->offsetInSharedCacheFromPointer(sharedCache, romClass);
-         *(uintptr_t *)cursor = romClassOffsetInSharedCache;
-         cursor += SIZEPOINTER;
-         }
-         break;
-
       case TR_ValidateArbitraryClass:
          {
          TR::AOTClassInfo *aotCI = (TR::AOTClassInfo*) relocation->getTargetAddress2();
diff --git a/runtime/compiler/z/codegen/J9AheadOfTimeCompile.cpp b/runtime/compiler/z/codegen/J9AheadOfTimeCompile.cpp
index 3d5dd42ea..5eed91f22 100644
--- a/runtime/compiler/z/codegen/J9AheadOfTimeCompile.cpp
+++ b/runtime/compiler/z/codegen/J9AheadOfTimeCompile.cpp
@@ -915,26 +915,6 @@ uint8_t *J9::Z::AheadOfTimeCompile::initializeAOTRelocationHeader(TR::IteratedEx
          }
          break;
 
-      case TR_ValidateStaticField:
-         {
-
-         *(uintptr_t*)cursor = (uintptr_t)relocation->getTargetAddress(); // Inlined site index
-         cursor += SIZEPOINTER;
-
-         TR::AOTClassInfo *aotCI = (TR::AOTClassInfo*)relocation->getTargetAddress2();
-         *(uintptr_t*)cursor = (uintptr_t) aotCI->_constantPool;
-         cursor += SIZEPOINTER;
-
-         *(uintptr_t*)cursor = (uintptr_t) aotCI->_cpIndex;
-         cursor += SIZEPOINTER;
-
-         void *romClass = (void *)fej9->getPersistentClassPointerFromClassPointer(aotCI->_clazz);
-         uintptr_t romClassOffsetInSharedCache = self()->offsetInSharedCacheFromPointer(sharedCache, romClass);
-         *(uintptr_t *)cursor = romClassOffsetInSharedCache;
-         cursor += SIZEPOINTER;
-     ",Consolidate TR_ValidateStaticField .,"""Refactor TR_ValidateStaticField relocation handling to use TR_RelocationRecordValidateStaticField""","The commit message should be:

""Unified handling of TR_ValidateStaticField relocation records across all architectures""

This commit message accurately reflects the changes made in the code, which involve unifying the handling of TR_ValidateStaticField relocation records across all architectures (aarch64, arm, p, x, and z).","""Remove TR_ValidateStaticField case from AOT relocation initialization""

This commit removes the handling of the TR_ValidateStaticField case from the initializeAOTRelocationHeader function in multiple compiler files for different architectures (AArch64, ARM, X86, Z). The code for handling this case was present in each of the files, and it has been removed in its entirety. The code for other cases, such as TR_ValidateClass and TR_ValidateArbitraryClass, remains unchanged.",Refactor `TR_ValidateStaticField` handling in `initializeAOTRelocationHeader` and `dumpRelocationHeaderData` across multiple platforms.,Model 1
"diff --git a/sulong/projects/com.oracle.truffle.llvm.runtime/src/com/oracle/truffle/llvm/runtime/LLVMFunctionDescriptor.java b/sulong/projects/com.oracle.truffle.llvm.runtime/src/com/oracle/truffle/llvm/runtime/LLVMFunctionDescriptor.java
index 15a671407bb..ffcbd9511b8 100644
--- a/sulong/projects/com.oracle.truffle.llvm.runtime/src/com/oracle/truffle/llvm/runtime/LLVMFunctionDescriptor.java
+++ b/sulong/projects/com.oracle.truffle.llvm.runtime/src/com/oracle/truffle/llvm/runtime/LLVMFunctionDescriptor.java
@@ -335,7 +335,6 @@ public final class LLVMFunctionDescriptor implements LLVMSymbol, LLVMInternalTru
     }
 
     public void define(LLVMIntrinsicProvider intrinsicProvider, NodeFactory nodeFactory) {
-        assert intrinsicProvider.isIntrinsified(name);
         Intrinsic intrinsification = new Intrinsic(intrinsicProvider, name, nodeFactory);
         define(intrinsicProvider.getLibrary(), new LLVMFunctionDescriptor.IntrinsicFunction(intrinsification), true);
     }
diff --git a/sulong/projects/com.oracle.truffle.llvm/src/com/oracle/truffle/llvm/Runner.java b/sulong/projects/com.oracle.truffle.llvm/src/com/oracle/truffle/llvm/Runner.java
index ac257d3f2a0..1a5f73f448c 100644
--- a/sulong/projects/com.oracle.truffle.llvm/src/com/oracle/truffle/llvm/Runner.java
+++ b/sulong/projects/com.oracle.truffle.llvm/src/com/oracle/truffle/llvm/Runner.java
@@ -1087,14 +1087,12 @@ final class Runner {
         for (LLVMParserResult parserResult : sulongLibraries) {
             for (LLVMSymbol symbol : parserResult.getRuntime().getFileScope().values()) {
                 if (symbol.isFunction() && intrinsicProvider.isIntrinsified(symbol.getName())) {
-                    if (symbol instanceof LLVMAlias) {
-                        throw new UnsupportedOperationException(""Replacing an alias with an intrinsic is not supported at the moment"");
-                    } else if (symbol instanceof LLVMFunctionDescriptor) {
-                        LLVMFunctionDescriptor function = (LLVMFunctionDescriptor) symbol;
-                        function.define(intrinsicProvider, parserResult.getRuntime().getNodeFactory());
-                    } else {
-                        throw new IllegalStateException(""Unknown symbol: "" + symbol.getClass());
-                    }
+                    /*
+                     * If `symbol` is an alias, `symbol.asFunction()` will follow the alias to the
+                    ",Allow intrinsification of alias functions ( intrinsify both the alias and the target ) .,"""Remove assertion and simplify intrinsic definition for LLVMFunctionDescriptor""","According to the diff, the commit message should be:

""Remove unsupported alias replacement and simplify intrinsic definition logic""

This commit message accurately reflects the changes made in the code, which include removing the unsupported alias replacement logic and simplifying the intrinsic definition logic by removing the checks for `LLVMAlias` and `LLVMFunctionDescriptor` instances.","""Remove unnecessary assertion in LLVMFunctionDescriptor.define() and refactor intrinsic handling in Runner.java""

This commit removes an assertion in the `LLVMFunctionDescriptor.define()` method and refactors the handling of intrinsics in the `Runner.java` class.

In `LLVMFunctionDescriptor.java`, the assertion `assert intrinsicProvider.isIntrinsified(name);` has been removed from the `define()` method. This assertion was used to ensure that the function being defined was an intrinsic, but it has been deemed unnecessary.

In `Runner.java`, the code for handling intrinsics has been refactored. The previous implementation used an `if-else` structure to handle different types of symbols (`LLVMAlias` and `LLVMFunctionDescriptor`). This has been replaced with a comment suggesting that if the symbol is an alias, `symbol.asFunction()` will follow the alias to the actual function. However, the actual implementation has not been added. This change might be part of a larger refactoring or an ongoing work.","""Remove unnecessary assertion and refactor intrinsic function definition handling in Runner class.""",Model 1
"diff --git a/test/org/opensolaris/opengrok/configuration/RuntimeEnvironmentTest.java b/test/org/opensolaris/opengrok/configuration/RuntimeEnvironmentTest.java
index e26b496d929..39ffa1ebd9c 100644
--- a/test/org/opensolaris/opengrok/configuration/RuntimeEnvironmentTest.java
+++ b/test/org/opensolaris/opengrok/configuration/RuntimeEnvironmentTest.java
@@ -81,6 +81,7 @@ public class RuntimeEnvironmentTest {
         String path = f.getCanonicalPath();
         assertTrue(f.delete());
         instance.setDataRoot(path);
+        assertTrue(f.delete());
         assertEquals(path, instance.getDataRootPath());
         assertEquals(path, instance.getDataRootFile().getCanonicalPath());
     }",Fix test to remove temprorary dataroot,"""Fixed RuntimeEnvironmentTest to delete file after setting data root""",Added test for deleting data root directory in RuntimeEnvironmentTest.,"""Added missing file deletion check in RuntimeEnvironmentTest.java""

This commit adds a line of code that checks if a file has been successfully deleted in the RuntimeEnvironmentTest.java file. This is to ensure that the file is properly removed before proceeding with the test case. The specific line of code added is:

`assertTrue(f.delete());`

This line checks if the `delete()` method on the `File` object `f` returns `true`, indicating that the file was successfully deleted. If the file was not successfully deleted, the `assertTrue()` method will throw an `AssertionError`, causing the test case to fail. This helps catch any issues with file deletion during the test.",Add redundant file delete check in RuntimeEnvironmentTest.,Model 1
"diff --git a/plugins/streaming/impls/jms/src/main/java/org/pentaho/di/trans/step/jms/JmsProducerMeta.java b/plugins/streaming/impls/jms/src/main/java/org/pentaho/di/trans/step/jms/JmsProducerMeta.java
index 5dc0f03364..cdf838897e 100644
--- a/plugins/streaming/impls/jms/src/main/java/org/pentaho/di/trans/step/jms/JmsProducerMeta.java
+++ b/plugins/streaming/impls/jms/src/main/java/org/pentaho/di/trans/step/jms/JmsProducerMeta.java
@@ -103,8 +103,8 @@ public class JmsProducerMeta extends BaseSerializingMeta implements StepMetaInte
   }
 
   public void setPropertyValuesByName( Map<String, String> propertyValuesByName ) {
-    this.propertyNames = conf( propertyValuesByName ).keys();
-    this.propertyValues = conf( propertyValuesByName ).vals();
+    this.propertyNames = new ArrayList<>( propertyValuesByName.keySet() );
+    this.propertyValues = new ArrayList<>( propertyValuesByName.values() );
   }
 
   public Map<String, String> getPropertyValuesByName() {",Removing sorting of JmsProducer properties ( <issue_id> ),"""Fixed JmsProducerMeta to correctly initialize propertyNames and propertyValues in setPropertyValuesByName method""","""Improve propertyValuesByName handling in JmsProducerMeta""","""Refactor JmsProducerMeta to use ArrayList for propertyNames and propertyValues in setPropertyValuesByName method""

Explanation: The change is in the method `setPropertyValuesByName` of the class `JmsProducerMeta`. The previous implementation used the `keys()` and `vals()` methods of a `conf` object to set the `propertyNames` and `propertyValues` respectively. Now, it uses `ArrayList` to store the keySet and values of the `propertyValuesByName` Map. This is a refactoring change that likely aims to improve performance or readability of the code.","""Fix method to set property names and values using ArrayList in JmsProducerMeta class""",Model 2
"diff --git a/maven-builder-support/pom.xml b/maven-builder-support/pom.xml
new file mode 100644
index 000000000..e70a34a50
--- /dev/null
+++ b/maven-builder-support/pom.xml
@@ -0,0 +1,49 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+
+<!--
+Licensed to the Apache Software Foundation (ASF) under one
+or more contributor license agreements.  See the NOTICE file
+distributed with this work for additional information
+regarding copyright ownership.  The ASF licenses this file
+to you under the Apache License, Version 2.0 (the
+""License""); you may not use this file except in compliance
+with the License.  You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing,
+software distributed under the License is distributed on an
+""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+KIND, either express or implied.  See the License for the
+specific language governing permissions and limitations
+under the License.
+-->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+  <modelVersion>4.0.0</modelVersion>
+
+  <parent>
+    <groupId>org.apache.maven</groupId>
+    <artifactId>maven</artifactId>
+    <version>3.2.6-SNAPSHOT</version>
+  </parent>
+
+  <artifactId>maven-builder-support</artifactId>
+
+  <name>Maven Settings</name>
+  <description>Maven Builder Support</description>
+
+  <scm><!-- remove when git scm url format can accept artifact-id at the end, as automatically inherited -->
+    <connection>scm:git:https://git-wip-us.apache.org/repos/asf/maven.git</connection>
+    <developerConnection>scm:git:https://git-wip-us.apache.org/repos/asf/maven.git</developerConnection>
+    <tag>HEAD</tag>
+  </scm>
+
+  <dependencies>
+    <dependency>
+      <groupId>org.codehaus.plexus</groupId>
+      <artifactId>plexus-utils</artifactId>
+    </dependency>
+  </dependencies>
+
+</project>
diff --git a/maven-builder-support/src/main/java/org/apache/maven/building/FileSource.java b/maven-builder-support/src/main/java/org/apache/maven/building/FileSource.java
new file mode 100644
index 000000000..b201ee685
--- /dev/null
+++ b/maven-builder-support/src/main/java/org/apache/maven/building/FileSource.java
@@ -0,0 +1,79 @@
+package org.apache.maven.building;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.IOException;
+import java.io.InputStream;
+
+/**
+ * Wraps an ordinary {@link File} as a source.
+ *
+ * @author Benjamin Bentmann
+ */
+public class FileSource
+    implements Source
+{
+    private final File file;
+
+    /**
+     * Creates a new source backed by the specified file.
+     *
+     * @param file The file, must not be {@code null}.
+     */
+    public FileSource( File file )
+    {
+        if ( file == null )
+        {
+            throw new IllegalArgumentException( ""no POM file specified"" );
+        }
+        this.file = file.getAbsoluteFile();
+    }
+
+    @Override
+    public InputStream getInputStream()
+        throws IOException
+    {
+        return new FileInputStream( file );
+    }
+
+    @Override
+    public String getLocation()
+    {
+        return file.getPath();
+    }
+
+    /**
+     * Gets the file of this source.
+     *
+     * @return The underlying file, never {@code null}.
+     */
+    public File getFile()
+    {
+        return file;
+    }
+
+    @Override
+    public String toString()
+    {
+        return getLocation();
+    }
+}
diff --git a/maven-builder-support/src/main/java/org/apache/maven/building/Source.java b/maven-builder-support/src/main/java/org/apache/maven/building/Source.java
new file mode 100644
index 000000000..1f7510ba7
--- /dev/null
+++ b/maven-builder-support/src/main/java/org/apache/maven/building/Source.java
@@ -0,0 +1,49 @@
+package org.apache.maven.building;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+import java.io.IOException;
+import java.io.InputStream;
+
+/**
+ * Provides access to the contents of a source independently of the backing store (e.g. file system, database, memory).
+ *
+ * @author Benjamin Bentmann
+ */
+public interface Source
+{
+
+    /**
+     * Gets a byte stream to the source contents. Closing the returned stream is the responsibility of the caller.
+     *
+     * @return A byte stream to the source contents, never {@code null}.
+     */
+    InputStream getInputStream()
+        throws IOException;
+
+    /**
+     * Provides a user-friendly hint about the location of the source. This could be a local file path, a URI or just an
+     * empty string. The intention is to assist users during error reporting.
+     *
+     * @return A user-friendly hint about the location of the source, never {@code null}.
+     */
+    String getLocation();
+
+}
diff --git a/maven-builder-support/src/main/java/org/apache/maven/building/StringSource.java b/maven-builder-support/src/main/java/org/apache/maven/building/StringSource.java
new file mode 100644
index 000000000..f9d87c0ba
--- /dev/null
+++ b/maven-builder-support/src/main/java/org/apache/maven/building/StringSource.java
@@ -0,0 +1,90 @@
+package org.apache.maven.building;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+import java.io.ByteArrayInputStream;
+import java.io.IOException;
+import java.io.InputStream;
+
+/**
+ * Wraps an ordinary {@link CharSequence} as a source.
+ *
+ * @author Benjamin Bentmann
+ */
+public class StringSource
+    implements Source
+{
+
+    private String content;
+
+    private String location;
+
+    /**
+     * Creates a new source backed by the specified string.
+     *
+     * @param content The String representation, may be empty or {@code null}.
+     */
+    public StringSource( CharSequence content )
+    {
+        this( content, null );
+    }
+
+    /**
+     * Creates a new source backed by the specified string.
+     *
+     * @param content The String representation, may be empty or {@code null}.
+     * @param location The location to report for this use, may be {@code null}.
+     */
+    public StringSource( CharSequence content, String location )
+    {
+        this.content = ( content != null ) ? content.toString() : """";
+        this.location = ( location != null ) ? location : ""(memory)"";
+    }
+
+    @Override
+    public InputStream getInputStream()
+        throws IOException
+    {
+        return new ByteArrayInputStream( content.getBytes( ""UTF-8"" ) );
+    }
+
+    @Override
+    public String getLocation()
+    {
+        return location;
+    }
+
+    /**
+     * Gets the content of this source.
+     *
+     * @return The underlying character stream, never {@code null}.
+     */
+    public String getContent()
+    {
+        return content;
+    }
+
+    @Override
+    public String toString()
+    {
+        return getLocation();
+    }
+
+}
diff --git a/maven-builder-support/src/main/java/org/apache/maven/building/UrlSource.java b/maven-builder-support/src/main/java/org/apache/maven/building/UrlSource.java
new file mode 100644
index 000000000..7a6e9b09b
--- /dev/null
+++ b/maven-builder-support/src/main/java/org/apache/maven/building/UrlSource.java
@@ -0,0 +1,80 @@
+package org.apache.maven.building;
+
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.net.URL;
+
+/**
+ * Wraps an ordinary {@link URL} as a source.
+ *
+ * @author Benjamin Bentmann
+ */
+public class UrlSource
+    implements Source
+{
+
+    private URL url;
+
+    /**
+     * Creates a new source backed by the specified URL.
+     *
+     * @param url The file, must not be {@code null}.
+     */
+    public UrlSource( URL url )
+    {
+        if ( url == null )
+        {
+            throw new IllegalArgumentException( ""no POM URL specified"" );
+        }
+        this.url = url;
+    }
+
+    @Override
+    public InputStream getInputStream()
+        throws IOException
+    {
+        return url.openStream();
+    }
+
+    @Override
+    public String getLocation()
+    {
+        return url.toString();
+    }
+
+    /**
+     * Gets the URL of this source.
+     *
+     * @return The underlying URL, never {@code null}.
+     */
+    public URL getUrl()
+    {
+        return url;
+    }
+
+    @Override
+    public String toString()
+    {
+        return getLocation();
+    }
+
+}
diff --git a/maven-model-builder/pom.xml b/maven-model-builder/pom.xml
index 8f29f5997..738f64fa7 100644
--- a/maven-model-builder/pom.xml
+++ b/maven-model-builder/pom.xml
@@ -47,6 +47,10 @@
       <groupId>org.apache.maven</groupId>
       <artifactId>maven-model</artifactId>
     </dependency>
+    <dependency>
+      <groupId>org.apache.maven</groupId>
+      <artifactId>maven-builder-support</artifactId>
+    </dependency>
 
     <dependency>
       <groupId>org.eclipse.sisu</groupId>
diff --git a/maven-model-builder/src/main/java/org/apache/maven/model/building/FileModelSource.java b/maven-model-builder/src/main/java/org/apache/maven/model/building/FileModelSource.java
index fcc85a81a..a2e114176 100644
--- a/maven-model-builder/src/main/java/org/apache/maven/model/building/FileModelSource.java
+++ b/maven-model-builder/src/main/java/org/apache/maven/model/building/FileModelSource.java
@@ -20,20 +20,17 @@
  */
 
 import java.io.File;
-import java.io.FileInputStream;
-import java.io.IOException;
-import java.io.InputStream;
 import java.net.URI;
 
+import org.apache.maven.building.FileSource;
+
 /**
  * Wraps an ordinary {@link File} as a model source.
  *
  * @author Benjamin Bentmann
  */
-public class FileModelSource
-    implements ModelSource2
+public class FileModelSource extends FileSource implements ModelSource2
 {
-    private final File pomFile;
 
     /**
      * Creates a new model source backed by the specified file.
@@ -42,45 +39,27 @@ public class FileModelSource
      */
     public FileModelSource( File pomFile )
     {
-        if ( pomFile == null )
-        {
-            throw new IllegalArgumentException( ""no POM file specified"" );
-        }
-        this.pomFile = pomFile.getAbsoluteFile();
-    }
-
-    public InputStream getInputStream()
-        throws IOException
-    {
-        return new FileInputStream( pomFile );
-    }
-
-    public String getLocation()
-    {
-        return pomFile.getPath();
+        super( pomFile );
     }
-
+    
     /**
-     * Gets the POM file of this model source.
-     *
-     * @return The underlying POM file, never {@code null}.
+     * 
+     * @return the file of this source
+     * 
+     * @deprecated instead use {@link #getFile()}
      */
+    @Deprecated
     public File getPomFile()
     {
-        return pomFile;
+        return getFile();
     }
-
+    
     @Override
-    public String toString()
-    {
-        return getLocation();
-    }
-
     public ModelSource2 getRelatedSource( String relPath )
     {
         relPath = relPath.replace( '\\', File.separatorChar ).replace( '/', File.separatorChar );
 
-        File relatedPom = new File( pomFile.getParentFile(), relPath );
+        File relatedPom = new File( getFile().getParentFile(), relPath );
 
         if ( relatedPom.isDirectory() )
         {
@@ -96,8 +75,9 @@ public ModelSource2 getRelatedSource( String relPath )
         return null;
     }
 
+    @Override
     public URI getLocationURI()
     {
-        return pomFile.toURI();
+        return getFile().toURI();
     }
 }
diff --git a/maven-model-builder/src/main/java/org/apache/maven/model/building/ModelSource.java b/maven-model-builder/src/main/java/org/apache/maven/model/building/ModelSource.java
index dc648bfb3..acb4651f8 100644
--- a/maven-model-builder/src/main/java/org/apache/maven/model/building/ModelSource.java
+++ b/maven-model-builder/src/main/java/org/apache/maven/model/building/ModelSource.java
@@ -1,5 +1,7 @@
 package org.apache.maven.model.building;
 
+import org.apache.maven.building.Source;
+
 /*
  * Licensed to the Apache Software Foundation (ASF) under one
  * or more contributor license agreements.  See the NOTICE file
@@ -19,8 +21,6 @@
  * under the License.
  */
 
-import java.io.IOException;
-import java.io.InputStream;
 
 /**
  * Provides access to the contents of a POM independently of the backing store (e.g. file system, database, memory).
@@ -30,24 +30,10 @@
  *
  * @author Benjamin Bentmann
  * @see ModelSource2
+ * @deprecated instead use {@link Source}
  */
-public interface ModelSource
+@Deprecated
+public interface ModelSource extends org.apache.maven.building.Source
 {
 
-    /**
-     * Gets a byte stream to the POM contents. Closing the returned stream is the responsibility of the caller.
-     *
-     * @return A byte stream to the POM contents, never {@code null}.
-     */
-    InputStream getInputStream()
-        throws IOException;
-
-    /**
-     * Provides a user-friendly hint about the location of the POM. This could be a local file path, a URI or just an
-     * empty string. The intention is to assist users during error reporting.
-     *
-     * @return A user-friendly hint about the location of the POM, never {@code null}.
-     */
-    String getLocation();
-
 }
diff --git a/maven-model-builder/src/main/java/org/apache/maven/model/building/StringModelSource.java b/maven-model-builder/src/main/java/org/apache/maven/model/building/StringModelSource.java
index edc4d3142..1d8406f4c 100644
--- a/maven-model-builder/src/main/java/org/apache/maven/model/building/StringModelSource.java
+++ b/maven-model-builder/src/main/java/org/apache/maven/model/building/StringModelSource.java
@@ -1,5 +1,7 @@
 package org.apache.maven.model.building;
 
+import org.apache.maven.building.StringSource;
+
 /*
  * Licensed to the Apache Software Foundation (ASF) under one
  * or more contributor license agreements.  See the NOTICE file
@@ -19,23 +21,19 @@
  * under the License.
  */
 
-import java.io.ByteArrayInputStream;
-import java.io.IOException;
-import java.io.InputStream;
 
 /**
  * Wraps an ordinary {@link CharSequence} as a model source.
  *
  * @author Benjamin Bentmann
+ * 
+ * @deprecated instead use {@link StringSource}
  */
-public class StringModelSource
+@Deprecated
+public class StringModelSource extends org.apache.maven.building.StringSource
     implements ModelSource
 {
 
-    private String pom;
-
-    private String location;
-
     /**
      * Creates a new model source backed by the specified string.
      *
@@ -54,35 +52,6 @@ public StringModelSource( CharSequence pom )
      */
     public StringModelSource( CharSequence pom, String location )
     {
-        this.pom = ( pom != null ) ? pom.toString() : """";
-        this.location = ( location != null ) ? location : ""(memory)"";
-    }
-
-    public InputStream getInputStream()
-        throws IOException
-    {
-        return new ByteArrayInputStream( pom.getBytes( ""UTF-8"" ) );
+        super( pom, location );
     }
-
-    public String getLocation()
-    {
-        return location;
-    }
-
-    /**
-     * Gets the character sequence of this model source.
-     *
-     * @return The underlying character stream, never {@code null}.
-     */
-    public String getModel()
-    {
-        return pom;
-    }
-
-    @Override
-    public String toString()
-    {
-        return getLocation();
-    }
-
 }
diff --git a/maven-model-builder/src/main/java/org/apache/maven/model/building/UrlModelSource.java b/maven-model-builder/src/main/java/org/apache/maven/model/building/UrlModelSource.java
index 07058b3a0..6ed25ed12 100644
--- a/maven-model-builder/src/main/java/org/apache/maven/model/building/UrlModelSource.java
+++ b/maven-model-builder/src/main/java/org/apache/maven/model/building/UrlModelSource.java
@@ -19,21 +19,21 @@
  * under the License.
  */
 
-import java.io.IOException;
-import java.io.InputStream;
 import java.net.URL;
 
+import org.apache.maven.building.UrlSource;
+
 /**
  * Wraps an ordinary {@link URL} as a model source.
  *
  * @author Benjamin Bentmann
+ * 
+ * @deprecated instead use {@link UrlSource}
  */
-public class UrlModelSource
+@Deprecated
+public class UrlModelSource extends org.apache.maven.building.UrlSource
     implements ModelSource
 {
-
-    private URL pomUrl;
-
     /**
      * Creates a new model source backed by the specified URL.
      *
@@ -41,38 +41,6 @@ public class UrlModelSource
      */
     public UrlModelSource( URL pomUrl )
     {
-        if ( pomUrl == null )
-        {
-            throw new IllegalArgumentException( ""no POM URL specified"" );
-        }
-        this.pomUrl = pomUrl;
-    }
-
-    public InputStream getInputStream()
-        throws IOException
-    {
-        return pomUrl.openStream();
+        super( pomUrl );
     }
-
-    public String getLocation()
-    {
-        return pomUrl.toString();
-    }
-
-    /**
-     * Gets the POM URL of this model source.
-     *
-     * @return The underlying POM URL, never {@code null}.
-     */
-    public URL getPomUrl()
-    {
-        return pomUrl;
-    }
-
-    @Override
-    public String toString()
-    {
-        return getLocation();
-    }
-
 }
diff --git a/maven-settings-builder/pom.xml b/maven-settings-builder/pom.xml
index 14cdeb31d..2d109f4cb 100644
--- a/maven-settings-builder/pom.xml
+++ b/maven-settings-builder/pom.xml
@@ -40,6 +40,11 @@ under the License.
   </scm>
 
   <dependencies>
+    <dependency>
+      <groupId>org.apache.maven</groupId>
+      <artifactId>maven-builder-support</artifactId>
+    </dependency>
+  
     <dependency>
       <groupId>org.codehaus.plexus</groupId>
       <artifactId>plexus-utils</artifactId>
diff --git a/maven-settings-builder/src/main/java/org/apache/maven/settings/building/FileSettingsSource.java b/maven-settings-builder/src/main/java/org/apache/maven/settings/building/FileSettingsSource.java
index a821e0883..3c2d32acb 100644
--- a/maven-settings-builder/src/main/java/org/apache/maven/settings/building/FileSettingsSource.java
+++ b/maven-settings-builder/src/main/java/org/apache/maven/settings/building/FileSettingsSource.java
@@ -20,21 +20,21 @@
  */
 
 import java.io.File;
-import java.io.FileInputStream;
-import java.io.IOException;
-import java.io.InputStream;
+
+import org.apache.maven.building.FileSource;
 
 /**
  * Wraps an ordinary {@link File} as a settings source.
  *
  * @author Benjamin Bentmann
+ * 
+ * @deprecated instead use {@link FileSource}
  */
-public class FileSettingsSource
+@Deprecated
+public class FileSettingsSource extends FileSource
     implements SettingsSource
 {
 
-    private File settingsFile;
-
     /**
      * Creates a new settings source backed by the specified file.
      *
@@ -42,38 +42,18 @@ public class FileSettingsSource
      */
     public FileSettingsSource( File settingsFile )
     {
-        if ( settingsFile == null )
-        {
-            throw new IllegalArgumentException( ""no settings file specified"" );
-        }
-        this.settingsFile = settingsFile.getAbsoluteFile();
-    }
-
-    public InputStream getInputStream()
-        throws IOException
-    {
-        return new FileInputStream( settingsFile );
-    }
-
-    public String getLocation()
-    {
-        return settingsFile.getPath();
+        super( settingsFile );
     }
 
     /**
      * Gets the settings file of this model source.
      *
      * @return The underlying settings file, never {@code null}.
+     * @deprecated instead use {@link #getFile()}
      */
+    @Deprecated
     public File getSettingsFile()
     {
-        return settingsFile;
-    }
-
-    @Override
-    public String toString()
-    {
-        return getLocation();
+        return getFile();
     }
-
 }
diff --git a/maven-settings-builder/src/main/java/org/apache/maven/settings/building/SettingsSource.java b/maven-settings-builder/src/main/java/org/apache/maven/settings/building/SettingsSource.java
index 3297ab43a..413a3570a 100644
--- a/maven-settings-builder/src/main/java/org/apache/maven/settings/building/SettingsSource.java
+++ b/maven-settings-builder/src/main/java/org/apache/maven/settings/building/SettingsSource.java
@@ -19,32 +19,17 @@
  * under the License.
  */
 
-import java.io.IOException;
-import java.io.InputStream;
+import org.apache.maven.building.Source;
 
 /**
  * Provides access to the contents of settings independently of the backing store (e.g. file system, database, memory).
  *
  * @author Benjamin Bentmann
+ * 
+ * @deprecated instead use {@link Source}
  */
-public interface SettingsSource
+@Deprecated
+public interface SettingsSource extends Source
 {
 
-    /**
-     * Gets a byte stream to the settings contents. Closing the returned stream is the responsibility of the caller.
-     * Note that each invocation of this method returns a new/fresh stream which represents the entire contents.
-     *
-     * @return A byte stream to the settings contents, never {@code null}.
-     */
-    InputStream getInputStream()
-        throws IOException;
-
-    /**
-     * Provides a user-friendly hint about the location of the settings. This could be a local file path, a URI or just
-     * an empty string. The intention is to assist users during error reporting.
-     *
-     * @return A user-friendly hint about the location of the settings, never {@code null}.
-     */
-    String getLocation();
-
 }
diff --git a/maven-settings-builder/src/main/java/org/apache/maven/settings/building/StringSettingsSource.java b/maven-settings-builder/src/main/java/org/apache/maven/settings/building/StringSettingsSource.java
index 5136f1bb2..dbe975806 100644
--- a/maven-settings-builder/src/main/java/org/apache/maven/settings/building/StringSettingsSource.java
+++ b/maven-settings-builder/src/main/java/org/apache/maven/settings/building/StringSettingsSource.java
@@ -19,23 +19,20 @@
  * under the License.
  */
 
-import java.io.ByteArrayInputStream;
-import java.io.IOException;
-import java.io.InputStream;
+import org.apache.maven.building.StringSource;
 
 /**
  * Wraps an ordinary {@link CharSequence} as a settings source.
  *
  * @author Benjamin Bentmann
+ * 
+ * @deprecated instead use {@link StringSource}
  */
-public class StringSettingsSource
+@Deprecated
+public class StringSettingsSource extends StringSource
     implements SettingsSource
 {
 
-    private String settings;
-
-    private String location;
-
     /**
      * Creates a new settings source backed by the specified string.
      *
@@ -54,35 +51,19 @@ public StringSettingsSource( CharSequence settings )
      */
     public StringSettingsSource( CharSequence settings, String location )
     {
-        this.settings = ( settings != null ) ? settings.toString() : """";
-        this.location = ( location != null ) ? location : ""(memory)"";
-    }
-
-    public InputStream getInputStream()
-        throws IOException
-    {
-        return new ByteArrayInputStream( settings.getBytes( ""UTF-8"" ) );
-    }
-
-    public String getLocation()
-    {
-        return location;
+        super( settings, location );
     }
 
     /**
      * Gets the character sequence of this settings source.
      *
      * @return The underlying character stream, never {@code null}.
+     * @deprecated instead use {@link #getContent()}
      */
+ ",Add module maven - builder - support .,"""Extracted source abstractions into maven-builder-support module""",Refactor Maven builder support to use a unified Source interface and remove deprecated classes and methods.,"This commit introduces a new Maven module named ""maven-builder-support"" that provides an abstraction for accessing the contents of a source independently of the backing store. The module contains three implementations of the new ""Source"" interface: ""FileSource"", ""StringSource"", and ""UrlSource"".

Additionally, the existing ""maven-model-builder"" and ""maven-settings-builder"" modules have been updated to use the new ""Source"" abstraction instead of their own implementations. Some classes have been deprecated in favor of the new ones provided by ""maven-builder-support"".

Here is a summary of the changes:

* New module ""maven-builder-support"" added with ""FileSource"", ""StringSource"", and ""UrlSource"" implementations of the new ""Source"" interface.
* ""maven-model-builder"" and ""maven-settings-builder"" modules updated to use the new ""Source"" abstraction.
* ""FileModelSource"", ""StringModelSource"", and ""UrlModelSource"" classes in ""maven-model-builder"" deprecated in favor of ""FileSource"", ""StringSource"", and ""UrlSource"", respectively.
* ""FileSettingsSource"" and ""StringSettingsSource"" classes in ""maven-settings-builder"" deprecated in favor of ""FileSource"" and ""StringSource"", respectively.

The commit message could be:

""Add maven-builder-support module with Source abstraction and update maven-model-builder and maven-settings-builder to use it; deprecate old implementations""","""Added new maven-builder-support module, updated relevant classes to use it, and marked old classes as deprecated.""",Model 2
"diff --git a/streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java b/streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java
index deb5e8927a..4238490a8b 100644
--- a/streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java
+++ b/streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java
@@ -227,7 +227,7 @@ public class StreamsConfig extends AbstractConfig {
 
     /** {@code rocksdb.config.setter} */
     public static final String ROCKSDB_CONFIG_SETTER_CLASS_CONFIG = ""rocksdb.config.setter"";
-    private static final String ROCKSDB_CONFIG_SETTER_CLASS_DOC = ""A Rocks DB config setter class that implements the <code>RocksDBConfigSetter</code> interface"";
+    private static final String ROCKSDB_CONFIG_SETTER_CLASS_DOC = ""A Rocks DB config setter class or class name that implements the <code>RocksDBConfigSetter</code> interface"";
 
     /** {@code security.protocol} */
     public static final String SECURITY_PROTOCOL_CONFIG = CommonClientConfigs.SECURITY_PROTOCOL_CONFIG;
diff --git a/streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java b/streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java
index a01de775ca..7a0b6ee5ee 100644
--- a/streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java
+++ b/streams/src/main/java/org/apache/kafka/streams/state/internals/RocksDBStore.java
@@ -16,6 +16,7 @@
  */
 package org.apache.kafka.streams.state.internals;
 
+import org.apache.kafka.common.config.ConfigDef;
 import org.apache.kafka.common.serialization.Serde;
 import org.apache.kafka.common.utils.Bytes;
 import org.apache.kafka.common.utils.Utils;
@@ -142,7 +143,12 @@ public class RocksDBStore<K, V> implements KeyValueStore<K, V> {
         fOptions.setWaitForFlush(true);
 
         final Map<String, Object> configs = context.appConfigs();
-        final Class<RocksDBConfigSetter> configSetterClass = (Class<RocksDBConfigSetter>) configs.get(StreamsConfig.ROCKSDB_CONFIG_SETTER_CLASS_CONFIG);
+        final Object configSetterValue = configs.get(StreamsConfig.ROCKSDB_CONFIG_SETTER_CLASS_CONFIG);
+        final Class<RocksDBConfigSetter> configSetterClass = (Class<RocksDBConfigSetter>) ConfigDef.parseType(
+                StreamsConfig.ROCKSDB_CONFIG_SETTER_CLASS_CONFIG,
+                configSetterValue,
+                ConfigDef.Type.CLASS);
+
         if (configSetterClass != null) {
             final RocksDBConfigSetter configSetter = Utils.newInstance(configSetterClass);
             configSetter.setConfig(name, options, configs);
diff --git a/streams/src/test/java/org/apache/kafka/streams/state/internals/RocksDBStoreTest.java b/streams/src/test/java/org/apache/kafka/streams/state/internals/RocksDBStoreTest.java
new file mode 100644
index 0000000000..c43a39a0a9
--- /dev/null
+++ b/streams/src/test/java/org/apache/kafka/streams/state/internals/RocksDBStoreTest.java
@@ -0,0 +1,103 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.kafka.streams.state.internals;
+
+import static org.junit.Assert.assertTrue;
+
+import java.io.File;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.apache.kafka.common.serialization.Serde;
+import org.apache.kafka.common.serialization.Serdes;
+import org.apache.kafka.streams.StreamsConfig;
+import org.apache.kafka.streams.processor.internals.RecordCollector;
+import org.apache.kafka.streams.state.RocksDBConfigSetter;
+import org.apache.kafka.test.MockProcessorContext;
+import org.apache.kafka.test.TestUtils;
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+import org.rocksdb.Options;
+
+public class RocksDBStoreTest {
+    private final File tempDir = TestUtils.tempDirectory();
+
+    private RocksDBStore<String, String> subject;
+
+    @Before
+    public void setUp() throws Exception {
+        subject = new RocksDBStore<>(""test"", Serdes.String(), Serdes.String());
+    }
+
+    @After
+    public void tearDown() throws Exception {
+        subject.close();
+    }
+
+    @Test
+    public void canSpecifyConfigSetterAsClass() throws Exception {
+        final Map<String, Object> configs = new HashMap<>();
+        configs.put(StreamsConfig.ROCKSDB_CONFIG_SETTER_CLASS_CONFIG, MockRocksDbConfigSetter.class);
+        MockRocksDbConfigSetter.called = false;
+        subject.openDB(new ConfigurableProcessorContext(tempDir, Serdes.String(), Serdes.String(),
+                null, null, configs));
+
+        assertTrue(MockRocksDbConfigSetter.called);
+    }
+
+    @Test
+    public void canSpecifyConfigSetterAsString() throws Exception {
+        final Map<String, Object> configs = new HashMap<>();
+        configs.put(StreamsConfig.ROCKSDB_CONFIG_SETTER_CLASS_CONFIG, MockRocksDbConfigSetter.class.getName());
+        MockRocksDbConfigSetter.called = false;
+        subject.openDB(new ConfigurableProcessorContext(tempDir, Serdes.String(), Serdes.String(),
+                null, null, configs));
+
+        assertTrue(MockRocksDbConfigSetter.called);
+    }
+
+
+    public static class MockRocksDbConfigSetter implements RocksDBConfigSetter {
+        static boolean called;
+
+        @Override
+        public void setConfig(final String storeName, final Options options, final Map<String, Object> configs) {
+            called = true;
+        }
+    }
+
+
+    private static class ConfigurableProcessorContext extends MockProcessorContext {
+        final Map<String, Object> configs;
+
+        ConfigurableProcessorContext(final File stateDir,
+                                     final Serde<?> keySerde,
+                                     final Serde<?> valSerde,
+                                     final RecordCollector collector,
+                                     final ThreadCache cache,
+                                     final Map<String, Object> configs) {
+            super(stateDir, keySerde, valSerde, collector, cache);
+            this.configs = configs;
+        }
+
+        @Override
+        public Map<String, Object> appConfigs() {
+            return configs;
+        }
+    }
+}",Allow rocksdb . config . setter to be specified as a String or Class instance .,"""Allow specifying RocksDB config setter as class name or instance""","""Allow specifying RocksDB config setter as a class name""

This commit message accurately reflects the changes made in the code, which now allows the RocksDB config setter to be specified as a class name in addition to a class.","""Update StreamsConfig to accept class name for ROCKSDB_CONFIG_SETTER_CLASS_CONFIG and add RocksDBStoreTest""

Here are the changes made in the commit:

1. In `StreamsConfig.java`, the documentation string for `ROCKSDB_CONFIG_SETTER_CLASS_CONFIG` has been updated to include class names as well as classes that implement the `RocksDBConfigSetter` interface.

```java
-    private static final String ROCKSDB_CONFIG_SETTER_CLASS_DOC = ""A Rocks DB config setter class that implements the <code>RocksDBConfigSetter</code> interface"";
+    private static final String ROCKSDB_CONFIG_SETTER_CLASS_DOC = ""A Rocks DB config setter class or class name that implements the <code>RocksDBConfigSetter</code> interface"";
```

2. In `RocksDBStore.java`, the code for getting the `ROCKSDB_CONFIG_SETTER_CLASS_CONFIG` has been updated to use `ConfigDef.parseType()` to parse the class or class name.

```java
-        final Class<RocksDBConfigSetter> configSetterClass = (Class<RocksDBConfigSetter>) configs.get(StreamsConfig.ROCKSDB_CONFIG_SETTER_CLASS_CONFIG);
+        final Object configSetterValue = configs.get(StreamsConfig.ROCKSDB_CONFIG_SETTER_CLASS_CONFIG);
+        final Class<RocksDBConfigSetter> configSetterClass = (Class<RocksDBConfigSetter>) ConfigDef.parseType(
+                StreamsConfig.ROCKSDB_CONFIG_SETTER_CLASS_CONFIG,
+                configSetterValue,
+                ConfigDef.Type.CLASS);
```

3. A new test file `RocksDBStoreTest.java` has been added to test the `RocksDBStore` class. The test checks if the `RocksDBConfigSetter` can be specified as a class or a string.","Allow specifying RocksDB config setter as either a class or a class name, and added relevant tests.",Model 3
"diff --git a/src/com/ichi2/anki/StudyOptions.java b/src/com/ichi2/anki/StudyOptions.java
index c643511711..1f9fe46cc2 100644
--- a/src/com/ichi2/anki/StudyOptions.java
+++ b/src/com/ichi2/anki/StudyOptions.java
@@ -1689,7 +1689,6 @@ public class StudyOptions extends Activity {
     private void reloadDeck() {
     	Deck deck = AnkiDroidApp.deck(); 
     	if (deck != null){
-		allTags = new String[0];
     		deck.closeDeck();
     		AnkiDroidApp.setDeck(null);
     	}",remove unnecessary line,"""Remove unused allTags initialization in reloadDeck method""","""Remove unnecessary initialization of allTags when reloading deck""

However, a more conventional commit message would be:

""Cleanup: Remove unnecessary allTags initialization in reloadDeck""

This commit message is more concise and follows the conventional format of including a brief description of the change.","""Remove allTags initialization in reloadDeck() method in StudyOptions.java""",Removed unnecessary array initialization for `allTags` in `reloadDeck` method of `StudyOptions.java`.,Model 2
"diff --git a/community/neo4j/src/main/java/org/neo4j/graphdb/facade/GraphDatabaseFacadeFactory.java b/community/neo4j/src/main/java/org/neo4j/graphdb/facade/GraphDatabaseFacadeFactory.java
index 567f00b8617..76437db077d 100644
--- a/community/neo4j/src/main/java/org/neo4j/graphdb/facade/GraphDatabaseFacadeFactory.java
+++ b/community/neo4j/src/main/java/org/neo4j/graphdb/facade/GraphDatabaseFacadeFactory.java
@@ -166,13 +166,14 @@ public class GraphDatabaseFacadeFactory
 
         Procedures procedures = setupProcedures( platform, edition, graphDatabaseFacade );
         platform.dependencies.satisfyDependency( new NonTransactionalDbmsOperations( procedures ) );
-        edition.setupSecurityModule( platform, procedures );
 
         Logger msgLog = platform.logging.getInternalLog( getClass() ).infoLogger();
         DatabaseManager databaseManager = edition.createDatabaseManager( graphDatabaseFacade, platform, edition, procedures, msgLog );
         platform.life.add( databaseManager );
         platform.dependencies.satisfyDependency( databaseManager );
 
+        edition.setupSecurityModule( platform, procedures );
+
         platform.life.add( platform.globalKernelExtensions );
         platform.life.add( createBoltServer( platform, edition, databaseManager ) );
         platform.life.add( new VmPauseMonitorComponent( config, platform.logging.getInternalLog( VmPauseMonitorComponent.class ), platform.jobScheduler ) );",Create databaseManager before setup security module,"""Move setupSecurityModule call after databaseManager creation""","""Readded setup of security module in GraphDatabaseFacadeFactory""","""Move setupSecurityModule call after creating DatabaseManager""

Explanation: The change moves the `edition.setupSecurityModule( platform, procedures );` call from before the creation of the `DatabaseManager` to after it. This means that the security module setup will now happen after the `DatabaseManager` has been created and added to the `platform.life` cycle.",Reordered setup of the security module in GraphDatabaseFacadeFactory for better initialization sequence.,Model 2
"diff --git a/README.md b/README.md
index 6e350f9..e79326a 100644
--- a/README.md
+++ b/README.md
@@ -16,12 +16,10 @@ Just add the dependency to your maven project:
 <dependency>
   <groupId>com.vdurmont<groupId>
   <artifactId>emoji-java<artifactId>
-  <version>1.0</version>
+  <version>1.0.0</version>
 </dependency>
 ```
 
-**The library is currently being published to the maven central repository. It may take a few days before the maven dependency is available.**
-
 You can also download the project, build it with `mvn clean install` and add the generated jar to your buildpath.
 
 ## How to use it?",Updating readme after publication on maven central,"""Update Maven dependency version and remove publishing notice in README""","Here's a short commit message based on the provided diff:

`Bump emoji-java version to 1.0.0`

This commit message accurately reflects the change made in the diff, which is updating the version of the emoji-java library from 1.0 to 1.0.0.","It seems like you're updating a README.md file for a project named ""emoji-java"". The changes you've made include:

1. Updating the version number from `1.0` to `1.0.0` in the Maven dependency section.
2. Removing a note about the library being published to the Maven central repository.

The commit message could be something like: ""Update README.md: Bump version to 1.0.0 and remove temporary note about Maven Central publication.""",Update README: correct Maven dependency version and remove outdated publication note.,Model 3
"diff --git a/core/src/main/java/bisq/core/trade/protocol/BuyerAsMakerProtocol.java b/core/src/main/java/bisq/core/trade/protocol/BuyerAsMakerProtocol.java
index ec5d554793..19dde182b7 100644
--- a/core/src/main/java/bisq/core/trade/protocol/BuyerAsMakerProtocol.java
+++ b/core/src/main/java/bisq/core/trade/protocol/BuyerAsMakerProtocol.java
@@ -212,6 +212,10 @@ public class BuyerAsMakerProtocol extends TradeProtocol implements BuyerProtocol
     // User clicked the ""bank transfer started"" button
     @Override
     public void onFiatPaymentStarted(ResultHandler resultHandler, ErrorMessageHandler errorMessageHandler) {
+        if (wasDisputed(errorMessageHandler)) {
+            return;
+        }
+
         if (trade.isDepositConfirmed() && !trade.isFiatSent()) {
             buyerAsMakerTrade.setState(Trade.State.BUYER_CONFIRMED_IN_UI_FIAT_PAYMENT_INITIATED);
             TradeTaskRunner taskRunner = new TradeTaskRunner(buyerAsMakerTrade,
diff --git a/core/src/main/java/bisq/core/trade/protocol/BuyerAsTakerProtocol.java b/core/src/main/java/bisq/core/trade/protocol/BuyerAsTakerProtocol.java
index 6665c001ec..5e4c17d256 100644
--- a/core/src/main/java/bisq/core/trade/protocol/BuyerAsTakerProtocol.java
+++ b/core/src/main/java/bisq/core/trade/protocol/BuyerAsTakerProtocol.java
@@ -237,6 +237,10 @@ public class BuyerAsTakerProtocol extends TradeProtocol implements BuyerProtocol
     // User clicked the ""bank transfer started"" button
     @Override
     public void onFiatPaymentStarted(ResultHandler resultHandler, ErrorMessageHandler errorMessageHandler) {
+        if (wasDisputed(errorMessageHandler)) {
+            return;
+        }
+
         if (!trade.isFiatSent()) {
             buyerAsTakerTrade.setState(Trade.State.BUYER_CONFIRMED_IN_UI_FIAT_PAYMENT_INITIATED);
 
diff --git a/core/src/main/java/bisq/core/trade/protocol/SellerAsMakerProtocol.java b/core/src/main/java/bisq/core/trade/protocol/SellerAsMakerProtocol.java
index 3a5ae4df9b..c7620fccf8 100644
--- a/core/src/main/java/bisq/core/trade/protocol/SellerAsMakerProtocol.java
+++ b/core/src/main/java/bisq/core/trade/protocol/SellerAsMakerProtocol.java
@@ -204,6 +204,10 @@ public class SellerAsMakerProtocol extends TradeProtocol implements SellerProtoc
     // User clicked the ""bank transfer received"" button, so we release the funds for payout
     @Override
     public void onFiatPaymentReceived(ResultHandler resultHandler, ErrorMessageHandler errorMessageHandler) {
+        if (wasDisputed(errorMessageHandler)) {
+            return;
+        }
+
         if (trade.getPayoutTx() == null) {
             sellerAsMakerTrade.setState(Trade.State.SELLER_CONFIRMED_IN_UI_FIAT_PAYMENT_RECEIPT);
             TradeTaskRunner taskRunner = new TradeTaskRunner(sellerAsMakerTrade,
diff --git a/core/src/main/java/bisq/core/trade/protocol/SellerAsTakerProtocol.java b/core/src/main/java/bisq/core/trade/protocol/SellerAsTakerProtocol.java
index fd42d66b7c..6f2f9815c1 100644
--- a/core/src/main/java/bisq/core/trade/protocol/SellerAsTakerProtocol.java
+++ b/core/src/main/java/bisq/core/trade/protocol/SellerAsTakerProtocol.java
@@ -196,6 +196,10 @@ public class SellerAsTakerProtocol extends TradeProtocol implements SellerProtoc
     // User clicked the ""bank transfer received"" button, so we release the funds for payout
     @Override
     public void onFiatPaymentReceived(ResultHandler resultHandler, ErrorMessageHandler errorMessageHandler) {
+        if (wasDisputed(errorMessageHandler)) {
+            return;
+        }
+
         if (trade.getPayoutTx() == null) {
             sellerAsTakerTrade.setState(Trade.State.SELLER_CONFIRMED_IN_UI_FIAT_PAYMENT_RECEIPT);
             TradeTaskRunner taskRunner = new TradeTaskRunner(sellerAsTakerTrade,
diff --git a/core/src/main/java/bisq/core/trade/protocol/TradeProtocol.java b/core/src/main/java/bisq/core/trade/protocol/TradeProtocol.java
index 4cf78045db..6c3d29b5d8 100644
--- a/core/src/main/java/bisq/core/trade/protocol/TradeProtocol.java
+++ b/core/src/main/java/bisq/core/trade/protocol/TradeProtocol.java
@@ -345,6 +345,16 @@ public abstract class TradeProtocol {
         cleanup();
     }
 
+    protected boolean wasDisputed(ErrorMessageHandler errorMessageHandler) {
+        if (trade.getDisputeState() != Trade.DisputeState.NO_DISPUTE) {
+            String msg = ""Dispute have been opened once. We do not allow anymore to confirm payment by button click."";
+            log.error(msg);
+            errorMessageHandler.handleErrorMessage(msg);
+            return true;
+        }
+        return false;
+    }
+
     private void sendAckMessage(@Nullable TradeMessage tradeMessage, boolean result, @Nullable String errorMessage) {
         // We complete at initial protocol setup with the setup listener tasks.
         // Other cases are if we start from an UI event the task runner (payment started, confirmed).
diff --git a/desktop/src/main/java/bisq/desktop/main/portfolio/pendingtrades/PendingTradesDataModel.java b/desktop/src/main/java/bisq/desktop/main/portfolio/pendingtrades/PendingTradesDataModel.java
index fb03b413f8..6d1a288f11 100644
--- a/desktop/src/main/java/bisq/desktop/main/portfolio/pendingtrades/PendingTradesDataModel.java
+++ b/desktop/src/main/java/bisq/desktop/main/portfolio/pendingtrades/PendingTradesDataModel.java
@@ -185,7 +185,7 @@ public class PendingTradesDataModel extends ActivatableDataModel {
     }
 
     public void onPaymentStarted(ResultHandler resultHandler, ErrorMessageHandler errorMessageHandler) {
-        final Trade trade = getTrade();
+        Trade trade = getTrade();
         checkNotNull(trade, ""trade must not be null"");
         checkArgument(trade instanceof BuyerTrade, ""Check failed: trade instanceof BuyerTrade"");
         ((BuyerTrade) trade).onFiatPaymentStarted(resultHandler, errorMessageHandler);",Add check if trade have been dispute to protocol classes,"""Prevent payment confirmation if a dispute has been opened""","""Prevent payment confirmation when a dispute has been opened""","""Added check for disputed trades before confirming fiat payment in BuyerAsMakerProtocol, BuyerAsTakerProtocol, SellerAsMakerProtocol, and SellerAsTakerProtocol. Also added a new method wasDisputed in TradeProtocol. Updated PendingTradesDataModel.""

Explanation:

* In BuyerAsMakerProtocol, BuyerAsTakerProtocol, SellerAsMakerProtocol, and SellerAsTakerProtocol, a new check has been added using the method wasDisputed before confirming fiat payment. If the trade has been disputed, the method will return and no further action will be taken.
* The method wasDisputed has been added to TradeProtocol. It checks if the trade's dispute state is not NO_DISPUTE, and if so, logs an error message and returns true. Otherwise, it returns false.
* In PendingTradesDataModel, the type of the trade variable in the onPaymentStarted method has been changed from final to non-final. This change is not directly related to the main functionality but is necessary due to a change in the checkNotNull method's behavior in more recent versions of the Google Guava library.",Added checks to prevent confirming payment if a trade dispute has occurred.,Model 3
"diff --git a/server/src/main/resources/update-checker/killbill-server-update-list.properties b/server/src/main/resources/update-checker/killbill-server-update-list.properties
index ebfb4e062a..f5aa67e83e 100644
--- a/server/src/main/resources/update-checker/killbill-server-update-list.properties
+++ b/server/src/main/resources/update-checker/killbill-server-update-list.properties
@@ -1,71 +1,81 @@
 ## Top level keys
 # general.notice = This notice should rarely, if ever, be used as everyone will see it
 
-## 0.8.7 -- latest release
-0.8.7.updates           =
-0.8.7.notices           = This is the latest GA release.
+## 0.8.9 -- latest release
+0.8.9.updates           =
+0.8.9.notices           = This is the latest GA release.
+0.8.9.release-notes     = http://kill-bill.org
+
+## 0.8.8
+0.8.8.updates           = 0.8.9
+0.8.8.notices           = We recommend upgrading to 0.8.9, our latest GA release.
+0.8.8.release-notes     = http://kill-bill.org
+
+## 0.8.7
+0.8.7.updates           = 0.8.9
+0.8.7.notices           = We recommend upgrading to 0.8.9, our latest GA release.
 0.8.7.release-notes     = http://kill-bill.org
 
 ## 0.8.6
-0.8.6.updates           = 0.8.7
-0.8.6.notices           = We recommend upgrading to 0.8.7, our latest GA release.
+0.8.6.updates           = 0.8.9
+0.8.6.notices           = We recommend upgrading to 0.8.9, our latest GA release.
 0.8.6.release-notes     = http://kill-bill.org
 
 ## 0.8.5
-0.8.5.updates           = 0.8.7
-0.8.5.notices           = We recommend upgrading to 0.8.7, our latest GA release.
+0.8.5.updates           = 0.8.9
+0.8.5.notices           = We recommend upgrading to 0.8.9, our latest GA release.
 0.8.5.release-notes     = http://kill-bill.org
 
 ## 0.8.4
-0.8.4.updates           = 0.8.7
-0.8.4.notices           = We recommend upgrading to 0.8.7, our latest GA release.
+0.8.4.updates           = 0.8.9
+0.8.4.notices           = We recommend upgrading to 0.8.9, our latest GA release.
 0.8.4.release-notes     = http://kill-bill.org
 
 ## 0.8.3
-0.8.3.updates           = 0.8.7
-0.8.3.notices           = We recommend upgrading to 0.8.7, our latest GA release.
+0.8.3.updates           = 0.8.9
+0.8.3.notices           = We recommend upgrading to 0.8.9, our latest GA release.
 0.8.3.release-notes     = http://kill-bill.org
 
 ## 0.8.2
-0.8.2.updates           = 0.8.7
-0.8.2.notices           = We recommend upgrading to 0.8.7, our latest GA release.
+0.8.2.updates           = 0.8.9
+0.8.2.notices           = We recommend upgrading to 0.8.9, our latest GA release.
 0.8.2.release-notes     = http://kill-bill.org
 
 ## 0.8.1
-0.8.1.updates           = 0.8.7
-0.8.1.notices           = We recommend upgrading to 0.8.7, our latest GA release.
+0.8.1.updates           = 0.8.9
+0.8.1.notices           = We recommend upgrading to 0.8.9, our latest GA release.
 0.8.1.release-notes     = http://kill-bill.org
 
 ## 0.8.0
-0.8.0.updates           = 0.8.7
-0.8.0.notices           = We recommend upgrading to 0.8.7, our latest GA release.
+0.8.0.updates           = 0.8.9
+0.8.0.notices           = We recommend upgrading to 0.8.9, our latest GA release.
 0.8.0.release-notes     = http://kill-bill.org
 
 ### 0.7.x series ###
 
 ## 0.7.2
 0.7.2.updates           =
-0.7.2.notices           = We recommend upgrading to 0.8.7, our latest GA release.
+0.7.2.notices           = We recommend upgrading to 0.8.9, our latest GA release.
 0.7.2.release-notes     = http://kill-bill.org
 
 ## 0.7.1
 0.7.1.updates           = 0.7.2
-0.7.1.notices           = We recommend upgrading to 0.8.7, our latest GA release.
+0.7.1.notices           = We recommend upgrading to 0.8.9, our latest GA release.
 0.7.1.release-notes     = http://kill-bill.org
 
 ## 0.7.0
 0.7.0.updates           = 0.7.2
-0.7.0.notices           = We recommend upgrading to 0.8.7, our latest GA release.
+0.7.0.notices           = We recommend upgrading to 0.8.9, our latest GA release.
 0.7.0.release-notes     = http://kill-bill.org
 
 ### 0.6.x series ###
 
 ## 0.6.17
 0.6.17.updates           =
-0.6.17.notices           = We recommend upgrading to 0.8.7, our latest GA release.
+0.6.17.notices           = We recommend upgrading to 0.8.9, our latest GA release.
 0.6.17.release-notes     = http://kill-bill.org
 
 ## 0.6.16
 0.6.16.updates           = 0.6.17
-0.6.16.notices           = We recommend upgrading to 0.8.7, our latest GA release.
+0.6.16.notices           = We recommend upgrading to 0.8.9, our latest GA release.
 0.6.16.release-notes     = http://kill-bill.org",update killbill - server - update - list . properties for release .,"""Update killbill-server-update-list.properties for 0.8.9 release""","""Update latest release to 0.8.9 and recommend upgrades from previous versions.""","The diff you provided shows that the `killbill-server-update-list.properties` file was updated to include new entries for versions 0.8.9 and 0.8.8, and that the `notices` and `updates` properties for several other versions were modified to recommend upgrading to 0.8.9, the latest GA release.

Here is a possible commit message for this change:

Update killbill-server-update-list.properties to recommend upgrading to 0.8.9

* Added entries for versions 0.8.9 and 0.8.8
* Updated notices and updates properties for versions 0.8.7 through 0.6.16 to recommend upgrading to 0.8.9, the latest GA release.",Update killbill-server-update-list.properties for version 0.8.9 and recommend upgrading to latest GA release.,Model 4
"diff --git a/enterprise/users/src/test/java/io/crate/auth/AuthenticationIntegrationTest.java b/enterprise/users/src/test/java/io/crate/auth/AuthenticationIntegrationTest.java
index 616040ceb3..377c4f4e48 100644
--- a/enterprise/users/src/test/java/io/crate/auth/AuthenticationIntegrationTest.java
+++ b/enterprise/users/src/test/java/io/crate/auth/AuthenticationIntegrationTest.java
@@ -19,7 +19,6 @@
 package io.crate.auth;
 
 import io.crate.integrationtests.SQLTransportIntegrationTest;
-import io.crate.protocols.postgres.PGErrorStatus;
 import io.crate.testing.UseJdbc;
 import io.netty.handler.codec.http.HttpHeaderNames;
 import org.apache.http.client.methods.CloseableHttpResponse;
@@ -39,11 +38,9 @@ import java.sql.SQLException;
 import java.util.Locale;
 import java.util.Properties;
 
-import static io.crate.protocols.postgres.PGErrorStatus.INTERNAL_ERROR;
 import static io.crate.protocols.postgres.PGErrorStatus.INVALID_AUTHORIZATION_SPECIFICATION;
 import static io.crate.testing.Asserts.assertThrows;
 import static io.crate.testing.SQLErrorMatcher.isPGError;
-import static io.crate.testing.SQLErrorMatcher.isSQLError;
 import static org.hamcrest.Matchers.containsString;
 import static org.hamcrest.Matchers.is;
 import static org.hamcrest.Matchers.notNullValue;
diff --git a/libs/dex/src/test/java/io/crate/data/AsyncFlatMapBatchIteratorTest.java b/libs/dex/src/test/java/io/crate/data/AsyncFlatMapBatchIteratorTest.java
index a2bc74643c..e589cc4df1 100644
--- a/libs/dex/src/test/java/io/crate/data/AsyncFlatMapBatchIteratorTest.java
+++ b/libs/dex/src/test/java/io/crate/data/AsyncFlatMapBatchIteratorTest.java
@@ -26,13 +26,11 @@ import static org.hamcrest.Matchers.contains;
 import static org.junit.Assert.assertThat;
 
 import java.util.Arrays;
-import java.util.Iterator;
 import java.util.List;
 import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
 import java.util.concurrent.TimeUnit;
-import java.util.function.Function;
 import java.util.stream.Collectors;
 
 import org.junit.Test;
diff --git a/libs/sql-parser/src/test/java/io/crate/sql/tree/JoinUsingTests.java b/libs/sql-parser/src/test/java/io/crate/sql/tree/JoinUsingTests.java
index 75abac79a0..308f1a29e8 100644
--- a/libs/sql-parser/src/test/java/io/crate/sql/tree/JoinUsingTests.java
+++ b/libs/sql-parser/src/test/java/io/crate/sql/tree/JoinUsingTests.java
@@ -27,7 +27,6 @@ import static org.junit.Assert.assertTrue;
 
 import java.util.ArrayList;
 import java.util.List;
-import java.util.concurrent.ThreadLocalRandom;
 
 public class JoinUsingTests {
 
diff --git a/plugins/azure-discovery/src/test/java/io/crate/azure/AzureSimpleTests.java b/plugins/azure-discovery/src/test/java/io/crate/azure/AzureSimpleTests.java
index 842af70a5d..9b946132a0 100644
--- a/plugins/azure-discovery/src/test/java/io/crate/azure/AzureSimpleTests.java
+++ b/plugins/azure-discovery/src/test/java/io/crate/azure/AzureSimpleTests.java
@@ -31,7 +31,6 @@ import org.junit.Test;
 import java.io.IOException;
 import java.util.Arrays;
 import java.util.Collection;
-import java.util.Collections;
 
 import static org.hamcrest.Matchers.notNullValue;
 
diff --git a/server/src/main/java/io/crate/execution/dsl/phases/NodeOperationTree.java b/server/src/main/java/io/crate/execution/dsl/phases/NodeOperationTree.java
index 7f9c512302..fe13169ab0 100644
--- a/server/src/main/java/io/crate/execution/dsl/phases/NodeOperationTree.java
+++ b/server/src/main/java/io/crate/execution/dsl/phases/NodeOperationTree.java
@@ -22,8 +22,6 @@
 
 package io.crate.execution.dsl.phases;
 
-import io.crate.execution.dsl.phases.ExecutionPhase;
-import io.crate.execution.dsl.phases.NodeOperation;
 
 import java.util.Collection;
 
diff --git a/server/src/main/java/io/crate/expression/reference/GatheringRefResolver.java b/server/src/main/java/io/crate/expression/reference/GatheringRefResolver.java
index f6b529595d..358ce76fc2 100644
--- a/server/src/main/java/io/crate/expression/reference/GatheringRefResolver.java
+++ b/server/src/main/java/io/crate/expression/reference/GatheringRefResolver.java
@@ -24,7 +24,6 @@ package io.crate.expression.reference;
 
 import io.crate.data.Input;
 import io.crate.metadata.Reference;
-import io.crate.expression.reference.ReferenceResolver;
 
 import java.util.function.Consumer;
 
diff --git a/server/src/main/java/org/elasticsearch/cluster/coordination/PendingClusterStateStats.java b/server/src/main/java/org/elasticsearch/cluster/coordination/PendingClusterStateStats.java
index e8f0fc2630..afef402951 100644
--- a/server/src/main/java/org/elasticsearch/cluster/coordination/PendingClusterStateStats.java
+++ b/server/src/main/java/org/elasticsearch/cluster/coordination/PendingClusterStateStats.java
@@ -22,7 +22,6 @@ package org.elasticsearch.cluster.coordination;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.io.stream.Writeable;
-import org.elasticsearch.common.xcontent.ToXContent.Params;
 import org.elasticsearch.common.xcontent.ToXContentFragment;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
diff --git a/server/src/main/java/org/elasticsearch/cluster/routing/allocation/RerouteExplanation.java b/server/src/main/java/org/elasticsearch/cluster/routing/allocation/RerouteExplanation.java
index 761096907d..bf0819cdf8 100644
--- a/server/src/main/java/org/elasticsearch/cluster/routing/allocation/RerouteExplanation.java
+++ b/server/src/main/java/org/elasticsearch/cluster/routing/allocation/RerouteExplanation.java
@@ -23,7 +23,6 @@ import org.elasticsearch.cluster.routing.allocation.command.AllocationCommand;
 import org.elasticsearch.cluster.routing.allocation.decider.Decision;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.xcontent.ToXContent.Params;
 import org.elasticsearch.common.xcontent.ToXContentObject;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
diff --git a/server/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingExplanations.java b/server/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingExplanations.java
index fe97b52429..728759df42 100644
--- a/server/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingExplanations.java
+++ b/server/src/main/java/org/elasticsearch/cluster/routing/allocation/RoutingExplanations.java
@@ -22,7 +22,6 @@ package org.elasticsearch.cluster.routing.allocation;
 import org.elasticsearch.cluster.routing.allocation.decider.Decision;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
-import org.elasticsearch.common.xcontent.ToXContent.Params;
 import org.elasticsearch.common.xcontent.ToXContentFragment;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 
diff --git a/server/src/main/java/org/elasticsearch/cluster/service/MasterService.java b/server/src/main/java/org/elasticsearch/cluster/service/MasterService.java
index aea3022eba..053cd979a9 100644
--- a/server/src/main/java/org/elasticsearch/cluster/service/MasterService.java
+++ b/server/src/main/java/org/elasticsearch/cluster/service/MasterService.java
@@ -68,7 +68,6 @@ import org.elasticsearch.threadpool.ThreadPool;
 
 import io.crate.common.collections.Lists2;
 import io.crate.common.unit.TimeValue;
-import static org.elasticsearch.common.util.concurrent.EsExecutors.daemonThreadFactory;
 
 public class MasterService extends AbstractLifecycleComponent {
 
diff --git a/server/src/main/java/org/elasticsearch/index/cache/query/DisabledQueryCache.java b/server/src/main/java/org/elasticsearch/index/cache/query/DisabledQueryCache.java
index df5158b6d7..d7c610dcc6 100644
--- a/server/src/main/java/org/elasticsearch/index/cache/query/DisabledQueryCache.java
+++ b/server/src/main/java/org/elasticsearch/index/cache/query/DisabledQueryCache.java
@@ -23,7 +23,6 @@ import org.apache.lucene.search.QueryCachingPolicy;
 import org.apache.lucene.search.Weight;
 import org.elasticsearch.index.AbstractIndexComponent;
 import org.elasticsearch.index.IndexSettings;
-import org.elasticsearch.index.cache.query.QueryCache;
 
 public class DisabledQueryCache extends AbstractIndexComponent implements QueryCache {
 
diff --git a/server/src/main/java/org/elasticsearch/index/cache/query/IndexQueryCache.java b/server/src/main/java/org/elasticsearch/index/cache/query/IndexQueryCache.java
index 77a32a6789..0f5597cc9c 100644
--- a/server/src/main/java/org/elasticsearch/index/cache/query/IndexQueryCache.java
+++ b/server/src/main/java/org/elasticsearch/index/cache/query/IndexQueryCache.java
@@ -24,7 +24,6 @@ import org.apache.lucene.search.Weight;
 import org.elasticsearch.ElasticsearchException;
 import org.elasticsearch.index.AbstractIndexComponent;
 import org.elasticsearch.index.IndexSettings;
-import org.elasticsearch.index.cache.query.QueryCache;
 import org.elasticsearch.indices.IndicesQueryCache;
 
 /**
diff --git a/server/src/main/java/org/elasticsearch/index/seqno/RetentionLease.java b/server/src/main/java/org/elasticsearch/index/seqno/RetentionLease.java
index c0fcd119c9..60d3b5971d 100644
--- a/server/src/main/java/org/elasticsearch/index/seqno/RetentionLease.java
+++ b/server/src/main/java/org/elasticsearch/index/seqno/RetentionLease.java
@@ -28,7 +28,6 @@ import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.io.stream.Writeable;
 import org.elasticsearch.common.xcontent.ConstructingObjectParser;
 import org.elasticsearch.common.xcontent.ToXContentObject;
-import org.elasticsearch.common.xcontent.ToXContent.Params;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
 
diff --git a/server/src/main/java/org/elasticsearch/snapshots/SnapshotId.java b/server/src/main/java/org/elasticsearch/snapshots/SnapshotId.java
index b80dfd94d7..3fb5ca8c93 100644
--- a/server/src/main/java/org/elasticsearch/snapshots/SnapshotId.java
+++ b/server/src/main/java/org/elasticsearch/snapshots/SnapshotId.java
@@ -22,7 +22,6 @@ package org.elasticsearch.snapshots;
 import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.io.stream.Writeable;
-import org.elasticsearch.common.xcontent.ToXContent.Params;
 import org.elasticsearch.common.xcontent.ToXContentObject;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentParser;
diff --git a/server/src/test/java/io/crate/analyze/CreateAlterTableStatementAnalyzerTest.java b/server/src/test/java/io/crate/analyze/CreateAlterTableStatementAnalyzerTest.java
index 38264575aa..d014ff9837 100644
--- a/server/src/test/java/io/crate/analyze/CreateAlterTableStatementAnalyzerTest.java
+++ b/server/src/test/java/io/crate/analyze/CreateAlterTableStatementAnalyzerTest.java
@@ -59,7 +59,6 @@ import org.elasticsearch.index.IndexSettings;
 import org.elasticsearch.index.mapper.MapperService;
 import org.elasticsearch.test.ClusterServiceUtils;
 import org.hamcrest.Matchers;
-import org.junit.Assert;
 import org.junit.Before;
 import org.junit.Test;
 import org.junit.jupiter.api.Assertions;
diff --git a/server/src/test/java/io/crate/analyze/DropViewAnalyzerTest.java b/server/src/test/java/io/crate/analyze/DropViewAnalyzerTest.java
index 438011d329..23b7c3e438 100644
--- a/server/src/test/java/io/crate/analyze/DropViewAnalyzerTest.java
+++ b/server/src/test/java/io/crate/analyze/DropViewAnalyzerTest.java
@@ -27,7 +27,6 @@ import io.crate.test.integration.CrateDummyClusterServiceUnitTest;
 import io.crate.testing.SQLExecutor;
 import org.junit.Test;
 
-import static org.hamcrest.Matchers.contains;
 import static org.hamcrest.Matchers.empty;
 import static org.hamcrest.Matchers.is;
 
diff --git a/server/src/test/java/io/crate/analyze/SubSelectAnalyzerTest.java b/server/src/test/java/io/crate/analyze/SubSelectAnalyzerTest.java
index 7abd6ae806..1003565625 100644
--- a/server/src/test/java/io/crate/analyze/SubSelectAnalyzerTest.java
+++ b/server/src/test/java/io/crate/analyze/SubSelectAnalyzerTest.java
@@ -44,7 +44,6 @@ import static io.crate.testing.SymbolMatchers.isFunction;
 import static io.crate.testing.SymbolMatchers.isLiteral;
 import static io.crate.testing.SymbolMatchers.isReference;
 import static io.crate.testing.TestingHelpers.isSQL;
-import static io.crate.testing.TestingHelpers.printedTable;
 import static org.hamcrest.Matchers.contains;
 import static org.hamcrest.Matchers.instanceOf;
 import static org.hamcrest.Matchers.is;
diff --git a/server/src/test/java/io/crate/analyze/expressions/ExpressionAnalyzerTest.java b/server/src/test/java/io/crate/analyze/expressions/ExpressionAnalyzerTest.java
index 6633889956..bac5df09ea 100644
--- a/server/src/test/java/io/crate/analyze/expressions/ExpressionAnalyzerTest.java
+++ b/server/src/test/java/io/crate/analyze/expressions/ExpressionAnalyzerTest.java
@@ -50,7 +50,6 @@ import io.crate.testing.SQLExecutor;
 import io.crate.testing.SqlExpressions;
 import io.crate.testing.T3;
 import io.crate.types.DataTypes;
-import io.crate.types.StringType;
 import org.joda.time.Period;
 import org.junit.Before;
 import org.junit.Test;
diff --git a/server/src/test/java/io/crate/breaker/SizeEstimatorFactoryTest.java b/server/src/test/java/io/crate/breaker/SizeEstimatorFactoryTest.java
index bb98f9626e..39ab72cafb 100644
--- a/server/src/test/java/io/crate/breaker/SizeEstimatorFactoryTest.java
+++ b/server/src/test/java/io/crate/breaker/SizeEstimatorFactoryTest.java
@@ -25,7 +25,6 @@ package io.crate.breaker;
 import io.crate.data.RowN;
 import io.crate.types.ArrayType;
 import io.crate.types.DataTypes;
-import io.crate.types.ObjectType;
 import io.crate.types.RowType;
 
 import org.junit.Test;
diff --git a/server/src/test/java/io/crate/execution/ddl/tables/AlterTableOperationTest.java b/server/src/test/java/io/crate/execution/ddl/tables/AlterTableOperationTest.java
index 12b701ab0c..65b5ef6aab 100644
--- a/server/src/test/java/io/crate/execution/ddl/tables/AlterTableOperationTest.java
+++ b/server/src/test/java/io/crate/execution/ddl/tables/AlterTableOperationTest.java
@@ -32,9 +32,6 @@ import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_BLOCKS_WR
 import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_REPLICAS;
 import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_NUMBER_OF_SHARDS;
 import static org.elasticsearch.cluster.metadata.IndexMetadata.SETTING_VERSION_CREATED;
-import static org.hamcrest.Matchers.contains;
-import static org.hamcrest.Matchers.containsInAnyOrder;
-import static org.hamcrest.Matchers.is;
 
 public class AlterTableOperationTest extends ESTestCase {
 
diff --git a/server/src/test/java/io/crate/execution/engine/collect/CollectTaskTest.java b/server/src/test/java/io/crate/execution/engine/collect/CollectTaskTest.java
index d2371fd7ca..f5d26ab0cc 100644
--- a/server/src/test/java/io/crate/execution/engine/collect/CollectTaskTest.java
+++ b/server/src/test/java/io/crate/execution/engine/collect/CollectTaskTest.java
@@ -23,9 +23,7 @@ package io.crate.execution.engine.collect;
 
 import static org.hamcrest.Matchers.is;
 import static org.junit.jupiter.api.Assertions.assertThrows;
-import static org.mockito.ArgumentMatchers.any;
 import static org.mockito.ArgumentMatchers.anyBoolean;
-import static org.mockito.ArgumentMatchers.eq;
 import static org.mockito.Mockito.mock;
 import static org.mockito.Mockito.times;
 import static org.mockito.Mockito.verify;
diff --git a/server/src/test/java/io/crate/execution/engine/collect/MapSideDataCollectOperationTest.java b/server/src/test/java/io/crate/execution/engine/collect/MapSideDataCollectOperationTest.java
index b9dfc4f689..40c361f007 100644
--- a/server/src/test/java/io/crate/execution/engine/collect/MapSideDataCollectOperationTest.java
+++ b/server/src/test/java/io/crate/execution/engine/collect/MapSideDataCollectOperationTest.java
@@ -33,7 +33,6 @@ import io.crate.metadata.CoordinatorTxnCtx;
 import io.crate.test.integration.CrateDummyClusterServiceUnitTest;
 import io.crate.testing.TestingRowConsumer;
 import io.crate.types.DataTypes;
-import org.elasticsearch.common.settings.Settings;
 import org.junit.Rule;
 import org.junit.Test;
 import org.junit.rules.TemporaryFolder;
diff --git a/server/src/test/java/io/crate/execution/engine/distribution/DistributingConsumerTest.java b/server/src/test/java/io/crate/execution/engine/distribution/DistributingConsumerTest.java
index 39231d668c..5a120ecdb9 100644
--- a/server/src/test/java/io/crate/execution/engine/distribution/DistributingConsumerTest.java
+++ b/server/src/test/java/io/crate/execution/engine/distribution/DistributingConsumerTest.java
@@ -37,8 +37,6 @@ import io.crate.testing.TestingBatchIterators;
 import io.crate.testing.TestingHelpers;
 import io.crate.testing.TestingRowConsumer;
 import io.crate.types.DataTypes;
-import org.apache.logging.log4j.LogManager;
-import org.apache.logging.log4j.Logger;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.common.breaker.CircuitBreakingException;
 import org.hamcrest.Matchers;
diff --git a/server/src/test/java/io/crate/execution/engine/indexing/BulkShardCreationLimiterTest.java b/server/src/test/java/io/crate/execution/engine/indexing/BulkShardCreationLimiterTest.java
index 82c9f1872a..483d965d6d 100644
--- a/server/src/test/java/io/crate/execution/engine/indexing/BulkShardCreationLimiterTest.java
+++ b/server/src/test/java/io/crate/execution/engine/indexing/BulkShardCreationLimiterTest.java
@@ -25,10 +25,8 @@ package io.crate.execution.engine.indexing;
 import io.crate.breaker.RamAccounting;
 import io.crate.execution.dml.ShardRequest;
 import org.elasticsearch.test.ESTestCase;
-import org.elasticsearch.common.io.stream.StreamInput;
 import org.junit.Test;
 
-import java.io.IOException;
 
 import static org.hamcrest.Matchers.is;
 
diff --git a/server/src/test/java/io/crate/execution/jobs/CountTaskTest.java b/server/src/test/java/io/crate/execution/jobs/CountTaskTest.java
index 0bcbe894e8..4c77e26778 100644
--- a/server/src/test/java/io/crate/execution/jobs/CountTaskTest.java
+++ b/server/src/test/java/io/crate/execution/jobs/CountTaskTest.java
@@ -35,7 +35,6 @@ import io.crate.planner.distribution.DistributionInfo;
 import io.crate.test.CauseMatcher;
 import org.elasticsearch.test.ESTestCase;
 import io.crate.testing.TestingRowConsumer;
-import org.elasticsearch.index.Index;
 import org.junit.Test;
 
 import java.util.Collections;
diff --git a/server/src/test/java/io/crate/expression/operator/CIDROperatorTest.java b/server/src/test/java/io/crate/expression/operator/CIDROperatorTest.java
index 827ff04865..7e4dd20920 100644
--- a/server/src/test/java/io/crate/expression/operator/CIDROperatorTest.java
+++ b/server/src/test/java/io/crate/expression/operator/CIDROperatorTest.java
@@ -24,9 +24,7 @@ package io.crate.expression.operator;
 
 import io.crate.expression.scalar.AbstractScalarFunctionsTest;
 import io.crate.expression.symbol.Literal;
-import org.junit.Rule;
 import org.junit.Test;
-import org.junit.rules.ExpectedException;
 
 public class CIDROperatorTest extends AbstractScalarFunctionsTest {
 
diff --git a/server/src/test/java/io/crate/expression/operator/OrOperatorTest.java b/server/src/test/java/io/crate/expression/operator/OrOperatorTest.java
index 0009794c7a..b2746cd705 100644
--- a/server/src/test/java/io/crate/expression/operator/OrOperatorTest.java
+++ b/server/src/test/java/io/crate/expression/operator/OrOperatorTest.java
@@ -3,8 +3,6 @@ package io.crate.expression.operator;
 import io.crate.expression.scalar.AbstractScalarFunctionsTest;
 import org.junit.Test;
 
-import static io.crate.testing.SymbolMatchers.isField;
-import static io.crate.testing.SymbolMatchers.isFunction;
 import static io.crate.testing.SymbolMatchers.isLiteral;
 
 public class OrOperatorTest extends AbstractScalarFunctionsTest {
diff --git a/server/src/test/java/io/crate/expression/operator/RegexpMatchCaseInsensitiveOperatorTest.java b/server/src/test/java/io/crate/expression/operator/RegexpMatchCaseInsensitiveOperatorTest.java
index 06f808151a..bcd01f5180 100644
--- a/server/src/test/java/io/crate/expression/operator/RegexpMatchCaseInsensitiveOperatorTest.java
+++ b/server/src/test/java/io/crate/expression/operator/RegexpMatchCaseInsensitiveOperatorTest.java
@@ -27,7 +27,6 @@ import io.crate.types.DataTypes;
 import org.junit.Test;
 
 import static org.hamcrest.Matchers.is;
-import static org.hamcrest.Matchers.nullValue;
 
 public class RegexpMatchCaseInsensitiveOperatorTest extends AbstractScalarFunctionsTest {
 
diff --git a/server/src/test/java/io/crate/expression/reference/doc/IpColumnReferenceTest.java b/server/src/test/java/io/crate/expression/reference/doc/IpColumnReferenceTest.java
index 6573ca4e6c..b022353738 100644
--- a/server/src/test/java/io/crate/expression/reference/doc/IpColumnReferenceTest.java
+++ b/server/src/test/java/io/crate/expression/reference/doc/IpColumnReferenceTest.java
@@ -37,9 +37,7 @@ import org.apache.lucene.search.TopDocs;
 import org.apache.lucene.util.BytesRef;
 import org.elasticsearch.common.network.InetAddresses;
 import org.hamcrest.Matchers;
-import org.junit.Rule;
 import org.junit.Test;
-import org.junit.rules.ExpectedException;
 
 import java.io.IOException;
 import java.net.InetAddress;
diff --git a/server/src/test/java/io/crate/expression/scalar/arithmetic/ArithmeticOverflowTest.java b/server/src/test/java/io/crate/expression/scalar/arithmetic/ArithmeticOverflowTest.java
index d34ce102dd..11af0d3ed1 100644
--- a/server/src/test/java/io/crate/expression/scalar/arithmetic/ArithmeticOverflowTest.java
+++ b/server/src/test/java/io/crate/expression/scalar/arithmetic/ArithmeticOverflowTest.java
@@ -24,9 +24,7 @@ package io.crate.expression.scalar.arithmetic;
 
 import io.crate.expression.scalar.AbstractScalarFunctionsTest;
 import io.crate.expression.symbol.Literal;
-import org.junit.Rule;
 import org.junit.Test;
-import org.junit.rules.ExpectedException;
 
 public class ArithmeticOverflowTest extends AbstractScalarFunctionsTest {
 
diff --git a/server/src/test/java/io/crate/expression/scalar/arithmetic/IntervalFunctionTest.java b/server/src/test/java/io/crate/expression/scalar/arithmetic/IntervalFunctionTest.java
index b643fc34fa..a11a2d902a 100644
--- a/server/src/test/java/io/crate/expression/scalar/arithmetic/IntervalFunctionTest.java
+++ b/server/src/test/java/io/crate/expression/scalar/arithmetic/IntervalFunctionTest.java
@@ -22,7 +22,6 @@
 
 package io.crate.expression.scalar.arithmetic;
 
-import io.crate.exceptions.ConversionException;
 import io.crate.expression.scalar.AbstractScalarFunctionsTest;
 import org.hamcrest.Matchers;
 import org.joda.time.Period;
diff --git a/server/src/test/java/io/crate/expression/scalar/string/ChrFunctionTest.java b/server/src/test/java/io/crate/expression/scalar/string/ChrFunctionTest.java
index 00bfc159fe..eeed2b8ee5 100644
--- a/server/src/test/java/io/crate/expression/scalar/string/ChrFunctionTest.java
+++ b/server/src/test/java/io/crate/expression/scalar/string/ChrFunctionTest.java
@@ -22,9 +22,7 @@
 
 package io.crate.expression.scalar.string;
 
-import org.junit.Rule;
 import org.junit.Test;
-import org.junit.rules.ExpectedException;
 
 import io.crate.expression.scalar.AbstractScalarFunctionsTest;
 
diff --git a/server/src/test/java/io/crate/expression/scalar/string/StringPaddingFunctionTest.java b/server/src/test/java/io/crate/expression/scalar/string/StringPaddingFunctionTest.java
index 40c143dc23..31319ec500 100644
--- a/server/src/test/java/io/crate/expression/scalar/string/StringPaddingFunctionTest.java
+++ b/server/src/test/java/io/crate/expression/scalar/string/StringPaddingFunctionTest.java
@@ -24,9 +24,7 @@ package io.crate.expression.scalar.string;
 
 import io.crate.expression.scalar.AbstractScalarFunctionsTest;
 import io.crate.expression.symbol.Literal;
-import org.junit.Rule;
 import org.junit.Test;
-import org.junit.rules.ExpectedException;
 
 public class StringPaddingFunctionTest extends AbstractScalarFunctionsTest {
 
diff --git a/server/src/test/java/io/crate/expression/scalar/timestamp/TimezoneFunctionTest.java b/server/src/test/java/io/crate/expression/scalar/timestamp/TimezoneFunctionTest.java
index c921e93f35..1588254bc2 100644
--- a/server/src/test/java/io/crate/expression/scalar/timestamp/TimezoneFunctionTest.java
+++ b/server/src/test/java/io/crate/expression/scalar/timestamp/TimezoneFunctionTest.java
@@ -25,9 +25,7 @@ package io.crate.expression.scalar.timestamp;
 import io.crate.expression.scalar.AbstractScalarFunctionsTest;
 import io.crate.expression.symbol.Literal;
 import io.crate.types.DataTypes;
-import org.junit.Rule;
 import org.junit.Test;
-import org.junit.rules.ExpectedException;
 
 public class TimezoneFunctionTest extends AbstractScalarFunctionsTest {
 
diff --git a/server/src/test/java/io/crate/integrationtests/DDLIntegrationTest.java b/server/src/test/java/io/crate/integrationtests/DDLIntegrationTest.java
index 93f7078af3..24189615f8 100644
--- a/server/src/test/java/io/crate/integrationtests/DDLIntegrationTest.java
+++ b/server/src/test/java/io/crate/integrationtests/DDLIntegrationTest.java
@@ -59,7 +59,6 @@ import io.crate.testing.SQLErrorMatcher;
 import io.crate.testing.TestingHelpers;
 import io.crate.testing.UseRandomizedSchema;
 import io.netty.handler.codec.http.HttpResponseStatus;
-import static org.junit.jupiter.api.Assertions.assertThrows;
 
 @ESIntegTestCase.ClusterScope()
 @UseRandomizedSchema(random = false)
diff --git a/server/src/test/java/io/crate/integrationtests/PostgresITest.java b/server/src/test/java/io/crate/integrationtests/PostgresITest.java
index 8876321358..3839adc8e4 100644
--- a/server/src/test/java/io/crate/integrationtests/PostgresITest.java
+++ b/server/src/test/java/io/crate/integrationtests/PostgresITest.java
@@ -25,14 +25,12 @@ package io.crate.integrationtests;
 import io.crate.action.sql.SQLOperations;
 import io.crate.execution.engine.collect.stats.JobsLogService;
 import io.crate.protocols.postgres.PostgresNetty;
-import io.crate.testing.Asserts;
 import io.crate.testing.DataTypeTesting;
 import io.crate.testing.UseJdbc;
 import io.crate.types.DataTypes;
 
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.test.ESIntegTestCase;
-import org.elasticsearch.test.junit.annotations.TestLogging;
 import org.hamcrest.Matchers;
 import org.junit.Before;
 import org.junit.BeforeClass;
diff --git a/server/src/test/java/io/crate/integrationtests/PromoteStaleReplicaITest.java b/server/src/test/java/io/crate/integrationtests/PromoteStaleReplicaITest.java
index b9bacb53d8..8ec45d0f6a 100644
--- a/server/src/test/java/io/crate/integrationtests/PromoteStaleReplicaITest.java
+++ b/server/src/test/java/io/crate/integrationtests/PromoteStaleReplicaITest.java
@@ -27,7 +27,6 @@ import org.elasticsearch.node.Node;
 import org.elasticsearch.test.ESIntegTestCase;
 import org.junit.Test;
 
-import java.util.Arrays;
 
 import static com.carrotsearch.randomizedtesting.RandomizedTest.$;
 import static io.crate.testing.TestingHelpers.printedTable;
diff --git a/server/src/test/java/io/crate/integrationtests/SQLTransportIntegrationTest.java b/server/src/test/java/io/crate/integrationtests/SQLTransportIntegrationTest.java
index c85617d908..bf0f73dc8d 100644
--- a/server/src/test/java/io/crate/integrationtests/SQLTransportIntegrationTest.java
+++ b/server/src/test/java/io/crate/integrationtests/SQLTransportIntegrationTest.java
@@ -21,7 +21,6 @@
 
 package io.crate.integrationtests;
 
-import com.carrotsearch.hppc.cursors.ObjectCursor;
 import com.carrotsearch.randomizedtesting.RandomizedContext;
 import com.carrotsearch.randomizedtesting.annotations.Listeners;
 import com.carrotsearch.randomizedtesting.annotations.TestGroup;
@@ -84,7 +83,6 @@ import org.elasticsearch.action.admin.cluster.state.ClusterStateResponse;
 import org.elasticsearch.client.Client;
 import org.elasticsearch.client.Requests;
 import org.elasticsearch.cluster.metadata.IndexMetadata;
-import org.elasticsearch.cluster.metadata.MappingMetadata;
 import org.elasticsearch.cluster.metadata.Metadata;
 import org.elasticsearch.cluster.service.ClusterService;
 import org.elasticsearch.common.Randomness;
@@ -94,7 +92,6 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.transport.BoundTransportAddress;
 import org.elasticsearch.common.xcontent.XContentBuilder;
 import org.elasticsearch.common.xcontent.XContentFactory;
-import org.elasticsearch.http.netty4.Netty4HttpServerTransport;
 import org.elasticsearch.index.Index;
 import org.elasticsearch.index.IndexService;
 import org.elasticsearch.index.shard.IndexShard;
diff --git a/server/src/test/java/io/crate/integrationtests/SeqNoBasedOCCIntegrationTest.java b/server/src/test/java/io/crate/integrationtests/SeqNoBasedOCCIntegrationTest.java
index d84f590c2b..e91341fbb1 100644
--- a/server/src/test/java/io/crate/integrationtests/SeqNoBasedOCCIntegrationTest.java
+++ b/server/src/test/java/io/crate/integrationtests/SeqNoBasedOCCIntegrationTest.java
@@ -22,14 +22,8 @@
 
 package io.crate.integrationtests;
 
-import io.crate.exceptions.VersioninigValidationException;
-import io.crate.protocols.postgres.PGErrorStatus;
-import io.netty.handler.codec.http.HttpResponseStatus;
 import org.junit.Test;
 
-import static io.crate.testing.Asserts.assertThrows;
-import static io.crate.testing.SQLErrorMatcher.isSQLError;
-import static org.hamcrest.Matchers.containsString;
 
 public class SeqNoBasedOCCIntegrationTest extends SQLTransportIntegrationTest {
 
diff --git a/server/src/test/java/io/crate/integrationtests/StaticInformationSchemaQueryTest.java b/server/src/test/java/io/crate/integrationtests/StaticInformationSchemaQueryTest.java
index ead9788dd8..5fa6acc270 100644
--- a/server/src/test/java/io/crate/integrationtests/StaticInformationSchemaQueryTest.java
+++ b/server/src/test/java/io/crate/integrationtests/StaticInformationSchemaQueryTest.java
@@ -24,7 +24,6 @@ package io.crate.integrationtests;
 import org.junit.Before;
 import org.junit.Test;
 
-import static io.crate.protocols.postgres.PGErrorStatus.INTERNAL_ERROR;
 import static io.crate.protocols.postgres.PGErrorStatus.UNDEFINED_TABLE;
 import static io.crate.testing.Asserts.assertThrows;
 import static io.crate.testing.SQLErrorMatcher.isSQLError;
diff --git a/server/src/test/java/io/crate/integrationtests/SubSelectIntegrationTest.java b/server/src/test/java/io/crate/integrationtests/SubSelectIntegrationTest.java
index 29969287ca..d49f890a62 100644
--- a/server/src/test/java/io/crate/integrationtests/SubSelectIntegrationTest.java
+++ b/server/src/test/java/io/crate/integrationtests/SubSelectIntegrationTest.java
@@ -29,7 +29,6 @@ import io.crate.statistics.Stats;
 import io.crate.statistics.TableStats;
 import io.crate.testing.TestingHelpers;
 import org.elasticsearch.test.ESIntegTestCase;
-import org.junit.Ignore;
 import org.junit.Test;
 
 import java.util.Arrays;
diff --git a/server/src/test/java/io/crate/integrationtests/SysClusterSettingsTest.java b/server/src/test/java/io/crate/integrationtests/SysClusterSettingsTest.java
index b22c0550bc..09f8039001 100644
--- a/server/src/test/java/io/crate/integrationtests/SysClusterSettingsTest.java
+++ b/server/src/test/java/io/crate/integrationtests/SysClusterSettingsTest.java
@@ -27,7 +27,6 @@ import io.crate.execution.engine.indexing.ShardingUpsertExecutor;
 import io.crate.settings.CrateSetting;
 import io.crate.udc.service.UDCService;
 import org.elasticsearch.cluster.ClusterInfoService;
-import org.elasticsearch.cluster.InternalClusterInfoService;
 import org.elasticsearch.common.settings.Setting;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.MemorySizeValue;
diff --git a/server/src/test/java/io/crate/integrationtests/TablesNeedUpgradeSysCheckTest.java b/server/src/test/java/io/crate/integrationtests/TablesNeedUpgradeSysCheckTest.java
index fcbd104e25..7ce3ce95eb 100644
--- a/server/src/test/java/io/crate/integrationtests/TablesNeedUpgradeSysCheckTest.java
+++ b/server/src/test/java/io/crate/integrationtests/TablesNeedUpgradeSysCheckTest.java
@@ -26,10 +26,8 @@ import org.apache.lucene.util.TestUtil;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.env.Environment;
 import org.elasticsearch.test.ESIntegTestCase;
-import org.junit.After;
 import org.junit.Test;
 
-import java.io.IOException;
 import java.io.InputStream;
 import java.nio.file.Files;
 import java.nio.file.Path;
diff --git a/server/src/test/java/io/crate/integrationtests/disruption/discovery/MasterDisruptionIT.java b/server/src/test/java/io/crate/integrationtests/disruption/discovery/MasterDisruptionIT.java
index 3ca8b78514..b5160b09ea 100644
--- a/server/src/test/java/io/crate/integrationtests/disruption/discovery/MasterDisruptionIT.java
+++ b/server/src/test/java/io/crate/integrationtests/disruption/discovery/MasterDisruptionIT.java
@@ -48,7 +48,6 @@ import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 
-import com.carrotsearch.randomizedtesting.annotations.Repeat;
 
 import static io.crate.metadata.IndexParts.toIndexName;
 import static org.hamcrest.Matchers.equalTo;
diff --git a/server/src/test/java/io/crate/memory/OnHeapMemoryManagerTest.java b/server/src/test/java/io/crate/memory/OnHeapMemoryManagerTest.java
index 229beef430..0898ebd7fc 100644
--- a/server/src/test/java/io/crate/memory/OnHeapMemoryManagerTest.java
+++ b/server/src/test/java/io/crate/memory/OnHeapMemoryManagerTest.java
@@ -22,7 +22,6 @@
 
 package io.crate.memory;
 
-import io.netty.buffer.ByteBuf;
 import org.junit.Test;
 
 import java.util.concurrent.atomic.AtomicLong;
diff --git a/server/src/test/java/io/crate/metadata/sys/SysClusterTableInfoTest.java b/server/src/test/java/io/crate/metadata/sys/SysClusterTableInfoTest.java
index 00c6ff6336..336fa7eb06 100644
--- a/server/src/test/java/io/crate/metadata/sys/SysClusterTableInfoTest.java
+++ b/server/src/test/java/io/crate/metadata/sys/SysClusterTableInfoTest.java
@@ -27,7 +27,6 @@ import io.crate.expression.reference.StaticTableReferenceResolver;
 import io.crate.license.LicenseService;
 import io.crate.metadata.ColumnIdent;
 import io.crate.metadata.settings.CrateSettings;
-import io.crate.settings.CrateSetting;
 import io.crate.test.integration.CrateDummyClusterServiceUnitTest;
 import org.hamcrest.Matchers;
 import org.junit.Test;
diff --git a/server/src/test/java/io/crate/planner/SelectPlannerTest.java b/server/src/test/java/io/crate/planner/SelectPlannerTest.java
index 81b5b4ade3..86dec9c6ea 100644
--- a/server/src/test/java/io/crate/planner/SelectPlannerTest.java
+++ b/server/src/test/java/io/crate/planner/SelectPlannerTest.java
@@ -63,7 +63,6 @@ import io.crate.planner.node.dql.QueryThenFetch;
 import io.crate.planner.node.dql.join.Join;
 import io.crate.planner.node.dql.join.JoinType;
 import io.crate.planner.operators.LogicalPlan;
-import io.crate.protocols.postgres.PGErrorStatus;
 import io.crate.statistics.Stats;
 import io.crate.statistics.TableStats;
 import io.crate.test.integration.CrateDummyClusterServiceUnitTest;
@@ -71,7 +70,6 @@ import io.crate.testing.SQLExecutor;
 import io.crate.testing.T3;
 import io.crate.testing.TestingHelpers;
 import io.crate.types.DataTypes;
-import io.netty.handler.codec.http.HttpResponseStatus;
 import org.hamcrest.Matchers;
 import org.junit.After;
 import org.junit.Before;
@@ -88,14 +86,12 @@ import java.util.stream.Collectors;
 
 import static io.crate.planner.operators.LogicalPlannerTest.isPlan;
 import static io.crate.testing.Asserts.assertThrows;
-import static io.crate.testing.SQLErrorMatcher.isSQLError;
 import static io.crate.testing.SymbolMatchers.isFunction;
 import static io.crate.testing.SymbolMatchers.isLiteral;
 import static io.crate.testing.SymbolMatchers.isReference;
 import static io.crate.testing.TestingHelpers.isSQL;
 import static java.util.Collections.singletonList;
 import static org.hamcrest.Matchers.contains;
-import static org.hamcrest.Matchers.containsString;
 import static org.hamcrest.Matchers.equalTo;
 import static org.hamcrest.Matchers.instanceOf;
 import static org.hamcrest.Matchers.is;
diff --git a/server/src/test/java/io/crate/planner/WhereClauseOptimizerTest.java b/server/src/test/java/io/crate/planner/WhereClauseOptimizerTest.java
index c8ff130b49..e88b8e3d8a 100644
--- a/server/src/test/java/io/crate/planner/WhereClauseOptimizerTest.java
+++ b/server/src/test/java/io/crate/planner/WhereClauseOptimizerTest.java
@@ -38,7 +38,6 @@ import static io.crate.testing.TestingHelpers.isDocKey;
 import static java.util.Collections.singletonList;
 import static org.hamcrest.Matchers.contains;
 import static org.hamcrest.Matchers.containsInAnyOrder;
-import static org.hamcrest.Matchers.empty;
 import static org.hamcrest.Matchers.is;
 
 public class WhereClauseOptimizerTest extends CrateDummyClusterServiceUnitTest{
diff --git a/server/src/test/java/io/crate/planner/consumer/GlobalAggregatePlannerTest.java b/server/src/test/java/io/crate/planner/consumer/GlobalAggregatePlannerTest.java
index 25aae87888..f77255b90a 100644
--- a/server/src/test/java/io/crate/planner/consumer/GlobalAggregatePlannerTest.java
+++ b/server/src/test/java/io/crate/planner/consumer/GlobalAggregatePlannerTest.java
@@ -24,27 +24,22 @@ package io.crate.planner.consumer;
 
 import io.crate.analyze.TableDefinitions;
 import io.crate.data.Row1;
-import io.crate.data.RowN;
 import io.crate.execution.dsl.projection.AggregationProjection;
-import io.crate.execution.dsl.projection.EvalProjection;
 import io.crate.execution.dsl.projection.FilterProjection;
 import io.crate.execution.dsl.projection.Projection;
 import io.crate.execution.dsl.projection.TopNProjection;
 import io.crate.planner.node.dql.Collect;
-import io.crate.planner.node.dql.join.Join;
 import io.crate.test.integration.CrateDummyClusterServiceUnitTest;
 import io.crate.testing.SQLExecutor;
 import io.crate.testing.T3;
 import org.hamcrest.Matchers;
 import org.junit.Before;
-import org.junit.Ignore;
 import org.junit.Test;
 
 import java.util.List;
 import java.util.UUID;
 
 import static io.crate.testing.SymbolMatchers.isAggregation;
-import static io.crate.testing.SymbolMatchers.isFunction;
 import static io.crate.testing.SymbolMatchers.isInputColumn;
 import static org.hamcrest.Matchers.contains;
 import static org.hamcrest.Matchers.instanceOf;
diff --git a/server/src/test/java/io/crate/planner/operators/CollectTest.java b/server/src/test/java/io/crate/planner/operators/CollectTest.java
index a39761952e..249a49764d 100644
--- a/server/src/test/java/io/crate/planner/operators/CollectTest.java
+++ b/server/src/test/java/io/crate/planner/operators/CollectTest.java
@@ -26,7 +26,6 @@ import io.crate.analyze.WhereClause;
 import io.crate.analyze.relations.DocTableRelation;
 import io.crate.data.Row;
 import io.crate.expression.symbol.Symbol;
-import io.crate.metadata.doc.DocTableInfo;
 import io.crate.statistics.TableStats;
 import io.crate.test.integration.CrateDummyClusterServiceUnitTest;
 import io.crate.testing.SQLExecutor;
diff --git a/server/src/test/java/io/crate/planner/optimizer/OptimizerTest.java b/server/src/test/java/io/crate/planner/optimizer/OptimizerTest.java
index c1c869638b..7aeb4d793c 100644
--- a/server/src/test/java/io/crate/planner/optimizer/OptimizerTest.java
+++ b/server/src/test/java/io/crate/planner/optimizer/OptimizerTest.java
@@ -23,7 +23,6 @@
 package io.crate.planner.optimizer;
 
 import io.crate.metadata.SearchPath;
-import io.crate.metadata.TransactionContext;
 import io.crate.metadata.settings.SessionSettings;
 import io.crate.planner.optimizer.rule.MergeFilters;
 import io.crate.planner.optimizer.rule.MoveFilterBeneathHashJoin;
diff --git a/server/src/test/java/io/crate/protocols/postgres/PostgresWireProtocolTest.java b/server/src/test/java/io/crate/protocols/postgres/PostgresWireProtocolTest.java
index 741279fc21..83aac0f0d0 100644
--- a/server/src/test/java/io/crate/protocols/postgres/PostgresWireProtocolTest.java
+++ b/server/src/test/java/io/crate/protocols/postgres/PostgresWireProtocolTest.java
@@ -61,7 +61,6 @@ import java.util.Arrays;
 import java.util.Collections;
 import java.util.List;
 import java.util.Map;
-import java.util.Set;
 import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
diff --git a/server/src/test/java/io/crate/protocols/postgres/types/RegprocTypeTest.java b/server/src/test/java/io/crate/protocols/postgres/types/RegprocTypeTest.java
index 0b012c9023..2de89b7dff 100644
--- a/server/src/test/java/io/crate/protocols/postgres/types/RegprocTypeTest.java
+++ b/server/src/test/java/io/crate/protocols/postgres/types/RegprocTypeTest.java
@@ -22,8 +22,6 @@
 
 package io.crate.protocols.postgres.types;
 
-import io.crate.metadata.functions.Signature;
-import io.crate.metadata.pgcatalog.OidHash;
 import io.crate.types.Regproc;
 import io.netty.buffer.ByteBuf;
 import io.netty.buffer.Unpooled;
diff --git a/server/src/test/java/io/crate/types/TypeConversionTest.java b/server/src/test/java/io/crate/types/TypeConversionTest.java
index 9637f85ce8..733fa2b23d 100644
--- a/server/src/test/java/io/crate/types/TypeConversionTest.java
+++ b/server/src/test/java/io/crate/types/TypeConversionTest.java
@@ -32,7 +32,6 @@ import org.elasticsearch.test.ESTestCase;
 import org.junit.Test;
 
 import io.crate.common.collections.Lists2;
-import org.elasticsearch.test.ESTestCase;
 
 public class TypeConversionTest extends ESTestCase {
 
diff --git a/server/src/test/java/org/elasticsearch/action/admin/indices/create/TransportCreatePartitionsActionTest.java b/server/src/test/java/org/elasticsearch/action/admin/indices/create/TransportCreatePartitionsActionTest.java
index a3e153c097..4c45137878 100644
--- a/server/src/test/java/org/elasticsearch/action/admin/indices/create/TransportCreatePartitionsActionTest.java
+++ b/server/src/test/java/org/elasticsearch/action/admin/indices/create/TransportCreatePartitionsActionTest.java
@@ -42,8 +42,6 @@ import java.util.UUID;
 import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.TimeUnit;
 
-import static io.crate.testing.Asserts.assertThrows;
-import static org.hamcrest.Matchers.instanceOf;
 import static org.hamcrest.Matchers.is;
 
 public class TransportCreatePartitionsActionTest extends SQLTransportIntegrationTest {
diff --git a/server/src/test/java/org/elasticsearch/cluster/allocation/FilteringAllocationIT.java b/server/src/test/java/org/elasticsearch/cluster/allocation/FilteringAllocationIT.java
index 8c9aafd8ea..6d1e1acb9c 100644
--- a/server/src/test/java/org/elasticsearch/cluster/allocation/FilteringAllocationIT.java
+++ b/server/src/test/java/org/elasticsearch/cluster/allocation/FilteringAllocationIT.java
@@ -27,7 +27,6 @@ import java.util.Collection;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
-import java.util.concurrent.TimeUnit;
 
 import org.elasticsearch.cluster.ClusterState;
 import org.elasticsearch.cluster.health.ClusterHealthStatus;
@@ -44,7 +43,6 @@ import org.elasticsearch.plugins.Plugin;
 import org.elasticsearch.test.ESIntegTestCase.ClusterScope;
 import org.elasticsearch.test.ESIntegTestCase.Scope;
 import org.elasticsearch.test.InternalSettingsPlugin;
-import org.junit.Ignore;
 import org.junit.Test;
 
 import io.crate.integrationtests.SQLTransportIntegrationTest;
diff --git a/server/src/test/java/org/elasticsearch/cluster/coordination/FollowersCheckerTests.java b/server/src/test/java/org/elasticsearch/cluster/coordination/FollowersCheckerTests.java
index 13d8ac1ca5..822336001b 100644
--- a/server/src/test/java/org/elasticsearch/cluster/coordination/FollowersCheckerTests.java
+++ b/server/src/test/java/org/elasticsearch/cluster/coordination/FollowersCheckerTests.java
@@ -59,7 +59,6 @@ import java.util.function.Supplier;
 import java.util.stream.Collectors;
 import java.util.stream.Stream;
 
-import static java.util.Collections.emptySet;
 import static org.elasticsearch.cluster.coordination.FollowersChecker.FOLLOWER_CHECK_ACTION_NAME;
 import static org.elasticsearch.cluster.coordination.FollowersChecker.FOLLOWER_CHECK_INTERVAL_SETTING;
 import static org.elasticsearch.cluster.coordination.FollowersChecker.FOLLOWER_CHECK_RETRY_COUNT_SETTING;
diff --git a/server/src/test/java/org/elasticsearch/cluster/routing/allocation/AllocationCommandsTests.java b/server/src/test/java/org/elasticsearch/cluster/routing/allocation/AllocationCommandsTests.java
index 6b73099704..6a7d48e062 100644
--- a/server/src/test/java/org/elasticsearch/cluster/routing/allocation/AllocationCommandsTests.java
+++ b/server/src/test/java/org/elasticsearch/cluster/routing/allocation/AllocationCommandsTests.java
@@ -73,7 +73,6 @@ import org.elasticsearch.index.Index;
 import org.elasticsearch.index.IndexNotFoundException;
 import org.elasticsearch.index.shard.ShardId;
 import org.elasticsearch.index.shard.ShardNotFoundException;
-import org.junit.Ignore;
 import org.junit.Test;
 
 public class AllocationCommandsTests extends ESAllocationTestCase {
diff --git a/server/src/test/java/org/elasticsearch/cluster/service/MasterServiceTests.java b/server/src/test/java/org/elasticsearch/cluster/service/MasterServiceTests.java
index 89be6048af..160656c461 100644
--- a/server/src/test/java/org/elasticsearch/cluster/service/MasterServiceTests.java
+++ b/server/src/test/java/org/elasticsearch/cluster/service/MasterServiceTests.java
@@ -35,7 +35,6 @@ import org.elasticsearch.cluster.LocalClusterUpdateTask;
 import org.elasticsearch.cluster.block.ClusterBlocks;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.cluster.node.DiscoveryNodes;
-import javax.annotation.Nullable;
 import org.elasticsearch.common.Priority;
 import io.crate.common.collections.Tuple;
 import org.elasticsearch.common.logging.Loggers;
@@ -56,7 +55,6 @@ import org.junit.Before;
 import org.junit.BeforeClass;
 
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
diff --git a/server/src/test/java/org/elasticsearch/gateway/GatewayIndexStateIT.java b/server/src/test/java/org/elasticsearch/gateway/GatewayIndexStateIT.java
index 4f063a1a3d..2e46520adc 100644
--- a/server/src/test/java/org/elasticsearch/gateway/GatewayIndexStateIT.java
+++ b/server/src/test/java/org/elasticsearch/gateway/GatewayIndexStateIT.java
@@ -51,7 +51,6 @@ import org.elasticsearch.test.ESIntegTestCase;
 import org.elasticsearch.test.ESIntegTestCase.ClusterScope;
 import org.elasticsearch.test.ESIntegTestCase.Scope;
 import org.elasticsearch.test.InternalTestCluster.RestartCallback;
-import org.junit.Ignore;
 import org.junit.Test;
 
 import java.io.IOException;
diff --git a/server/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java b/server/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
index 1eb2a5f2ca..6c14b15002 100644
--- a/server/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
+++ b/server/src/test/java/org/elasticsearch/index/engine/InternalEngineTests.java
@@ -89,7 +89,6 @@ import org.apache.logging.log4j.Logger;
 import org.apache.logging.log4j.core.LogEvent;
 import org.apache.logging.log4j.core.appender.AbstractAppender;
 import org.apache.logging.log4j.core.filter.RegexFilter;
-import org.apache.lucene.codecs.lucene50.Lucene50StoredFieldsFormat;
 import org.apache.lucene.codecs.lucene87.Lucene87StoredFieldsFormat;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.LongPoint;
diff --git a/server/src/test/java/org/elasticsearch/index/engine/TranslogHandler.java b/server/src/test/java/org/elasticsearch/index/engine/TranslogHandler.java
index 3ae436ff0b..2ab5dfb2ba 100644
--- a/server/src/test/java/org/elasticsearch/index/engine/TranslogHandler.java
+++ b/server/src/test/java/org/elasticsearch/index/engine/TranslogHandler.java
@@ -28,7 +28,6 @@ import org.elasticsearch.index.analysis.IndexAnalyzers;
 import org.elasticsearch.index.analysis.NamedAnalyzer;
 import org.elasticsearch.index.mapper.DocumentMapper;
 import org.elasticsearch.index.mapper.MapperService;
-import org.elasticsearch.index.mapper.Mapping;
 import org.elasticsearch.index.mapper.RootObjectMapper;
 import org.elasticsearch.index.mapper.SourceToParse;
 import org.elasticsearch.index.seqno.SequenceNumbers;
@@ -40,8 +39,6 @@ import org.elasticsearch.indices.mapper.MapperRegistry;
 import io.crate.Constants;
 
 import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
 
 import static java.util.Collections.emptyList;
 import static java.util.Collections.emptyMap;
diff --git a/server/src/test/java/org/elasticsearch/index/shard/IndexShardTestCase.java b/server/src/test/java/org/elasticsearch/index/shard/IndexShardTestCase.java
index 0864815ea0..05d4b84cbb 100644
--- a/server/src/test/java/org/elasticsearch/index/shard/IndexShardTestCase.java
+++ b/server/src/test/java/org/elasticsearch/index/shard/IndexShardTestCase.java
@@ -21,7 +21,6 @@
  */
 package org.elasticsearch.index.shard;
 
-import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.IndexNotFoundException;
 import org.apache.lucene.store.Directory;
 import org.elasticsearch.Version;
diff --git a/server/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java b/server/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
index 61a79ee09b..1cf54189ef 100644
--- a/server/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
+++ b/server/src/test/java/org/elasticsearch/index/shard/IndexShardTests.java
@@ -68,7 +68,6 @@ import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.atomic.AtomicLong;
 import java.util.concurrent.atomic.AtomicReference;
-import java.util.function.BiConsumer;
 import java.util.function.Consumer;
 import java.util.function.Function;
 import java.util.function.LongFunction;
diff --git a/server/src/test/java/org/elasticsearch/index/shard/PrimaryReplicaSyncerTests.java b/server/src/test/java/org/elasticsearch/index/shard/PrimaryReplicaSyncerTests.java
index a0d7a75a1f..3289191460 100644
--- a/server/src/test/java/org/elasticsearch/index/shard/PrimaryReplicaSyncerTests.java
+++ b/server/src/test/java/org/elasticsearch/index/shard/PrimaryReplicaSyncerTests.java
@@ -41,7 +41,6 @@ import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.unit.ByteSizeValue;
 import org.elasticsearch.common.xcontent.XContentType;
 import org.elasticsearch.index.VersionType;
-import org.elasticsearch.index.engine.Engine.IndexResult;
 import org.elasticsearch.index.mapper.SourceToParse;
 import org.elasticsearch.index.seqno.SequenceNumbers;
 import org.elasticsearch.index.translog.TestTranslog;
diff --git a/server/src/test/java/org/elasticsearch/index/shard/RestoreOnlyRepository.java b/server/src/test/java/org/elasticsearch/index/shard/RestoreOnlyRepository.java
index 40f0d403d3..84d9197f2b 100644
--- a/server/src/test/java/org/elasticsearch/index/shard/RestoreOnlyRepository.java
+++ b/server/src/test/java/org/elasticsearch/index/shard/RestoreOnlyRepository.java
@@ -23,7 +23,6 @@
 package org.elasticsearch.index.shard;
 
 import org.apache.lucene.index.IndexCommit;
-import org.elasticsearch.Version;
 import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.cluster.metadata.IndexMetadata;
 import org.elasticsearch.cluster.metadata.Metadata;
diff --git a/server/src/test/java/org/elasticsearch/index/translog/TranslogTests.java b/server/src/test/java/org/elasticsearch/index/translog/TranslogTests.java
index 3fffa8f829..ce3e032b28 100644
--- a/server/src/test/java/org/elasticsearch/index/translog/TranslogTests.java
+++ b/server/src/test/java/org/elasticsearch/index/translog/TranslogTests.java
@@ -88,7 +88,6 @@ import org.apache.lucene.codecs.CodecUtil;
 import org.apache.lucene.document.Field;
 import org.apache.lucene.document.NumericDocValuesField;
 import org.apache.lucene.document.TextField;
-import org.apache.lucene.index.IndexFormatTooOldException;
 import org.apache.lucene.index.Term;
 import org.apache.lucene.mockfile.FilterFileChannel;
 import org.apache.lucene.mockfile.FilterFileSystemProvider;
diff --git a/server/src/test/java/org/elasticsearch/test/BackgroundIndexer.java b/server/src/test/java/org/elasticsearch/test/BackgroundIndexer.java
index 44436eb1c5..1142235e30 100644
--- a/server/src/test/java/org/elasticsearch/test/BackgroundIndexer.java
+++ b/server/src/test/java/org/elasticsearch/test/BackgroundIndexer.java
@@ -49,7 +49,6 @@ import org.elasticsearch.common.util.concurrent.ConcurrentCollections;
 import org.junit.Assert;
 
 import io.crate.common.unit.TimeValue;
-import io.crate.exceptions.Exceptions;
 import io.crate.testing.DataTypeTesting;
 import io.crate.types.DataTypes;
 
diff --git a/server/src/test/java/org/elasticsearch/test/FieldMaskingReader.java b/server/src/test/java/org/elasticsearch/test/FieldMaskingReader.java
index 3aba68868f..78bb3d9287 100644
--- a/server/src/test/java/org/elasticsearch/test/FieldMaskingReader.java
+++ b/server/src/test/java/org/elasticsearch/test/FieldMaskingReader.java
@@ -23,7 +23,6 @@ import org.apache.lucene.index.FieldFilterLeafReader;
 import org.apache.lucene.index.FilterDirectoryReader;
 import org.apache.lucene.index.FilterLeafReader;
 import org.apache.lucene.index.LeafReader;
-import org.apache.lucene.index.IndexReader.CacheHelper;
 
 import java.io.IOException;
 import java.util.Collections;
@@ -67,4 +66,4 @@ public class FieldMaskingReader extends FilterDirectoryReader {
     public CacheHelper getReaderCacheHelper() {
         return in.getReaderCacheHelper();
     }
-}
\ No newline at end of file
+}
diff --git a/server/src/test/java/org/elasticsearch/test/engine/MockEngineSupport.java b/server/src/test/java/org/elasticsearch/test/engine/MockEngineSupport.java
index 62ff7f47ad..11c690d4f2 100644
--- a/server/src/test/java/org/elasticsearch/test/engine/MockEngineSupport.java
+++ b/server/src/test/java/org/elasticsearch/test/engine/MockEngineSupport.java
@@ -24,7 +24,6 @@ import org.apache.lucene.index.AssertingDirectoryReader;
 import org.apache.lucene.index.DirectoryReader;
 import org.apache.lucene.index.FilterDirectoryReader;
 import org.apache.lucene.index.IndexReader;
-import org.apache.lucene.search.AssertingIndexSearcher;
 import org.apache.lucene.search.QueryCache;
 import org.apache.lucene.search.QueryCachingPolicy;
 import org.apache.lucene.util.LuceneTestCase;
diff --git a/server/src/test/java/org/elasticsearch/test/hamcrest/ElasticsearchAssertions.java b/server/src/test/java/org/elasticsearch/test/hamcrest/ElasticsearchAssertions.java
index f731be8e54..2628d8f0b9 100644
--- a/server/src/test/java/org/elasticsearch/test/hamcrest/ElasticsearchAssertions.java
+++ b/server/src/test/java/org/elasticsearch/test/hamcrest/ElasticsearchAssertions.java
@@ -61,13 +61,10 @@ import static org.hamcrest.CoreMatchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
 import static org.hamcrest.Matchers.greaterThan;
 import static org.hamcrest.Matchers.hasItem;
-import static org.hamcrest.Matchers.hasKey;
 import static org.hamcrest.Matchers.instanceOf;
 import static org.hamcrest.Matchers.not;
-import static org.hamcrest.Matchers.notNullValue;
 import static org.junit.Assert.assertArrayEquals;
 import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
diff --git a/server/src/test/java/org/elasticsearch/test/store/MockFSDirectoryFactory.java b/server/src/test/java/org/elasticsearch/test/store/MockFSDirectoryFactory.java
index 8ba25857ed..c2484e0c28 100644
--- a/server/src/test/java/org/elasticsearch/test/store/MockFSDirectoryFactory.java
+++ b/server/src/test/java/org/elasticsearch/test/store/MockFSDirectoryFactory.java
@@ -19,19 +19,16 @@
 
 package org.elasticsearch.test.store;
 
-import com.carrotsearch.randomizedtesting.SeedUtils;
 import com.carrotsearch.randomizedtesting.generators.RandomPicks;
 import org.apache.logging.log4j.Logger;
 import org.apache.lucene.index.CheckIndex;
 import org.apache.lucene.store.BaseDirectoryWrapper;
 import org.apache.lucene.store.Directory;
-import org.apache.lucene.store.LockFactory;
 import org.apache.lucene.store.LockObtainFailedException;
 import org.apache.lucene.store.MockDirectoryWrapper;
 import org.apache.lucene.util.LuceneTestCase;
 import org.apache.lucene.util.TestRuleMarkFailure;
 import org.elasticsearch.cluster.metadata.IndexMetadata;
-import org.elasticsearch.common.inject.Inject;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
 import org.elasticsearch.common.lucene.Lucene;
 import org.elasticsearch.common.settings.Setting;
@@ -52,7 +49,6 @@ import java.io.Closeable;
 import java.io.IOException;
 import java.io.PrintStream;
 import java.nio.charset.StandardCharsets;
-import java.nio.file.Path;
 import java.util.Arrays;
 import java.util.Random;
 
diff --git a/server/src/test/java/org/elasticsearch/test/store/MockFSIndexStore.java b/server/src/test/java/org/elasticsearch/test/store/MockFSIndexStore.java
index 7e3e302ddb..d32249f32b 100644
--- a/server/src/test/java/org/elasticsearch/test/store/MockFSIndexStore.java
+++ b/server/src/test/java/org/elasticsearch/test/store/MockFSIndexStore.java
@@ -26,13 +26,10 @@ import org.elasticsearch.common.settings.Setting;
 import org.elasticsearch.common.settings.Setting.Property;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.index.IndexModule;
-import org.elasticsearch.index.IndexSettings;
 import org.elasticsearch.index.shard.IndexEventListener;
 import org.elasticsearch.index.shard.IndexShard;
 import org.elasticsearch.index.shard.IndexShardState;
 import org.elasticsearch.index.shard.ShardId;
-import org.elasticsearch.index.shard.ShardPath;
-import org.elasticsearch.index.store.DirectoryService;
 import org.elasticsearch.plugins.IndexStorePlugin;
 import org.elasticsearch.plugins.Plugin;
 
@@ -42,7 +39,6 @@ import java.util.EnumSet;
 import java.util.IdentityHashMap;
 import java.util.List;
 import java.util.Map;
-import java.util.function.Function;
 
 public final class MockFSIndexStore {
 
diff --git a/server/src/test/java/org/elasticsearch/test/tasks/MockTaskManager.java b/server/src/test/java/org/elasticsearch/test/tasks/MockTaskManager.java
index 2482081b34..8103bc353c 100644
--- a/server/src/test/java/org/elasticsearch/test/tasks/MockTaskManager.java
+++ b/server/src/test/java/org/elasticsearch/test/tasks/MockTaskManager.java
@@ -32,7 +32,6 @@ import org.elasticsearch.tasks.TaskManager;
 import org.elasticsearch.threadpool.ThreadPool;
 
 import java.util.Collection;
-import java.util.Set;
 import java.util.concurrent.CopyOnWriteArrayList;
 
 /**
diff --git a/server/src/test/java/org/elasticsearch/test/transport/MockTransport.java b/server/src/test/java/org/elasticsearch/test/transport/MockTransport.java
index 7e29040cc4..e52e89907c 100644
--- a/server/src/test/java/org/elasticsearch/test/transport/MockTransport.java
+++ b/server/src/test/java/org/elasticsearch/test/transport/MockTransport.java
@@ -30,7 +30,6 @@ import org.elasticsearch.common.component.LifecycleListener;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
 import org.elasticsearch.common.io.stream.NamedWriteableAwareStreamInput;
 import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
-import org.elasticsearch.common.lease.Releasable;
 import org.elasticsearch.common.settings.ClusterSettings;
 import org.elasticsearch.common.settings.Settings;
 import org.elasticsearch.common.transport.BoundTransportAddress;
diff --git a/server/src/test/java/org/elasticsearch/test/transport/MockTransportService.java b/server/src/test/java/org/elasticsearch/test/transport/MockTransportService.java
index c2fcc71587..97891eed7c 100644
--- a/server/src/test/java/org/elasticsearch/test/transport/MockTransportService.java
+++ b/server/src/test/java/org/elasticsearch/test/transport/MockTransportService.java
@@ -28,7 +28,6 @@ import javax.annotation.Nullable;
 import org.elasticsearch.common.UUIDs;
 import org.elasticsearch.common.io.stream.BytesStreamOutput;
 import org.elasticsearch.common.io.stream.NamedWriteableRegistry;
-import org.elasticsearch.common.lease.Releasable;
 import org.elasticsearch.common.network.NetworkService;
 import org.elasticsearch.common.settings.ClusterSettings;
 import org.elasticsearch.common.settings.Setting;
diff --git a/server/src/test/java/org/elasticsearch/transport/OutboundHandlerTests.java b/server/src/test/java/org/elasticsearch/transport/OutboundHandlerTests.java
index 4f2232a3cf..b0955b0f45 100644
--- a/server/src/test/java/org/elasticsearch/transport/OutboundHandlerTests.java
+++ b/server/src/test/java/org/elasticsearch/transport/OutboundHandlerTests.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.transport;
 
 import static org.hamcrest.CoreMatchers.instanceOf;
-import static org.hamcrest.Matchers.contains;
 
 import java.io.IOException;
 import java.nio.charset.StandardCharsets;
@@ -41,7 +40,6 @@ import org.elasticsearch.common.io.stream.StreamInput;
 import org.elasticsearch.common.io.stream.StreamOutput;
 import org.elasticsearch.common.transport.TransportAddress;
 import org.elasticsearch.common.util.BigArrays;
-import org.elasticsearch.common.util.concurrent.ThreadContext;
 import org.elasticsearch.test.ESTestCase;
 import org.elasticsearch.threadpool.TestThreadPool;
 import org.elasticsearch.threadpool.ThreadPool;
diff --git a/server/src/test/java/org/elasticsearch/transport/TcpTransportTest.java b/server/src/test/java/org/elasticsearch/transport/TcpTransportTest.java
index 7f541a0208..51d96052e2 100644
--- a/server/src/test/java/org/elasticsearch/transport/TcpTransportTest.java
+++ b/server/src/test/java/org/elasticsearch/transport/TcpTransportTest.java
@@ -20,7 +20,6 @@
 package org.elasticsearch.transport;
 
 import org.elasticsearch.Version;
-import org.elasticsearch.action.ActionListener;
 import org.elasticsearch.cluster.node.DiscoveryNode;
 import org.elasticsearch.common.network.NetworkService;
 import org.elasticsearch.common.settings.Settings;
diff --git a/server/src/test/java/org/elasticsearch/transport/TransportKeepAliveTests.java b/server/src/test/java/org/elasticsearch/transport/TransportKeepAliveTests.java
index 47c9bb7cd1..ad122a3e06 100644
--- a/server/src/test/java/org/elasticsearch/transport/TransportKeepAliveTests.java
+++ b/server/src/test/java/org/elasticsearch/transport/TransportKeepAliveTests.java
@@ -30,7 +30,6 @@ import java.util.ArrayDeque;
 import java.util.Arrays;
 import java.util.Collections;
 import java.util.Deque;
-import java.util.concurrent.ScheduledFuture;
 
 import org.elasticsearch.common.AsyncBiFunction;
 import org.elasticsearch.common.bytes.BytesReference;",Remove unused imports in test code,Remove unused imports,"""Remove unused imports and classes""","""Update dependencies and make code improvements""

This commit updates various dependencies, such as the version of Netty used in CrateDB, and makes several code improvements, including:

* Removing unused imports and code
* Adding new tests and improving existing ones
* Fixing minor bugs and improving error handling
* Improving documentation and comments

Overall, this commit aims to improve the reliability and maintainability of the codebase.","""Remove unused imports across multiple test and main Java files to clean up the codebase. No functional changes.""",Model 3
"diff --git a/src/main/java/com/google/devtools/build/lib/rules/android/AndroidConfiguration.java b/src/main/java/com/google/devtools/build/lib/rules/android/AndroidConfiguration.java
index bc697ce828..49b8006280 100644
--- a/src/main/java/com/google/devtools/build/lib/rules/android/AndroidConfiguration.java
+++ b/src/main/java/com/google/devtools/build/lib/rules/android/AndroidConfiguration.java
@@ -708,7 +708,7 @@ public class AndroidConfiguration extends BuildConfiguration.Fragment
 
     @Option(
         name = ""android_aapt"",
-        defaultValue = ""auto"",
+        defaultValue = ""aapt2"",
         documentationCategory = OptionDocumentationCategory.TOOLCHAIN,
         effectTags = {
           OptionEffectTag.AFFECTS_OUTPUTS,
@@ -968,7 +968,7 @@ public class AndroidConfiguration extends BuildConfiguration.Fragment
           OptionMetadataTag.INCOMPATIBLE_CHANGE,
           OptionMetadataTag.TRIGGERED_BY_ALL_INCOMPATIBLE_CHANGES
         },
-        defaultValue = ""false"",
+        defaultValue = ""true"",
         help =
             ""Switch the Android rules to use aapt2 by default for resource processing. ""
                 + ""To resolve issues when migrating your app to build with aapt2, see ""
diff --git a/src/main/java/com/google/devtools/build/lib/rules/android/AndroidRuleClasses.java b/src/main/java/com/google/devtools/build/lib/rules/android/AndroidRuleClasses.java
index df2a7a855e..8c083a4457 100644
--- a/src/main/java/com/google/devtools/build/lib/rules/android/AndroidRuleClasses.java
+++ b/src/main/java/com/google/devtools/build/lib/rules/android/AndroidRuleClasses.java
@@ -856,6 +856,9 @@ public final class AndroidRuleClasses {
           .add(attr(""manifest_values"", STRING_DICT))
           /* <!-- #BLAZE_RULE(android_binary).ATTRIBUTE(aapt_version) -->
           Select the version of aapt for this rule.<br/>
+
+          This attribute only takes effect if you set `--android_aapt=auto`.<br/>
+
           Possible values:
           <ul>
               <li><code>aapt_version = ""aapt""</code>: Use aapt (deprecated).</li>
diff --git a/src/test/java/com/google/devtools/build/lib/analysis/mock/BazelAnalysisMock.java b/src/test/java/com/google/devtools/build/lib/analysis/mock/BazelAnalysisMock.java
index 7d3d892d5e..2ff576ef11 100644
--- a/src/test/java/com/google/devtools/build/lib/analysis/mock/BazelAnalysisMock.java
+++ b/src/test/java/com/google/devtools/build/lib/analysis/mock/BazelAnalysisMock.java
@@ -348,6 +348,7 @@ public final class BazelAnalysisMock extends AnalysisMock {
         ""android_sdk("",
         ""    name = 'sdk',"",
         ""    aapt = ':static_aapt_tool',"",
+        ""    aapt2 = ':static_aapt2_tool',"",
         ""    adb = ':static_adb_tool',"",
         ""    aidl = ':static_aidl_tool',"",
         ""    android_jar = ':android_runtime_jar',"",
diff --git a/src/test/java/com/google/devtools/build/lib/rules/android/AndroidAssetsTest.java b/src/test/java/com/google/devtools/build/lib/rules/android/AndroidAssetsTest.java
index 3d47cb9b8e..d714a3dee8 100644
--- a/src/test/java/com/google/devtools/build/lib/rules/android/AndroidAssetsTest.java
+++ b/src/test/java/com/google/devtools/build/lib/rules/android/AndroidAssetsTest.java
@@ -57,9 +57,6 @@ public class AndroidAssetsTest extends ResourceTestBase {
 
   @Test
   public void testParseAapt2() throws Exception {
-    mockAndroidSdkWithAapt2();
-    useConfiguration(""--android_sdk=//sdk:sdk"");
-
     RuleContext ruleContext = getRuleContext();
     AndroidAssets assets = getLocalAssets();
 
@@ -158,9 +155,6 @@ public class AndroidAssetsTest extends ResourceTestBase {
 
   @Test
   public void testMergeAapt2() throws Exception {
-    mockAndroidSdkWithAapt2();
-    useConfiguration(""--android_sdk=//sdk:sdk"");
-
     RuleContext ruleContext = getRuleContext();
     ParsedAndroidAssets parsed =
         getLocalAssets().parse(AndroidDataContext.forNative(ruleContext), AndroidAaptVersion.AAPT2);
diff --git a/src/test/java/com/google/devtools/build/lib/rules/android/AndroidBinaryTest.java b/src/test/java/com/google/devtools/build/lib/rules/android/AndroidBinaryTest.java
index ed7a4903a0..e1d51406af 100644
--- a/src/test/java/com/google/devtools/build/lib/rules/android/AndroidBinaryTest.java
+++ b/src/test/java/com/google/devtools/build/lib/rules/android/AndroidBinaryTest.java
@@ -877,6 +877,8 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
 
   @Test
   public void testResourceShrinkingAction() throws Exception {
+    useConfiguration(""--android_aapt=aapt"");
+
     scratch.file(""java/com/google/android/hello/BUILD"",
         ""android_binary(name = 'hello',"",
         ""               srcs = ['Foo.java'],"",
@@ -933,8 +935,9 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
   }
 
   @Test
-  public void testResourceCycleShrinking() throws Exception {
-    useConfiguration(""--experimental_android_resource_cycle_shrinking=true"");
+  public void testResourceCycleShrinkingWithAapt() throws Exception {
+    useConfiguration(""--android_aapt=aapt"", ""--experimental_android_resource_cycle_shrinking=true"");
+
     checkError(
         ""java/a"",
         ""a"",
@@ -1326,6 +1329,9 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
 
   @Test
   public void testFilteredResourcesInvalidFilter() throws Exception {
+    // This test is an analysis-time check with aapt.
+    useConfiguration(""--android_aapt=aapt"");
+
     String badQualifier = ""invalid-qualifier"";
 
     checkError(
@@ -1340,6 +1346,9 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
 
   @Test
   public void testFilteredResourcesInvalidResourceDir() throws Exception {
+    // This test is an analysis-time check with aapt.
+    useConfiguration(""--android_aapt=aapt"");
+
     String badQualifierDir = ""values-invalid-qualifier"";
 
     checkError(
@@ -1359,10 +1368,6 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
         ImmutableList.of(""res/values/foo.xml"", ""res/values-en/foo.xml"", ""res/values-fr/foo.xml"");
     String dir = ""java/r/android"";
 
-    mockAndroidSdkWithAapt2();
-
-    useConfiguration(""--android_sdk=//sdk:sdk"");
-
     ConfiguredTarget binary =
         scratchConfiguredTarget(
             dir,
@@ -1390,6 +1395,8 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
 
   @Test
   public void testFilteredResourcesSimple() throws Exception {
+    useConfiguration(""--android_aapt=aapt"");
+
     testDirectResourceFiltering(
         ""en"",
         /* unexpectedQualifiers= */ ImmutableList.of(""fr""),
@@ -1678,6 +1685,8 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
       String folderType,
       String suffix)
       throws Exception {
+    // Filtering is done at the analysis time for aapt.
+    useConfiguration(""--android_aapt=aapt"");
 
     List<String> unexpectedResources = new ArrayList<>();
     for (String qualifier : unexpectedQualifiers) {
@@ -1757,6 +1766,9 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
 
   @Test
   public void testFilteredTransitiveResources() throws Exception {
+    // Filtering is done at analysis time for aapt.
+    useConfiguration(""--android_aapt=aapt"");
+
     String matchingResource = ""res/values-en/foo.xml"";
     String unqualifiedResource = ""res/values/foo.xml"";
     String notMatchingResource = ""res/values-fr/foo.xml"";
@@ -1799,6 +1811,9 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
 
   @Test
   public void testFilteredTransitiveResourcesDifferentDensities() throws Exception {
+    // Filtering is done at analysis time for aapt.
+    useConfiguration(""--android_aapt=aapt"");
+
     String dir = ""java/r/android"";
 
     ConfiguredTarget binary =
@@ -1846,6 +1861,9 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
 
   @Test
   public void testFilteredResourcesAllFilteredOut() throws Exception {
+    // Filtering is done at analysis time for aapt.
+    useConfiguration(""--android_aapt=aapt"");
+
     String dir = ""java/r/android"";
 
     final String keptBaseDir = ""partly_filtered_dir"";
@@ -2081,6 +2099,9 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
 
   @Test
   public void testUseRClassGeneratorMultipleDeps() throws Exception {
+    // This test assumes using aapt.
+    useConfiguration(""--android_aapt=aapt"");
+
     scratch.file(
         ""java/r/android/BUILD"",
         ""android_library(name = 'lib1',"",
@@ -2515,6 +2536,7 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
         ""android_sdk("",
         ""    name = 'sdk',"",
         ""    aapt = 'aapt',"",
+        ""    aapt2 = 'aapt2',"",
         ""    adb = 'adb',"",
         ""    aidl = 'aidl',"",
         ""    android_jar = 'android.jar',"",
@@ -2553,6 +2575,7 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
         ""    name = 'sdk',"",
         ""    build_tools_version = '24.0.0',"",
         ""    aapt = 'aapt',"",
+        ""    aapt2 = 'aapt2',"",
         ""    adb = 'adb',"",
         ""    aidl = 'aidl',"",
         ""    android_jar = 'android.jar',"",
@@ -3562,40 +3585,8 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
     assertContainsEvent(""*super* busted package group"");
   }
 
-  @Test
-  public void testAapt2WithoutAndroidSdk() throws Exception {
-    useConfiguration(""--android_aapt=aapt2"");
-    checkError(
-        ""java/a"",
-        ""a"",
-        ""aapt2 processing requested but not available on the android_sdk"",
-        ""android_binary("",
-        ""    name = 'a',"",
-        ""    srcs = ['A.java'],"",
-        ""    manifest = 'AndroidManifest.xml',"",
-        ""    resource_files = [ 'res/values/values.xml' ], "",
-        ""    aapt_version = 'aapt2'"",
-        "")"");
-  }
-
-  @Test
-  public void testAapt2FlagWithoutAndroidSdk() throws Exception {
-    useConfiguration(""--android_aapt=aapt2"");
-    checkError(
-        ""java/a"",
-        ""a"",
-        ""aapt2 processing requested but not available on the android_sdk"",
-        ""android_binary("",
-        ""    name = 'a',"",
-        ""    srcs = ['A.java'],"",
-        ""    manifest = 'AndroidManifest.xml',"",
-        ""    resource_files = [ 'res/values/values.xml' ], "",
-        "")"");
-  }
-
   @Test
   public void testAapt2WithAndroidSdk() throws Exception {
-    mockAndroidSdkWithAapt2();
     scratch.file(
         ""java/a/BUILD"",
         ""android_binary("",
@@ -3606,17 +3597,20 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
         ""    aapt_version = 'aapt2'"",
         "")"");
 
-    useConfiguration(""--android_sdk=//sdk:sdk"");
     ConfiguredTarget a = getConfiguredTarget(""//java/a:a"");
     Artifact apk = getImplicitOutputArtifact(a, AndroidRuleClasses.ANDROID_RESOURCES_APK);
 
     assertThat(getGeneratingSpawnActionArgs(apk))
-        .containsAtLeast(""--aapt2"", ""sdk/aapt2"", ""--tool"", ""AAPT2_PACKAGE"");
+        .containsAtLeast(
+            ""--aapt2"",
+            // The path to aapt2 is different between Blaze and Bazel, so we omit it here.
+            // It's safe to do so as we've already checked for the `--aapt2` flag.
+            ""--tool"",
+            ""AAPT2_PACKAGE"");
   }
 
   @Test
   public void testAapt2WithAndroidSdkAndDependencies() throws Exception {
-    mockAndroidSdkWithAapt2();
     scratch.file(
         ""java/b/BUILD"",
         ""android_library("",
@@ -3637,7 +3631,6 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
         ""    aapt_version = 'aapt2'"",
         "")"");
 
-    useConfiguration(""--android_sdk=//sdk:sdk"");
     ConfiguredTarget a = getConfiguredTarget(""//java/a:a"");
     ConfiguredTarget b = getDirectPrerequisite(a, ""//java/b:b"");
 
@@ -3648,7 +3641,12 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
 
     SpawnAction apkAction = getGeneratingSpawnAction(apk);
     assertThat(getGeneratingSpawnActionArgs(apk))
-        .containsAtLeast(""--aapt2"", ""sdk/aapt2"", ""--tool"", ""AAPT2_PACKAGE"");
+        .containsAtLeast(
+            ""--aapt2"",
+            // The path to aapt2 is different between Blaze and Bazel, so we omit it here.
+            // It's safe to do so as we've already checked for the `--aapt2` flag.
+            ""--tool"",
+            ""AAPT2_PACKAGE"");
 
     assertThat(apkAction.getInputs())
         .contains(
@@ -3662,7 +3660,6 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
 
   @Test
   public void testAapt2ResourceShrinkingAction() throws Exception {
-    mockAndroidSdkWithAapt2();
     scratch.file(
         ""java/com/google/android/hello/BUILD"",
         ""android_binary(name = 'hello',"",
@@ -3674,7 +3671,6 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
         ""               shrink_resources = 1,"",
         ""               proguard_specs = ['proguard-spec.pro'],)"");
 
-    useConfiguration(""--android_sdk=//sdk:sdk"");
     ConfiguredTargetAndData targetAndData =
         getConfiguredTargetAndData(""//java/com/google/android/hello:hello"");
     ConfiguredTarget binary = targetAndData.getConfiguredTarget();
@@ -3726,9 +3722,7 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
 
   @Test
   public void testAapt2ResourceCycleShrinking() throws Exception {
-    mockAndroidSdkWithAapt2();
-    useConfiguration(
-        ""--android_sdk=//sdk:sdk"", ""--experimental_android_resource_cycle_shrinking=true"");
+    useConfiguration(""--experimental_android_resource_cycle_shrinking=true"");
     scratch.file(
         ""java/com/google/android/hello/BUILD"",
         ""android_binary(name = 'hello',"",
@@ -3759,9 +3753,7 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
 
   @Test
   public void testAapt2ResourceCycleShinkingWithoutResourceShrinking() throws Exception {
-    mockAndroidSdkWithAapt2();
-    useConfiguration(
-        ""--android_sdk=//sdk:sdk"", ""--experimental_android_resource_cycle_shrinking=true"");
+    useConfiguration(""--experimental_android_resource_cycle_shrinking=true"");
     checkError(
         ""java/a"",
         ""a"",
@@ -4324,7 +4316,6 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
 
   @Test
   public void testSkipParsingActionFlagGetsPropagated() throws Exception {
-    mockAndroidSdkWithAapt2();
     scratch.file(
         ""java/b/BUILD"",
         ""android_library("",
@@ -4345,7 +4336,7 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
         ""    aapt_version = 'aapt2'"",
         "")"");
 
-    useConfiguration(""--android_sdk=//sdk:sdk"", ""--experimental_skip_parsing_action"");
+    useConfiguration(""--experimental_skip_parsing_action"");
     ConfiguredTarget a = getConfiguredTarget(""//java/a:a"");
     ConfiguredTarget b = getDirectPrerequisite(a, ""//java/b:b"");
 
@@ -4368,7 +4359,6 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
 
   @Test
   public void alwaysSkipParsingActionWithAapt2() throws Exception {
-    mockAndroidSdkWithAapt2();
     scratch.file(
         ""java/b/BUILD"",
         ""android_library("",
@@ -4389,7 +4379,6 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
         ""    aapt_version = 'aapt2'"",
         "")"");
 
-    useConfiguration(""--android_sdk=//sdk:sdk"");
     ConfiguredTarget a = getConfiguredTarget(""//java/a:a"");
     ConfiguredTarget b = getDirectPrerequisite(a, ""//java/b:b"");
 
@@ -4412,7 +4401,6 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
 
   @Test
   public void testAapt1BuildsWithAapt2Sdk() throws Exception {
-    mockAndroidSdkWithAapt2();
     scratch.file(
         ""java/b/BUILD"",
         ""android_library("",
@@ -4433,7 +4421,7 @@ public class AndroidBinaryTest extends AndroidBuildViewTestCase {
         ""    aapt_version = 'aapt'"",
         "")"");
 
-    useConfiguration(""--android_sdk=//sdk:sdk"", ""--experimental_skip_parsing_action"");
+    useConfiguration(""--android_aapt=aapt"", ""--experimental_skip_parsing_action"");
     ConfiguredTarget a = getConfiguredTarget(""//java/a:a"");
     ConfiguredTarget b = getDirectPrerequisite(a, ""//java/b:b"");
 
diff --git a/src/test/java/com/google/devtools/build/lib/rules/android/AndroidBuildViewTestCase.java b/src/test/java/com/google/devtools/build/lib/rules/android/AndroidBuildViewTestCase.java
index a321f3cba8..4cc956a302 100644
--- a/src/test/java/com/google/devtools/build/lib/rules/android/AndroidBuildViewTestCase.java
+++ b/src/test/java/com/google/devtools/build/lib/rules/android/AndroidBuildViewTestCase.java
@@ -52,19 +52,10 @@ import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import javax.annotation.Nullable;
-import org.junit.Before;
 
 /** Common methods shared between Android related {@link BuildViewTestCase}s. */
 public abstract class AndroidBuildViewTestCase extends BuildViewTestCase {
 
-  @Before
-  public void setup() throws Exception {
-    // Force tests to use aapt to unblock global aapt2 migration, until these
-    // tests are migrated to use aapt2.
-    // TODO(jingwen): https://github.com/bazelbuild/bazel/issues/6907
-    useConfiguration(""--android_aapt=aapt"");
-  }
-
   protected Iterable<Artifact> getNativeLibrariesInApk(ConfiguredTarget target) {
     return Iterables.filter(
         getGeneratingAction(getCompressedUnsignedApk(target)).getInputs(),
@@ -455,31 +446,4 @@ public abstract class AndroidBuildViewTestCase extends BuildViewTestCase {
         .isNull();
   }
 
-  /**
-   * Creates a mock SDK with aapt2.
-   *
-   * <p>You'll need to use a configuration pointing to it, such as ""--android_sdk=//sdk:sdk"", to use
-   * it.
-   */
-  public void mockAndroidSdkWithAapt2() throws Exception {
-    scratch.file(
-        ""sdk/BUILD"",
-        ""android_sdk("",
-        ""    name = 'sdk',"",
-        ""    aapt = 'aapt',"",
-        ""    aapt2 = 'aapt2',"",
-        ""    adb = 'adb',"",
-        ""    aidl = 'aidl',"",
-        ""    android_jar = 'android.jar',"",
-        ""    apksigner = 'apksigner',"",
-        ""    dx = 'dx',"",
-        ""    framework_aidl = 'framework_aidl',"",
-        ""    main_dex_classes = 'main_dex_classes',"",
-        ""    main_dex_list_creator = 'main_dex_list_creator',"",
-        ""    proguard = 'proguard',"",
-        ""    shrinked_android_jar = 'shrinked_android_jar',"",
-        ""    zipalign = 'zipalign',"",
-        ""    tags = ['__ANDROID_RULES_MIGRATION__'],"",
-        "")"");
-  }
 }
diff --git a/src/test/java/com/google/devtools/build/lib/rules/android/AndroidCommonTest.java b/src/test/java/com/google/devtools/build/lib/rules/android/AndroidCommonTest.java
index c317b429b9..81de74ddaf 100644
--- a/src/test/java/com/google/devtools/build/lib/rules/android/AndroidCommonTest.java
+++ b/src/test/java/com/google/devtools/build/lib/rules/android/AndroidCommonTest.java
@@ -38,14 +38,6 @@ public class AndroidCommonTest extends BuildViewTestCase {
     scratch.file(""java/srcs/a.properties"", ""foo"");
   }
 
-  @Before
-  public void setup() throws Exception {
-    // Force tests to use aapt to unblock global aapt2 migration, until these
-    // tests are migrated to use aapt2.
-    // TODO(jingwen): https://github.com/bazelbuild/bazel/issues/6907
-    useConfiguration(""--android_aapt=aapt"");
-  }
-
   // regression test for #3169099
   @Test
   public void testLibrarySrcs() throws Exception {
diff --git a/src/test/java/com/google/devtools/build/lib/rules/android/AndroidLibraryTest.java b/src/test/java/com/google/devtools/build/lib/rules/android/AndroidLibraryTest.java
index 96dd324b99..974e1359bd 100644
--- a/src/test/java/com/google/devtools/build/lib/rules/android/AndroidLibraryTest.java
+++ b/src/test/java/com/google/devtools/build/lib/rules/android/AndroidLibraryTest.java
@@ -842,6 +842,7 @@ public class AndroidLibraryTest extends AndroidBuildViewTestCase {
         ""android_sdk("",
         ""    name = 'sdk',"",
         ""    aapt = 'aapt',"",
+        ""    aapt2 = 'aapt2',"",
         ""    adb = 'adb',"",
         ""    aidl = 'aidl',"",
         ""    aidl_lib = ':aidl_lib',"",
@@ -1392,7 +1393,7 @@ public class AndroidLibraryTest extends AndroidBuildViewTestCase {
                 .getActionForArtifactEndingWith(artifacts,
                     ""/"" + resources.getJavaSourceJar().getFilename());
     assertThat(resourceParserAction.getMnemonic()).isEqualTo(""AndroidResourceParser"");
-    assertThat(resourceClassJarAction.getMnemonic()).isEqualTo(""AndroidResourceMerger"");
+    assertThat(resourceClassJarAction.getMnemonic()).isEqualTo(""AndroidCompiledResourceMerger"");
     assertThat(resourceSrcJarAction.getMnemonic()).isEqualTo(""AndroidResourceValidator"");
     // Validator also generates an R.txt.
     assertThat(resourceSrcJarAction.getOutputs()).contains(resources.getRTxt());
diff --git a/src/test/java/com/google/devtools/build/lib/rules/android/AndroidResourcesTest.java b/src/test/java/com/google/devtools/build/lib/rules/android/AndroidResourcesTest.java
index 08b79d0bfc..6b4f2a3fc9 100644
--- a/src/test/java/com/google/devtools/build/lib/rules/android/AndroidResourcesTest.java
+++ b/src/test/java/com/google/devtools/build/lib/rules/android/AndroidResourcesTest.java
@@ -230,15 +230,14 @@ public class AndroidResourcesTest extends ResourceTestBase {
 
   @Test
   public void testParseNoCompile() throws Exception {
-    useConfiguration(""--android_aapt=aapt"");
-
     RuleContext ruleContext = getRuleContext();
     ParsedAndroidResources parsed =
         assertParse(
             ruleContext,
             DataBinding.contextFrom(
                 ruleContext,
-                ruleContext.getConfiguration().getFragment(AndroidConfiguration.class)));
+                ruleContext.getConfiguration().getFragment(AndroidConfiguration.class)),
+            AndroidAaptVersion.AAPT);
 
     // Since we are not using aapt2, there should be no compiled symbols
     assertThat(parsed.getCompiledSymbols()).isNull();
@@ -252,11 +251,8 @@ public class AndroidResourcesTest extends ResourceTestBase {
 
   @Test
   public void testParseAndCompile() throws Exception {
-    mockAndroidSdkWithAapt2();
-    useConfiguration(""--android_sdk=//sdk:sdk"", ""--android_aapt=aapt2"");
-
     RuleContext ruleContext = getRuleContext();
-    ParsedAndroidResources parsed = assertParse(ruleContext);
+    ParsedAndroidResources parsed = assertParse(ruleContext, AndroidAaptVersion.AAPT2);
 
     assertThat(parsed.getCompiledSymbols()).isNotNull();
 
@@ -276,12 +272,9 @@ public class AndroidResourcesTest extends ResourceTestBase {
 
   @Test
   public void testParseWithDataBinding() throws Exception {
-    mockAndroidSdkWithAapt2();
-    useConfiguration(""--android_sdk=//sdk:sdk"", ""--android_aapt=aapt2"");
-
     RuleContext ruleContext = getRuleContextWithDataBinding();
 
-    ParsedAndroidResources parsed = assertParse(ruleContext);
+    ParsedAndroidResources parsed = assertParse(ruleContext, AndroidAaptVersion.AAPT2);
 
     // The parse action should take resources and busybox artifacts in and output symbols
     assertActionArtifacts(
@@ -304,15 +297,13 @@ public class AndroidResourcesTest extends ResourceTestBase {
 
   @Test
   public void testMergeDataBinding() throws Exception {
-    useConfiguration(""--android_aapt=aapt"");
-
     RuleContext ruleContext = getRuleContextWithDataBinding();
-    ParsedAndroidResources parsed = assertParse(ruleContext);
+    ParsedAndroidResources parsed = assertParse(ruleContext, AndroidAaptVersion.AAPT);
     MergedAndroidResources merged =
         parsed.merge(
             AndroidDataContext.forNative(ruleContext),
             ResourceDependencies.empty(),
-            AndroidAaptVersion.chooseTargetAaptVersion(ruleContext));
+            AndroidAaptVersion.AAPT);
 
     // Besides processed manifest, inherited values should be equal
     assertThat(parsed).isEqualTo(new ParsedAndroidResources(merged, parsed.getStampedManifest()));
@@ -338,12 +329,10 @@ public class AndroidResourcesTest extends ResourceTestBase {
 
   @Test
   public void testMergeCompiled() throws Exception {
-    mockAndroidSdkWithAapt2();
-    useConfiguration(
-        ""--android_sdk=//sdk:sdk"", ""--android_aapt=aapt2"", ""--experimental_skip_parsing_action"");
+    useConfiguration(""--experimental_skip_parsing_action"");
 
     RuleContext ruleContext = getRuleContext();
-    ParsedAndroidResources parsed = assertParse(ruleContext);
+    ParsedAndroidResources parsed = assertParse(ruleContext, AndroidAaptVersion.AAPT2);
     MergedAndroidResources merged =
         parsed.merge(
             AndroidDataContext.forNative(ruleContext),
@@ -382,14 +371,11 @@ public class AndroidResourcesTest extends ResourceTestBase {
 
   @Test
   public void testValidateAapt() throws Exception {
-    useConfiguration(""--android_aapt=aapt"");
     RuleContext ruleContext = getRuleContext();
 
-    MergedAndroidResources merged = makeMergedResources(ruleContext);
+    MergedAndroidResources merged = makeMergedResources(ruleContext, AndroidAaptVersion.AAPT);
     ValidatedAndroidResources validated =
-        merged.validate(
-            AndroidDataContext.forNative(ruleContext),
-            AndroidAaptVersion.chooseTargetAaptVersion(ruleContext));
+        merged.validate(AndroidDataContext.forNative(ruleContext), AndroidAaptVersion.AAPT);
 
     // Inherited values should be equal
     assertThat(merged).isEqualTo(new MergedAndroidResources(validated));
@@ -410,15 +396,11 @@ public class AndroidResourcesTest extends ResourceTestBase {
 
   @Test
   public void testValidateAapt2() throws Exception {
-    mockAndroidSdkWithAapt2();
-    useConfiguration(""--android_sdk=//sdk:sdk"", ""--android_aapt=aapt2"");
     RuleContext ruleContext = getRuleContext();
 
-    MergedAndroidResources merged = makeMergedResources(ruleContext);
+    MergedAndroidResources merged = makeMergedResources(ruleContext, AndroidAaptVersion.AAPT2);
     ValidatedAndroidResources validated =
-        merged.validate(
-            AndroidDataContext.forNative(ruleContext),
-            AndroidAaptVersion.chooseTargetAaptVersion(ruleContext));
+        merged.validate(AndroidDataContext.forNative(ruleContext), AndroidAaptVersion.AAPT2);
 
     // Inherited values should be equal
     assertThat(merged).isEqualTo(new MergedAndroidResources(validated));
@@ -458,12 +440,12 @@ public class AndroidResourcesTest extends ResourceTestBase {
 
     ProcessedAndroidData processedData =
         ProcessedAndroidData.of(
-            makeParsedResources(ruleContext),
+            makeParsedResources(ruleContext, AndroidAaptVersion.AAPT),
             AndroidAssets.from(ruleContext)
                 .process(
                     AndroidDataContext.forNative(ruleContext),
                     AssetDependencies.empty(),
-                    AndroidAaptVersion.chooseTargetAaptVersion(ruleContext)),
+                    AndroidAaptVersion.AAPT),
             manifest,
             rTxt,
             ruleContext.getImplicitOutputArtifact(AndroidRuleClasses.ANDROID_JAVA_SOURCE_JAR),
@@ -518,8 +500,7 @@ public class AndroidResourcesTest extends ResourceTestBase {
 
   @Test
   public void test_incompatibleUseAapt2ByDefaultEnabled_targetsAapt2() throws Exception {
-    mockAndroidSdkWithAapt2();
-    useConfiguration(""--android_sdk=//sdk:sdk"", ""--incompatible_use_aapt2_by_default"");
+    useConfiguration(""--incompatible_use_aapt2_by_default"");
     RuleContext ruleContext =
         getRuleContext(
             ""android_binary"", ""aapt_version = 'auto',"", ""manifest = 'AndroidManifest.xml',"");
@@ -527,30",Automated rollback of commit <issue_id> . . * * * Reason for rollback * * * .,Migrate Android rules to use aapt2 by default for resource processing.,"""Switch Android rules to use aapt2 by default for resource processing""","This commit updates the AndroidConfiguration class in the Bazel build system to use aapt2 as the default version for resource processing. It also adds a new option, `--incompatible_use_aapt2_by_default`, which enables this behavior. Additionally, it updates the documentation for the `aapt_version` attribute in the `android_binary` rule to clarify that it only takes effect when `--android_aapt=auto` is set. Finally, it updates a test to use the new default value for `--android_aapt`.",Set aapt2 as default for Android builds by updating configuration and removing aapt usage in tests.,Model 2
"diff --git a/app/src/main/java/com/termux/app/TermuxActivity.java b/app/src/main/java/com/termux/app/TermuxActivity.java
index 0fe5b5d..c0517b6 100644
--- a/app/src/main/java/com/termux/app/TermuxActivity.java
+++ b/app/src/main/java/com/termux/app/TermuxActivity.java
@@ -603,7 +603,9 @@ public final class TermuxActivity extends Activity implements ServiceConnection
             new AlertDialog.Builder(this).setTitle(R.string.max_terminals_reached_title).setMessage(R.string.max_terminals_reached_message)
                 .setPositiveButton(android.R.string.ok, null).show();
         } else {
-            TerminalSession newSession = mTermService.createTermSession(null, null, null, failSafe);
+            TerminalSession currentSession = getCurrentTermSession();
+            String workingDirectory = (currentSession == null) ? null : currentSession.getCwd();
+            TerminalSession newSession = mTermService.createTermSession(null, null, workingDirectory, failSafe);
             if (sessionName != null) {
                 newSession.mSessionName = sessionName;
             }
diff --git a/terminal-emulator/src/main/java/com/termux/terminal/TerminalSession.java b/terminal-emulator/src/main/java/com/termux/terminal/TerminalSession.java
index 5b82b0f..1743e84 100644
--- a/terminal-emulator/src/main/java/com/termux/terminal/TerminalSession.java
+++ b/terminal-emulator/src/main/java/com/termux/terminal/TerminalSession.java
@@ -8,6 +8,7 @@ import android.system.Os;
 import android.system.OsConstants;
 import android.util.Log;
 
+import java.io.File;
 import java.io.FileDescriptor;
 import java.io.FileInputStream;
 import java.io.FileOutputStream;
@@ -339,4 +340,25 @@ public final class TerminalSession extends TerminalOutput {
         return mShellPid;
     }
 
+    /** Returns the shell's working directory or null if it was unavailable. */
+    public String getCwd() {
+        if (mShellPid < 1) {
+            return null;
+        }
+        try {
+            final String cwdSymlink = String.format(""/proc/%s/cwd/"", mShellPid);
+            String outputPath = new File(cwdSymlink).getCanonicalPath();
+            if (!outputPath.endsWith(""/"")) {
+                outputPath += '/';
+            }
+            if (!cwdSymlink.equals(outputPath)) {
+                return outputPath;
+            }
+        } catch (IOException | SecurityException e) {
+            Log.e(EmulatorDebug.LOG_TAG, ""Error getting current directory"", e);
+        }
+        return null;
+    }
+
+
 }",Create new terminal sessions with directory of active session .,"""New terminal sessions now start in the current working directory""","""Improve handling of working directory when creating new terminal sessions""

This commit message accurately describes the changes made in the commit, which involve modifying the working directory when creating a new terminal session.","The commit message could be:

""Add functionality to get current working directory in TermuxActivity and TerminalSession""

Explanation:

The first part of the diff shows a change in TermuxActivity.java where a new variable 'workingDirectory' is added which gets the current working directory if a current session exists. This is then passed to the createTermSession method.

The second part of the diff shows a new method 'getCwd()' in TerminalSession.java which returns the current working directory of the shell.

Therefore, the commit message should reflect that these changes are related to getting the current working directory in both TermuxActivity and TerminalSession.","""Add working directory inheritance for new terminal sessions in TermuxActivity.""",Model 1
"diff --git a/src/main/java/com/xtremelabs/robolectric/Robolectric.java b/src/main/java/com/xtremelabs/robolectric/Robolectric.java
index 913b63168..9ca9696f5 100644
--- a/src/main/java/com/xtremelabs/robolectric/Robolectric.java
+++ b/src/main/java/com/xtremelabs/robolectric/Robolectric.java
@@ -1,17 +1,50 @@
 package com.xtremelabs.robolectric;
 
-import android.app.*;
+import android.app.Activity;
+import android.app.ActivityGroup;
+import android.app.ActivityManager;
+import android.app.AlarmManager;
+import android.app.AlertDialog;
+import android.app.Application;
+import android.app.Dialog;
+import android.app.KeyguardManager;
+import android.app.ListActivity;
+import android.app.Notification;
+import android.app.NotificationManager;
+import android.app.PendingIntent;
+import android.app.ProgressDialog;
+import android.app.Service;
 import android.appwidget.AppWidgetManager;
 import android.bluetooth.BluetoothAdapter;
 import android.bluetooth.BluetoothDevice;
-import android.content.*;
+import android.content.ContentResolver;
+import android.content.ContentValues;
+import android.content.Context;
+import android.content.ContextWrapper;
+import android.content.Intent;
 import android.content.pm.ResolveInfo;
 import android.content.res.AssetManager;
 import android.content.res.Configuration;
 import android.content.res.Resources;
-import android.database.sqlite.*;
-import android.graphics.*;
-import android.graphics.drawable.*;
+import android.database.sqlite.SQLiteCursor;
+import android.database.sqlite.SQLiteDatabase;
+import android.database.sqlite.SQLiteOpenHelper;
+import android.database.sqlite.SQLiteProgram;
+import android.database.sqlite.SQLiteQueryBuilder;
+import android.database.sqlite.SQLiteStatement;
+import android.graphics.Bitmap;
+import android.graphics.Canvas;
+import android.graphics.ColorMatrix;
+import android.graphics.Matrix;
+import android.graphics.Paint;
+import android.graphics.Path;
+import android.graphics.Rect;
+import android.graphics.drawable.BitmapDrawable;
+import android.graphics.drawable.ColorDrawable;
+import android.graphics.drawable.Drawable;
+import android.graphics.drawable.LayerDrawable;
+import android.graphics.drawable.ShapeDrawable;
+import android.graphics.drawable.StateListDrawable;
 import android.hardware.Camera;
 import android.hardware.SensorManager;
 import android.location.Geocoder;
@@ -23,19 +56,68 @@ import android.net.ConnectivityManager;
 import android.net.NetworkInfo;
 import android.net.wifi.WifiInfo;
 import android.net.wifi.WifiManager;
-import android.os.*;
-import android.preference.*;
+import android.os.Bundle;
+import android.os.CountDownTimer;
+import android.os.Handler;
+import android.os.HandlerThread;
+import android.os.Looper;
+import android.os.Parcel;
+import android.os.PowerManager;
+import android.os.ResultReceiver;
+import android.preference.DialogPreference;
+import android.preference.ListPreference;
+import android.preference.Preference;
+import android.preference.PreferenceActivity;
+import android.preference.PreferenceCategory;
+import android.preference.PreferenceGroup;
+import android.preference.PreferenceScreen;
 import android.telephony.SmsManager;
 import android.telephony.TelephonyManager;
 import android.text.ClipboardManager;
 import android.text.format.DateFormat;
 import android.text.method.PasswordTransformationMethod;
-import android.view.*;
+import android.view.Display;
+import android.view.LayoutInflater;
+import android.view.MenuInflater;
+import android.view.MotionEvent;
+import android.view.View;
+import android.view.ViewConfiguration;
+import android.view.ViewGroup;
 import android.view.animation.Animation;
 import android.view.animation.AnimationUtils;
 import android.view.inputmethod.InputMethodManager;
-import android.webkit.*;
-import android.widget.*;
+import android.webkit.CookieManager;
+import android.webkit.CookieSyncManager;
+import android.webkit.JsPromptResult;
+import android.webkit.JsResult;
+import android.webkit.SslErrorHandler;
+import android.webkit.WebSettings;
+import android.webkit.WebView;
+import android.widget.AbsListView;
+import android.widget.AbsSeekBar;
+import android.widget.AdapterView;
+import android.widget.ArrayAdapter;
+import android.widget.CursorAdapter;
+import android.widget.ExpandableListView;
+import android.widget.Filter;
+import android.widget.FrameLayout;
+import android.widget.Gallery;
+import android.widget.GridView;
+import android.widget.ImageView;
+import android.widget.ListView;
+import android.widget.ProgressBar;
+import android.widget.RatingBar;
+import android.widget.RemoteViews;
+import android.widget.ResourceCursorAdapter;
+import android.widget.SeekBar;
+import android.widget.SimpleCursorAdapter;
+import android.widget.TabHost;
+import android.widget.TextView;
+import android.widget.Toast;
+import android.widget.VideoView;
+import android.widget.ViewAnimator;
+import android.widget.ViewFlipper;
+import android.widget.ZoomButtonsController;
 import com.xtremelabs.robolectric.bytecode.RobolectricInternals;
 import com.xtremelabs.robolectric.bytecode.ShadowWrangler;
 import com.xtremelabs.robolectric.shadows.*;
@@ -163,6 +245,7 @@ public class Robolectric {
                 ShadowFilter.class,
                 ShadowFloatMath.class,
                 ShadowFrameLayout.class,
+                ShadowGallery.class,
                 ShadowGeocoder.class,
                 ShadowGeoPoint.class,
                 ShadowGridView.class,
@@ -480,6 +563,10 @@ public class Robolectric {
         return (ShadowFrameLayout) shadowOf_(instance);
     }
 
+    public static ShadowGallery shadowOf(Gallery instance) {
+        return (ShadowGallery) shadowOf_(instance);
+    }
+
     public static ShadowGeocoder shadowOf(Geocoder instance) {
         return (ShadowGeocoder) shadowOf_(instance);
     }
diff --git a/src/main/java/com/xtremelabs/robolectric/shadows/ShadowGallery.java b/src/main/java/com/xtremelabs/robolectric/shadows/ShadowGallery.java
new file mode 100644
index 000000000..43dbcebda
--- /dev/null
+++ b/src/main/java/com/xtremelabs/robolectric/shadows/ShadowGallery.java
@@ -0,0 +1,27 @@
+package com.xtremelabs.robolectric.shadows;
+
+import android.view.KeyEvent;
+import android.widget.Gallery;
+import com.xtremelabs.robolectric.internal.Implementation;
+import com.xtremelabs.robolectric.internal.Implements;
+import com.xtremelabs.robolectric.internal.RealObject;
+
+@Implements(Gallery.class)
+public class ShadowGallery extends ShadowAbsSpinner {
+
+    @RealObject Gallery gallery;
+
+    @Implementation
+    public boolean onKeyDown(int keyCode, KeyEvent event) {
+        switch (keyCode) {
+            case KeyEvent.KEYCODE_DPAD_RIGHT:
+            case KeyEvent.KEYCODE_DPAD_LEFT:
+                if (onKeyListener != null) {
+                    onKeyListener.onKey(gallery, keyCode, event);
+                }
+                return true;
+        }
+        return false;
+    }
+
+}
diff --git a/src/test/java/com/xtremelabs/robolectric/shadows/GalleryTest.java b/src/test/java/com/xtremelabs/robolectric/shadows/GalleryTest.java
new file mode 100644
index 000000000..97de42fcb
--- /dev/null
+++ b/src/test/java/com/xtremelabs/robolectric/shadows/GalleryTest.java
@@ -0,0 +1,59 @@
+package com.xtremelabs.robolectric.shadows;
+
+import android.view.KeyEvent;
+import android.view.View;
+import android.widget.Gallery;
+import com.xtremelabs.robolectric.WithTestDefaultsRunner;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+
+import static org.hamcrest.CoreMatchers.equalTo;
+import static org.hamcrest.CoreMatchers.sameInstance;
+import static org.hamcrest.MatcherAssert.assertThat;
+import static org.junit.Assert.assertTrue;
+
+@RunWith(WithTestDefaultsRunner.class)
+public class GalleryTest {
+    private Gallery gallery;
+    private TestOnKeyListener listener;
+    private KeyEvent event;
+
+    @Before
+    public void setUp() throws Exception {
+        gallery = new Gallery(null);
+        listener = new TestOnKeyListener();
+        gallery.setOnKeyListener(listener);
+        event = new KeyEvent(1, 2);
+    }
+
+    @Test
+    public void onKeyDown_dPadRightShouldTriggerKeyEventDPadRight() throws Exception {
+        assertTrue(gallery.onKeyDown(KeyEvent.KEYCODE_DPAD_RIGHT, event));
+        assertThat(listener.keyCode, equalTo(KeyEvent.KEYCODE_DPAD_RIGHT));
+        assertThat((Gallery) listener.view, sameInstance(gallery));
+        assertThat(listener.event, sameInstance(event));
+    }
+
+    @Test
+    public void onKeyDown_dPadLeftShouldTriggerKeyEventListener() throws Exception {
+        assertTrue(gallery.onKeyDown(KeyEvent.KEYCODE_DPAD_RIGHT, event));
+        assertThat(listener.keyCode, equalTo(KeyEvent.KEYCODE_DPAD_RIGHT));
+        assertThat((Gallery)listener.view, sameInstance(gallery));
+        assertThat(listener.event, sameInstance(event));
+    }
+
+    private static class TestOnKeyListener implements View.OnKeyListener {
+        View view;
+        int keyCode;
+        KeyEvent event;
+
+        @Override
+        public boolean onKey(View view, int keyCode, KeyEvent event) {
+            this.view = view;
+            this.keyCode = keyCode;
+            this.event = event;
+            return false;
+        }
+    }
+}",Add shadow for Gallery with rudimentary support for key events,"""Added support for Android's Gallery widget in Robolectric""","""Add support for Gallery widget and implement onKeyDown behavior""","""Added ShadowGallery and GalleryTest""

This commit adds a new class, `ShadowGallery`, which is a shadow class for the Android `Gallery` widget. It also adds a corresponding test class, `GalleryTest`, which tests the behavior of the `ShadowGallery` class.

The `ShadowGallery` class is annotated with `@Implements(Gallery.class)`, indicating that it is a shadow for the `Gallery` class. It has a single field, `gallery`, which is annotated with `@RealObject`. This field will hold a reference to the real `Gallery` object that is being shadowed.

The `ShadowGallery` class has a single method, `onKeyDown(int, KeyEvent)`, which is annotated with `@Implementation`. This method will be called instead of the real `Gallery`'s `onKeyDown` method when a key event is dispatched to the `Gallery`. The implementation of this method checks if the key code is `KEYCODE_DPAD_RIGHT` or `KEYCODE_DPAD_LEFT`, and if so, it calls the `onKeyListener`'s `onKey` method with the appropriate key code and event.

The `GalleryTest` class tests the behavior of the `ShadowGallery` class. It has a single test method, `testOnKeyDown_dPadRightShouldTriggerKeyEventDPadRight`, which tests that pressing the right d-pad key on a `Gallery` will trigger an `onKey` event with the correct key code and event object. It also tests that the `onKey` event is triggered on the same `Gallery` instance that received the key event.

Overall, this commit adds support for testing the behavior of the `Gallery` widget using Robolectric.","Add support for shadowing Gallery with key event handling, along with corresponding unit tests in Robolectric.",Model 4
"diff --git a/sonar-core/src/main/java/org/sonar/core/plugins/PluginClassloaders.java b/sonar-core/src/main/java/org/sonar/core/plugins/PluginClassloaders.java
index 2b2c27600be..a53effc5c34 100644
--- a/sonar-core/src/main/java/org/sonar/core/plugins/PluginClassloaders.java
+++ b/sonar-core/src/main/java/org/sonar/core/plugins/PluginClassloaders.java
@@ -123,6 +123,10 @@ public class PluginClassloaders {
       }
       return realm;
     } catch (Throwable e) {
+      // SONAR-3688
+      // Throwable is explicitely caught instead of Exception in order to log the plugins
+      // that are compiled for Java > 5. In such case java.lang.UnsupportedClassVersionError
+      // is raised. 
       throw new SonarException(""Fail to build the classloader of "" + plugin.getKey(), e);
     }
   }
@@ -144,6 +148,10 @@ public class PluginClassloaders {
       }
       return true;
     } catch (Throwable e) {
+      // SONAR-3688
+      // Throwable is explicitely caught instead of Exception in order to log the plugins
+      // that are compiled for Java > 5. In such case java.lang.UnsupportedClassVersionError
+      // is raised. 
       throw new SonarException(""Fail to extend the plugin "" + plugin.getBasePlugin() + "" for "" + plugin.getKey(), e);
     }
   }
@@ -208,8 +216,10 @@ public class PluginClassloaders {
       return (Plugin) claz.newInstance();
 
     } catch (Throwable e) {
-      // Do not catch only Exception in order to detect the plugins compiled for Java > 5
-      // (it raises a java.lang.UnsupportedClassVersionError)
+      // SONAR-3688
+      // Throwable is explicitely caught instead of Exception in order to log the plugins
+      // that are compiled for Java > 5. In such case java.lang.UnsupportedClassVersionError
+      // is raised. 
       throw new SonarException(""Fail to load plugin "" + metadata.getKey(), e);
     }
   }",Add some comments,"""SONAR-3688: Catch Throwable instead of Exception to log plugins compiled for Java > 5""","""Fixed plugin loading for Java > 5 by catching Throwable instead of Exception (#SONAR-3688)""","""Explicitly catch Throwable instead of Exception to log plugins compiled for Java > 5 (refs SONAR-3688)""",Logging plugins compiled for Java > 5 by explicitly catching Throwable instead of Exception.,Model 4
"diff --git a/hazelcast-documentation/src/CommonGotchas.md b/hazelcast-documentation/src/CommonGotchas.md
index f6ca05eaea..648dbef25d 100644
--- a/hazelcast-documentation/src/CommonGotchas.md
+++ b/hazelcast-documentation/src/CommonGotchas.md
@@ -11,12 +11,12 @@ Hazelcast is the distributed implementation of several structures that exist in
 
 2.  Hazelcast always return a clone copy of a value. Modifying the returned value does not change the actual value in the map (or multimap or list or set). You should put modified value back to make changes visible to all nodes.
 
-```java
-V value = map.get(key);
-value.updateSomeProperty();
-map.put(key, value);
-```
-If `cache-value` is true (default is true), Hazelcast caches that returned value for fast access in local node. Modifications done to this cached value without putting it back to map will be visible to only local node, successive `get` calls will return the same cached value. To reflect modifications to distributed map, you should put modified value back into map.
+
+    ```java
+    V value = map.get(key);
+    value.updateSomeProperty();
+    map.put(key, value);
+    ```
 
 3.  Collections which return values of methods such as `IMap.keySet`, `IMap.values`, `IMap.entrySet`, `MultiMap.get`, `MultiMap.remove`, `IMap.keySet`, `IMap.values`, contain cloned values. These collections are NOT backup by related Hazelcast objects. So changes to the these are **NOT** reflected in the originals, and vice-versa.
 
diff --git a/hazelcast-documentation/src/FAQ.md b/hazelcast-documentation/src/FAQ.md
new file mode 100644
index 0000000000..61911ec194
--- /dev/null
+++ b/hazelcast-documentation/src/FAQ.md
@@ -0,0 +1,252 @@
+
+
+# Frequently Asked Questions
+
+**1\. Why 271 as the Default Partition Count**
+
+The partition count 271, being a prime number, is a good choice since it will be distributed to the nodes almost evenly. For a small to medium sized cluster, the count 271 gives almost even partition distribution and optimal sized partitions.  As your cluster becomes bigger, this count should be made bigger to have evenly distributed partitions.
+
+**2\. How Do Nodes Discover One Other**
+
+
+When a node is started in a cluster, it will dynamically and automatically be discovered. There are three types of discovery.
+
+-	One is the multicast. Nodes in a cluster discover each other by multicast, by default. 
+-	Second is discovery by TCP/IP. The first node created in the cluster (leader) will form a list of IP addresses of other joining nodes and send this list to these nodes. So, nodes will know each other.
+-	And, if your application is placed on Amazon EC2, Hazelcast has an automatic discovery mechanism, as the third discovery type. You will just give your Amazon credentials and the joining node will be discovered automatically.
+
+Once nodes are discovered, all the communication between them will be via TCP/IP.
+
+**3\. What Happens When a Node Goes Down**
+
+Once a node is gone (e.g.crashes) and since data in each node has a backup in other nodes:
+
+-	First, the backups in other nodes are restored
+-	Then, data from these restored backups are recovered
+-	And finally, backups for these recovered data are formed
+
+So, eventually, no data is lost.
+
+
+
+**4\. How Do I Choose Keys Properly**
+
+When you store a key & value in a distributed Map, Hazelcast serializes the key and value, and stores the byte array version of them in local ConcurrentHashMaps. These ConcurrentHashMaps use `equals` and `hashCode` methods of byte array version of your key. It does not take into account the actual `equals` and `hashCode` implementations of your objects. So it is important that you choose your keys in a proper way. 
+
+Implementing `equals` and `hashCode` is not enough, it is also important that the object is always serialized into the same byte array. All primitive types like String, Long, Integer, etc. are good candidates for keys to be used in Hazelcast. An unsorted Set is an example of a very bad candidate because Java Serialization may serialize the same unsorted set in two different byte arrays.
+
+Note that the distributed Set and List store their entries as the keys in a distributed Map. So the notes above apply to the objects you store in Set and List.
+
+**4\. How Do I Reflect Value Modification in Distributed Data Structures**
+
+Hazelcast always return a clone copy of a value. Modifying the returned value does not change the actual value in the map (or multimap, list, set). You should put the modified value back to make changes visible to all nodes.
+
+```java
+V value = map.get(key);
+value.updateSomeProperty();
+map.put(key, value);
+```
+
+Collections which return values of methods such as `IMap.keySet`, `IMap.values`, `IMap.entrySet`, `MultiMap.get`, `MultiMap.remove`, `IMap.keySet`, `IMap.values`, contain cloned values. These collections are NOT backup by related Hazelcast objects. So changes to the these are **NOT** reflected in the originals, and vice-versa.
+
+**5\. How Do I Test My Hazelcast Cluster**
+
+Hazelcast allows you to create more than one instance on the same JVM. Each member is called `HazelcastInstance` and each will have its own configuration, socket and threads, i.e. you can treat them as totally separate instances. 
+
+This enables us to write and run cluster unit tests on a single JVM. As you can use this feature for creating separate members different applications running on the same JVM (imagine running multiple web applications on the same JVM), you can also use this feature for testing Hazelcast cluster.
+
+Let's say you want to test if two members have the same size of a map.
+
+```java
+@Test
+public void testTwoMemberMapSizes() {
+    // start the first member
+    HazelcastInstance h1 = Hazelcast.newHazelcastInstance(null);
+    // get the map and put 1000 entries
+    Map map1 = h1.getMap(""testmap"");
+    for (int i = 0; i < 1000; i++) {
+        map1.put(i, ""value"" + i);
+    }
+    // check the map size
+    assertEquals(1000, map1.size());
+    // start the second member
+    HazelcastInstance h2 = Hazelcast.newHazelcastInstance(null);
+    // get the same map from the second member
+    Map map2 = h2.getMap(""testmap"");
+    // check the size of map2
+    assertEquals(1000, map2.size());
+    // check the size of map1 again
+    assertEquals(1000, map1.size());
+}
+```
+
+In the test above, everything happens in the same thread. When developing multi-threaded test, coordination of the thread executions has to be carefully handled. Usage of `CountDownLatch` for thread coordination is highly recommended. You can certainly use other things. Here is an example where we need to listen for messages and make sure that we got these messages:
+
+```java
+@Test
+public void testTopic() {
+    // start two member cluster
+    HazelcastInstance h1 = Hazelcast.newHazelcastInstance(null);
+    HazelcastInstance h2 = Hazelcast.newHazelcastInstance(null);
+    String topicName = ""TestMessages"";
+    // get a topic from the first member and add a messageListener
+    ITopic<String> topic1 = h1.getTopic(topicName);
+    final CountDownLatch latch1 = new CountDownLatch(1);
+    topic1.addMessageListener(new MessageListener() {
+        public void onMessage(Object msg) {
+            assertEquals(""Test1"", msg);
+            latch1.countDown();
+        }
+    });
+    // get a topic from the second member and add a messageListener
+    ITopic<String> topic2 = h2.getTopic(topicName);
+    final CountDownLatch latch2 = new CountDownLatch(2);
+    topic2.addMessageListener(new MessageListener() {
+        public void onMessage(Object msg) {
+            assertEquals(""Test1"", msg);
+            latch2.countDown();
+        }
+    });
+    // publish the first message, both should receive this
+    topic1.publish(""Test1"");
+    // shutdown the first member
+    h1.shutdown();
+    // publish the second message, second member's topic should receive this
+    topic2.publish(""Test1"");
+    try {
+        // assert that the first member's topic got the message
+        assertTrue(latch1.await(5, TimeUnit.SECONDS));
+        // assert that the second members' topic got two messages
+        assertTrue(latch2.await(5, TimeUnit.SECONDS));
+    } catch (InterruptedException ignored) {
+    }
+}
+```
+You can surely start Hazelcast members with different configurations. Let's say we want to test if Hazelcast `LiteMember` can shutdown fine.
+
+```java
+@Test(timeout = 60000)
+public void shutdownLiteMember() {
+    // first config for normal cluster member
+    Config c1 = new XmlConfigBuilder().build();
+    c1.setPortAutoIncrement(false);
+    c1.setPort(5709);
+    // second config for LiteMember
+    Config c2 = new XmlConfigBuilder().build();
+    c2.setPortAutoIncrement(false);
+    c2.setPort(5710);
+    // make sure to set LiteMember=true
+    c2.setLiteMember(true);
+    // start the normal member with c1
+    HazelcastInstance hNormal = Hazelcast.newHazelcastInstance(c1);
+    // start the LiteMember with different configuration c2
+    HazelcastInstance hLite = Hazelcast.newHazelcastInstance(c2);
+    hNormal.getMap(""default"").put(""1"", ""first"");
+    assert hLite.getMap(""default"").get(""1"").equals(""first"");
+    hNormal.shutdown();
+    hLite.shutdown();
+}
+```
+Also remember to call `Hazelcast.shutdownAll()` after each test case to make sure that there is no other running member left from the previous tests.
+
+```java
+@After
+public void cleanup() throws Exception {
+    Hazelcast.shutdownAll();
+}
+```
+
+For more information please [check our existing tests.](https://github.com/hazelcast/hazelcast/tree/master/hazelcast/src/test/java/com/hazelcast/cluster)
+
+
+**6\. When **`RuntimeInterruptedException`** is Thrown**
+
+Most of the Hazelcast operations throw an `RuntimeInterruptedException` (which is unchecked version of `InterruptedException`) if a user thread is interrupted while waiting a response. Hazelcast uses RuntimeInterruptedException to pass InterruptedException up through interfaces that do not have InterruptedException in their signatures. The users should be able to catch and handle `RuntimeInterruptedException` in such cases as if their threads are interrupted on a blocking operation.
+
+**7\. When **`ConcurrentModificationException`** is Thrown**
+
+Some of Hazelcast operations can throw `ConcurrentModificationException` under transaction while trying to acquire a resource, although operation signatures do not define such an exception. Exception is thrown if resource cannot be acquired in a specific time. The users should be able to catch and handle `ConcurrentModificationException` while they are using Hazelcast transactions.
+
+
+**8\. How is the Split-Brain Syndrome Handled**
+
+Imagine that you have 10-node cluster and for some reason the network is divided into two in a way that 4 servers cannot see the other 6. As a result you ended up having two separate clusters; 4-node cluster and 6-node cluster. Members in each sub-cluster are thinking that the other nodes are dead even though they are not. This situation is called Network Partitioning (a.k.a. Split-Brain Syndrome).
+
+Since it is a network failure, there is no way to avoid it programatically and your application will run as two separate independent clusters. But we should be able to answer the following questions: ""What will happen after the network failure is fixed and connectivity is restored between these two clusters? Will these two clusters merge into one again? If they do, how are the data conflicts resolved, because you might end up having two different values for the same key in the same map?""
+
+Here is how Hazelcast deals with it:
+
+1.  The oldest member of the cluster checks if there is another cluster with the same group-name and group-password in the network.
+
+2.  If the oldest member finds such cluster, then it figures out which cluster should merge to the other.
+
+3.  Each member of the merging cluster will do the following:
+
+	-   pause
+
+	-   take locally owned map entries
+
+	-   close all of its network connections (detach from its cluster)
+
+	-   join to the new cluster
+
+	-   send merge request for each of its locally owned map entry
+
+	-   resume
+
+So each member of the merging cluster is actually rejoining to the new cluster and sending merge request for each of its locally owned map entry. Two important points: 
+
+-	Smaller cluster will merge into the bigger one. If they have equal number of members then a hashing algorithm determines the merging cluster.
+-	Each cluster may have different versions of the same key in the same map. Destination cluster will decide how to handle merging entry based on the `MergePolicy` set for that map. There are built-in merge policies such as `PassThroughMergePolicy`, `PutIfAbsentMapMergePolicy`, `HigherHitsMapMergePolicy` and `LatestUpdateMapMergePolicy`. But you can develop your own merge policy by implementing `com.hazelcast.map.merge.MapMergePolicy`. You should set the full class name of your implementation to the merge-policy configuration.
+
+
+```java
+public interface MergePolicy {
+    /**
+    * Returns the value of the entry after the merge
+    * of entries with the same key. Returning value can be
+    * You should consider the case where existingEntry is null.
+    *
+    * @param mapName       name of the map
+    * @param mergingEntry  entry merging into the destination cluster
+    * @param existingEntry existing entry in the destination cluster
+    * @return final value of the entry. If returns null then entry will be removed.
+    */
+    Object merge(String mapName, EntryView mergingEntry, EntryView existingEntry);
+}
+```
+
+Here is how merge policies are specified per map:
+
+```xml
+<hazelcast>
+    ...
+    <map name=""default"">
+        <backup-count>1</backup-count>
+        <eviction-policy>NONE</eviction-policy>
+        <max-size>0</max-size>
+        <eviction-percentage>25</eviction-percentage>
+        <!--
+            While recovering from split-brain (network partitioning),
+            map entries in the small cluster will merge into the bigger cluster
+            based on the policy set here. When an entry merge into the
+            cluster, there might an existing entry with the same key already.
+            Values of these entries might be different for that same key.
+            Which value should be set for the key? Conflict is resolved by
+            the policy set here. Default policy is hz.ADD_NEW_ENTRY
+
+            There are built-in merge policies such as
+            There are built-in merge policies such as
+            com.hazelcast.map.merge.PassThroughMergePolicy; entry will be added if there is no existing entry for the key.
+            com.hazelcast.map.merge.PutIfAbsentMapMergePolicy ; entry will be added if the merging entry doesn't exist in the cluster.
+            com.hazelcast.map.merge.HigherHitsMapMergePolicy ; entry with the higher hits wins.
+            com.hazelcast.map.merge.LatestUpdateMapMergePolicy ; entry with the latest update wins.
+        -->
+        <merge-policy>MY_MERGE_POLICY_CLASS</merge-policy>
+    </map>
+
+    ...
+</hazelcast>
+```
+
+",remove cache - value doc parts,"""Added FAQ section to documentation and updated CommonGotchas section""","Here's a possible commit message based on the provided diff:

`Update Hazelcast documentation with new FAQs and gotchas`

This commit message is concise and accurately reflects the changes made in the commit. It mentions the specific files that were updated (FAQs and gotchas) and provides a brief description of the changes.","The commit message should be: ""Update CommonGotchas.md: Add code block for modifying map value example""","""Added FAQ section to Hazelcast documentation covering common queries and troubleshooting.""",Model 4
"diff --git a/library/src/com/emilsjolander/components/stickylistheaders/StickyListHeadersListView.java b/library/src/com/emilsjolander/components/stickylistheaders/StickyListHeadersListView.java
index 6736b9c..184b96a 100644
--- a/library/src/com/emilsjolander/components/stickylistheaders/StickyListHeadersListView.java
+++ b/library/src/com/emilsjolander/components/stickylistheaders/StickyListHeadersListView.java
@@ -203,6 +203,10 @@ public class StickyListHeadersListView extends ListView {
 
 	@Override
 	public void setAdapter(ListAdapter adapter) {
+		if (this.isInEditMode()) {
+			super.setAdapter(adapter);
+			return;
+		}
 		if(adapter == null){
 			mAdapter = null;
 			reset();
diff --git a/sample/project.properties b/sample/project.properties
index 003959a..0a62d81 100644
--- a/sample/project.properties
+++ b/sample/project.properties
@@ -12,4 +12,4 @@
 
 # Project target.
 target=android-16
-android.library.reference.1=../Library
+android.library.reference.1=../library
diff --git a/sample/res/layout/main.xml b/sample/res/layout/main.xml
index 92f6e33..641ec31 100644
--- a/sample/res/layout/main.xml
+++ b/sample/res/layout/main.xml
@@ -1,5 +1,6 @@
 <?xml version=""1.0"" encoding=""utf-8""?>
 <LinearLayout xmlns:android=""http://schemas.android.com/apk/res/android""
+    xmlns:tools=""http://schemas.android.com/tools""
     android:layout_width=""match_parent""
     android:layout_height=""match_parent""
     android:orientation=""vertical"">
@@ -12,7 +13,8 @@
         android:clipToPadding=""false"" 
         android:scrollbarStyle=""outsideOverlay""
         android:fastScrollEnabled=""true""
-        android:drawSelectorOnTop=""true"" />
+        android:drawSelectorOnTop=""true""
+        tools:listitem=""@layout/test_list_item_layout"" />
     
     <TextView 
         android:id=""@+id/empty""",added xml preview code from master branch,"""Fixed adapter setting in edit mode and updated sample project references and layout""","The commit message should be:

""Fix library reference path and add edit mode check for setAdapter method""

This message accurately describes the two changes made in the commit: the correction of the library reference path in the project properties and the addition of an edit mode check in the `setAdapter` method of `StickyListHeadersListView`.","""Added check for edit mode in StickyListHeadersListView and tools namespace in sample main.xml""

Explanation:
The first change is in the StickyListHeadersListView.java file where a check for edit mode has been added before setting the adapter. If the view is in edit mode, the super class's setAdapter method is called and the method returns.

The second change is in the main.xml file of the sample project. The tools namespace has been added and the listitem attribute has been set to ""@layout/test_list_item_layout"" for the StickyListHeadersListView. This attribute is used by the Android Studio layout editor to display a preview of the list items.","Fix adapter setting in edit mode, correct library reference, and add tools namespace with list item preview in XML.",Model 2
"diff --git a/src/main/java/com/google/devtools/build/lib/sandbox/SandboxHelpers.java b/src/main/java/com/google/devtools/build/lib/sandbox/SandboxHelpers.java
index 004c8dffbc..de018b1dbf 100644
--- a/src/main/java/com/google/devtools/build/lib/sandbox/SandboxHelpers.java
+++ b/src/main/java/com/google/devtools/build/lib/sandbox/SandboxHelpers.java
@@ -26,6 +26,8 @@ import com.google.devtools.build.lib.analysis.BlazeDirectories;
 import com.google.devtools.build.lib.analysis.config.BuildConfiguration;
 import com.google.devtools.build.lib.buildtool.BuildRequest;
 import com.google.devtools.build.lib.cmdline.Label;
+import com.google.devtools.build.lib.events.Event;
+import com.google.devtools.build.lib.events.EventHandler;
 import com.google.devtools.build.lib.standalone.StandaloneSpawnStrategy;
 import com.google.devtools.build.lib.util.Preconditions;
 import com.google.devtools.build.lib.vfs.Path;
@@ -38,7 +40,10 @@ import java.util.concurrent.atomic.AtomicInteger;
 /** Helper methods that are shared by the different sandboxing strategies in this package. */
 final class SandboxHelpers {
 
-  static void lazyCleanup(ExecutorService backgroundWorkers, final SandboxRunner runner) {
+  static void lazyCleanup(
+      ExecutorService backgroundWorkers,
+      final EventHandler eventHandler,
+      final SandboxRunner runner) {
     // By deleting the sandbox directory in the background, we avoid having to wait for it to
     // complete before returning from the action, which improves performance.
     backgroundWorkers.execute(
@@ -46,18 +51,15 @@ final class SandboxHelpers {
           @Override
           public void run() {
             try {
-              while (!Thread.currentThread().isInterrupted()) {
-                try {
-                  runner.cleanup();
-                  return;
-                } catch (IOException e2) {
-                  // Sleep & retry.
-                  Thread.sleep(250);
-                }
-              }
-            } catch (InterruptedException e) {
-              // Mark ourselves as interrupted and then exit.
-              Thread.currentThread().interrupt();
+              runner.cleanup();
+            } catch (IOException e) {
+              // Can't do anything except logging here. SandboxModule#afterCommand will try again
+              // and alert the user if cleanup still fails.
+              eventHandler.handle(
+                  Event.warn(
+                      String.format(
+                          ""Could not delete sandbox directory after action execution: %s (%s)"",
+                          runner.getSandboxPath(), e)));
             }
           }
         });
diff --git a/src/main/java/com/google/devtools/build/lib/sandbox/SandboxModule.java b/src/main/java/com/google/devtools/build/lib/sandbox/SandboxModule.java
index 53c5c67bfb..df28aaf27c 100644
--- a/src/main/java/com/google/devtools/build/lib/sandbox/SandboxModule.java
+++ b/src/main/java/com/google/devtools/build/lib/sandbox/SandboxModule.java
@@ -21,11 +21,13 @@ import com.google.devtools.build.lib.actions.ActionContextConsumer;
 import com.google.devtools.build.lib.actions.ActionContextProvider;
 import com.google.devtools.build.lib.buildtool.BuildRequest;
 import com.google.devtools.build.lib.buildtool.buildevent.BuildStartingEvent;
-import com.google.devtools.build.lib.concurrent.ExecutorUtil;
+import com.google.devtools.build.lib.events.Event;
 import com.google.devtools.build.lib.runtime.BlazeModule;
 import com.google.devtools.build.lib.runtime.Command;
 import com.google.devtools.build.lib.runtime.CommandEnvironment;
 import com.google.devtools.build.lib.util.Preconditions;
+import com.google.devtools.build.lib.vfs.FileSystemUtils;
+import com.google.devtools.build.lib.vfs.Path;
 import com.google.devtools.common.options.OptionsBase;
 import java.io.IOException;
 import java.util.concurrent.ExecutorService;
@@ -35,18 +37,18 @@ import java.util.concurrent.Executors;
  * This module provides the Sandbox spawn strategy.
  */
 public final class SandboxModule extends BlazeModule {
-  // Per-server state
-  private ExecutorService backgroundWorkers;
-
   // Per-command state
   private CommandEnvironment env;
   private BuildRequest buildRequest;
+  private ExecutorService backgroundWorkers;
+  private SandboxOptions sandboxOptions;
 
   @Override
   public Iterable<ActionContextProvider> getActionContextProviders() {
     Preconditions.checkNotNull(env);
     Preconditions.checkNotNull(buildRequest);
     Preconditions.checkNotNull(backgroundWorkers);
+    sandboxOptions = buildRequest.getOptions(SandboxOptions.class);
     try {
       return ImmutableList.<ActionContextProvider>of(
           SandboxActionContextProvider.create(env, buildRequest, backgroundWorkers));
@@ -79,13 +81,46 @@ public final class SandboxModule extends BlazeModule {
 
   @Override
   public void afterCommand() {
+    // We want to make sure that all sandbox directories are deleted after a command finishes or at
+    // least the user gets notified if some of them can't be deleted. However we can't rely on the
+    // background workers for that, because a) they can't log, and b) if a directory is undeletable,
+    // the Runnable might never finish. So we cancel them and delete the remaining directories here,
+    // where we have more control.
+    backgroundWorkers.shutdownNow();
+    if (sandboxOptions != null && !sandboxOptions.sandboxDebug) {
+      Path sandboxRoot =
+          env.getDirectories()
+              .getOutputBase()
+              .getRelative(env.getRuntime().getProductName() + ""-sandbox"");
+      if (sandboxRoot.exists()) {
+        try {
+          for (Path child : sandboxRoot.getDirectoryEntries()) {
+            try {
+              FileSystemUtils.deleteTree(child);
+            } catch (IOException e) {
+              env.getReporter()
+                  .handle(
+                      Event.warn(
+                          String.format(
+                              ""Could not delete sandbox directory: %s (%s)"",
+                              child.getPathString(), e)));
+            }
+          }
+          sandboxRoot.delete();
+        } catch (IOException e) {
+          env.getReporter()
+              .handle(
+                  Event.warn(
+                      String.format(
+                          ""Could not delete %s directory: %s"", sandboxRoot.getBaseName(), e)));
+        }
+      }
+    }
+
     env = null;
     buildRequest = null;
-
-    // ""bazel clean"" will also try to delete the sandbox directories, leading to a race condition
-    // if it is run right after a ""bazel build"". We wait for and shutdown the background worker pool
-    // before continuing to avoid this.
-    ExecutorUtil.interruptibleShutdown(backgroundWorkers);
+    backgroundWorkers = null;
+    sandboxOptions = null;
   }
 
   @Subscribe
diff --git a/src/main/java/com/google/devtools/build/lib/sandbox/SandboxRunner.java b/src/main/java/com/google/devtools/build/lib/sandbox/SandboxRunner.java
index 4bb2b95c1b..dabbf66aa8 100644
--- a/src/main/java/com/google/devtools/build/lib/sandbox/SandboxRunner.java
+++ b/src/main/java/com/google/devtools/build/lib/sandbox/SandboxRunner.java
@@ -122,4 +122,8 @@ abstract class SandboxRunner {
       FileSystemUtils.deleteTree(sandboxPath);
     }
   }
+
+  Path getSandboxPath() {
+    return sandboxPath;
+  }
 }
diff --git a/src/main/java/com/google/devtools/build/lib/sandbox/SandboxStrategy.java b/src/main/java/com/google/devtools/build/lib/sandbox/SandboxStrategy.java
index d02ffc22a6..b5d787c4be 100644
--- a/src/main/java/com/google/devtools/build/lib/sandbox/SandboxStrategy.java
+++ b/src/main/java/com/google/devtools/build/lib/sandbox/SandboxStrategy.java
@@ -26,6 +26,7 @@ import com.google.devtools.build.lib.actions.Spawns;
 import com.google.devtools.build.lib.analysis.BlazeDirectories;
 import com.google.devtools.build.lib.buildtool.BuildRequest;
 import com.google.devtools.build.lib.events.Event;
+import com.google.devtools.build.lib.events.EventHandler;
 import com.google.devtools.build.lib.util.Preconditions;
 import com.google.devtools.build.lib.vfs.Path;
 import com.google.devtools.build.lib.vfs.PathFragment;
@@ -70,6 +71,7 @@ abstract class SandboxStrategy implements SandboxedSpawnActionContext {
       SandboxRunner runner,
       AtomicReference<Class<? extends SpawnActionContext>> writeOutputFiles)
       throws ExecException, InterruptedException {
+    EventHandler eventHandler = actionExecutionContext.getExecutor().getEventHandler();
     try {
       runner.run(
           spawn.getArguments(),
@@ -90,17 +92,14 @@ abstract class SandboxStrategy implements SandboxedSpawnActionContext {
         } catch (IOException e) {
           // Catch the IOException and turn it into an error message, otherwise this might hide an
           // exception thrown during runner.run earlier.
-          actionExecutionContext
-              .getExecutor()
-              .getEventHandler()
-              .handle(
-                  Event.error(
-                      ""I/O exception while extracting output artifacts from sandboxed execution: ""
-                          + e));
+          eventHandler.handle(
+              Event.error(
+                  ""I/O exception while extracting output artifacts from sandboxed execution: ""
+                      + e));
         }
       }
       if (!sandboxOptions.sandboxDebug) {
-        SandboxHelpers.lazyCleanup(backgroundWorkers, runner);
+        SandboxHelpers.lazyCleanup(backgroundWorkers, eventHandler, runner);
       }
     }
 
diff --git a/src/test/shell/bazel/bazel_sandboxing_test.sh b/src/test/shell/bazel/bazel_sandboxing_test.sh
index 38b918979b..17e3d4fed2 100755
--- a/src/test/shell/bazel/bazel_sandboxing_test.sh
+++ b/src/test/shell/bazel/bazel_sandboxing_test.sh
@@ -222,8 +222,7 @@ function test_sandbox_cleanup() {
   bazel build examples/genrule:tools_work &> $TEST_log \
     || fail ""Hermetic genrule failed: examples/genrule:tools_work""
   bazel shutdown &> $TEST_log || fail ""bazel shutdown failed""
-  ls -la ""$(bazel info output_base)/bazel-sandbox""
-  if [[ ""$(ls -A ""$(bazel info execution_root)""/bazel-sandbox)"" ]]; then
+  if [[ ""$(ls -la ""$(bazel info output_base)/bazel-sandbox"")"" ]]; then
     fail ""Build left files around afterwards""
   fi
 }","Fix an issue where a \"" build \"" command might hang after it finished , because sandbox directories could not be cleaned up . . - - .","""Improve sandbox cleanup and error handling in sandboxing strategies""","""Add event handling and logging for sandbox cleanup failures""","""Add event handling for failed sandbox cleanup and improve sandbox directory deletion""

This commit makes the following changes:

1. Adds event handling for failed sandbox cleanup: If an IOException occurs while deleting the sandbox directory after an action execution, an event is logged to warn the user about the issue.
2. Improves sandbox directory deletion: After a command finishes, the background workers are shut down, and any remaining sandbox directories are deleted. If a directory cannot be deleted, the user is notified with a warning event.

The changes are made in the following files:

* SandboxHelpers.java: The `lazyCleanup` method is updated to include event handling for failed sandbox cleanup.
* SandboxModule.java: The `afterCommand` method is updated to shut down the background workers and delete any remaining sandbox directories.
* SandboxRunner.java: A new method `getSandboxPath` is added to return the sandbox path.
* SandboxStrategy.java: The `runSpawn` method is updated to include event handling for failed sandbox cleanup.

Additionally, a small change is made to the bazel\_sandboxing\_test.sh script to improve the check for remaining sandbox directories after a command finishes.",Improve sandbox directory cleanup with logging for errors and ensure all directories are deleted after command execution.,Model 2
"diff --git a/src/main/java/org/roaringbitmap/BitSetUtil.java b/src/main/java/org/roaringbitmap/BitSetUtil.java
index ee6a96ed..f6ba8668 100644
--- a/src/main/java/org/roaringbitmap/BitSetUtil.java
+++ b/src/main/java/org/roaringbitmap/BitSetUtil.java
@@ -1,190 +1,124 @@
 package org.roaringbitmap;
 
+import java.util.Arrays;
 import java.util.BitSet;
 
 public class BitSetUtil {
-	static final int CHUNK_SIZE = 1 << 16;
+	// a block consists has a maximum of 1024 words, each representing 64 bits, thus representing at maximum 65536 bits
+	static final int BLOCK_LENGTH = 1024; 
 
 	/**
-	 * Generate RoaringBitmap out of the given bitSet
+	 * Generate RoaringBitmap out of the bitSet
 	 * 
-	 * @param bitset
-	 * @return bitmap
+	 * @param bitSet
+	 * @return roaring bitmap
 	 */
-	static RoaringBitmap bitmapOf(final BitSet bitset) {
-		// dont make method public, so other parties wont use it.
-		// if daniel likes it, he will put it to RoaringBitmap :>
-		final int bitsetLength = bitset.length();
-		if (bitsetLength == 0) {
+	static RoaringBitmap bitmapOf(final BitSet bitSet) {
+		final int cardinality = bitSet.cardinality();
+		if (cardinality == 0) {
 			return new RoaringBitmap();
+		} else if (cardinality <= ArrayContainer.DEFAULT_MAX_SIZE) {
+			// if it is a tiny bitSet, we can directly build a arrayContainer, without an extra bitSet#toLongArray
+			final RoaringBitmap bitmap = new RoaringBitmap();
+			bitmap.highLowContainer.append((short)0, arrayContainerOf(cardinality, bitSet));
+			return bitmap;
+		} else {
+			return bitmapOf(cardinality, bitSet.toLongArray());
 		}
+	}
 
+	/**
+	 * Generate RoaringBitmap out of a long[], each long using little-endian representation of its bits 
+	 * 
+	 * @see BitSet#toLongArray() for an equivalent
+	 * @param bitset
+	 * @return roaring bitmap
+	 */
+    static RoaringBitmap bitmapOf(final long[] words) {
+		final int overallCardinality = cardinality(0, words.length, words);
+		if (overallCardinality == 0) {
+			return new RoaringBitmap();
+		} else {
+			return bitmapOf(overallCardinality, words);
+		}
+    }
+    
+	private static RoaringBitmap bitmapOf(final int cardinality, final long[] words) {
+		// split long[] into blocks. 
+		// each block becomes a single container, if any bit is set
 		final RoaringBitmap ans = new RoaringBitmap();
-
-		// divide bitset in 1<<16 chunks
-		final int chunkSize = 1 << 16;
-		for (int offset = 0; offset < bitsetLength; offset += chunkSize) {
-			// avoid empty container creation, if there is no bit in range anyways
-			if (BitSetUtil.any(offset, chunkSize, bitset)) {
-				final Container container = BitSetUtil.containerOf(offset, chunkSize, bitset);
-
-				// it is always the first container, it never replaces or expands an existing one
-				// => index is always negative, no extra check needed
-				final short hb = Util.highbits(offset);
-				final int i = ans.highLowContainer.getIndex(hb);
-				ans.highLowContainer.insertNewKeyValueAt(-i - 1, hb, container);
+		int containerIndex = 0;
+		int currentCardinality = 0;
+		
+		// for each block
+		// (unless we already have reached overall cardinality, e.g. when long[] is way longer and has no bits set, then we can skip everything else)
+		for (int from = 0; from < words.length && currentCardinality < cardinality; from += BLOCK_LENGTH) {
+			final int to = Math.min(from + BLOCK_LENGTH, words.length);
+			final int blockCardinality = cardinality(from, to, words);
+			if (blockCardinality > 0) { 
+				ans.highLowContainer.insertNewKeyValueAt(containerIndex++, Util.highbits(from * Long.SIZE), BitSetUtil.containerOf(from, to, blockCardinality, words));
+				currentCardinality += blockCardinality;
 			}
 		}
 		return ans;
 	}
 
-	private static Container containerOf(final int offset, final int length, final BitSet bitSet) {
-		// TODO: find a good way to decide between arraycontainer/bitmapcontainer and runcontainer, without using lots of allocations
-		final int cardinality = cardinality(offset, length, bitSet);
-		if (cardinality <= ArrayContainer.DEFAULT_MAX_SIZE) {
-			// containers with DEFAULT_MAX_SZE or less integers should be ArrayContainers
-			return arrayContainerOf(offset, length, cardinality, bitSet);
+	private static Container containerOf(final int from, final int to, final int blockCardinality, final long[] words) {
+		// find the best container available
+		if (blockCardinality <= ArrayContainer.DEFAULT_MAX_SIZE) {
+			// containers with DEFAULT_MAX_SIZE or less integers should be ArrayContainers
+			return arrayContainerOf(from, to, blockCardinality, words);
+		} else {
+			// otherwise use bitmap container, which is kinda the same as Bitset
+			// ideas for the future: 
+			// - if blockCardinality is rather high, then runlength encoding via RunContainer might be the better choice) 
+			// - (maybe there is also another way of recognizing high amount of repetition? i would rather scan the words once in the beginning and save memory at the end?)	
+			return new BitmapContainer(Arrays.copyOfRange(words, from, to), blockCardinality);
 		}
-
-		final int runs = BitSetUtil.nbrRuns(offset, length, bitSet);
-		if (runs == 0) {
-			return new RunContainer();
-		}
-		return runContainerOf(offset, length, runs, bitSet);
 	}
 
-	private static ArrayContainer arrayContainerOf(final int offset, final int length, final int cardinality, final BitSet bs) {
-		// content is sorted, as BitSet is already sorted  
+	private static ArrayContainer arrayContainerOf(final int from, final int to, final int cardinality, final long[] words) {
+		// precondition: cardinality is max 4096
 		final short[] content = new short[cardinality];
-		int j = 0;
-		for (int i = bs.nextSetBit(offset), offsetLength = offset + length; i >= 0 && i < offsetLength; i = bs.nextSetBit(i + 1)) {
-			content[j++] = (short) (i - offset);
-		}
-		return new ArrayContainer(content);
-	}
-
-	private static RunContainer runContainerOf(final int offset, final int length, final int nbrRuns, final BitSet bs) {
-		if (nbrRuns == 0) {
-			return new RunContainer(new short[0], 0);
-		}
-
-		short[] valueslength = new short[2 * nbrRuns];
-
-		int index = -1;
-		int runLength = 0;
-		boolean finish = false;
-		int runs = 0;
-		for (int i = bs.nextSetBit(offset), offsetLength = offset + length; i >= 0 && i < offsetLength; i = bs.nextSetBit(i + 1)) {
-			// operate on index i here
-			if (i == Integer.MAX_VALUE) {
-				if (index != -1) {
-					valueslength[runs * 2] = (short) (index - offset);
-					valueslength[runs * 2 + 1] = (short) runLength;
-					runs++;
-				}
-				finish = true;
-				break; // or (i+1) would overflow
-			}
-
-			if (index == -1) {
-				index = i;
-				runLength = 0;
-			} else {
-				if (index + runLength + 1 == i) {
-					runLength++;
-				} else {
-					valueslength[runs * 2] = (short) (index - offset);
-					valueslength[runs * 2 + 1] = (short) runLength;
-					runs++;
-
-					index = i;
-					runLength = 0;
-				}
-			}
-		}
-
-		if (index != -1 && !finish) {
-			valueslength[runs * 2] = (short) (index - offset);
-			valueslength[runs * 2 + 1] = (short) runLength;
-			runs++;
-		}
-
-		return new RunContainer(valueslength, nbrRuns);
-	}
-
-	/**
-	 * How many runs of consecutive values are necessary to represents the set
-	 * bits in the range of the bitSet
-	 * 
-	 * @param offset
-	 * @param length
-	 * @param bitSet
-	 * @return nbrruns
-	 */
-	private static int nbrRuns(final int offset, final int length, final BitSet bitSet) {
-		int index = -1;
-		int runLength = 0;
-		boolean finish = false;
-		int runs = 0;
-		for (int i = bitSet.nextSetBit(offset), offsetLength = offset + length; i >= 0 && i < offsetLength; i = bitSet.nextSetBit(i + 1)) {
-			// operate on index i here
-			if (i == Integer.MAX_VALUE) {
-				if (index != -1) {
-					runs++;
+		int index = 0;
+						
+		// for each word, unless we already have reached cardinality
+		long word = 0;
+		for (int i = from, socket = 0; i < to && index < cardinality; i++, socket += Long.SIZE) { 
+			if (words[i] == 0) continue;
+			
+			// for each bit, unless updated word has become 0 (no more bits left) or we already have reached cardinality
+			word = words[i];
+			for (int bitIndex = 0; word != 0 && bitIndex < Long.SIZE && index < cardinality; word >>>= 1, bitIndex++) {
+				// TODO: does it make sense to start with (0+trailing zeros) or not worth the effort? 
+				// (what could be the fastest way to iterate through the long?)
+				if ((word & 1l) != 0) {
+					content[index++] = (short)(socket + bitIndex);
 				}
-				finish = true;
-				break; // or (i+1) would overflow
 			}
-
-			if (index == -1) {
-				index = i;
-				runLength = 0;
-			} else {
-				if (index + runLength + 1 == i) {
-					runLength++;
-				} else {
-					runs++;
-					index = i;
-					runLength = 0;
-				}
-			}
-		}
-
-		if (index != -1 && !finish) {
-			runs++;
 		}
-		return runs;
-	}
-
-	/**
-	 * Returns true, if any bit is set in range of the bitSet
-	 * 
-	 * @param offset
-	 * @param length
-	 * @param bitSet
-	 * @return true, if any bit is set in range of the bitSet
-	 */
-	private static boolean any(final int offset, final int length, final BitSet bitSet) {
-		final int index = bitSet.nextSetBit(offset);
-		return index >= 0 && index < offset + length;
+		return new ArrayContainer(content);
 	}
 
-	/**
-	 * Counts set bits in the range of the bitSet
-	 * 
-	 * @param offset
-	 * @param length
-	 * @param bitSet
-	 * @return counted set bits in the range of the bitSet
-	 */
-	private static int cardinality(final int offset, final int length, final BitSet bitSet) {
-		int cardinality = 0;
-		for (int i = bitSet.nextSetBit(offset), offsetLength = offset + length; i >= 0 && i < offsetLength; i = bitSet.nextSetBit(i + 1)) {
-			if (i == Integer.MAX_VALUE) {
-				break; // or (i+1) would overflow
-			}
-			cardinality++;
+	private static ArrayContainer arrayContainerOf(final int cardinality, final BitSet bs) {
+		final short[] content = new short[cardinality];
+		int index = 0;
+	    for (int i = bs.nextSetBit(0); i >= 0; i = bs.nextSetBit(i+1)) {
+	             // operate on index i here
+	             if (i == Integer.MAX_VALUE) {
+	                 break; // or (i+1) would overflow
+	             }
+	             content[index++] = (short)i;
+	    }
+	    return new ArrayContainer(content);
+	};
+	
+
+	private static int cardinality(final int from, final int to, final long[] words) {
+		int sum = 0;
+		for (int i = from; i < to; i++) {
+			sum += Long.bitCount(words[i]);
 		}
-		return cardinality;
+		return sum;
 	}
 }
diff --git a/src/test/java/org/roaringbitmap/TestBitSetUtil.java b/src/test/java/org/roaringbitmap/TestBitSetUtil.java
index dae2cd13..b74da67d 100644
--- a/src/test/java/org/roaringbitmap/TestBitSetUtil.java
+++ b/src/test/java/org/roaringbitmap/TestBitSetUtil.java
@@ -18,7 +18,36 @@ public class TestBitSetUtil {
 	@Test
 	public void testFullBitSet() {
 		final BitSet bitset = new BitSet();
-		bitset.set(0, BitSetUtil.CHUNK_SIZE * 10);
+		final int nbits = BitSetUtil.BLOCK_LENGTH * Long.SIZE * 50;
+		bitset.set(0, nbits);
+		final RoaringBitmap bitmap = BitSetUtil.bitmapOf(bitset);
+		assertEqualBitsets(bitset, bitmap);
+	}
+	
+	@Test
+	public void testFlipFlapBetweenRandomFullAndEmptyBitSet() {		
+		final Random random = new Random();	
+		final int nbitsPerBlock = BitSetUtil.BLOCK_LENGTH * Long.SIZE;
+		final int blocks = 50;
+		final BitSet bitset = new BitSet(nbitsPerBlock*blocks);
+		
+		// i want a mix of empty blocks, randomly filled blocks and full blocks
+		for (int block = 0; block < blocks * nbitsPerBlock; block+=nbitsPerBlock) {
+			int type = random.nextInt(3);
+			switch(type) {
+				case 0:
+					// a block with random set bits
+					appendRandomBitset(random, block, bitset, nbitsPerBlock);
+					break;
+				case 1:
+					// a full block
+					bitset.set(block, block+nbitsPerBlock);
+					break;
+				default:
+					// and an empty block; 
+					break;
+			}
+		}
 		final RoaringBitmap bitmap = BitSetUtil.bitmapOf(bitset);
 		assertEqualBitsets(bitset, bitmap);
 	}
@@ -26,8 +55,10 @@ public class TestBitSetUtil {
 	@Test
 	public void testRandomBitmap() {
 		final Random random = new Random();
-		for (int i = 0; i < 10; i++) {
-			final BitSet bitset = randomBitset(random, random.nextInt(BitSetUtil.CHUNK_SIZE * 10));
+		final int runs = 500;
+		final int maxNbits = 500000;
+		for (int i = 0; i < runs; i++) {
+			final BitSet bitset = randomBitset(random, random.nextInt(maxNbits));
 			final RoaringBitmap bitmap = BitSetUtil.bitmapOf(bitset);
 			assertEqualBitsets(bitset, bitmap);
 		}
@@ -41,11 +72,15 @@ public class TestBitSetUtil {
 		}
 	}
 
-	private static BitSet randomBitset(final Random random, final int length) {
-		final BitSet bitset = new BitSet();
-		for (int i = 0; i < length; i++) {
-			bitset.set(i, random.nextBoolean());
+	private static BitSet appendRandomBitset(final Random random, final int offset, final BitSet bitset, final int nbits) {
+		for (int i = 0; i < nbits; i++) {
+			bitset.set(offset+i, random.nextBoolean());
 		}
 		return bitset;
 	}
+	private static BitSet randomBitset(final Random random, final int length) {
+		final BitSet bitset = new BitSet();
+		return appendRandomBitset(random, 0, bitset, length); 
+	}
+
 }",implement transformation to RoaringBitmap via long [ ] as well,"""Optimize BitSetUtil to use BLOCK_LENGTH instead of CHUNK_SIZE and improve performance by reducing allocations and using more efficient container types""","""Refactor BitSetUtil to use blocks of 1024 words instead of chunks of 1<<16 bits, improve performance and memory usage.""","""Refactor BitSetUtil to use blocks of 65536 bits and add tests for random bitsets""

Explanation:

* The constant CHUNK\_SIZE has been renamed to BLOCK\_LENGTH and its value has been changed from 1 << 16 to 1024 \* Long.SIZE, representing a maximum of 65536 bits.
* The method bitmapOf has been refactored to use blocks of 65536 bits instead of chunks of 65536 bits.
* The method containerOf has been refactored to use blocks of 65536 bits instead of chunks of 65536 bits.
* The method arrayContainerOf has been refactored to use blocks of 65536 bits instead of chunks of 65536 bits.
* The method runContainerOf has been removed.
* The method nbrRuns has been removed.
* The method any has been removed.
* The method cardinality has been refactored to use blocks of 65536 bits instead of chunks of 65536 bits.
* A new method bitmapOf has been added to generate a RoaringBitmap from a long[] using little-endian representation of its bits.
* Several new tests have been added to test the new functionality, including tests for random bitsets and a test for a full bitset.","""Enhanced BitSetUtil with better container handling and added tests for random and mixed BitSet scenarios.""",Model 1
"diff --git a/distribution/ReleaseNotes.txt b/distribution/ReleaseNotes.txt
index 2efc7db9a..4d0b64526 100644
--- a/distribution/ReleaseNotes.txt
+++ b/distribution/ReleaseNotes.txt
@@ -12,6 +12,7 @@ HEAD, planned as v0.16
 - Added a priority encoder component.
 - Added tooltips showing the actual value of wires.
 - Added a shortcut S to split a single wire into two wires.
+- Added selectable number format to inputs and outputs.
 - Improved performance through more efficient decoupling of the GUI thread and the simulation thread.
 - Bug fixes
   - Fixed a bug in the RAMSinglePortSel component: Write was not edge-triggered on WE. Now it is.
diff --git a/src/main/java/de/neemann/digital/core/io/In.java b/src/main/java/de/neemann/digital/core/io/In.java
index 7ee6abf4e..d18f5e396 100644
--- a/src/main/java/de/neemann/digital/core/io/In.java
+++ b/src/main/java/de/neemann/digital/core/io/In.java
@@ -33,6 +33,7 @@ public class In implements Element {
             .addAttribute(Keys.INPUT_DEFAULT)
             .addAttribute(Keys.IS_HIGH_Z)
             .addAttribute(Keys.DESCRIPTION)
+            .addAttribute(Keys.INT_FORMAT)
             .addAttribute(Keys.PINNUMBER);
 
     private final ObservableValue output;
diff --git a/src/main/java/de/neemann/digital/core/io/Out.java b/src/main/java/de/neemann/digital/core/io/Out.java
index a935b31f1..daf62ed8c 100644
--- a/src/main/java/de/neemann/digital/core/io/Out.java
+++ b/src/main/java/de/neemann/digital/core/io/Out.java
@@ -30,6 +30,7 @@ public class Out implements Element {
             .addAttribute(Keys.BITS)
             .addAttribute(Keys.LABEL)
             .addAttribute(Keys.DESCRIPTION)
+            .addAttribute(Keys.INT_FORMAT)
             .addAttribute(Keys.PINNUMBER);
 
     /**
diff --git a/src/main/java/de/neemann/digital/draw/shapes/InputShape.java b/src/main/java/de/neemann/digital/draw/shapes/InputShape.java
index 707446d78..2c49cf9e4 100644
--- a/src/main/java/de/neemann/digital/draw/shapes/InputShape.java
+++ b/src/main/java/de/neemann/digital/draw/shapes/InputShape.java
@@ -9,6 +9,7 @@ import de.neemann.digital.core.element.ElementAttributes;
 import de.neemann.digital.core.element.Keys;
 import de.neemann.digital.core.element.PinDescriptions;
 import de.neemann.digital.core.io.In;
+import de.neemann.digital.core.io.IntFormat;
 import de.neemann.digital.draw.elements.IOState;
 import de.neemann.digital.draw.elements.Pin;
 import de.neemann.digital.draw.elements.Pins;
@@ -32,6 +33,7 @@ public class InputShape implements Shape {
 
     private final String label;
     private final PinDescriptions outputs;
+    private final IntFormat format;
     private IOState ioState;
     private SingleValueDialog dialog;
     private Value value;
@@ -50,6 +52,8 @@ public class InputShape implements Shape {
             this.label = attr.getLabel();
         else
             this.label = attr.getLabel() + "" ("" + pinNumber + "")"";
+
+        format = attr.get(Keys.INT_FORMAT);
     }
 
     @Override
@@ -116,7 +120,7 @@ public class InputShape implements Shape {
                 style = Style.getWireStyle(value);
                 if (value.getBits() > 1) {
                     Vector textPos = new Vector(-1 - SIZE, -4 - SIZE);
-                    graphic.drawText(textPos, textPos.add(1, 0), value.getValueString(), Orientation.CENTERBOTTOM, Style.NORMAL);
+                    graphic.drawText(textPos, textPos.add(1, 0), format.format(value), Orientation.CENTERBOTTOM, Style.NORMAL);
                 }
             }
 
diff --git a/src/main/java/de/neemann/digital/draw/shapes/OutputShape.java b/src/main/java/de/neemann/digital/draw/shapes/OutputShape.java
index e173b5266..2c3ded408 100644
--- a/src/main/java/de/neemann/digital/draw/shapes/OutputShape.java
+++ b/src/main/java/de/neemann/digital/draw/shapes/OutputShape.java
@@ -5,6 +5,7 @@ import de.neemann.digital.core.Value;
 import de.neemann.digital.core.element.ElementAttributes;
 import de.neemann.digital.core.element.Keys;
 import de.neemann.digital.core.element.PinDescriptions;
+import de.neemann.digital.core.io.IntFormat;
 import de.neemann.digital.draw.elements.IOState;
 import de.neemann.digital.draw.elements.Pin;
 import de.neemann.digital.draw.elements.Pins;
@@ -38,6 +39,7 @@ public class OutputShape implements Shape {
     public static final Vector RADL = new Vector(SIZE, SIZE);
     private final String label;
     private final PinDescriptions inputs;
+    private final IntFormat format;
     private IOState ioState;
     private Value value;
 
@@ -55,6 +57,8 @@ public class OutputShape implements Shape {
             this.label = attr.getLabel();
         else
             this.label = attr.getLabel() + "" ("" + pinNumber + "")"";
+
+        format = attr.get(Keys.INT_FORMAT);
     }
 
     @Override
@@ -88,7 +92,7 @@ public class OutputShape implements Shape {
                 style = Style.getWireStyle(value);
                 if (value.getBits() > 1) {
                     Vector textPos = new Vector(1 + SIZE, -4 - SIZE);
-                    graphic.drawText(textPos, textPos.add(1, 0), value.getValueString(), Orientation.CENTERBOTTOM, Style.NORMAL);
+                    graphic.drawText(textPos, textPos.add(1, 0), format.format(value), Orientation.CENTERBOTTOM, Style.NORMAL);
                 }
             }
 
diff --git a/src/test/java/de/neemann/digital/core/io/IntFormatTest.java b/src/test/java/de/neemann/digital/core/io/IntFormatTest.java
index 4f3877289..8281eea39 100644
--- a/src/test/java/de/neemann/digital/core/io/IntFormatTest.java
+++ b/src/test/java/de/neemann/digital/core/io/IntFormatTest.java
@@ -18,6 +18,7 @@ public class IntFormatTest extends TestCase {
         assertEquals(""FFFF"", IntFormat.hex.format(new Value(-1, 14)));
         assertEquals(""FFFF"", IntFormat.hex.format(new Value(-1, 15)));
         assertEquals(""FFFF"", IntFormat.hex.format(new Value(-1, 16)));
+        assertEquals(""FEDCBA9876543210"", IntFormat.hex.format(new Value(0xFEDCBA9876543210L, 64)));
     }
 
     public void testBin() throws Exception {",Added selectable number format to inputs and outputs .,"""Added selectable number format to inputs and outputs""",Added selectable number format to inputs and outputs.,"The commit message should be:

Added selectable number format to inputs and outputs.

The changes include:

* Added `Keys.INT_FORMAT` attribute to `In` and `Out` classes.
* Added `IntFormat` to `InputShape` and `OutputShape` classes.
* Updated `InputShape` and `OutputShape` classes to use `IntFormat` for displaying the value.
* Added a test case for `IntFormat` in `IntFormatTest`.

The changes allow the user to select the number format for inputs and outputs, and the selected format is used for displaying the value. The supported number formats are binary, decimal, and hexadecimal.","""Added selectable number format for inputs and outputs, including HEX formatting support for large values.""",Model 1
"diff --git a/build.gradle b/build.gradle
index 91f23273ee..40e814244c 100644
--- a/build.gradle
+++ b/build.gradle
@@ -71,9 +71,9 @@ dependencies {
 
     compile 'org.swinglabs:swingx:1.6.1' // do not update, 1.6.5.1 is broken
 
-    compile 'org.apache.pdfbox:pdfbox:1.8.10'
-    compile 'org.apache.pdfbox:fontbox:1.8.10'
-    compile 'org.apache.pdfbox:jempbox:1.8.10'
+    compile 'org.apache.pdfbox:pdfbox:1.8.11'
+    compile 'org.apache.pdfbox:fontbox:1.8.11'
+    compile 'org.apache.pdfbox:jempbox:1.8.11'
 
     compile 'commons-cli:commons-cli:1.3.1'
 ","Updated versions for pdfbox , fontbox , and jempbox","""Update Apache PDFBox dependencies to version 1.8.11""","""Update Apache PDFBox to version 1.8.11""","""Updated PDFBox dependencies to version 1.8.11""",Updated Apache PDFBox dependencies from version 1.8.10 to 1.8.11.,Model 1
"diff --git a/sonar-server/src/main/webapp/WEB-INF/app/controllers/dashboard_controller.rb b/sonar-server/src/main/webapp/WEB-INF/app/controllers/dashboard_controller.rb
index 5c02d7a47e1..a4d9cce2c80 100644
--- a/sonar-server/src/main/webapp/WEB-INF/app/controllers/dashboard_controller.rb
+++ b/sonar-server/src/main/webapp/WEB-INF/app/controllers/dashboard_controller.rb
@@ -119,7 +119,7 @@ class DashboardController < ApplicationController
           prop.save!
         end
       end
-      widget.resource_id=params[:resource_id]
+      widget.resource_id=Project.by_key(params[:resource_id]).id
       widget.configured=true
       widget.save!
       render :update do |page|
diff --git a/sonar-server/src/main/webapp/WEB-INF/app/views/dashboard/_widget_properties.html.erb b/sonar-server/src/main/webapp/WEB-INF/app/views/dashboard/_widget_properties.html.erb
index cdc03e0d892..bcac687922d 100644
--- a/sonar-server/src/main/webapp/WEB-INF/app/views/dashboard/_widget_properties.html.erb
+++ b/sonar-server/src/main/webapp/WEB-INF/app/views/dashboard/_widget_properties.html.erb
@@ -1,7 +1,8 @@
 <% form_remote_tag :url => {:action => :save_widget, :wid => widget.id, :id => params[:id]},
                    :method => :post,
                    :update => {:failure => ""error#{widget.id}""},
-                   :failure => ""$('error#{widget.id}').show()"" do -%>
+                   :failure => ""$('error#{widget.id}').show()"",
+                   :id => ""form-edit-#{widget.key.parameterize}"" do -%>
   <div id=""error<%= widget.id -%>"" class=""error"" style=""display: none""></div>
   <table class=""table width100"">
     <tbody>
@@ -14,7 +15,7 @@
               :resource_type_property => 'supportsGlobalDashboards',
               :selected_resource => widget.resource,
               :width => '250px',
-              :html_id => ""sel-prj-#{widget.id}""} -%>
+              :html_id => ""widget-select-prj-#{widget.key.parameterize}""} -%>
         </td>
       </tr>
     <% end %>
@@ -33,7 +34,7 @@
 
     <tr>
       <td colspan=""2"">
-        <%= submit_tag message('save') %>
+        <%= submit_tag message('save'), :id => ""widget-save-#{widget.key.parameterize}"" -%>
         <% if widget.configured %>
           <a href=""#"" onClick=""portal.cancelEditWidget(<%= widget.id -%>);return false;""><%= message('cancel') -%></a>
         <% end %>
diff --git a/sonar-server/src/main/webapp/stylesheets/dashboard.css b/sonar-server/src/main/webapp/stylesheets/dashboard.css
index f7216704e12..4572c090454 100644
--- a/sonar-server/src/main/webapp/stylesheets/dashboard.css
+++ b/sonar-server/src/main/webapp/stylesheets/dashboard.css
@@ -46,7 +46,7 @@
 #dashboard .widget-title {
   background-color: #4B9FD5;
   color: #FEFEFE;
-  padding: 3px 0 3px 5px;
+  padding: 5px;
   height: 16px;
   line-height: 16px;
   vertical-align: middle;",Add HTML IDs for integration tests,"""Improve dashboard widget configuration and styling""","""Refactor dashboard widget configuration and rendering to improve resource ID handling and add unique IDs to form and submit buttons.""","""Update DashboardController to set resource\_id using Project.by\_key and update widget properties view and stylesheet""

Here are the changes made in this commit:

1. In `dashboard_controller.rb`, the `resource_id` of a widget is now set using `Project.by_key(params[:resource_id]).id` instead of just `params[:resource_id]`.
2. In `_widget_properties.html.erb`, an `id` attribute has been added to the `form_remote_tag` and the `submit_tag`. The `id` attribute values use `widget.key.parameterize` to generate a unique identifier for each widget.
3. In `dashboard.css`, the `padding` property of the `.widget-title` class has been changed from `3px 0 3px 5px` to `5px`. This will increase the padding around the widget title.",Improved widget configuration handling and added unique IDs for form elements in Dashboard for better DOM manipulation and styling.,Model 4
"diff --git a/controller-api/src/main/java/com/yahoo/vespa/hosted/controller/api/role/PathGroup.java b/controller-api/src/main/java/com/yahoo/vespa/hosted/controller/api/role/PathGroup.java
index 95f394aefef..419344eae95 100644
--- a/controller-api/src/main/java/com/yahoo/vespa/hosted/controller/api/role/PathGroup.java
+++ b/controller-api/src/main/java/com/yahoo/vespa/hosted/controller/api/role/PathGroup.java
@@ -51,7 +51,7 @@ enum PathGroup {
     /** Paths used for user management on the tenant level. */
     tenantUsers(Matcher.tenant,
                 PathPrefix.api,
-                ""/user/v1/tenant/{tenant}""),
+                ""/user/v1/tenant/{tenant}"", ""/user/v1/tenant/{tenant}/info/""),
 
     /** Paths used by tenant administrators. */
     tenantInfo(Matcher.tenant,",Add info path to path group,"""Added '/user/v1/tenant/{tenant}/info/' path to PathGroup.tenantUsers""",Added additional path for tenant user info.,"""Added new path '/user/v1/tenant/{tenant}/info/' to PathGroup.tenantUsers in PathGroup.java""","""Add new path for tenant user info under tenantUsers PathGroup to improve user management.""",Model 1
"diff --git a/examples.txt b/examples.txt
index 5a821d8a83b..254e8a48ff0 100644
--- a/examples.txt
+++ b/examples.txt
@@ -105,12 +105,8 @@ Task Appointment
 Config API
 String Template
 HTTP Redirects
-Inbound Request with Multiparts
-Outbound Request with Multiparts
-Encode Nested BodyParts in Multipart
-Decode Nested BodyParts in Multipart
-Inbound Response with Multiparts
-Outbound Response with Multiparts
+Request with Multiparts
+Response with Multiparts
 gRPC Unary Non Blocking
 grpc Unary Blocking
 grpc Secured Unary Blocking
diff --git a/examples/filter-connector/filter_connector.bal b/examples/filter-connector/filter_connector.bal
deleted file mode 100644
index 4d5543974ed..00000000000
--- a/examples/filter-connector/filter_connector.bal
+++ /dev/null
@@ -1,55 +0,0 @@
-import ballerina/io;
-
-@Description {value:""This is the base connector you are going to decorate.""}
-connector StockQuoteConnector (int i) {
-    action getStock (string ID) (int stockPrice) {
-        //This value is returned by the base connector.
-        //In a real world scenario, a backend service is called to get the result.
-        return 999;
-    }
-}
-
-@Description {value:""This is the filter connector, which will be decorating the base connector.""}
-connector CacheConnector<StockQuoteConnector stockC> (string j) {
-    //For this example, the connector is pre-loaded with sample cache values that are stored in a map.
-    map cachedKeys = {""IBM"":350, ""WSO2"":300};
-    action getStock (string ID) (int stockPrice) {
-        int result = -1;
-        // If the ID that was called is defined in the cache map, it returns the value assigned to the ID.
-        //Else, it calls the functions in the base connector.
-        if (cachedKeys[ID] != null) {
-            result, _ = (int)cachedKeys[ID];
-        } else {
-            // If the ID that was called does not match the values in the cache, which is the functionality of the
-            //filter connector, the base connectors functionality is called to check for the ID and its corresponding
-            //value.
-            //Once the value is found, it is stored in the 'cachedKeys' map.
-            result = stockC.getStock(ID);
-            cachedKeys[ID] = result;
-        }
-        return result;
-    }
-}
-
-function main (string... args) {
-    // Create the 'StockQuoteConnector' that acts as the base connector and decorate it using the 'CacheConnector'
-    // that acts as the filter connector.
-    StockQuoteConnector stockQC = create StockQuoteConnector(5)
-                                  with CacheConnector(""Bob"");
-
-    // Invoke the action of the 'StockQuoteConnector' by passing 'WSO2' as the ID. Since WSO2 is stored
-    //in the 'cachedKeys' map of the filter connector the respective price value is printed.
-    int price = stockQC.getStock(""WSO2"");
-    io:println(price);
-
-    // Invoke the action of the 'StockQuoteConnector' by passing 'IBM' as the ID. Since IBM is stored in the
-    // 'cachedKeys' map of the filter connector the respective price value is printed.
-    price = stockQC.getStock(""IBM"");
-    io:println(price);
-
-    // Invoke the action of the 'StockQuoteConnector' by passing 'Ballerina' as the ID. Since 'Ballerina' is not stored
-    // in the 'cachedKeys' map of the filter connector, the base connector functionality is called and the price defined
-    //for it is printed.
-    price = stockQC.getStock(""Ballerina"");
-    io:println(price);
-}
diff --git a/examples/filter-connector/filter_connector.description b/examples/filter-connector/filter_connector.description
deleted file mode 100644
index 2865a9a3e5e..00000000000
--- a/examples/filter-connector/filter_connector.description
+++ /dev/null
@@ -1,3 +0,0 @@
-//Filter connectors are used to decorate an existing connector with additional functionality.
-//You can extend the functionality of a native or ballerina based connector using a filter connector without altering
-//the original connector.
\ No newline at end of file
diff --git a/examples/filter-connector/filter_connector.out b/examples/filter-connector/filter_connector.out
deleted file mode 100644
index 535b6dbf22f..00000000000
--- a/examples/filter-connector/filter_connector.out
+++ /dev/null
@@ -1,4 +0,0 @@
-$ ballerina run filter_connector.bal
-300
-350
-999",Remove filter connector BBE,"""Remove filter-connector example and update examples.txt""","""Removed filter-connector example and simplified Multipart examples""","""Remove filter connector example and update examples.txt""

This commit removes the filter connector example code and related description file, and updates the examples.txt file to reflect these changes. Specifically, it removes the filter\_connector.bal and filter\_connector.description files, and updates the examples.txt file by removing the references to the filter connector example. Additionally, it updates the examples.txt file to replace the 'Inbound Request with Multiparts' and 'Outbound Request with Multiparts' examples with 'Request with Multiparts' and 'Response with Multiparts' examples.","""Remove filter-connector example and simplify multipart request/response descriptions in examples.txt.""",Model 4
"diff --git a/sdks/go/pkg/beam/core/runtime/exec/sdf_invokers.go b/sdks/go/pkg/beam/core/runtime/exec/sdf_invokers.go
new file mode 100644
index 0000000000..6beac0fbb3
--- /dev/null
+++ b/sdks/go/pkg/beam/core/runtime/exec/sdf_invokers.go
@@ -0,0 +1,301 @@
+// Licensed to the Apache Software Foundation (ASF) under one or more
+// contributor license agreements.  See the NOTICE file distributed with
+// this work for additional information regarding copyright ownership.
+// The ASF licenses this file to You under the Apache License, Version 2.0
+// (the ""License""); you may not use this file except in compliance with
+// the License.  You may obtain a copy of the License at
+//
+//    http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an ""AS IS"" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package exec
+
+import (
+	""github.com/apache/beam/sdks/go/pkg/beam/core/funcx""
+	""github.com/apache/beam/sdks/go/pkg/beam/core/sdf""
+	""github.com/apache/beam/sdks/go/pkg/beam/core/util/reflectx""
+	""github.com/apache/beam/sdks/go/pkg/beam/internal/errors""
+	""reflect""
+)
+
+// This file contains invokers for SDF methods. These invokers are based off
+// exec.invoker which is used for regular DoFns. Since exec.invoker is
+// specialized for DoFns it cannot be used for SDF methods. Instead, these
+// invokers pare down the functionality to only what is essential for
+// executing SDF methods, including per-element optimizations.
+//
+// Each SDF method invoker in this file is specific to a certain method, but
+// they are all used the same way. Create an invoker with new[Method]Invoker
+// in the Up method of an exec.Unit, and then invoke it with Invoke. Finally,
+// call Reset on it when the bundle ends in FinishBundle.
+//
+// These invokers are not thread-safe.
+
+// cirInvoker is an invoker for CreateInitialRestriction.
+type cirInvoker struct {
+	fn   *funcx.Fn
+	args []interface{} // Cache to avoid allocating new slices per-element.
+	call func(elms *FullValue) (rest interface{})
+}
+
+func newCreateInitialRestrictionInvoker(fn *funcx.Fn) (*cirInvoker, error) {
+	n := &cirInvoker{
+		fn:   fn,
+		args: make([]interface{}, len(fn.Param)),
+	}
+	if err := n.initCallFn(); err != nil {
+		return nil, errors.WithContext(err, ""sdf CreateInitialRestriction invoker"")
+	}
+	return n, nil
+}
+
+func (n *cirInvoker) initCallFn() error {
+	// Expects a signature of the form:
+	// (key?, value) restriction
+	// TODO(BEAM-9643): Link to full documentation.
+	switch fnT := n.fn.Fn.(type) {
+	case reflectx.Func1x1:
+		n.call = func(elms *FullValue) interface{} {
+			return fnT.Call1x1(elms.Elm)
+		}
+	case reflectx.Func2x1:
+		n.call = func(elms *FullValue) interface{} {
+			return fnT.Call2x1(elms.Elm, elms.Elm2)
+		}
+	default:
+		switch len(n.fn.Param) {
+		case 1:
+			n.call = func(elms *FullValue) interface{} {
+				n.args[0] = elms.Elm
+				return n.fn.Fn.Call(n.args)[0]
+			}
+		case 2:
+			n.call = func(elms *FullValue) interface{} {
+				n.args[0] = elms.Elm
+				n.args[1] = elms.Elm2
+				return n.fn.Fn.Call(n.args)[0]
+			}
+		default:
+			return errors.Errorf(""CreateInitialRestriction fn %v has unexpected number of parameters: %v"",
+				n.fn.Fn.Name(), len(n.fn.Param))
+		}
+	}
+
+	return nil
+}
+
+// Invoke calls CreateInitialRestriction with the given FullValue as the element
+// and returns the resulting restriction.
+func (n *cirInvoker) Invoke(elms *FullValue) (rest interface{}) {
+	return n.call(elms)
+}
+
+// Reset zeroes argument entries in the cached slice to allow values to be
+// garbage collected after the bundle ends.
+func (n *cirInvoker) Reset() {
+	for i := range n.args {
+		n.args[i] = nil
+	}
+}
+
+// srInvoker is an invoker for SplitRestriction.
+type srInvoker struct {
+	fn   *funcx.Fn
+	args []interface{} // Cache to avoid allocating new slices per-element.
+	call func(elms *FullValue, rest interface{}) (splits interface{})
+}
+
+func newSplitRestrictionInvoker(fn *funcx.Fn) (*srInvoker, error) {
+	n := &srInvoker{
+		fn:   fn,
+		args: make([]interface{}, len(fn.Param)),
+	}
+	if err := n.initCallFn(); err != nil {
+		return nil, errors.WithContext(err, ""sdf SplitRestriction invoker"")
+	}
+	return n, nil
+}
+
+func (n *srInvoker) initCallFn() error {
+	// Expects a signature of the form:
+	// (key?, value, restriction) []restriction
+	// TODO(BEAM-9643): Link to full documentation.
+	switch fnT := n.fn.Fn.(type) {
+	case reflectx.Func2x1:
+		n.call = func(elms *FullValue, rest interface{}) interface{} {
+			return fnT.Call2x1(elms.Elm, rest)
+		}
+	case reflectx.Func3x1:
+		n.call = func(elms *FullValue, rest interface{}) interface{} {
+			return fnT.Call3x1(elms.Elm, elms.Elm2, rest)
+		}
+	default:
+		switch len(n.fn.Param) {
+		case 2:
+			n.call = func(elms *FullValue, rest interface{}) interface{} {
+				n.args[0] = elms.Elm
+				n.args[1] = rest
+				return n.fn.Fn.Call(n.args)[0]
+			}
+		case 3:
+			n.call = func(elms *FullValue, rest interface{}) interface{} {
+				n.args[0] = elms.Elm
+				n.args[1] = elms.Elm2
+				n.args[2] = rest
+				return n.fn.Fn.Call(n.args)[0]
+			}
+		default:
+			return errors.Errorf(""SplitRestriction fn %v has unexpected number of parameters: %v"",
+				n.fn.Fn.Name(), len(n.fn.Param))
+		}
+	}
+	return nil
+}
+
+// Invoke calls SplitRestriction given a FullValue containing an element and
+// the associated restriction, and returns a slice of split restrictions.
+func (n *srInvoker) Invoke(elms *FullValue, rest interface{}) (splits []interface{}) {
+	ret := n.call(elms, rest)
+
+	// Return value is an interface{}, but we need to convert it to a []interface{}.
+	val := reflect.ValueOf(ret)
+	s := make([]interface{}, 0, val.Len())
+	for i := 0; i < val.Len(); i++ {
+		s = append(s, val.Index(i).Interface())
+	}
+	return s
+}
+
+// Reset zeroes argument entries in the cached slice to allow values to be
+// garbage collected after the bundle ends.
+func (n *srInvoker) Reset() {
+	for i := range n.args {
+		n.args[i] = nil
+	}
+}
+
+// rsInvoker is an invoker for RestrictionSize.
+type rsInvoker struct {
+	fn   *funcx.Fn
+	args []interface{} // Cache to avoid allocating new slices per-element.
+	call func(elms *FullValue, rest interface{}) (size float64)
+}
+
+func newRestrictionSizeInvoker(fn *funcx.Fn) (*rsInvoker, error) {
+	n := &rsInvoker{
+		fn:   fn,
+		args: make([]interface{}, len(fn.Param)),
+	}
+	if err := n.initCallFn(); err != nil {
+		return nil, errors.WithContext(err, ""sdf RestrictionSize invoker"")
+	}
+	return n, nil
+}
+
+func (n *rsInvoker) initCallFn() error {
+	// Expects a signature of the form:
+	// (key?, value, restriction) float64
+	// TODO(BEAM-9643): Link to full documentation.
+	switch fnT := n.fn.Fn.(type) {
+	case reflectx.Func2x1:
+		n.call = func(elms *FullValue, rest interface{}) float64 {
+			return fnT.Call2x1(elms.Elm, rest).(float64)
+		}
+	case reflectx.Func3x1:
+		n.call = func(elms *FullValue, rest interface{}) float64 {
+			return fnT.Call3x1(elms.Elm, elms.Elm2, rest).(float64)
+		}
+	default:
+		switch len(n.fn.Param) {
+		case 2:
+			n.call = func(elms *FullValue, rest interface{}) float64 {
+				n.args[0] = elms.Elm
+				n.args[1] = rest
+				return n.fn.Fn.Call(n.args)[0].(float64)
+			}
+		case 3:
+			n.call = func(elms *FullValue, rest interface{}) float64 {
+				n.args[0] = elms.Elm
+				n.args[1] = elms.Elm2
+				n.args[2] = rest
+				return n.fn.Fn.Call(n.args)[0].(float64)
+			}
+		default:
+			return errors.Errorf(""RestrictionSize fn %v has unexpected number of parameters: %v"",
+				n.fn.Fn.Name(), len(n.fn.Param))
+		}
+	}
+	return nil
+}
+
+// Invoke calls RestrictionSize given a FullValue containing an element and
+// the associated restriction, and returns a size.
+func (n *rsInvoker) Invoke(elms *FullValue, rest interface{}) (size float64) {
+	return n.call(elms, rest)
+}
+
+// Reset zeroes argument entries in the cached slice to allow values to be
+// garbage collected after the bundle ends.
+func (n *rsInvoker) Reset() {
+	for i := range n.args {
+		n.args[i] = nil
+	}
+}
+
+// ctInvoker is an invoker for CreateTracker.
+type ctInvoker struct {
+	fn   *funcx.Fn
+	args []interface{} // Cache to avoid allocating new slices per-element.
+	call func(rest interface{}) sdf.RTracker
+}
+
+func newCreateTrackerInvoker(fn *funcx.Fn) (*ctInvoker, error) {
+	n := &ctInvoker{
+		fn:   fn,
+		args: make([]interface{}, len(fn.Param)),
+	}
+	if err := n.initCallFn(); err != nil {
+		return nil, errors.WithContext(err, ""sdf CreateTracker invoker"")
+	}
+	return n, nil
+}
+
+func (n *ctInvoker) initCallFn() error {
+	// Expects a signature of the form:
+	// (restriction) sdf.RTracker
+	// TODO(BEAM-9643): Link to full documentation.
+	switch fnT := n.fn.Fn.(type) {
+	case reflectx.Func1x1:
+		n.call = func(rest interface{}) sdf.RTracker {
+			return fnT.Call1x1(rest).(sdf.RTracker)
+		}
+	default:
+		if len(n.fn.Param) != 1 {
+			return errors.Errorf(""CreateTracker fn %v has unexpected number of parameters: %v"",
+				n.fn.Fn.Name(), len(n.fn.Param))
+		}
+		n.call = func(rest interface{}) sdf.RTracker {
+			n.args[0] = rest
+			return n.fn.Fn.Call(n.args)[0].(sdf.RTracker)
+		}
+	}
+	return nil
+}
+
+// Invoke calls CreateTracker given a restriction and returns an sdf.RTracker.
+func (n *ctInvoker) Invoke(rest interface{}) sdf.RTracker {
+	return n.call(rest)
+}
+
+// Reset zeroes argument entries in the cached slice to allow values to be
+// garbage collected after the bundle ends.
+func (n *ctInvoker) Reset() {
+	for i := range n.args {
+		n.args[i] = nil
+	}
+}
diff --git a/sdks/go/pkg/beam/core/runtime/exec/sdf_invokers_test.go b/sdks/go/pkg/beam/core/runtime/exec/sdf_invokers_test.go
new file mode 100644
index 0000000000..29ae981bd5
--- /dev/null
+++ b/sdks/go/pkg/beam/core/runtime/exec/sdf_invokers_test.go
@@ -0,0 +1,279 @@
+// Licensed to the Apache Software Foundation (ASF) under one or more
+// contributor license agreements.  See the NOTICE file distributed with
+// this work for additional information regarding copyright ownership.
+// The ASF licenses this file to You under the Apache License, Version 2.0
+// (the ""License""); you may not use this file except in compliance with
+// the License.  You may obtain a copy of the License at
+//
+//    http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an ""AS IS"" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+
+package exec
+
+import (
+	""github.com/apache/beam/sdks/go/pkg/beam/core/graph""
+	""github.com/google/go-cmp/cmp""
+	""testing""
+)
+
+// TestInvokes runs tests on each SDF method invoker, using the SDFs defined
+// in this file. Tests both single-element and KV element cases.
+func TestInvokes(t *testing.T) {
+	// Setup.
+	dfn, err := graph.NewDoFn(&Sdf{}, graph.NumMainInputs(graph.MainSingle))
+	if err != nil {
+		t.Fatalf(""invalid function: %v"", err)
+	}
+	sdf := (*graph.SplittableDoFn)(dfn)
+
+	dfn, err = graph.NewDoFn(&KvSdf{}, graph.NumMainInputs(graph.MainKv))
+	if err != nil {
+		t.Fatalf(""invalid function: %v"", err)
+	}
+	kvsdf := (*graph.SplittableDoFn)(dfn)
+
+	// Tests.
+	t.Run(""createInitialRestrictionCallFn"", func(t *testing.T) {
+		tests := []struct {
+			name string
+			sdf  *graph.SplittableDoFn
+			elms *FullValue
+			want Restriction
+		}{
+			{""SingleElem"", sdf, &FullValue{Elm: 5}, Restriction{5}},
+			{""KvElem"", kvsdf, &FullValue{Elm: 5, Elm2: 2}, Restriction{7}},
+		}
+		for _, test := range tests {
+			test := test
+			fn := test.sdf.CreateInitialRestrictionFn()
+			t.Run(test.name, func(t *testing.T) {
+				invoker, err := newCreateInitialRestrictionInvoker(fn)
+				if err != nil {
+					t.Fatalf(""newCreateInitialRestrictionInvoker failed: %v"", err)
+				}
+				got := invoker.Invoke(test.elms)
+				if !cmp.Equal(got, test.want) {
+					t.Errorf(""Invoke(%v) has incorrect output: got: %v, want: %v"",
+						test.elms, got, test.want)
+				}
+				invoker.Reset()
+				for i, arg := range invoker.args {
+					if arg != nil {
+						t.Errorf(""Reset() failed to empty all args. args[%v] = %v"", i, arg)
+					}
+				}
+			})
+		}
+	})
+
+	t.Run(""invokeSplitRestriction"", func(t *testing.T) {
+		tests := []struct {
+			name string
+			sdf  *graph.SplittableDoFn
+			elms *FullValue
+			rest Restriction
+			want []interface{}
+		}{
+			{
+				""SingleElem"",
+				sdf,
+				&FullValue{Elm: 5},
+				Restriction{3},
+				[]interface{}{Restriction{8}, Restriction{9}},
+			}, {
+				""KvElem"",
+				kvsdf,
+				&FullValue{Elm: 5, Elm2: 2},
+				Restriction{3},
+				[]interface{}{Restriction{8}, Restriction{5}},
+			},
+		}
+		for _, test := range tests {
+			test := test
+			fn := test.sdf.SplitRestrictionFn()
+			t.Run(test.name, func(t *testing.T) {
+				invoker, err := newSplitRestrictionInvoker(fn)
+				if err != nil {
+					t.Fatalf(""newSplitRestrictionInvoker failed: %v"", err)
+				}
+				got := invoker.Invoke(test.elms, test.rest)
+				if !cmp.Equal(got, test.want) {
+					t.Errorf(""Invoke(%v, %v) has incorrect output: got: %v, want: %v"",
+						test.elms, test.rest, got, test.want)
+				}
+				invoker.Reset()
+				for i, arg := range invoker.args {
+					if arg != nil {
+						t.Errorf(""Reset() failed to empty all args. args[%v] = %v"", i, arg)
+					}
+				}
+			})
+		}
+	})
+
+	t.Run(""invokeRestrictionSize"", func(t *testing.T) {
+		tests := []struct {
+			name string
+			sdf  *graph.SplittableDoFn
+			elms *FullValue
+			rest Restriction
+			want float64
+		}{
+			{
+				""SingleElem"",
+				sdf,
+				&FullValue{Elm: 5},
+				Restriction{3},
+				8,
+			}, {
+				""KvElem"",
+				kvsdf,
+				&FullValue{Elm: 5, Elm2: 2},
+				Restriction{3},
+				10,
+			},
+		}
+		for _, test := range tests {
+			test := test
+			fn := test.sdf.RestrictionSizeFn()
+			t.Run(test.name, func(t *testing.T) {
+				invoker, err := newRestrictionSizeInvoker(fn)
+				if err != nil {
+					t.Fatalf(""newRestrictionSizeInvoker failed: %v"", err)
+				}
+				got := invoker.Invoke(test.elms, test.rest)
+				if !cmp.Equal(got, test.want) {
+					t.Errorf(""Invoke(%v, %v) has incorrect output: got: %v, want: %v"",
+						test.elms, test.rest, got, test.want)
+				}
+			})
+		}
+	})
+
+	t.Run(""invokeCreateTracker"", func(t *testing.T) {
+		tests := []struct {
+			name string
+			sdf  *graph.SplittableDoFn
+			rest Restriction
+			want *RTracker
+		}{
+			{
+				""SingleElem"",
+				sdf,
+				Restriction{3},
+				&RTracker{
+					Restriction{3},
+					1,
+				},
+			}, {
+				""KvElem"",
+				kvsdf,
+				Restriction{5},
+				&RTracker{
+					Restriction{5},
+					2,
+				},
+			},
+		}
+		for _, test := range tests {
+			test := test
+			fn := test.sdf.CreateTrackerFn()
+			t.Run(test.name, func(t *testing.T) {
+				invoker, err := newCreateTrackerInvoker(fn)
+				if err != nil {
+					t.Fatalf(""newCreateTrackerInvoker failed: %v"", err)
+				}
+				got := invoker.Invoke(test.rest)
+				if !cmp.Equal(got, test.want) {
+					t.Errorf(""Invoke(%v) has incorrect output: got: %v, want: %v"",
+						test.rest, got, test.want)
+				}
+			})
+		}
+	})
+}
+
+type Restriction struct {
+	Val int
+}
+
+// RTracker's methods can all be no-ops, we just need it to implement sdf.RTracker.
+type RTracker struct {
+	Rest Restriction
+	Val  int
+}
+
+func (rt *RTracker) TryClaim(interface{}) bool                      { return false }
+func (rt *RTracker) GetError() error                                { return nil }
+func (rt *RTracker) TrySplit(fraction float64) (interface{}, error) { return nil, nil }
+func (rt *RTracker) GetProgress() float64                           { return 0 }
+func (rt *RTracker) IsDone() bool                                   { return false }
+
+// In order to test that these methods get called properly, each one has an
+// implementation that lets us confirm that each argument was passed properly.
+
+type Sdf struct {
+}
+
+// CreateInitialRestriction creates a restriction with the given value.
+func (fn *Sdf) CreateInitialRestriction(i int) Restriction {
+	return Restriction{i}
+}
+
+// SplitRestriction outputs two restrictions, the first containing the sum of i
+// and rest.Val, the second containing the same value plus 1.
+func (fn *Sdf) SplitRestriction(i int, rest Restriction) []Restriction {
+	return []Restriction{{rest.Val + i}, {rest.Val + i + 1}}
+}
+
+// RestrictionSize returns the sum of i and rest.Val as a float64.
+func (fn *Sdf) RestrictionSize(i int, rest Restriction) float64 {
+	return (float64)(i + rest.Val)
+}
+
+// CreateTracker creates an RTracker containing the given restriction and a Val
+// of 1.
+func (fn *Sdf) CreateTracker(rest Restriction) *RTracker {
+	return &RTracker{rest, 1}
+}
+
+// ProcessElement is a no-op, it's only included to pass validation.
+func (fn *Sdf) ProcessElement(*RTracker, int) int {
+	return 0
+}
+
+type KvSdf struct {
+}
+
+// CreateInitialRestriction creates a restriction with the sum of the given
+// values.
+func (fn *KvSdf) CreateInitialRestriction(i int, j int) Restriction {
+	return Restriction{i + j}
+}
+
+// SplitRestriction outputs two restrictions, the first containing the sum of i
+// and rest.Val, the second containing the sum of j and rest.Val.
+func (fn *KvSdf) SplitRestriction(i int, j int, rest Restriction) []Restriction {
+	return []Restriction{{rest.Val + i}, {rest.Val + j}}
+}
+
+// RestrictionSize returns the sum of i, j, and rest.Val as a float64.
+func (fn *KvSdf) RestrictionSize(i int, j int, rest Restriction) float64 {
+	return (float64)(i + j + rest.Val)
+}
+
+// CreateTracker creates an RTracker containing the given restriction and a Val
+// of 2.
+func (fn *KvSdf) CreateTracker(rest Restriction) *RTracker {
+	return &RTracker{rest, 2}
+}
+
+// ProcessElement is a no-op, it's only included to pass validation.
+func (fn *KvSdf) ProcessElement(*RTracker, int, int) int {
+	return 0
+}",Create runtime invokers for SDF methods . .,"""Add SDF method invokers for CreateInitialRestriction, SplitRestriction, RestrictionSize, and CreateTracker""","Implement SDF method invokers and test cases.

This commit message is concise and accurately describes the changes made in the commit. It mentions the implementation of SDF method invokers and the addition of test cases, which is in line with the code changes shown in the diff.","The commit message could be:

""Add SDF method invokers and tests""

Explanation:

This commit adds new files `sdfs_invokers.go` and `sdfs_invokers_test.go` to the `exec` package. The `sdfs_invokers.go` file contains invokers for SDF methods, such as `CreateInitialRestriction`, `SplitRestriction`, `RestrictionSize`, and `CreateTracker`. These invokers are used to call the corresponding SDF methods with the appropriate arguments and return values.

The `sdfs_invokers_test.go` file contains tests for the SDF method invokers. It tests both single-element and KV element cases for each invoker using the SDFs defined in the file. The tests check that the output of the invoker matches the expected output for a given input.

The commit also includes a new type `Restriction` and an `RTracker` struct that implements the `sdf.RTracker` interface. These are used in the SDF methods and tests.

Overall, this commit adds new functionality to the `exec` package for invoking SDF methods and includes tests to ensure their correctness.","""Added SDF method invokers and their tests for CreateInitialRestriction, SplitRestriction, RestrictionSize, and CreateTracker in Go SDK.""",Model 4
"diff --git a/undertow/benchmark_config b/undertow/benchmark_config
index 47f4a943b..2d7d78b1d 100644
--- a/undertow/benchmark_config
+++ b/undertow/benchmark_config
@@ -11,7 +11,7 @@
     },
     ""mysql"" : {
       ""setup_file"": ""setup"",
-      ""db_url"": ""/db"",
+      ""db_url"": ""/db/mysql"",
       ""query_url"": ""/db/mysql?queries="",
       ""fortune_url"": ""/fortunes/mysql"",
       ""update_url"": ""/updates/mysql?queries="",
@@ -20,7 +20,7 @@
     },
     ""postgresql"" : {
       ""setup_file"": ""setup"",
-      ""db_url"": ""/db"",
+      ""db_url"": ""/db/postgresql"",
       ""query_url"": ""/db/postgresql?queries="",
       ""fortune_url"": ""/fortunes/postgresql"",
       ""update_url"": ""/updates/postgresql?queries="",
@@ -29,7 +29,7 @@
     },
     ""mongodb"" : {
       ""setup_file"": ""setup"",
-      ""db_url"": ""/db"",
+      ""db_url"": ""/db/mongodb"",
       ""query_url"": ""/db/mongodb?queries="",
       ""fortune_url"": ""/fortunes/mongodb"",
       ""update_url"": ""/updates/mongodb?queries="",",correct a few URLs in benchmark_config,"""Update database URLs in benchmark config to include database type""","""Update database URLs in benchmark_config to include database type""","""Update benchmark_config: Add database type to URLs""

Explanation:
The diff shows changes made to the file 'undertow/benchmark_config'. In this case, the changes involve adding the database type (mysql, postgresql, mongodb) to the URLs for database, query, fortune, and update operations. This modification helps in differentiating the URLs based on the database type being used.","Updated database URLs in 'benchmark_config' to be specific for each database type (mysql, postgresql, mongodb).",Model 1
"diff --git a/core/src/main/resources/lib/layout/layout.properties b/core/src/main/resources/lib/layout/layout.properties
index 2e364c5bbf..5df92c068d 100644
--- a/core/src/main/resources/lib/layout/layout.properties
+++ b/core/src/main/resources/lib/layout/layout.properties
@@ -22,3 +22,6 @@
 
 searchBox.url=http://hudson.gotdns.com/wiki/display/HUDSON/Search+Box
 logout=log out
+DISABLE\ AUTO\ REFRESH=
+ENABLE\ AUTO\ REFRESH=
+Page\ generated=",added missing keys .,"""Added auto refresh and page generated labels to layout properties""",Added new properties for auto refresh and page generation in layout.properties.,"""Added DISABLE AUTO REFRESH and ENABLE AUTO REFRESH properties in layout.properties""","""Added labels for enabling/disabling auto refresh and page generated timestamp in layout properties.""",Model 1
"diff --git a/javaparser-core-generators/src/main/java/com/github/javaparser/generator/core/node/MainConstructorGenerator.java b/javaparser-core-generators/src/main/java/com/github/javaparser/generator/core/node/MainConstructorGenerator.java
index 1c6362c48..fb7419812 100644
--- a/javaparser-core-generators/src/main/java/com/github/javaparser/generator/core/node/MainConstructorGenerator.java
+++ b/javaparser-core-generators/src/main/java/com/github/javaparser/generator/core/node/MainConstructorGenerator.java
@@ -44,7 +44,7 @@ public class MainConstructorGenerator extends NodeGenerator {
             }
         }
 
-        body.getStatements().add(0, parseExplicitConstructorInvocationStmt(superCall.toString()));
+        body.getStatements().addToTop(parseExplicitConstructorInvocationStmt(superCall.toString()));
 
         body.addStatement(""customInitialization();"");
 
diff --git a/javaparser-core/src/main/java/com/github/javaparser/ast/CompilationUnit.java b/javaparser-core/src/main/java/com/github/javaparser/ast/CompilationUnit.java
index 1360311ce..4caf6b7d8 100644
--- a/javaparser-core/src/main/java/com/github/javaparser/ast/CompilationUnit.java
+++ b/javaparser-core/src/main/java/com/github/javaparser/ast/CompilationUnit.java
@@ -665,5 +665,4 @@ public final class CompilationUnit extends Node {
         }
         return super.replace(node, replacementNode);
     }
-
 }
diff --git a/javaparser-core/src/main/java/com/github/javaparser/ast/Node.java b/javaparser-core/src/main/java/com/github/javaparser/ast/Node.java
index 250a372f5..2fb8fc501 100644
--- a/javaparser-core/src/main/java/com/github/javaparser/ast/Node.java
+++ b/javaparser-core/src/main/java/com/github/javaparser/ast/Node.java
@@ -42,12 +42,11 @@ import com.github.javaparser.metamodel.PropertyMetaModel;
 import com.github.javaparser.printer.PrettyPrinter;
 import com.github.javaparser.printer.PrettyPrinterConfiguration;
 import com.github.javaparser.resolution.SymbolResolver;
-
 import javax.annotation.Generated;
 import java.util.*;
-
 import static com.github.javaparser.ast.Node.Parsedness.PARSED;
 import static java.util.Collections.unmodifiableList;
+import com.github.javaparser.ast.Node;
 
 /**
  * Base class for all nodes of the abstract syntax tree.
@@ -676,5 +675,6 @@ public abstract class Node implements Cloneable, HasParentNode<Node>, Visitable,
     }
 
     // We need to expose it because we will need to use it to inject the SymbolSolver
-    public static final DataKey<SymbolResolver> SYMBOL_RESOLVER_KEY = new DataKey<SymbolResolver>() { };
+    public static final DataKey<SymbolResolver> SYMBOL_RESOLVER_KEY = new DataKey<SymbolResolver>() {
+    };
 }
diff --git a/javaparser-core/src/main/java/com/github/javaparser/ast/NodeList.java b/javaparser-core/src/main/java/com/github/javaparser/ast/NodeList.java
index 94154b1a7..2161f3378 100644
--- a/javaparser-core/src/main/java/com/github/javaparser/ast/NodeList.java
+++ b/javaparser-core/src/main/java/com/github/javaparser/ast/NodeList.java
@@ -165,6 +165,51 @@ public class NodeList<N extends Node> implements List<N>, Iterable<N>, HasParent
         innerList.add(index, node);
     }
 
+    /**
+     * Inserts the node before all other nodes.
+     */
+    public NodeList<N> addToTop(N node) {
+        add(0, node);
+        return this;
+    }
+
+    /**
+     * Inserts the node after all other nodes. (This is simply an alias for add.)
+     */
+    public NodeList<N> addToBottom(N node) {
+        add(node);
+        return this;
+    }
+
+    /**
+     * Inserts the node after afterThisNode.
+     *
+     * @throws IllegalArgumentException when afterThisNode is not in this list.
+     */
+    public NodeList<N> addAfter(N node, N afterThisNode) {
+        int i = indexOf(afterThisNode);
+        if (i == -1) {
+            throw new IllegalArgumentException(""Can't find node to insert after."");
+        }
+        add(i + 1, node);
+        return this;
+    }
+
+    /**
+     * Inserts the node before beforeThisNode.
+     *
+     * @throws IllegalArgumentException when beforeThisNode is not in this list.
+     */
+    public NodeList<N> addBefore(N node, N beforeThisNode) {
+        int i = indexOf(beforeThisNode);
+        if (i == -1) {
+            throw new IllegalArgumentException(""Can't find node to insert before."");
+        }
+        add(i, node);
+        return this;
+    }
+
+
     @Override
     public Optional<Node> getParentNode() {
         return Optional.ofNullable(parentNode);
diff --git a/javaparser-core/src/main/java/com/github/javaparser/ast/body/MethodDeclaration.java b/javaparser-core/src/main/java/com/github/javaparser/ast/body/MethodDeclaration.java
index ccda1673d..7aa2c9616 100644
--- a/javaparser-core/src/main/java/com/github/javaparser/ast/body/MethodDeclaration.java
+++ b/javaparser-core/src/main/java/com/github/javaparser/ast/body/MethodDeclaration.java
@@ -50,7 +50,6 @@ import javax.annotation.Generated;
 import com.github.javaparser.TokenRange;
 import com.github.javaparser.resolution.Resolvable;
 import com.github.javaparser.resolution.declarations.ResolvedMethodDeclaration;
-
 import java.util.function.Consumer;
 
 /**
diff --git a/javaparser-core/src/main/java/com/github/javaparser/ast/type/ClassOrInterfaceType.java b/javaparser-core/src/main/java/com/github/javaparser/ast/type/ClassOrInterfaceType.java
index 5a7328de4..f9f028ccb 100644
--- a/javaparser-core/src/main/java/com/github/javaparser/ast/type/ClassOrInterfaceType.java
+++ b/javaparser-core/src/main/java/com/github/javaparser/ast/type/ClassOrInterfaceType.java
@@ -42,7 +42,6 @@ import static java.util.stream.Collectors.joining;
 import javax.annotation.Generated;
 import com.github.javaparser.TokenRange;
 import com.github.javaparser.resolution.types.ResolvedReferenceType;
-
 import java.util.function.Consumer;
 
 /**
@@ -287,5 +286,4 @@ public final class ClassOrInterfaceType extends ReferenceType implements NodeWit
     public ResolvedReferenceType resolve() {
         return getSymbolResolver().resolve(this, ResolvedReferenceType.class);
     }
-
 }
diff --git a/javaparser-core/src/main/java/com/github/javaparser/ast/type/IntersectionType.java b/javaparser-core/src/main/java/com/github/javaparser/ast/type/IntersectionType.java
index 8799e7470..8fb69f49b 100644
--- a/javaparser-core/src/main/java/com/github/javaparser/ast/type/IntersectionType.java
+++ b/javaparser-core/src/main/java/com/github/javaparser/ast/type/IntersectionType.java
@@ -40,7 +40,6 @@ import javax.annotation.Generated;
 import com.github.javaparser.TokenRange;
 import com.github.javaparser.resolution.types.ResolvedIntersectionType;
 import com.github.javaparser.resolution.types.ResolvedReferenceType;
-
 import java.util.function.Consumer;
 
 /**
diff --git a/javaparser-core/src/main/java/com/github/javaparser/ast/type/PrimitiveType.java b/javaparser-core/src/main/java/com/github/javaparser/ast/type/PrimitiveType.java
index c88ad7b1d..aa64bba6d 100644
--- a/javaparser-core/src/main/java/com/github/javaparser/ast/type/PrimitiveType.java
+++ b/javaparser-core/src/main/java/com/github/javaparser/ast/type/PrimitiveType.java
@@ -40,7 +40,6 @@ import javax.annotation.Generated;
 import com.github.javaparser.TokenRange;
 import com.github.javaparser.resolution.types.ResolvedPrimitiveType;
 import com.github.javaparser.resolution.types.ResolvedReferenceType;
-
 import java.util.function.Consumer;
 
 /**
diff --git a/javaparser-core/src/main/java/com/github/javaparser/ast/type/ReferenceType.java b/javaparser-core/src/main/java/com/github/javaparser/ast/type/ReferenceType.java
index 5b0d13b36..6aae58292 100644
--- a/javaparser-core/src/main/java/com/github/javaparser/ast/type/ReferenceType.java
+++ b/javaparser-core/src/main/java/com/github/javaparser/ast/type/ReferenceType.java
@@ -30,7 +30,6 @@ import com.github.javaparser.metamodel.JavaParserMetaModel;
 import javax.annotation.Generated;
 import com.github.javaparser.TokenRange;
 import com.github.javaparser.resolution.types.ResolvedReferenceType;
-
 import java.util.function.Consumer;
 
 /**
diff --git a/javaparser-core/src/main/java/com/github/javaparser/ast/type/Type.java b/javaparser-core/src/main/java/com/github/javaparser/ast/type/Type.java
index 585bf029b..6c9a1500f 100644
--- a/javaparser-core/src/main/java/com/github/javaparser/ast/type/Type.java
+++ b/javaparser-core/src/main/java/com/github/javaparser/ast/type/Type.java
@@ -35,10 +35,8 @@ import com.github.javaparser.TokenRange;
 import com.github.javaparser.resolution.Resolvable;
 import com.github.javaparser.resolution.SymbolResolver;
 import com.github.javaparser.resolution.types.ResolvedType;
-
 import java.util.function.Consumer;
 import java.util.function.Supplier;
-
 import static com.github.javaparser.utils.CodeGenerationUtils.f;
 
 /**
diff --git a/javaparser-core/src/main/java/com/github/javaparser/ast/type/TypeParameter.java b/javaparser-core/src/main/java/com/github/javaparser/ast/type/TypeParameter.java
index 3d4f470b7..468c4626c 100644
--- a/javaparser-core/src/main/java/com/github/javaparser/ast/type/TypeParameter.java
+++ b/javaparser-core/src/main/java/com/github/javaparser/ast/type/TypeParameter.java
@@ -40,7 +40,6 @@ import javax.annotation.Generated;
 import com.github.javaparser.TokenRange;
 import com.github.javaparser.resolution.declarations.ResolvedTypeParameterDeclaration;
 import com.github.javaparser.resolution.types.ResolvedTypeVariable;
-
 import java.util.function.Consumer;
 
 /**
@@ -55,8 +54,7 @@ import java.util.function.Consumer;
  * @author Julio Vilmar Gesser
  * @see com.github.javaparser.ast.nodeTypes.NodeWithTypeParameters
  */
-public final class TypeParameter extends ReferenceType
-        implements NodeWithSimpleName<TypeParameter>, NodeWithAnnotations<TypeParameter> {
+public final class TypeParameter extends ReferenceType implements NodeWithSimpleName<TypeParameter>, NodeWithAnnotations<TypeParameter> {
 
     private SimpleName name;
 
diff --git a/javaparser-core/src/main/java/com/github/javaparser/ast/type/UnionType.java b/javaparser-core/src/main/java/com/github/javaparser/ast/type/UnionType.java
index c60d2c443..c888af772 100644
--- a/javaparser-core/src/main/java/com/github/javaparser/ast/type/UnionType.java
+++ b/javaparser-core/src/main/java/com/github/javaparser/ast/type/UnionType.java
@@ -40,7 +40,6 @@ import javax.annotation.Generated;
 import com.github.javaparser.TokenRange;
 import com.github.javaparser.resolution.types.ResolvedReferenceType;
 import com.github.javaparser.resolution.types.ResolvedUnionType;
-
 import java.util.function.Consumer;
 
 /**
diff --git a/javaparser-core/src/main/java/com/github/javaparser/ast/type/UnknownType.java b/javaparser-core/src/main/java/com/github/javaparser/ast/type/UnknownType.java
index 733fff848..1b34897af 100644
--- a/javaparser-core/src/main/java/com/github/javaparser/ast/type/UnknownType.java
+++ b/javaparser-core/src/main/java/com/github/javaparser/ast/type/UnknownType.java
@@ -36,7 +36,6 @@ import com.github.javaparser.TokenRange;
 import com.github.javaparser.resolution.types.ResolvedReferenceType;
 import com.github.javaparser.resolution.types.ResolvedType;
 import com.github.javaparser.resolution.types.ResolvedUnionType;
-
 import java.util.function.Consumer;
 
 /**
diff --git a/javaparser-core/src/main/java/com/github/javaparser/ast/type/VoidType.java b/javaparser-core/src/main/java/com/github/javaparser/ast/type/VoidType.java
index 74420da36..9a17a15d4 100644
--- a/javaparser-core/src/main/java/com/github/javaparser/ast/type/VoidType.java
+++ b/javaparser-core/src/main/java/com/github/javaparser/ast/type/VoidType.java
@@ -36,7 +36,6 @@ import javax.annotation.Generated;
 import com.github.javaparser.TokenRange;
 import com.github.javaparser.resolution.types.ResolvedUnionType;
 import com.github.javaparser.resolution.types.ResolvedVoidType;
-
 import java.util.function.Consumer;
 
 /**
diff --git a/javaparser-core/src/main/java/com/github/javaparser/ast/type/WildcardType.java b/javaparser-core/src/main/java/com/github/javaparser/ast/type/WildcardType.java
index fb23f7a36..69f2b2e90 100644
--- a/javaparser-core/src/main/java/com/github/javaparser/ast/type/WildcardType.java
+++ b/javaparser-core/src/main/java/com/github/javaparser/ast/type/WildcardType.java
@@ -38,7 +38,6 @@ import javax.annotation.Generated;
 import com.github.javaparser.TokenRange;
 import com.github.javaparser.resolution.types.ResolvedUnionType;
 import com.github.javaparser.resolution.types.ResolvedWildcard;
-
 import java.util.function.Consumer;
 
 /**
diff --git a/javaparser-core/src/main/javacc-support/com/github/javaparser/GeneratedJavaParserSupport.java b/javaparser-core/src/main/javacc-support/com/github/javaparser/GeneratedJavaParserSupport.java
index e041e1ce4..476316c29 100644
--- a/javaparser-core/src/main/javacc-support/com/github/javaparser/GeneratedJavaParserSupport.java
+++ b/javaparser-core/src/main/javacc-support/com/github/javaparser/GeneratedJavaParserSupport.java
@@ -60,7 +60,7 @@ class GeneratedJavaParserSupport {
         if (list == null) {
             list = new NodeList<>();
         }
-        list.add(0, obj);
+        list.addToTop(obj);
         return list;
     }
 
diff --git a/javaparser-testing/src/test/java/com/github/javaparser/ast/NodeListTest.java b/javaparser-testing/src/test/java/com/github/javaparser/ast/NodeListTest.java
index a9e32efac..2c2ffcdaf 100644
--- a/javaparser-testing/src/test/java/com/github/javaparser/ast/NodeListTest.java
+++ b/javaparser-testing/src/test/java/com/github/javaparser/ast/NodeListTest.java
@@ -226,4 +226,62 @@ public class NodeListTest {
 
         assertEquals(""[abc, bcd, cde]"", list.toString());
     }
+    
+    @Test
+    public void addToTop() {
+        final NodeList<Name> list = nodeList(new Name(""abc""), new Name(""bcd""), new Name(""cde""));
+
+        list.addToTop(new Name(""xxx""));
+        
+        assertEquals(""[xxx, abc, bcd, cde]"", list.toString());
+    }
+    
+    @Test
+    public void addToBottom() {
+        final NodeList<Name> list = nodeList(new Name(""abc""), new Name(""bcd""), new Name(""cde""));
+
+        list.addToBottom(new Name(""xxx""));
+        
+        assertEquals(""[abc, bcd, cde, xxx]"", list.toString());
+    }
+
+    @Test
+    public void addBefore() {
+        Name n = new Name(""bcd"");
+        final NodeList<Name> list = nodeList(new Name(""abc""), n, new Name(""cde""));
+
+        list.addBefore(new Name(""xxx""), n);
+        
+        assertEquals(""[abc, xxx, bcd, cde]"", list.toString());
+    }
+
+    @Test
+    public void addAfter() {
+        Name n = new Name(""bcd"");
+        final NodeList<Name> list = nodeList(new Name(""abc""), n, new Name(""cde""));
+
+        list.addAfter(new Name(""xxx""), n);
+        
+        assertEquals(""[abc, bcd, xxx, cde]"", list.toString());
+    }
+
+    @Test
+    public void addBeforeFirst() {
+        Name abc = new Name(""abc"");
+        final NodeList<Name> list = nodeList(abc, new Name(""bcd""), new Name(""cde""));
+
+        list.addBefore(new Name(""xxx""), abc);
+        
+        assertEquals(""[xxx, abc, bcd, cde]"", list.toString());
+    }
+
+    @Test
+    public void addAfterLast() {
+        Name cde = new Name(""cde"");
+        final NodeList<Name> list = nodeList(new Name(""abc""), new Name(""bcd""), cde);
+
+        list.addAfter(new Name(""xxx""), cde);
+        
+        assertEquals(""[abc, bcd, cde, xxx]"", list.toString());
+    }
 }
diff --git a/javaparser-testing/src/test/java/com/github/javaparser/ast/visitor/ModifierVisitorTest.java b/javaparser-testing/src/test/java/com/github/javaparser/ast/visitor/ModifierVisitorTest.java
index 6492687a8..f7bfa52cb 100644
--- a/javaparser-testing/src/test/java/com/github/javaparser/ast/visitor/ModifierVisitorTest.java
+++ b/javaparser-testing/src/test/java/com/github/javaparser/ast/visitor/ModifierVisitorTest.java
@@ -48,7 +48,7 @@ public class ModifierVisitorTest {
             public Visitable visit(final StringLiteralExpr n, final Void arg) {
                 String v = n.getValue();
 
-                list.add(0, new StringLiteralExpr(""extra "" + v));
+                list.addToTop(new StringLiteralExpr(""extra "" + v));
                 list.remove(new StringLiteralExpr(""t""));
 
                 if (v.equals(""a"")) {
diff --git a/javaparser-testing/src/test/java/com/github/javaparser/printer/lexicalpreservation/transformations/ast/body/ClassOrInterfaceDeclarationTransformationsTest.java b/javaparser-testing/src/test/java/com/github/javaparser/printer/lexicalpreservation/transformations/ast/body/ClassOrInterfaceDeclarationTransformationsTest.java
index 2f07e334c..d7b7b45fa 100644
--- a/javaparser-testing/src/test/java/com/github/javaparser/printer/lexicalpreservation/transformations/ast/body/ClassOrInterfaceDeclarationTransformationsTest.java
+++ b/javaparser-testing/src/test/java/com/github/javaparser/printer/lexicalpreservation/transformations/ast/body/ClassOrInterfaceDeclarationTransformationsTest.java
@@ -84,7 +84,7 @@ public class ClassOrInterfaceDeclarationTransformationsTest extends AbstractLexi
     @Test
     public void addingTypeParameterAsFirstWhenThereAreSome() throws IOException {
         ClassOrInterfaceDeclaration cid = consider(""class A<U> {}"");
-        cid.getTypeParameters().add(0, new TypeParameter(""T"", new NodeList<>()));
+        cid.getTypeParameters().addToTop(new TypeParameter(""T"", new NodeList<>()));
         assertTransformedToString(""class A<T, U> {}"", cid);
     }
 ",Add some useful methods to NodeList,"""Added NodeList methods for inserting nodes at specific positions""","""Added methods to NodeList to insert nodes at specific positions and improved related tests""","""Added methods to NodeList for inserting nodes at specific positions""

Explanation: The commit adds several methods to the NodeList class, which is used to store a list of nodes in the JavaParser library. The new methods include addToTop, addToBottom, addAfter, and addBefore, which allow nodes to be inserted at specific positions in the list. The diff also includes changes to the MainConstructorGenerator class, which uses the new addToTop method to insert a statement at the beginning of a constructor's body. Additionally, there are some minor changes to the NodeListTest class to test the new methods.","""Refactor NodeList to add addToTop and addToBottom methods and update related references and tests accordingly.""",Model 2
"diff --git a/liquibase-core/src/main/java/liquibase/Liquibase.java b/liquibase-core/src/main/java/liquibase/Liquibase.java
index 8c17e9488..89c0390ad 100644
--- a/liquibase-core/src/main/java/liquibase/Liquibase.java
+++ b/liquibase-core/src/main/java/liquibase/Liquibase.java
@@ -52,6 +52,8 @@ import java.io.*;
 import java.text.DateFormat;
 import java.util.*;
 
+import static java.util.ResourceBundle.getBundle;
+
 /**
  * Primary facade class for interacting with Liquibase.
  * The built in command line, Ant, Maven and other ways of running Liquibase are wrappers around methods in this class.
@@ -59,6 +61,13 @@ import java.util.*;
 public class Liquibase {
 
     private static final Logger LOG = LogService.getLog(Liquibase.class);
+    protected static final int CHANGESET_ID_NUM_PARTS = 3;
+    protected static final int CHANGESET_ID_AUTHOR_PART = 2;
+    protected static final int CHANGESET_ID_CHANGESET_PART = 1;
+    protected static final int CHANGESET_ID_CHANGELOG_PART = 0;
+    private static ResourceBundle coreBundle = getBundle(""liquibase/i18n/liquibase-core"");
+    protected static final String MSG_COULD_NOT_RELEASE_LOCK = coreBundle.getString(""could.not.release.lock"");
+
     protected Database database;
     private DatabaseChangeLog databaseChangeLog;
     private String changeLogFile;
@@ -197,7 +206,7 @@ public class Liquibase {
             try {
                 lockService.releaseLock();
             } catch (LockException e) {
-                LOG.severe(LogType.LOG, ""Could not release lock"", e);
+                LOG.severe(LogType.LOG, MSG_COULD_NOT_RELEASE_LOCK, e);
             }
             resetServices();
         }
@@ -302,7 +311,7 @@ public class Liquibase {
             try {
                 lockService.releaseLock();
             } catch (LockException e) {
-                LOG.severe(LogType.LOG, ""Could not release lock"", e);
+                LOG.severe(LogType.LOG, MSG_COULD_NOT_RELEASE_LOCK, e);
             }
             resetServices();
         }
@@ -347,7 +356,7 @@ public class Liquibase {
             try {
                 lockService.releaseLock();
             } catch (LockException e) {
-                LOG.severe(LogType.LOG, ""Could not release lock"", e);
+                LOG.severe(LogType.LOG, MSG_COULD_NOT_RELEASE_LOCK, e);
             }
             resetServices();
         }
@@ -633,7 +642,7 @@ public class Liquibase {
         changeLogParameters.setContexts(contexts);
         changeLogParameters.setLabels(labelExpression);
 
-        /* We have no other choice than to save the current Executer here. */
+        /* We have no other choice than to save the current Executor here. */
         @SuppressWarnings(""squid:S1941"")
         Executor oldTemplate = ExecutorService.getInstance().getExecutor(database);
         ExecutorService.getInstance().setExecutor(database, new LoggingExecutor(
@@ -708,7 +717,7 @@ public class Liquibase {
             try {
                 lockService.releaseLock();
             } catch (LockException e) {
-                LOG.severe(LogType.LOG, ""Could not release lock"", e);
+                LOG.severe(LogType.LOG, MSG_COULD_NOT_RELEASE_LOCK, e);
             }
         }
         resetServices();
@@ -797,7 +806,7 @@ public class Liquibase {
             try {
                 lockService.releaseLock();
             } catch (LockException e) {
-                LOG.severe(LogType.LOG, ""Could not release lock"", e);
+                LOG.severe(LogType.LOG, MSG_COULD_NOT_RELEASE_LOCK, e);
             }
         }
         resetServices();
@@ -874,7 +883,7 @@ public class Liquibase {
             try {
                 lockService.releaseLock();
             } catch (LockException e) {
-                LOG.severe(LogType.LOG, ""Could not release lock"", e);
+                LOG.severe(LogType.LOG, MSG_COULD_NOT_RELEASE_LOCK, e);
             }
             resetServices();
         }
@@ -945,7 +954,7 @@ public class Liquibase {
             try {
                 lockService.releaseLock();
             } catch (LockException e) {
-                LOG.severe(LogType.LOG, ""Could not release lock"", e);
+                LOG.severe(LogType.LOG, MSG_COULD_NOT_RELEASE_LOCK, e);
             }
             resetServices();
         }
@@ -1085,7 +1094,7 @@ public class Liquibase {
             try {
                 lockService.releaseLock();
             } catch (LockException e) {
-                LOG.severe(LogType.LOG, ""Could not release lock"", e);
+                LOG.severe(LogType.LOG, MSG_COULD_NOT_RELEASE_LOCK, e);
             }
             ExecutorService.getInstance().setExecutor(database, oldTemplate);
             resetServices();
@@ -1150,7 +1159,7 @@ public class Liquibase {
             try {
                 lockService.releaseLock();
             } catch (LockException e) {
-                LOG.severe(LogType.LOG, ""Could not release lock"", e);
+                LOG.severe(LogType.LOG, MSG_COULD_NOT_RELEASE_LOCK, e);
             }
         }
     }
@@ -1167,7 +1176,7 @@ public class Liquibase {
             try {
                 lockService.releaseLock();
             } catch (LockException e) {
-                LOG.severe(LogType.LOG, ""Could not release",Do i18n and replace magic numbers with constants,"""Extracted 'Could not release lock' message to a resource bundle and added constants for changelog ID parts""","According to the diff, the commit message should be:

""Improved error handling for lock release in Liquibase""

This commit message captures the essence of the changes made in the diff, which is to improve error handling for lock release in the Liquibase class.","The commit message could be:

Refactor Liquibase class to use resource bundle for i18n

Details:
- Import `java.util.ResourceBundle` and add a static `ResourceBundle` instance for the core messages.
- Define constants for changset ID parts and messages.
- Replace hardcoded error message ""Could not release lock"" with the corresponding message from the resource bundle.

This commit refactors the `Liquibase` class to use a resource bundle for internationalization (i18n). It introduces a static `ResourceBundle` instance for core messages and defines constants for changset ID parts and messages. The hardcoded error message ""Could not release lock"" is replaced with the corresponding message from the resource bundle.",Refactor and use constants for repetitive strings and bundle resources in Liquibase.java for better maintainability and localization.,Model 4
"diff --git a/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/annotation/messages_tr.properties b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/annotation/messages_tr.properties
new file mode 100644
index 000000000..9bd32797e
--- /dev/null
+++ b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/annotation/messages_tr.properties
@@ -0,0 +1,18 @@
+#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
+
+annotation.incorrect.style        = Anotasyon stili \u015Fu \u015Fekilde olmal\u0131: ''{0}''.
+annotation.missing.deprecated     = @java.lang.Deprecated anotasyonu ve @deprecated Javadoc etiketi (a\u00E7\u0131klamas\u0131yla birlikte) birlikte kullan\u0131lmal\u0131.
+annotation.missing.override       = @inheritDoc Javadoc etiketi kullan\u0131ld\u0131\u011F\u0131nda @java.lang.Override anotasyonu da kullan\u0131lmal\u0131.
+annotation.not.valid.on           = {0} anotasyonu bu konumda ge\u00E7erli de\u011Fil.
+annotation.package.location       = Paket anotasyonlar\u0131 package-info.java dosyas\u0131nda tan\u0131mlanmal\u0131.
+annotation.parens.missing         = Anotasyonun kapatma parantezi ('')'') olmal\u0131.
+annotation.parens.present         = Anotasyonun kapatma parantezi ('')'') olmamal\u0131.
+annotation.trailing.comma.missing = Anotasyonun dizi de\u011Ferlerini takip eden bir virg\u00FCl kullan\u0131lmal\u0131d\u0131r.
+annotation.trailing.comma.present = Anotasyonun dizi de\u011Ferlerini takip eden bir virg\u00FCl kullan\u0131lmamal\u0131d\u0131r.
+
+javadoc.duplicateTag = Tekrarlanm\u0131\u015F {0} etiketi.
+javadoc.missing      = Javadoc a\u00E7\u0131klamas\u0131 eksik.
+
+suppressed.warning.not.allowed = ''{0}'' uyar\u0131s\u0131 bu konumda bast\u0131r\u0131lamaz.
+
+tag.not.valid.on = {0} Javadoc etiketi bu konumda ge\u00E7ersiz.
diff --git a/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/blocks/messages_tr.properties b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/blocks/messages_tr.properties
new file mode 100644
index 000000000..f5b5725af
--- /dev/null
+++ b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/blocks/messages_tr.properties
@@ -0,0 +1,12 @@
+#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
+
+block.empty  = Bo\u015F blok bulundu: {0}
+block.nested = \u0130\u00E7 i\u00E7e bloklar kullan\u0131lmamal\u0131d\u0131r.
+block.noStmt = Blok en az bir ifade i\u00E7ermeli.
+
+line.alone    = ''{0}'' ifadesi sat\u0131rda tek ba\u015F\u0131na olmal\u0131.
+line.new      = ''{0}'' ifadesi yeni sat\u0131rda olmal\u0131.
+line.previous = ''{0}'' ifadesi \u00F6nceki sat\u0131rda olmal\u0131.
+line.same     = ''{0}'' ifadesi ayn\u0131 sat\u0131rda olmal\u0131.
+
+needBraces = ''{0}'' yap\u0131s\u0131 s\u00FCsl\u00FC parantezler ('''{}''') kullanmal\u0131.
diff --git a/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/coding/messages_tr.properties b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/coding/messages_tr.properties
new file mode 100644
index 000000000..45f0b6b99
--- /dev/null
+++ b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/coding/messages_tr.properties
@@ -0,0 +1,98 @@
+#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
+
+array.trailing.comma = Dizi, takip eden bir virg\u00FCl i\u00E7ermelidir.
+
+assignment.inner.avoid = Dahili atamalar kullan\u0131lmamal\u0131d\u0131r.
+
+avoid.clone.method     = ''clone'' metodu kullan\u0131lmamal\u0131d\u0131r.
+avoid.finalizer.method = ''finalize'' metodu kullan\u0131lmamal\u0131d\u0131r.
+
+covariant.equals = java.lang.Object s\u0131n\u0131f\u0131n\u0131n ''equals'' metodundan ba\u015Fka bir ''equals'' metodu tan\u0131mlanm\u0131\u015F, java.lang.Object s\u0131n\u0131f\u0131ndan gelen ''equals'' metodu da ezilmelidir (override).
+
+declaration.order.access      = De\u011Fi\u015Fken, eri\u015Fim seviyesine g\u00F6re yanl\u0131\u015F s\u0131rada tan\u0131mlanm\u0131\u015F.
+declaration.order.constructor = ''constructor'' tan\u0131m\u0131 yanl\u0131\u015F s\u0131rada yap\u0131lm\u0131\u015F.
+declaration.order.instance    = De\u011Fi\u015Fken tan\u0131m\u0131 yanl\u0131\u015F s\u0131rada yap\u0131lm\u0131\u015F.
+declaration.order.method      = Metot tan\u0131m\u0131 yanl\u0131\u015F s\u0131rada yap\u0131lm\u0131\u015F.
+declaration.order.static      = ''static'' de\u011Fi\u015Fken tan\u0131m\u0131 yanl\u0131\u015F s\u0131rada yap\u0131lm\u0131\u015F.
+
+default.comes.last = ''switch'' i\u00E7erisindeki ''default'' ifadesi son durum olarak yer almal\u0131d\u0131r.
+
+doublechecked.locking.avoid = Double-Checked Locking (DCL - lock mekanizmas\u0131nda ikili kontrol) yap\u0131lmam\u0131\u015F.
+
+empty.statement = Bo\u015F ifade.
+
+equals.avoid.null           = ''equals'' metodunda kullan\u0131lan harflerden olu\u015Fan ifadeler ''equals'' metodunun sol taraf\u0131nda yer almal\u0131d\u0131r.
+equals.noHashCode           = ''equals'' metodu tan\u0131mlayan s\u0131n\u0131flar ''hashCode'' metodunu da tan\u0131mlamal\u0131d\u0131r.
+
+equalsIgnoreCase.avoid.null = ''equalsIgnoreCase'' metodunda kullan\u0131lan harflerden olu\u015Fan ifadeler ''equalsIgnoreCase'' metodunun sol taraf\u0131nda yer almal\u0131d\u0131r.
+
+explicit.init = ''{0}'' de\u011Fi\u015Fkeni (verilmese bile zaten ilklendirme de\u011Feri olan) ''{1}'' de\u011Feriyle ilklendirilmi\u015F.
+
+fall.through      = ''switch'' ifadesinin bir \u00F6nceki durumundan a\u015Fa\u011F\u0131 d\u00FC\u015Fme mevcut (''break'' kullan\u0131lmam\u0131\u015F olabilir).
+fall.through.last = ''switch'' ifadesinin son durumundan a\u015Fa\u011F\u0131 d\u00FC\u015Fme mevcut (''break'' kullan\u0131lmam\u0131\u015F olabilir).
+
+final.variable = ''{0}'' de\u011Fi\u015Fkeni ''final'' olarak tan\u0131mlanmal\u0131d\u0131r.
+
+hidden.field = ''{0}'', ba\u015Fka bir alan\u0131 gizliyor.
+
+illegal.catch      = ''{0}'' istisnas\u0131n\u0131/hatas\u0131n\u0131 yakalamaya izin verilmiyor.
+illegal.throw      = ''{0}'' istisnas\u0131n\u0131/hatas\u0131n\u0131 f\u0131rlatmaya izin verilmiyor.
+illegal.token      = ''{0}'' kullan\u0131m\u0131na izin verilmiyor.
+illegal.token.text = \u0130zin verilmeyen bir kal\u0131p kullan\u0131lm\u0131\u015F ''{0}''.
+illegal.type       = ''{0}'' tipinde de\u011Fi\u015Fken, d\u00F6n\u00FC\u015F de\u011Feri ya da parametre tan\u0131mlanmamal\u0131d\u0131r.
+
+inline.conditional.avoid = Sat\u0131r i\u00E7i ko\u015Fullu ifadeler kullan\u0131lmamal\u0131d\u0131r.
+
+instantiation.avoid = {0} s\u0131n\u0131f\u0131n\u0131n yeni nesnesi \u00FCretilmemelidir.
+
+junit.method.name                = ''{0}'' metodu ''{1}'' olarak adland\u0131r\u0131lmal\u0131d\u0131r.
+junit.method.parameters          = ''{0}'' metodu parametresiz olarak tan\u0131mlanmal\u0131.
+junit.method.protected.or.public = ''{0}'' metodu ''public'' ya da ''protected'' olmal\u0131.
+junit.method.public.and.static   = ''{0}'' metodu ''static'' olarak tan\u0131mlanmal\u0131.
+junit.method.return.type         = ''{0}'' metodunun d\u00F6n\u00FC\u015F tipi ''{1}'' olmal\u0131.
+junit.method.static              = ''{0}'' metodu ''static'' olarak tan\u0131mlanmamal\u0131.
+
+magic.number = ''{0}'' say\u0131s\u0131 ''magic number''d\u0131r. \u00D6nce tan\u0131mlanmal\u0131, sonra kullan\u0131lmal\u0131.
+
+missing.ctor                = S\u0131n\u0131f, bir ''constructor'' tan\u0131mlamal\u0131.
+missing.package.declaration = Paket tan\u0131m\u0131 yap\u0131lmam\u0131\u015F.
+missing.super.call          = ''{0}'' metodu ''super.{0}'' metodunu \u00E7a\u011F\u0131rmal\u0131.
+missing.switch.default      = ''default'' olmadan ''switch'' kullan\u0131lm\u0131\u015F.
+
+modified.control.variable = Kontrol de\u011Fi\u015Fkeninin de\u011Feri de\u011Fi\u015Ftirilmi\u015F.
+
+multiple.statements.line             = Her sat\u0131rda sadece bir ifade olmal\u0131d\u0131r.
+multiple.string.literal              = ''{0}'' de\u011Feri dosyada {1} defa kullan\u0131lm\u0131\u015F.
+multiple.variable.declarations       = Her sat\u0131rda sadece bir de\u011Fi\u015Fken tan\u0131mlanmal\u0131.
+multiple.variable.declarations.comma = Her de\u011Fi\u015Fken tan\u0131m\u0131 kendi ifadesinde yer almal\u0131.
+
+nested.for.depth = \u0130\u00E7 i\u00E7e kullan\u0131lan ''for'' say\u0131s\u0131 {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+nested.if.depth  = \u0130\u00E7 i\u00E7e kullan\u0131lan ''if-else'' say\u0131s\u0131 {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+nested.try.depth = \u0130\u00E7 i\u00E7e kullan\u0131lan ''try'' say\u0131s\u0131 {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+
+package.dir.mismatch = Paket tan\u0131m\u0131 ''{0}'' klas\u00F6r\u00FCyle e\u015Fle\u015Fmiyor.
+
+parameter.assignment = ''{0}'' parametresine atama yap\u0131lamaz.
+
+redundant.throws.classInfo = {0} i\u00E7in s\u0131n\u0131f bilgisi al\u0131nam\u0131yor.
+redundant.throws.duplicate = ''throws'' ifadesinde ''{0}'' tekrardan kullan\u0131lm\u0131\u015F.
+redundant.throws.subclass  = ''{0}'', ''{1}'' s\u0131n\u0131f\u0131n\u0131n alt s\u0131n\u0131f\u0131d\u0131r, ''throws'' kullan\u0131m\u0131 gereksizdir.
+redundant.throws.unchecked = ''{0}'' ''unchecked'' bir istisnad\u0131r, ''throws'' kullan\u0131m\u0131 gereksizdir.
+
+require.this.method           = ''{0}'' metoduna eri\u015Fim ""this."" kullan\u0131larak yap\u0131lmal\u0131d\u0131r.
+require.this.unfound.variable = ''{0}'' ifadesinin nerede tan\u0131mland\u0131\u011F\u0131 bilinmiyor.
+require.this.variable         = ''{0}'' de\u011Fi\u015Fkenine eri\u015Fim ""this."" kullan\u0131larak yap\u0131lmal\u0131d\u0131r.
+
+return.count = Kullan\u0131lan ''return'' say\u0131s\u0131 {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+
+simplify.boolreturn = Ko\u015Ful mant\u0131\u011F\u0131 kald\u0131r\u0131labilir.
+simplify.expression = \u0130fade sadele\u015Ftirilebilir.
+
+string.literal.equality = ''String'' ifadeleri ''{0}'' kullanarak de\u011Fil, equals() metodu kullanarak kar\u015F\u0131la\u015Ft\u0131r\u0131lmal\u0131.
+
+unnecessary.paren.assign  = Atama ifadesinin sa\u011F taraf\u0131nda gereksiz parantez mevcut.
+unnecessary.paren.expr    = \u0130fadenin etraf\u0131nda gereksiz parantez mevcut.
+unnecessary.paren.ident   = ''{0}'' belirte\u00E7inin etraf\u0131nda gereksiz parantez mevcut.
+unnecessary.paren.literal = ''{0}'' etraf\u0131nda gereksiz parantez mevcut.
+unnecessary.paren.return  = Geri d\u00F6n\u00FC\u015F de\u011Feri etraf\u0131nda gereksiz parantez mevcut.
+unnecessary.paren.string  = ''{0}'' etraf\u0131nda gereksiz parantez mevcut.
diff --git a/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/design/messages_tr.properties b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/design/messages_tr.properties
new file mode 100644
index 000000000..5507c5766
--- /dev/null
+++ b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/design/messages_tr.properties
@@ -0,0 +1,17 @@
+#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
+
+arrangement.members.before.inner = Alanlar ve metotlar i\u00E7 s\u0131n\u0131flardan \u00F6nce olmal\u0131.
+
+design.forExtension = ''{0}'' metodu kendinden t\u00FCretmek i\u00E7in tasarlanmad\u0131 - ''abstract'' ya da ''final'' olarak tan\u0131mlanmal\u0131, veya i\u00E7i bo\u015F olmal\u0131.
+
+final.class = {0} s\u0131n\u0131f\u0131 ''final'' olarak tan\u0131mlanmal\u0131.
+
+hide.utility.class = Utility s\u0131n\u0131flar\u0131 (sadece ''static'' metotlar i\u00E7eren s\u0131n\u0131flar) ''public'' ya da varsay\u0131lan bir ''constructor'' i\u00E7ermemelidir.
+
+interface.type = Aray\u00FCzler bir t\u00FCr olarak tan\u0131mlanmal\u0131, dolay\u0131s\u0131yla metotlar\u0131 olmal\u0131.
+
+mutable.exception = ''{0}'' alan\u0131 ''final'' olarak tan\u0131mlanmal\u0131.
+
+throws.count = Kullan\u0131lan ''throws'' say\u0131s\u0131 {0,number,integer} (maksimum izin verilen say\u0131 {1,number,integer}).
+
+variable.notPrivate = ''{0}'' de\u011Fi\u015Fkeni ''private'' olarak tan\u0131mlanmal\u0131 ve  eri\u015Fim metotlar\u0131na(getter/setter) sahip olmal\u0131.
diff --git a/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/duplicates/messages_tr.properties b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/duplicates/messages_tr.properties
new file mode 100644
index 000000000..4a3f27ea1
--- /dev/null
+++ b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/duplicates/messages_tr.properties
@@ -0,0 +1,3 @@
+#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
+
+duplicates.lines = ''{1}'' dosyas\u0131nda {2} numaral\u0131 sat\u0131rdan itibaren {0} sat\u0131r tekrarlanm\u0131\u015F ifade bulundu.
diff --git a/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/header/messages_tr.properties b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/header/messages_tr.properties
new file mode 100644
index 000000000..21c4c770e
--- /dev/null
+++ b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/header/messages_tr.properties
@@ -0,0 +1,4 @@
+#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
+
+header.mismatch = Sat\u0131r, beklenen ba\u015Fl\u0131k sat\u0131r\u0131 olan ''{0}'' ile e\u015Fle\u015Fmiyor.
+header.missing  = Ba\u015Fl\u0131k eksik - dosyada yeterli sat\u0131r yok.
diff --git a/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/imports/messages_tr.properties b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/imports/messages_tr.properties
new file mode 100644
index 000000000..dc913dc81
--- /dev/null
+++ b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/imports/messages_tr.properties
@@ -0,0 +1,14 @@
+#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
+
+import.avoidStar            = Y\u0131ld\u0131zl\u0131 (''.*'' \u015Feklinde) import kullan\u0131lmamal\u0131d\u0131r - {0}.
+import.avoidStatic          = ''static'' bir ifade ''import'' edilmemeli - {0}.
+import.control.disallowed   = \u0130zin verilmeyen ''import'' kullan\u0131m\u0131 - {0}
+import.control.missing.file = ''import'' kontrol dosyas\u0131 eksik.
+import.control.unknown.pkg  = ''import'' kontrol dosyas\u0131 bu paketi kapsam\u0131yor.
+import.duplicate            = ''import'' ifadesi {0,number,integer} sat\u0131r\u0131nda tekrarlanm\u0131\u015F - {1}.
+import.illegal              = Ge\u00E7ersiz paketten ''import'' yap\u0131lm\u0131\u015F - {0}.
+import.lang                 = ''java.lang'' paketinden gereksiz ''import'' yap\u0131lm\u0131\u015F - {0}.
+import.ordering             = ''{0}'' ''import'' ifadesinin s\u0131ras\u0131 hatal\u0131.
+import.same                 = Ayn\u0131 paketten gereksiz ''import'' yap\u0131lm\u0131\u015F - ''{0}''.
+import.separation           = ''{0}'' ifadesi kendinden \u00F6nceki ''import'' ifadelerinden ayr\u0131lmal\u0131.
+import.unused               = Kullan\u0131lmayan import - {0}.
diff --git a/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/indentation/messages_tr.properties b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/indentation/messages_tr.properties
new file mode 100644
index 000000000..69e2d8d30
--- /dev/null
+++ b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/indentation/messages_tr.properties
@@ -0,0 +1,4 @@
+#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
+
+indentation.child.error = {0} ifadesi do\u011Fru hizalanmam\u0131\u015F. Bulundu\u011Fu s\u00FCtun {1}, olmas\u0131 gereken s\u00FCtun {2}.
+indentation.error       = {0} ifadesi do\u011Fru hizalanmam\u0131\u015F. Bulundu\u011Fu s\u00FCtun {1}, olmas\u0131 gereken s\u00FCtun {2}.
diff --git a/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/javadoc/messages_tr.properties b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/javadoc/messages_tr.properties
new file mode 100644
index 000000000..63dd662c9
--- /dev/null
+++ b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/javadoc/messages_tr.properties
@@ -0,0 +1,23 @@
+#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
+
+javadoc.classInfo         = {0} etiketi ''{1}'' i\u00E7in s\u0131n\u0131f bilgisi al\u0131nam\u0131yor.
+javadoc.duplicateTag      = {0} etiketi tekrarlanm\u0131\u015F.
+javadoc.empty             = Javadoc tan\u0131m alan\u0131 bo\u015F b\u0131rak\u0131lm\u0131\u015F.
+javadoc.expectedTag       = ''{1}'' i\u00E7in {0} etiketi gerekli.
+javadoc.extrahtml         = Fazladan HTML etiketi bulundu: {0}
+javadoc.incompleteTag     = Tamamlanmam\u0131\u015F HTML etiketi bulundu: {0}
+javadoc.invalidInheritDoc = '{'@inheritDoc'}' etiketi kullan\u0131m\u0131 ge\u00E7ersiz.
+javadoc.legacyPackageHtml = Eskide kalan package.html dosyalar\u0131 kald\u0131r\u0131lmal\u0131.
+javadoc.missing           = Javadoc a\u00E7\u0131klamas\u0131 eksik.
+javadoc.noperiod          = \u0130lk c\u00FCmle nokta ile bitmeli.
+javadoc.packageHtml       = Paket dok\u00FCmantasyon dosyas\u0131 eksik.
+javadoc.packageInfo       = package-info.java dosyas\u0131 eksik.
+javadoc.return.expected   = @return etiketi eksik.
+javadoc.unclosedhtml      = Kapat\u0131lmam\u0131\u015F bir HTML etiketi bulundu: {0}
+javadoc.unknownTag        = Bilinmeyen etiket: ''{0}''.
+javadoc.unusedTag         = ''{1}'' i\u00E7in kullan\u0131lmayan {0} etiketi mevcut.
+javadoc.unusedTagGeneral  = Kullan\u0131lmayan Javadoc etiketi.
+javadoc.writeTag          = {0}={1}
+
+type.missingTag = T\u00FCr i\u00E7in yaz\u0131lan Javadoc a\u00E7\u0131klamas\u0131nda {0} etiketi eksik.
+type.tagFormat  = T\u00FCr i\u00E7in yaz\u0131lan {0} Javadoc etiketi \u015Fu kal\u0131pta olmal\u0131: ''{1}''.
diff --git a/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/messages_tr.properties b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/messages_tr.properties
new file mode 100644
index 000000000..9d29a2503
--- /dev/null
+++ b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/messages_tr.properties
@@ -0,0 +1,34 @@
+#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
+
+array.type.style = Dizi parantezleri ge\u00E7ersiz konumda bulunuyor.
+
+descendant.token.max     = ''{2}'' eleman\u0131ndan t\u00FCremi\u015F ''{3}'' i\u00E7in toplam {0} say\u0131s\u0131 maksimum {1} de\u011Ferinden daha y\u00FCksek.
+descendant.token.min     = ''{2}'' eleman\u0131ndan t\u00FCremi\u015F ''{3}'' i\u00E7in toplam {0} say\u0131s\u0131 minimum {1} de\u011Ferinden daha d\u00FC\u015F\u00FCk.
+descendant.token.sum.max = ''{2}'' alt\u0131ndaki toplam {0} say\u0131s\u0131 maksimum {1} de\u011Ferinden daha y\u00FCksek.
+descendant.token.sum.min = ''{2}'' alt\u0131ndaki toplam {0} say\u0131s\u0131 minimum {1} de\u011Ferinden daha d\u00FC\u015F\u00FCk.
+
+duplicate.regexp = Tekrarlanm\u00FD\u00FEbir kal\u0131p bulundu: ''{0}''.
+
+final.parameter = {0} parametresi ''final'' olarak tan\u0131mlanmal\u0131.
+
+illegal.regexp = Sat\u0131rda ge\u00E7ersiz bir kal\u0131p var: ''{0}''.
+
+missing.switch.default = ''default'' durumu olmayan bir ''switch'' mevcut.
+
+noNewlineAtEOF = Dosyan\u0131n sonunda yeni sat\u0131r karakteri yok.
+
+required.regexp = Dosyada olmas\u0131 gereken ''{0}'' kal\u0131b\u0131 yok.
+
+todo.match = A\u00E7\u0131klamalar, ''to-do'' format\u0131 olan ''{0}'' ile \u00E7ak\u0131\u015F\u0131yor.
+
+trailing.comments = \u0130zleyen (trailing) a\u00E7\u0131klamalar kullan\u0131lmamal\u0131d\u0131r.
+
+translation.missingKey = ''{0}'' anahtar\u0131 eksik.
+
+type.file.mismatch = En d\u0131\u015Ftaki t\u00FCr\u00FCn ad\u0131 dosya ad\u0131yla ayn\u0131 de\u011Fil.
+
+unable.open = ''{0}'' a\u00E7\u0131lam\u0131yor.
+
+uncommented.main = ''main'' metoduna a\u00E7\u0131klama girilmeli.
+
+upperEll = B\u00FCy\u00FCk harf ''L'' kullan\u0131lmal\u0131.
diff --git a/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/metrics/messages_tr.properties b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/metrics/messages_tr.properties
new file mode 100644
index 000000000..9ff845974
--- /dev/null
+++ b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/metrics/messages_tr.properties
@@ -0,0 +1,55 @@
+#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
+
+booleanExpressionComplexity = Mant\u0131ksal ifadenin karma\u015F\u0131kl\u0131\u011F\u0131 {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+
+classDataAbstractionCoupling = Class Data Abstraction Coupling (CDAC) de\u011Feri {0,number,integer} {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}). Nesnesi olu\u015Fturulan s\u0131n\u0131flar {2}. (CDAC: Bir s\u0131n\u0131f\u0131n, kendinden farkl\u0131 ka\u00E7 s\u0131n\u0131f\u0131n nesnesini olu\u015Fturdu\u011Fu.)
+
+classFanOutComplexity = Class Fan-Out Complexity (CFOC) de\u011Feri {0,number,integer} {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}). (CFOC: Bir s\u0131n\u0131f\u0131n, kendinden ba\u015Fka ka\u00E7 farkl\u0131 s\u0131n\u0131f\u0131 kulland\u0131\u011F\u0131)
+
+cyclomaticComplexity = Cyclomatic Complexity de\u011Feri {0,number,integer} {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}). (Cyclomatic Complexity: Bir metodun, constructorun ya da statik blo\u011Fun m\u00FCmk\u00FCn olan minimum ger\u00E7eklenme yolu say\u0131s\u0131)
+
+duplicateLiteral = ''{0}'' s\u00F6zc\u00FC\u011F\u00FC kod i\u00E7erisinde tekrarlanmamal\u0131, tan\u0131mlan\u0131p \u00F6yle kullan\u0131lmal\u0131.
+
+finalField = ''{0}'' alan\u0131 ''final'' olarak tan\u0131mlanmal\u0131.
+
+illegalAbstractClassName = ''{0}'' s\u0131n\u0131f\u0131n\u0131n ad\u0131 \u015Fu kal\u0131pta olmal\u0131: ''{1}''.
+
+illegalCatch = ''{0}'' istisnas\u0131n\u0131/hatas\u0131n\u0131 yakalamaya izin verilmiyor.
+
+illegalThrows = ''{0}'' istisnas\u0131n\u0131/hatas\u0131n\u0131 f\u0131rlatmaya izin verilmiyor.
+
+illegalToken = ''{0}'' kullanmaya izin verilmiyor.
+
+illegalType = ''{0}'' tipinde de\u011Fi\u015Fkenler, parametreler ya da geri d\u00F6n\u00FC\u015F de\u011Ferleri tan\u0131mlamaya, izin verilmiyor.
+
+junit.methodName              = ''{0}'' metodunun ad\u0131 ''{1}'' olmal\u0131.
+junit.methodParameters        = ''{0}'' metodu parametresiz olarak tan\u0131mlanmal\u0131.
+junit.methodPublicAndStatic   = ''{0}'' metodu ''static'' olarak tan\u0131mlanmal\u0131.
+junit.methodPublicOrProtected = {0} metodu ''public'' ya da ''protected'' olarak tan\u0131mlanmal\u0131.
+junit.methodReturnType        = ''{0}'' metodunun geri d\u00F6n\u00FC\u015F tipi ''void'' olmal\u0131.
+
+mutableException = ''{0}'' alan\u0131 ''final'' olarak tan\u0131mlanmal\u0131.
+
+ncss.class  = Bu s\u0131n\u0131f\u0131n a\u00E7\u0131klama olmayan kaynak kod sat\u0131r\u0131 (NCSS) say\u0131s\u0131  {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+ncss.file   = Bu dosyan\u0131n a\u00E7\u0131klama olmayan kaynak kod sat\u0131r\u0131 (NCSS) say\u0131s\u0131  {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+ncss.method = Bu metodun a\u00E7\u0131klama olmayan kaynak kod sat\u0131r\u0131 (NCSS) say\u0131s\u0131  {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+
+nestedIfDepth = \u0130\u00E7 i\u00E7e kullan\u0131lan ''if-else'' say\u0131s\u0131 {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+
+nestedTryDepth = \u0130\u00E7 i\u00E7e kullan\u0131lan ''try'' say\u0131s\u0131 {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+
+npathComplexity = NPath Complexity de\u011Feri {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}). (NPath Complexity: Bir metodun m\u00FCmk\u00FCn olan t\u00FCm ger\u00E7eklenme yollar\u0131n\u0131n say\u0131s\u0131)
+
+packageDeclaration = Paket tan\u0131m\u0131 eksik.
+
+parameterAssignment = ''{0}'' parametresine de\u011Fer atanamaz.
+
+returnCount = ''return'' say\u0131s\u0131 {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+
+returnFromCatch = ''catch'' ifadesi i\u00E7inde ''return'' kullan\u0131lamaz.
+
+returnFromFinally = ''finally'' ifadesi i\u00E7inde ''return'' kullan\u0131lamaz.
+
+throwsCount = Kullan\u0131lan ''throws'' say\u0131s\u0131 {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+
+unusedVariable = ''{0}'' de\u011Fi\u015Fkeni hi\u00E7 kullan\u0131lmam\u0131\u015F.
diff --git a/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/modifier/messages_tr.properties b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/modifier/messages_tr.properties
new file mode 100644
index 000000000..f0bdc3768
--- /dev/null
+++ b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/modifier/messages_tr.properties
@@ -0,0 +1,7 @@
+#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
+
+annotation.order = ''{0}'' anotasyon niteleyicisi, anotasyon olmayan niteleyicilerden \u00F6nce kullan\u0131lmal\u0131.
+
+mod.order = ''{0}'' niteleyicisi, Java taraf\u0131ndan \u00F6nerilen s\u0131rada de\u011Fil.
+
+redundantModifier = Gereksiz ''{0}'' niteleyicisi.
diff --git a/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/naming/messages_tr.properties b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/naming/messages_tr.properties
new file mode 100644
index 000000000..9d4024e72
--- /dev/null
+++ b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/naming/messages_tr.properties
@@ -0,0 +1,9 @@
+#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
+
+illegal.abstract.class.name = ''{0}'' ismi, \u015Fu kal\u0131pta olmal\u0131: ''{1}''.
+
+method.name.equals.class.name = ''{0}'' metodunun ad\u0131 kendini kapsayan t\u00FCr ile ayn\u0131 olmamal\u0131.
+
+name.invalidPattern = ''{0}'' ismi, \u015Fu kal\u0131pta olmal\u0131: ''{1}''.
+
+no.abstract.class.modifier = ''{0}'' s\u0131n\u0131f\u0131 ''abstract'' olarak tan\u0131mlanmal\u0131.
diff --git a/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/regexp/messages_tr.properties b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/regexp/messages_tr.properties
new file mode 100644
index 000000000..46876eaa6
--- /dev/null
+++ b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/regexp/messages_tr.properties
@@ -0,0 +1,4 @@
+#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
+
+regexp.exceeded = Sat\u0131r, ge\u00E7ersiz ''{0}'' kal\u0131b\u0131yla e\u015Fle\u015Fiyor.
+regexp.minimum  = Dosya, ''{1}'' kal\u0131b\u0131 i\u00E7in en az {0} e\u015Fle\u015Fme i\u00E7ermiyor.
diff --git a/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/sizes/messages_tr.properties b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/sizes/messages_tr.properties
new file mode 100644
index 000000000..a6a5a4698
--- /dev/null
+++ b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/sizes/messages_tr.properties
@@ -0,0 +1,19 @@
+#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
+
+executableStatementCount = Y\u00FCr\u00FCt\u00FClebilir ifade say\u0131s\u0131 {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+
+maxLen.anonInner = \u0130simsiz i\u00E7 s\u0131n\u0131f uzunlu\u011Fu  {0,number,integer} sat\u0131r (maksimum izin verilen de\u011Fer {1,number,integer}).
+maxLen.file      = Dosya uzunlu\u011Fu {0,number,integer} sat\u0131r (maksimum izin verilen de\u011Fer {1,number,integer}).
+maxLen.method    = Metot uzunlu\u011Fu {0,number,integer} sat\u0131r (maksimum izin verilen de\u011Fer {1,number,integer}).
+
+maxLineLen = Sat\u0131r {0,number,integer} de\u011Ferinden daha uzun.
+
+maxOuterTypes = Tan\u0131mlanan d\u0131\u015F t\u00FCr say\u0131s\u0131  {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+
+maxParam = {0,number,integer} de\u011Ferinden daha fazla parametre mevcut.
+
+too.many.methods          = Toplam metot say\u0131s\u0131 {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+too.many.packageMethods   = Toplam ''package'' eri\u015Fimli metot say\u0131s\u0131 {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+too.many.privateMethods   = Toplam ''private'' metot say\u0131s\u0131 {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+too.many.protectedMethods = Toplam ''protected'' metot say\u0131s\u0131 {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
+too.many.publicMethods    = Toplam ''public'' metot say\u0131s\u0131 {0,number,integer} (maksimum izin verilen de\u011Fer {1,number,integer}).
diff --git a/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/whitespace/messages_tr.properties b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/whitespace/messages_tr.properties
new file mode 100644
index 000000000..b72bb29a5
--- /dev/null
+++ b/src/checkstyle/com/puppycrawl/tools/checkstyle/checks/whitespace/messages_tr.properties
@@ -0,0 +1,16 @@
+#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
+
+containsTab = Sat\u0131r, sekme karakteri i\u00E7ermekte.
+
+file.containsTab = Dosya, sekme karakterleri i\u00E7ermekte (sadece ilk bulunan g\u00F6steriliyor).
+
+line.alone    = ''{0}'' ifadesi sat\u0131rda tek ba\u015F\u0131na olmal\u0131.
+line.new      = ''{0}'' ifadesi yeni bir sat\u0131rda olmal\u0131.
+line.previous = ''{0}'' ifadesi \u00F6nceki sat\u0131rda olmal\u0131.
+line.same     = ''{0}'' ifadesi ayn\u0131 sat\u0131rda olmal\u0131.
+
+ws.followed      = ''{0}'' ifadesinden sonra bo\u015Fluk kullan\u0131lm\u0131\u015F.
+ws.illegalFollow = ''{0}'' ifadesinden sonra ge\u00E7ersiz bir karakter kullan\u0131lm\u0131\u015F.
+ws.notFollowed   = ''{0}'' ifadesinden sonra bo\u015Fluk kullan\u0131lmam\u0131\u015F.
+ws.notPreceded   = ''{0}'' ifadesinden \u00F6nce bo\u015Fluk kullan\u0131lmam\u0131\u015F.
+ws.preceded      = ''{0}'' ifadesinden \u00F6nce bo\u015Fluk kullan\u0131lm\u0131\u015F.
diff --git a/src/checkstyle/com/puppycrawl/tools/checkstyle/messages_tr.properties b/src/checkstyle/com/puppycrawl/tools/checkstyle/messages_tr.properties
new file mode 100644
index 000000000..faae902a1
--- /dev/null
+++ b/src/checkstyle/com/puppycrawl/tools/checkstyle/messages_tr.properties
@@ -0,0 +1,8 @@
+#Generated by ResourceBundle Editor (http://eclipse-rbe.sourceforge.net)
+
+DefaultLogger.addException  = {0} denetlenirken hata olu\u015Ftu.
+DefaultLogger.auditFinished = Denetleme tamamland\u0131.
+DefaultLogger.auditStarted  = Denetleme ba\u015Fl\u0131yor...
+
+general.exception    = Bir istisna yakaland\u0131 - {0}
+general.fileNotFound = Dosya bulunamad\u0131!
diff --git a/src/xdocs/releasenotes.xml b/src/xdocs/releasenotes.xml
index 8b62d59d3..93a855a02 100755
--- a/src/xdocs/releasenotes.xml
+++ b/src/xdocs/releasenotes.xml
@@ -43,6 +43,10 @@
           <a href=""http://jeremymanson.blogspot.com.au/2008/05/double-checked-locking.html"">here</a>
           for more details.
         </li>
+        <li>
+          Added Turkish message translations. Thanks to poyrazus
+          for patch #3460908.
+        </li>
       </ul>
     </section>
 ",added Turkish translations,"""Added Turkish message translations""",Added Turkish message translations. Thanks to poyrazus for patch #3460908.,"The commit message should be:

Added Turkish message translations. Thanks to poyrazus for patch #3460908.","""Added Turkish message translations for various Checkstyle checks. Updated release notes to acknowledge contribution by poyrazus.""",Model 4
"diff --git a/resources/src/main/java/org/robolectric/res/android/ResTableResourceName.java b/resources/src/main/java/org/robolectric/res/android/ResTableResourceName.java
new file mode 100644
index 000000000..d141e40b4
--- /dev/null
+++ b/resources/src/main/java/org/robolectric/res/android/ResTableResourceName.java
@@ -0,0 +1,9 @@
+package org.robolectric.res.android;
+
+// transliterated from from https://android.googlesource.com/platform/frameworks/base/+/android-7.1.1_r13/include/androidfw/ResourceTypes.h
+// struct resource_name
+public class ResTableResourceName {
+  public String packageName;
+  public String type;
+  public String name;
+}",Add ResTableResourceName,"""Added ResTableResourceName class to org.robolectric.res.android package""","""Add ResTableResourceName class for Android resource names""","""Added ResTableResourceName class to org.robolectric.res.android package""

This new class appears to be a simple data holder for package name, type, and name, which seems to be translated from the ResourceTypes.h file in the Android framework. It's always a good idea to include a commit message that briefly describes the changes made in the commit, so that others (or future you) can easily understand what changes were made and why.","Add ResTableResourceName class to represent resource names, transliterated from ResourceTypes.h in Android framework.",Model 3
"diff --git a/runtime/Go/antlr/interval_set_test.go b/runtime/Go/antlr/interval_set_test.go
new file mode 100644
index 000000000..832559df3
--- /dev/null
+++ b/runtime/Go/antlr/interval_set_test.go
@@ -0,0 +1,51 @@
+package antlr
+
+import (
+	""testing""
+)
+
+func assertInterval(t *testing.T, i *Interval, l int){
+	if i.length() != l{
+		t.Errorf(""For interval [%s] [%d] length is expected, [%d] is actual"", i.String(), l, i.length())
+	}
+}
+
+func assertString(t *testing.T, result string, expected string){
+	if result != expected{
+		t.Errorf(""expected: %s, result:%s"", result, expected)
+	}
+}
+
+func TestDefaultIntervalLength(t *testing.T){
+	assertInterval(t, NewInterval(0,0), 1)
+	assertInterval(t, NewInterval(100, 100), 1)
+
+}
+
+func TestIntervalSetAbsorb(t *testing.T){
+	s := NewIntervalSet()
+	s.addRange(10,20)
+	s.addRange(11,19)
+	assertString(t, ""10..20"", s.toIndexString())
+}
+
+func TestIntervalSetOverlap(t *testing.T){
+	s := NewIntervalSet()
+	s.addRange(10, 20)
+	s.addRange(15, 25)
+	assertString(t, ""10..25"", s.toIndexString())
+}
+
+func TestIntervalSetIndependent(t *testing.T)  {
+	s := NewIntervalSet()
+	s.addRange(10, 20)
+	s.addRange(30, 40)
+	assertString(t, ""{10..20, 30..40}"", s.toIndexString())
+}
+
+func TestIntervalSetAdjoint(t *testing.T)  {
+	s := NewIntervalSet()
+	s.addRange(10,20)
+	s.addRange(20, 30)
+	assertString(t, ""10..30"", s.toIndexString())
+}
\ No newline at end of file",added initial tests for interval set,"""Added interval set tests for Go ANTLR runtime""","""Added interval set tests for default length, absorb, overlap, independent, and adjoint intervals""","""Add interval_set_test.go file for testing interval set functionality in ANTLR Go runtime package""","Add unit tests for Interval and IntervalSet functionality, including overlap, absorption, independence, and adjacency scenarios.",Model 3
"diff --git a/aeron-archive/src/main/java/io/aeron/archive/Archiver.java b/aeron-archive/src/main/java/io/aeron/archive/Archiver.java
index 5ce84a312..4142147ae 100644
--- a/aeron-archive/src/main/java/io/aeron/archive/Archiver.java
+++ b/aeron-archive/src/main/java/io/aeron/archive/Archiver.java
@@ -19,6 +19,7 @@ import io.aeron.Aeron;
 import io.aeron.archive.client.AeronArchive;
 import org.agrona.CloseHelper;
 import org.agrona.ErrorHandler;
+import org.agrona.IoUtil;
 import org.agrona.LangUtil;
 import org.agrona.collections.IntArrayList;
 import org.agrona.concurrent.*;
@@ -746,6 +747,17 @@ public final class Archiver implements AutoCloseable
             return presetRecordingFileName;
         }
 
+        /**
+         * Delete the archive directory if the {@link #archiveDir()} value is not null.
+         */
+        public void deleteArchiveDirectory()
+        {
+            if (null != archiveDir)
+            {
+                IoUtil.delete(archiveDir, false);
+            }
+        }
+
         List<String> presetRecordingChannels()
         {
             return presetRecordingChannels;
diff --git a/aeron-archive/src/test/java/io/aeron/archive/ArchiverSystemTest.java b/aeron-archive/src/test/java/io/aeron/archive/ArchiverSystemTest.java
index 26298c8e2..d8a76db3f 100644
--- a/aeron-archive/src/test/java/io/aeron/archive/ArchiverSystemTest.java
+++ b/aeron-archive/src/test/java/io/aeron/archive/ArchiverSystemTest.java
@@ -147,11 +147,7 @@ public class ArchiverSystemTest
         CloseHelper.close(archiver);
         CloseHelper.close(driver);
 
-        if (null != archiver.context().archiveDir())
-        {
-            IoUtil.delete(archiver.context().archiveDir(), false);
-        }
-
+        archiver.context().deleteArchiveDirectory();
         driver.context().deleteAeronDirectory();
     }
 
diff --git a/aeron-archive/src/test/java/io/aeron/archive/workloads/ArchiveRecordingLoadTest.java b/aeron-archive/src/test/java/io/aeron/archive/workloads/ArchiveRecordingLoadTest.java
index 82307daad..c51db6b2e 100644
--- a/aeron-archive/src/test/java/io/aeron/archive/workloads/ArchiveRecordingLoadTest.java
+++ b/aeron-archive/src/test/java/io/aeron/archive/workloads/ArchiveRecordingLoadTest.java
@@ -32,7 +32,6 @@ import io.aeron.logbuffer.LogBufferDescriptor;
 import io.aeron.protocol.DataHeaderFlyweight;
 import org.agrona.BufferUtil;
 import org.agrona.CloseHelper;
-import org.agrona.IoUtil;
 import org.agrona.concurrent.UnsafeBuffer;
 import org.junit.*;
 import org.junit.rules.TestWatcher;
@@ -118,11 +117,7 @@ public class ArchiveRecordingLoadTest
         CloseHelper.quietClose(archiver);
         CloseHelper.quietClose(driver);
 
-        if (null != archiver.context().archiveDir())
-        {
-            IoUtil.delete(archiver.context().archiveDir(), false);
-        }
-
+        archiver.context().deleteArchiveDirectory();
         driver.context().deleteAeronDirectory();
     }
 
diff --git a/aeron-archive/src/test/java/io/aeron/archive/workloads/ArchiveReplayLoadTest.java b/aeron-archive/src/test/java/io/aeron/archive/workloads/ArchiveReplayLoadTest.java
index ab3dbc6c5..f10afb454 100644
--- a/aeron-archive/src/test/java/io/aeron/archive/workloads/ArchiveReplayLoadTest.java
+++ b/aeron-archive/src/test/java/io/aeron/archive/workloads/ArchiveReplayLoadTest.java
@@ -35,7 +35,6 @@ import io.aeron.protocol.DataHeaderFlyweight;
 import org.agrona.BufferUtil;
 import org.agrona.CloseHelper;
 import org.agrona.DirectBuffer;
-import org.agrona.IoUtil;
 import org.agrona.concurrent.UnsafeBuffer;
 import org.junit.*;
 import org.junit.rules.TestWatcher;
@@ -126,11 +125,7 @@ public class ArchiveReplayLoadTest
         CloseHelper.close(archiver);
         CloseHelper.close(driver);
 
-        if (null != archiver.context().archiveDir())
-        {
-            IoUtil.delete(archiver.context().archiveDir(), false);
-        }
-
+        archiver.context().deleteArchiveDirectory();
         driver.context().deleteAeronDirectory();
     }
 ",Add a deleteArchiveDirectory to the archiver context .,"""Extract archive directory deletion into Archiver method""","""Refactor deletion of archive directories in Archiver and tests""","""Add deleteArchiveDirectory method to Archiver and use it in tests""

This commit introduces a new method `deleteArchiveDirectory()` in the `Archiver` class. This method deletes the archive directory if the `archiveDir` value is not null.

Additionally, in the test classes `ArchiverSystemTest`, `ArchiveRecordingLoadTest`, and `ArchiveReplayLoadTest`, the new method is used to delete the archive directory instead of the previous approach where the directory was deleted using `IoUtil.delete()` after checking if `archiver.context().archiveDir()` is not null.

This change simplifies the code in the test classes and makes the deletion of the archive directory more straightforward.",Add method to delete archive directory in Archiver context and refactor tests to use it.,Model 4
"diff --git a/dependency-check-core/src/test/java/org/owasp/dependencycheck/analyzer/AbstractSuppressionAnalyzerTest.java b/dependency-check-core/src/test/java/org/owasp/dependencycheck/analyzer/AbstractSuppressionAnalyzerTest.java
index cfda81250..c82d91e0e 100644
--- a/dependency-check-core/src/test/java/org/owasp/dependencycheck/analyzer/AbstractSuppressionAnalyzerTest.java
+++ b/dependency-check-core/src/test/java/org/owasp/dependencycheck/analyzer/AbstractSuppressionAnalyzerTest.java
@@ -17,39 +17,41 @@
  */
 package org.owasp.dependencycheck.analyzer;
 
-import java.net.MalformedURLException;
-import java.net.URISyntaxException;
-import java.util.List;
-import java.util.Set;
-import java.util.logging.Level;
-import java.util.logging.Logger;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNull;
 import org.junit.Before;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.ExpectedException;
 import org.owasp.dependencycheck.BaseTest;
 import org.owasp.dependencycheck.Engine;
 import org.owasp.dependencycheck.analyzer.exception.AnalysisException;
 import org.owasp.dependencycheck.dependency.Dependency;
+import org.owasp.dependencycheck.suppression.SuppressionParseException;
 import org.owasp.dependencycheck.suppression.SuppressionRule;
 import org.owasp.dependencycheck.utils.Settings;
 
+import java.net.MalformedURLException;
+import java.net.URISyntaxException;
+import java.util.List;
+import java.util.Set;
+import java.util.logging.Level;
+import java.util.logging.Logger;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNull;
+
 /**
- *
  * @author Jeremy Long <jeremy.long@owasp.org>
  */
 public class AbstractSuppressionAnalyzerTest extends BaseTest {
 
+    @Rule
+    public ExpectedException exception = ExpectedException.none();
+
+    private AbstractSuppressionAnalyzer instance;
+
     @Before
-    public void setUp() throws Exception {
-        try {
-            final String uri = this.getClass().getClassLoader().getResource(""suppressions.xml"").toURI().toURL().toString();
-            Settings.setString(Settings.KEYS.SUPPRESSION_FILE, uri);
-        } catch (URISyntaxException ex) {
-            Logger.getLogger(AbstractSuppressionAnalyzerTest.class.getName()).log(Level.SEVERE, null, ex);
-        } catch (MalformedURLException ex) {
-            Logger.getLogger(AbstractSuppressionAnalyzerTest.class.getName()).log(Level.SEVERE, null, ex);
-        }
+    public void createObjectUnderTest() throws Exception {
+        instance = new AbstractSuppressionAnalyzerImpl();
     }
 
     /**
@@ -57,32 +59,52 @@ public class AbstractSuppressionAnalyzerTest extends BaseTest {
      */
     @Test
     public void testGetSupportedExtensions() {
-        AbstractSuppressionAnalyzer instance = new AbstractSuppressionAnalyzerImpl();
         Set<String> result = instance.getSupportedExtensions();
         assertNull(result);
     }
 
     /**
-     * Test of initialize method, of class AbstractSuppressionAnalyzer.
+     * Test of getRules method, of class AbstractSuppressionAnalyzer for suppression file declared as URL.
      */
     @Test
-    public void testInitialize() throws Exception {
-        AbstractSuppressionAnalyzer instance = new AbstractSuppressionAnalyzerImpl();
+    public void testGetRulesFromSuppressionFileFromURL() throws Exception {
+        setSupressionFileFromURL();
         instance.initialize();
+        int expCount = 5;
+        List<SuppressionRule> result = instance.getRules();
+        assertEquals(expCount, result.size());
     }
 
     /**
-     * Test of getRules method, of class AbstractSuppressionAnalyzer.
+     * Test of getRules method, of class AbstractSuppressionAnalyzer for suppression file declared as URL.
      */
     @Test
-    public void testGetRules() throws Exception {
-        AbstractSuppressionAnalyzer instance = new AbstractSuppressionAnalyzerImpl();
+    public void testGetRulesFromSuppressionFileInClasspath() throws Exception {
+        Settings.setString(Settings.KEYS.SUPPRESSION_FILE, ""suppressions.xml"");
         instance.initialize();
         int expCount = 5;
         List<SuppressionRule> result = instance.getRules();
         assertEquals(expCount, result.size());
     }
 
+    @Test
+    public void testFailureToLocateSuppressionFileInClasspath() throws Exception {
+        Settings.setString(Settings.KEYS.SUPPRESSION_FILE, ""doesnotexist.xml"");
+        exception.expect(SuppressionParseException.class);
+        instance.initialize();
+    }
+
+    private void setSupressionFileFromURL() throws Exception {
+        try {
+            final String uri = this.getClass().getClassLoader().getResource(""suppressions.xml"").toURI().toURL().toString();
+            Settings.setString(Settings.KEYS.SUPPRESSION_FILE, uri);
+        } catch (URISyntaxException ex) {
+            Logger.getLogger(AbstractSuppressionAnalyzerTest.class.getName()).log(Level.SEVERE, null, ex);
+        } catch (MalformedURLException ex) {
+            Logger.getLogger(AbstractSuppressionAnalyzerTest.class.getName()).log(Level.SEVERE, null, ex);
+        }
+    }
+
     public class AbstractSuppressionAnalyzerImpl extends AbstractSuppressionAnalyzer {
 
         @Override",added test case for classpath suppression file and missing file .,"""Refactor AbstractSuppressionAnalyzerTest to improve test setup and add new test case for suppression file not found""",Added support for suppression file declared as URL and improved test coverage for AbstractSuppressionAnalyzer.,"""Refactor AbstractSuppressionAnalyzerTest to use JUnit's ExpectedException rule and extract setUp method""

Explanation:

* The `@Rule` annotation is added to use JUnit's `ExpectedException` rule for better exception handling in tests.
* The `setUp` method is renamed to `createObjectUnderTest` and its content is moved to a new method `setSupressionFileFromURL`.
* The `instance` variable is initialized in the `createObjectUnderTest` method instead of the `setUp` method.
* A new test method `testFailureToLocateSuppressionFileInClasspath` is added to test the behavior when the suppression file cannot be located in the classpath.
* The `setSupressionFileFromURL` method is added to set the suppression file from a URL, which is used in the `testGetRulesFromSuppressionFileFromURL` method.
* The `testInitialize` method is removed since it is not necessary after the refactoring.
* The `testGetRules` method is renamed to `testGetRulesFromSuppressionFileInClasspath` to better reflect its purpose.
* The `testGetRulesFromSuppressionFileFromURL` method is added to test the behavior when the suppression file is declared as a URL.","""Refactor AbstractSuppressionAnalyzerTest to improve setup, exception handling, and add tests for classpath and URL suppression files.""",Model 1
"diff --git a/dubbo-rpc/dubbo-rpc-grpc/src/main/java/org/apache/dubbo/rpc/protocol/grpc/GrpcInvoker.java b/dubbo-rpc/dubbo-rpc-grpc/src/main/java/org/apache/dubbo/rpc/protocol/grpc/GrpcInvoker.java
index c7e074909..4ca6fb796 100644
--- a/dubbo-rpc/dubbo-rpc-grpc/src/main/java/org/apache/dubbo/rpc/protocol/grpc/GrpcInvoker.java
+++ b/dubbo-rpc/dubbo-rpc-grpc/src/main/java/org/apache/dubbo/rpc/protocol/grpc/GrpcInvoker.java
@@ -111,8 +111,6 @@ public class GrpcInvoker<T> extends AbstractInvoker<T> {
             Status status = statusException.getStatus();
             if (status.getCode() == Status.Code.DEADLINE_EXCEEDED) {
                 return RpcException.TIMEOUT_EXCEPTION;
-            } else if (status.getCode() == Status.Code.DEADLINE_EXCEEDED) {
-                //
             }
         }
         return RpcException.UNKNOWN_EXCEPTION;",Duplicate condition in \' if \' statement inspection ( <issue_id> ),"""Remove duplicate deadline exceeded status check in GrpcInvoker""","""Remove duplicate condition for DEADLINE_EXCEEDED status in GrpcInvoker""","""Remove duplicate condition in GrpcInvoker.java""

Explanation: The commit message indicates that a duplicate condition check for `Status.Code.DEADLINE_EXCEEDED` was removed from the `GrpcInvoker.java` file. This change helps to simplify the code and avoid unnecessary redundancy.",Removed redundant DEADLINE_EXCEEDED condition in GrpcInvoker to clean up the code.,Model 4
"diff --git a/tool/test/org/antlr/v4/test/rt/csharp/TestParserErrors.java b/tool/test/org/antlr/v4/test/rt/csharp/TestParserErrors.java
index 6898f0e58..f05ad1a72 100644
--- a/tool/test/org/antlr/v4/test/rt/csharp/TestParserErrors.java
+++ b/tool/test/org/antlr/v4/test/rt/csharp/TestParserErrors.java
@@ -39,7 +39,7 @@ public class TestParserErrors extends BaseTest {
 	public void testSingleTokenDeletionConsumption() throws Exception {
 		String grammar = ""grammar T;\n"" +
 	                  ""myset: ('b'|'c') ;\n"" +
-	                  ""a: 'a' myset 'd' {Console.WriteLine($myset.stop);} ;"";
+	                  ""a: 'a' myset 'd' {Console.WriteLine(\""\"" + $myset.stop);} ; "";
 		String found = execParser(""T.g4"", grammar, ""TParser"", ""TLexer"", ""a"", ""aabd"", false);
 		assertEquals(""[@2,2:2='b',<1>,1:2]\n"", found);
 		assertEquals(""line 1:1 extraneous input 'a' expecting {'b', 'c'}\n"", this.stderrDuringParse);
@@ -80,7 +80,7 @@ public class TestParserErrors extends BaseTest {
 	public void testSingleSetInsertionConsumption() throws Exception {
 		String grammar = ""grammar T;\n"" +
 	                  ""myset: ('b'|'c') ;\n"" +
-	                  ""a: 'a' myset 'd' {Console.WriteLine($myset.stop);} ;"";
+	                  ""a: 'a' myset 'd' {Console.WriteLine(\""\"" + $myset.stop);} ; "";
 		String found = execParser(""T.g4"", grammar, ""TParser"", ""TLexer"", ""a"", ""ad"", false);
 		assertEquals(""[@0,0:0='a',<3>,1:0]\n"", found);
 		assertEquals(""line 1:1 missing {'b', 'c'} at 'd'\n"", this.stderrDuringParse);",freshen unit tests,"""Fix string concatenation in TestParserErrors.java""

This commit message is short and to the point, indicating that the commit is fixing an issue with string concatenation in the specified Java file.","The commit message should be:

""Fix Console.WriteLine formatting in TestParserErrors tests""

This message accurately reflects the change made in the commit, which is to fix the formatting of the Console.WriteLine statement in the TestParserErrors tests.","""Update TestParserErrors.java: Add missing quotation marks in Console.WriteLine()""

Explanation:
In the provided diff, the change is made in the TestParserErrors.java file where quotation marks are added inside the Console.WriteLine() function calls in the grammar rule 'a'. This update is necessary to correctly print the $myset.stop value as a string.",Updated Console.WriteLine statements to concatenate $myset.stop with an empty string to resolve type mismatch.,Model 3
"diff --git a/docs/reference/redirects.asciidoc b/docs/reference/redirects.asciidoc
index ef578170e4a..748b1df0875 100644
--- a/docs/reference/redirects.asciidoc
+++ b/docs/reference/redirects.asciidoc
@@ -632,32 +632,67 @@ See <<cat-transforms>>.
 [role=""exclude"",id=""testing""]
 === Testing
 
-This page was deleted.
+This page was deleted. 
+Information about the Java testing framework was removed 
+({es-issue}55257[#55257]) from the {es} Reference 
+because it was out of date and erroneously implied that it should be used by application developers.  
+There is an issue ({es-issue}55258[#55258]) 
+for providing general testing guidance for applications that communicate with {es}. 
 
 [role=""exclude"",id=""testing-framework""]
 === Java testing framework
 
 This page was deleted.
+Information about the Java testing framework was removed 
+({es-issue}55257[55257]) from the {es} Reference 
+because it was out of date and erroneously implied that it should be used by application developers.  
+There is an issue ({es-issue}[#55258]) 
+for providing general testing guidance for applications that communicate with {es}. 
+
 
 [role=""exclude"",id=""why-randomized-testing""]
 === Why randomized testing?
 
 This page was deleted.
+Information about the Java testing framework was removed 
+({es-issue}55257[55257]) from the {es} Reference 
+because it was out of date and erroneously implied that it should be used by application developers.  
+There is an issue ({es-issue}[#55258]) 
+for providing general testing guidance for applications that communicate with {es}. 
+
 
 [role=""exclude"",id=""using-elasticsearch-test-classes""]
 === Using the {es} test classes
 
 This page was deleted.
+Information about the Java testing framework was removed 
+({es-issue}55257[55257]) from the {es} Reference 
+because it was out of date and erroneously implied that it should be used by application developers.  
+There is an issue ({es-issue}55258[#55258]) 
+for providing general testing guidance for applications that communicate with {es}. 
+
 
 [role=""exclude"",id=""unit-tests""]
 === Unit tests
 
 This page was deleted.
+Information about the Java testing framework was removed 
+({es-issue}55257[55257]) from the {es} Reference 
+because it was out of date and erroneously implied that it should be used by application developers.  
+There is an issue ({es-issue}55258[#55258]) 
+for providing general testing guidance for applications that communicate with {es}. 
+
 
 [role=""exclude"",id=""integration-tests""]
 === Integration tests
 
 This page was deleted.
+Information about the Java testing framework was removed 
+({es-issue}55257[55257]) from the {es} Reference 
+because it was out of date and erroneously implied that it should be used by application developers.  
+There is an issue ({es-issue}55258[#55258]) 
+for providing general testing guidance for applications that communicate with {es}. 
+
 
 [role=""exclude"",id=""number-of-shards""]
 ==== Number of shards",Add info about why we removed test fw docs ( <issue_id> ) ( <issue_id> ) .,"""Remove outdated Java testing framework documentation (ES-55257)""","""Removed outdated Java testing framework information from the Elasticsearch Reference and added issue links for future testing guidance.""","It seems like you're updating a documentation file for Elasticsearch and you've removed some sections related to testing. The sections removed were outdated and incorrectly suggested that they should be used by application developers. You've also added references to the issues (#55257 and #55258) related to these changes.

As for the commit message, it could be something like this:

""Remove outdated information about the Java testing framework and add references to related issues (#55257 and #55258). The removed sections erroneously suggested that the framework should be used by application developers. A new issue (#55258) has been created to provide general testing guidance for applications that communicate with Elasticsearch.""",Removed outdated Java testing framework documentation and provided issues for general testing guidance for Elasticsearch applications.,Model 3
"diff --git a/core/src/main/java/org/elasticsearch/common/cache/Cache.java b/core/src/main/java/org/elasticsearch/common/cache/Cache.java
new file mode 100644
index 00000000000..f0f72428989
--- /dev/null
+++ b/core/src/main/java/org/elasticsearch/common/cache/Cache.java
@@ -0,0 +1,642 @@
+/*
+ * Licensed to Elasticsearch under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Elasticsearch licenses this file to you under
+ * the Apache License, Version 2.0 (the ""License""); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.elasticsearch.common.cache;
+
+import org.elasticsearch.common.collect.Tuple;
+
+import java.util.*;
+import java.util.concurrent.atomic.LongAdder;
+import java.util.concurrent.locks.ReadWriteLock;
+import java.util.concurrent.locks.ReentrantLock;
+import java.util.concurrent.locks.ReentrantReadWriteLock;
+import java.util.function.Function;
+import java.util.function.ToLongBiFunction;
+
+/**
+ * A simple concurrent cache.
+ *<p>
+ * Cache is a simple concurrent cache that supports time-based and weight-based evictions, with notifications for all
+ * evictions. The design goals for this cache were simplicity and read performance. This means that we are willing to
+ * accept reduced write performance in exchange for easy-to-understand code. Cache statistics for hits, misses and
+ * evictions are exposed.
+ *<p>
+ * The design of the cache is relatively simple. The cache is segmented into 256 segments which are backed by HashMaps.
+ * The segments are protected by a re-entrant read/write lock. The read/write locks permit multiple concurrent readers
+ * without contention, and the segments gives us write throughput without impacting readers (so readers are blocked only
+ * if they are reading a segment that a writer is writing to).
+ * <p>
+ * The LRU functionality is backed by a single doubly-linked list chaining the entries in order of insertion. This
+ * LRU list is protected by a lock that serializes all writes to it. There are opportunities for improvements
+ * here if write throughput is a concern.
+ * <ol>
+ *     <li>LRU list mutations could be inserted into a blocking queue that a single thread is reading from
+ *     and applying to the LRU list.</li>
+ *     <li>Promotions could be deferred for entries that were ""recently"" promoted.</li>
+ *     <li>Locks on the list could be taken per node being modified instead of globally.</li>
+ * </ol>
+ *
+ * Evictions only occur after a mutation to the cache (meaning an entry promotion, a cache insertion, or a manual
+ * invalidation) or an explicit call to {@link #refresh()}.
+ *
+ * @param <K> The type of the keys
+ * @param <V> The type of the values
+ */
+public class Cache<K, V> {
+    // positive if entries have an expiration
+    private long expireAfter = -1;
+
+    // the number of entries in the cache
+    private int count = 0;
+
+    // the weight of the entries in the cache
+    private long weight = 0;
+
+    // the maximum weight that this cache supports
+    private long maximumWeight = -1;
+
+    // the weigher of entries
+    private ToLongBiFunction<K, V> weigher = (k, v) -> 1;
+
+    // the removal callback
+    private RemovalListener<K, V> removalListener = notification -> {
+    };
+
+    // use CacheBuilder to construct
+    Cache() {
+    }
+
+    void setExpireAfter(long expireAfter) {
+        if (expireAfter <= 0) {
+            throw new IllegalArgumentException(""expireAfter <= 0"");
+        }
+        this.expireAfter = expireAfter;
+    }
+
+    void setMaximumWeight(long maximumWeight) {
+        if (maximumWeight < 0) {
+            throw new IllegalArgumentException(""maximumWeight < 0"");
+        }
+        this.maximumWeight = maximumWeight;
+    }
+
+    void setWeigher(ToLongBiFunction<K, V> weigher) {
+        Objects.requireNonNull(weigher);
+        this.weigher = weigher;
+    }
+
+    void setRemovalListener(RemovalListener<K, V> removalListener) {
+        this.removalListener = removalListener;
+    }
+
+    /**
+     * The relative time used to track time-based evictions.
+     *
+     * @return the current relative time
+     */
+    protected long now() {
+        // System.nanoTime takes non-negligible time, so we only use it if we need it
+        return expireAfter == -1 ? 0 : System.nanoTime();
+    }
+
+    // the state of an entry in the LRU list
+    enum State {NEW, EXISTING, DELETED}
+
+    static class Entry<K, V> {
+        final K key;
+        final V value;
+        long accessTime;
+        Entry<K, V> before;
+        Entry<K, V> after;
+        State state = State.NEW;
+
+        public Entry(K key, V value, long accessTime) {
+            this.key = key;
+            this.value = value;
+            this.accessTime = accessTime;
+        }
+
+        @Override
+        public boolean equals(Object obj) {
+            if (obj == null) {
+                return false;
+            } else if (!(obj instanceof Entry)) {
+                return false;
+            } else {
+                @SuppressWarnings(""unchecked"")
+                Entry<K, V> e = (Entry<K, V>) obj;
+                return Objects.equals(key, e.key);
+            }
+        }
+
+        @Override
+        public int hashCode() {
+            return Objects.hashCode(key);
+        }
+    }
+
+    /**
+     * A cache segment.
+     *
+     * A CacheSegment is backed by a HashMap and is protected by a read/write lock.
+     *
+     * @param <K> the type of the keys
+     * @param <V> the type of the values
+     */
+    private static class CacheSegment<K, V> {
+        // read/write lock protecting mutations to the segment
+        ReadWriteLock lock = new ReentrantReadWriteLock();
+        Map<K, Entry<K, V>> map = new HashMap<>();
+        SegmentStats segmentStats = new SegmentStats();
+
+        /**
+         * get an entry from the segment
+         *
+         * @param key the key of the entry to get from the cache
+         * @param now the access time of this entry
+         * @return the entry if there was one, otherwise null
+         */
+        Entry<K, V> get(K key, long now) {
+            lock.readLock().lock();
+            Entry<K, V> entry = map.get(key);
+            lock.readLock().unlock();
+            if (entry != null) {
+                segmentStats.hit();
+                entry.accessTime = now;
+            } else {
+                segmentStats.miss();
+            }
+            return entry;
+        }
+
+        /**
+         * put an entry into the segment
+         *
+         * @param key the key of the entry to add to the cache
+         * @param value the value of the entry to add to the cache
+         * @param now the access time of this entry
+         * @param onlyIfAbsent whether or not an existing entry should be replaced
+         * @return a tuple of the new entry and the existing entry, if there was one otherwise null
+         */
+        Tuple<Entry<K, V>, Entry<K, V>> put(K key, V value, long now, boolean onlyIfAbsent) {
+            Entry<K, V> entry = new Entry<>(key, value, now);
+            lock.writeLock().lock();
+            Entry<K, V> existing = null;
+            if (!onlyIfAbsent || (onlyIfAbsent && map.get(key) == null)) {
+                existing = map.put(key, entry);
+            }
+            lock.writeLock().unlock();
+            return Tuple.tuple(entry, existing);
+        }
+
+        /**
+         * remove an entry from the segment
+         *
+         * @param key the key of the entry to remove from the cache
+         * @return the removed entry if there was one, otherwise null
+         */
+        Entry<K, V> remove(K key) {
+            lock.writeLock().lock();
+            Entry<K, V> entry = map.remove(key);
+            lock.writeLock().unlock();
+            if (entry != null) {
+                segmentStats.eviction();
+            }
+            return entry;
+        }
+
+        private static class SegmentStats {
+            private final LongAdder hits = new LongAdder();
+            private final LongAdder misses = new LongAdder();
+            private final LongAdder evictions = new LongAdder();
+
+            void hit() {
+                hits.increment();
+            }
+
+            void miss() {
+                misses.increment();
+            }
+
+            void eviction() {
+                evictions.increment();
+            }
+        }
+    }
+
+    private CacheSegment<K, V>[] segments = new CacheSegment[256];
+
+    {
+        for (int i = 0; i < segments.length; i++) {
+            segments[i] = new CacheSegment<>();
+        }
+    }
+
+    Entry<K, V> head;
+    Entry<K, V> tail;
+
+    // lock protecting mutations to the LRU list
+    private ReentrantLock lock = new ReentrantLock();
+
+    /**
+     * Returns the value to which the specified key is mapped, or null if this map contains no mapping for the key.
+     *
+     * @param key the key whose associated value is to be returned
+     * @return the value to which the specified key is mapped, or null if this map contains no mapping for the key
+     */
+    public V get(K key) {
+        long now = now();
+        CacheSegment<K, V> segment = getCacheSegment(key);
+        Entry<K, V> entry = segment.get(key, now);
+        if (entry == null || isExpired(entry, now)) {
+            return null;
+        } else {
+            promote(entry, now);
+            return entry.value;
+        }
+    }
+
+    /**
+     * If the specified key is not already associated with a value (or is mapped to null), attempts to compute its
+     * value using the given mapping function and enters it into this map unless null.
+     *
+     * @param key the key whose associated value is to be returned or computed for if non-existant
+     * @param mappingFunction the function to compute a value given a key
+     * @return the current (existing or computed) value associated with the specified key, or null if the computed
+     * value is null
+     */
+    public V computeIfAbsent(K key, Function<K, V> mappingFunction) {
+        long now = now();
+        V value = get(key);
+        if (value == null) {
+            value = mappingFunction.apply(key);
+            if (value != null) {
+                put(key, value, now, true);
+            }
+        }
+        return value;
+    }
+
+    /**
+     * Associates the specified value with the specified key in this map. If the map previously contained a mapping for
+     * the key, the old value is replaced.
+     *
+     * @param key key with which the specified value is to be associated
+     * @param value value to be associated with the specified key
+     */
+    public void put(K key, V value) {
+        long now = now();
+        put(key, value, now, false);
+    }
+
+    private void put(K key, V value, long now, boolean onlyIfAbsent) {
+        CacheSegment<K, V> segment = getCacheSegment(key);
+        Tuple<Entry<K, V>, Entry<K, V>> tuple = segment.put(key, value, now, onlyIfAbsent);
+        lock.lock();
+        boolean replaced = false;
+        if (tuple.v2() != null && tuple.v2().state == State.EXISTING) {
+            if (unlink(tuple.v2())) {
+                replaced = true;
+            }
+        }
+        promote(tuple.v1(), now);
+        lock.unlock();
+        if (replaced) {
+            removalListener.onRemoval(new RemovalNotification(tuple.v2().key, tuple.v2().value, RemovalNotification.RemovalReason.REPLACED));
+        }
+    }
+
+    /**
+     * Invalidate the association for the specified key. A removal notification will be issued for invalidated
+     * entries with {@link org.elasticsearch.common.cache.RemovalNotification.RemovalReason} INVALIDATED.
+     *
+     * @param key the key whose mapping is to be invalidated from the cache
+     */
+    public void invalidate(K key) {
+        CacheSegment<K, V> segment = getCacheSegment(key);
+        Entry<K, V> entry = segment.remove(key);
+        if (entry != null) {
+            lock.lock();
+            delete(entry, RemovalNotification.RemovalReason.INVALIDATED);
+            lock.unlock();
+        }
+    }
+
+    /**
+     * Invalidate all cache entries. A removal notification will be issued for invalidated entries with
+     * {@link org.elasticsearch.common.cache.RemovalNotification.RemovalReason} INVALIDATED.
+     */
+    public void invalidateAll() {
+        Entry<K, V> h = head;
+        Arrays.stream(segments).forEach(segment -> segment.lock.writeLock().lock());
+        lock.lock();
+        Arrays.stream(segments).forEach(segment -> segment.map = new HashMap<>());
+        Entry<K, V> current = head;
+        while (current != null) {
+            current.state = State.DELETED;
+            current = current.after;
+        }
+        head = tail = null;
+        count = 0;
+        weight = 0;
+        lock.unlock();
+        Arrays.stream(segments).forEach(segment -> segment.lock.writeLock().unlock());
+        while (h != null) {
+            removalListener.onRemoval(new RemovalNotification<>(h.key, h.value, RemovalNotification.RemovalReason.INVALIDATED));
+            h = h.after;
+        }
+    }
+
+    /**
+     * Force any outstanding size-based and time-based evictions to occur
+     */
+    public void refresh() {
+        long now = now();
+        lock.lock();
+        evict(now);
+        lock.unlock();
+    }
+
+    /**
+     * The number of entries in the cache.
+     *
+     * @return the number of entries in the cache
+     */
+    public int count() {
+        return count;
+    }
+
+    /**
+     * The weight of the entries in the cache.
+     *
+     * @return the weight of the entries in the cache
+     */
+    public long weight() {
+        return weight;
+    }
+
+    /**
+     * An LRU sequencing of the keys in the cache that supports removal.
+     *
+     * @return an LRU-ordered {@link Iterable} over the keys in the cache
+     */
+    public Iterable<K> keys() {
+        return () -> new Iterator<K>() {
+            private CacheIterator iterator = new CacheIterator(head);
+
+            @Override
+            public boolean hasNext() {
+                return iterator.hasNext();
+            }
+
+            @Override
+            public K next() {
+                return iterator.next().key;
+            }
+
+            @Override
+            public void remove() {
+                iterator.remove();
+            }
+        };
+    }
+
+    /**
+     * An LRU sequencing of the values in the cache.
+     *
+     * @return an LRU-ordered {@link Iterable} over the values in the cache
+     */
+    public Iterable<V> values() {
+        return () -> new Iterator<V>() {
+            private CacheIterator iterator = new CacheIterator(head);
+
+            @Override
+            public boolean hasNext() {
+                return iterator.hasNext();
+            }
+
+            @Override
+            public V next() {
+                return iterator.next().value;
+            }
+        };
+    }
+
+    private class CacheIterator implements Iterator<Entry<K, V>> {
+        private Entry<K, V> current;
+        private Entry<K, V> next;
+
+        CacheIterator(Entry<K, V> head) {
+            current = null;
+            next = head;
+        }
+
+        @Override
+        public boolean hasNext() {
+            return next != null;
+        }
+
+        @Override
+        public Entry<K, V> next() {
+            current = next;
+            next = next.after;
+            return current;
+        }
+
+        @Override
+        public void remove() {
+            Entry<K, V> entry = current;
+            if (entry != null) {
+                CacheSegment<K, V> segment = getCacheSegment(entry.key);
+                segment.remove(entry.key);
+     ",Create concurrent cache with flexible eviction policies .,"""Add a simple concurrent cache implementation with time-based and weight-based evictions""","Added a concurrent cache implementation with time-based and weight-based evictions, along with notifications for all evictions.","This is a new file named `Cache.java` that implements a simple concurrent cache with support for time-based and weight-based evictions, as well as notifications for all evictions. The cache is segmented into 256 segments, each protected by a re-entrant read/write lock, and the LRU functionality is backed by a single doubly-linked list chaining the entries in order of insertion. Evictions only occur after a mutation to the cache or an explicit call to `refresh()`. The cache statistics for hits, misses, and evictions are exposed. The design of the cache prioritizes read performance and simplicity.","Added a new Cache class with support for concurrent, time-based, and weight-based evictions with LRU functionality.",Model 2
"diff --git a/examples/image_classifier/README.md b/examples/image_classifier/README.md
index 22ea3553..cf3b2547 100644
--- a/examples/image_classifier/README.md
+++ b/examples/image_classifier/README.md
@@ -2,15 +2,15 @@
 
 * TorchVision Image Classification Models : Download a pre-trained model state_dict for computer vision model that classifies images from the following :
 
-  * [Image Classification with AlexNet](image_classifier/alexnet) - https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth
-  * [Image Classification with DenseNet161](image_classifier/densenet_161) - https://download.pytorch.org/models/densenet161-8d451a50.pth
-  * [Image Classification with ResNet18](image_classifier/resnet_18) - https://download.pytorch.org/models/resnet18-5c106cde.pth
-  * [Image Classification with SqueezeNet 1_1](image_classifier/squeezenet) - https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth
-  * [Image Classification with VGG11](image_classifier/vgg_11) - https://download.pytorch.org/models/vgg11-bbd30ac9.pth
+  * [Image Classification with AlexNet](alexnet) - https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth
+  * [Image Classification with DenseNet161](densenet_161) - https://download.pytorch.org/models/densenet161-8d451a50.pth
+  * [Image Classification with ResNet18](resnet_18) - https://download.pytorch.org/models/resnet18-5c106cde.pth
+  * [Image Classification with SqueezeNet 1_1](squeezenet) - https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth
+  * [Image Classification with VGG11](vgg_11) - https://download.pytorch.org/models/vgg11-bbd30ac9.pth
 
 * Create a model architecture file (model-file) based on selected model or use the sample provided with above examples.
 
-* You can use the [index_to_name.json](image_classifier/index_to_name.json) file for mapping predicted index to class or use a custom one.
+* You can use the [index_to_name.json](index_to_name.json) file for mapping predicted index to class or use a custom one.
 
 * Create a torch model archive file using the above provided syntax command.
 ",fixed broken lins,"""Update image classifier README to remove unnecessary directory paths""","""Update README.md with corrected model links and file paths.""",Updated example links and index_to_name.json file reference in README.md for image classifier examples.,"""Update model and JSON file paths in image_classifier README for clarity.""",Model 3
"diff --git a/az-core/src/main/java/azkaban/utils/TimeUtils.java b/az-core/src/main/java/azkaban/utils/TimeUtils.java
index 43522fa9..a991b783 100644
--- a/az-core/src/main/java/azkaban/utils/TimeUtils.java
+++ b/az-core/src/main/java/azkaban/utils/TimeUtils.java
@@ -37,6 +37,7 @@ public class TimeUtils {
 
   private static final String DATE_TIME_ZONE_PATTERN = ""yyyy/MM/dd HH:mm:ss z"";
   private static final String DATE_TIME_PATTERN = ""yyyy-MM-dd HH:mm:ss"";
+  private static int ONE_DAY = 86400;
 
   /**
    * Formats the given millisecond instant into a string using the pattern ""yyyy/MM/dd HH:mm:ss z""
@@ -236,4 +237,13 @@ public class TimeUtils {
   public static boolean timeEscapedOver(long referenceTime, int second) {
     return ((System.currentTimeMillis() - referenceTime) / 1000F) > (second * 1.0);
   }
+
+  /**
+   * Check how many days escaped over
+   * @param referenceTime reference time
+   * @return number of days
+   */
+  public static int daysEscapedOver(long referenceTime) {
+    return Math.round(((System.currentTimeMillis() - referenceTime) / 1000f) / (ONE_DAY * 1.0f) - 0.5f);
+  }
 }
diff --git a/az-core/src/test/java/azkaban/utils/TimeUtilsTest.java b/az-core/src/test/java/azkaban/utils/TimeUtilsTest.java
index 597813cd..8c683cb0 100644
--- a/az-core/src/test/java/azkaban/utils/TimeUtilsTest.java
+++ b/az-core/src/test/java/azkaban/utils/TimeUtilsTest.java
@@ -29,4 +29,14 @@ public class TimeUtilsTest {
     Assert.assertTrue( TimeUtils.timeEscapedOver(baseTime, 1));
     Assert.assertFalse(TimeUtils.timeEscapedOver(baseTime, 2));
   }
+
+  @Test
+  public void testDayEscapedOver() throws InterruptedException {
+    long baseTime = System.currentTimeMillis();
+    long oneDayBefore =  baseTime - 86399000;
+    TimeUnit.SECONDS.sleep(3);
+    Assert.assertEquals( TimeUtils.daysEscapedOver(baseTime), 0);
+    Assert.assertEquals(TimeUtils.daysEscapedOver(oneDayBefore), 1);
+  }
+
 }
diff --git a/az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopPigJob.java b/az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopPigJob.java
index 8ab02dcb..7c53b003 100644
--- a/az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopPigJob.java
+++ b/az-hadoop-jobtype-plugin/src/main/java/azkaban/jobtype/HadoopPigJob.java
@@ -170,17 +170,29 @@ public class HadoopPigJob extends AbstractHadoopJavaProcessJob {
         File srcFile = new File(getScriptAbsolutePath());
         File dstFile = new File(getRunnableScriptAbsolutePath());
         Path dstPath = Paths.get(getRunnableScriptDir());
+        getLog().info(String.format(""[Ramp Modification Start] [srcFile = %s, dstFile = %s, dstPath = %s]"",
+            srcFile.toPath().toAbsolutePath().toString(),
+            dstFile.toPath().toAbsolutePath().toString(),
+            dstPath.toString()));
         if (!Files.exists(dstPath)) {
           Files.createDirectories(dstPath);
+          getLog().info(String.format(""[Ramp Modification Destination Directory Created. %s]"",
+              dstPath.toAbsolutePath().toString()));
         }
         dstFile.createNewFile();
+        getLog().info(String.format(""[Ramp Modification Destination File Created. %s]"",
+            dstFile.toPath().toAbsolutePath().toString()));
         getLog().info(String.format(""[Ramp Modify Script File] : old = %s, new = %s"",
             srcFile.getAbsolutePath(), dstFile.getAbsolutePath()));
         copyAndModifyScript(srcFile, dstFile, rampRegisterItems);
+        getLog().info(String.format(""[Ramp Modification End] [dstFile = %s]"",
+            dstFile.toPath().toAbsolutePath().toString()));
+        list.add(getRunnableScript());
       } catch (IOException e) {
-        e.printStackTrace();
+        getLog().error(e);
+        getLog().info(""[Ramp cannot successfully modify the script, Failover to the baseline.]"");
+        list.add(getScript());
       }
-      list.add(getRunnableScript());
     }
 
     return StringUtils.join((Collection<String>) list, "" "");
diff --git a/azkaban-common/src/main/java/azkaban/executor/ExecutableRamp.java b/azkaban-common/src/main/java/azkaban/executor/ExecutableRamp.java
index ff290835..4b077191 100644
--- a/azkaban-common/src/main/java/azkaban/executor/ExecutableRamp.java
+++ b/azkaban-common/src/main/java/azkaban/executor/ExecutableRamp.java
@@ -215,7 +215,7 @@ public class ExecutableRamp implements IRefreshable<ExecutableRamp> {
       this.numOfFailure = source.numOfFailure;
       this.numOfIgnored = source.numOfFailure;
 
-      this.isPaused = source.isPaused ? source.isPaused : this.isPaused;
+      this.isPaused = source.isPaused;
       this.rampStage = (source.rampStage > this.rampStage) ? source.rampStage : this.rampStage;
       this.isActive = source.isActive;
 
@@ -344,7 +344,12 @@ public class ExecutableRamp implements IRefreshable<ExecutableRamp> {
 
   public boolean isActive() {
     long diff = this.getState().startTime - System.currentTimeMillis();
-    return this.getState().isActive && (!this.getState().isPaused) && (diff < 0);
+    boolean isActive = this.getState().isActive && (!this.getState().isPaused) && (diff < 0);
+    if (!isActive) {
+      LOGGER.info(""[Ramp Is Isolated] (isActive = {}, isPause = {}, timeDiff = {}"",
+          this.getState().isActive, this.getState().isPaused, diff);
+    }
+    return isActive;
   }
 
   synchronized public void cacheResult(Action action) {
@@ -363,13 +368,15 @@ public class ExecutableRamp implements IRefreshable<ExecutableRamp> {
     this.state.lastUpdatedTime = System.currentTimeMillis();
 
     // verify the failure threshold
+    int trails = this.state.numOfTrail + this.state.cachedNumOfTrail;
+    int fails = this.state.numOfFailure + this.state.cachedNumOfFailure;
     int failure = this.metadata.isPercentageScaleForMaxFailure
-        ?
-        (int) (((this.state.numOfFailure + this.state.cachedNumOfFailure) * 100.0)
-            / ((this.state.numOfTrail + this.state.cachedNumOfTrail) * 1.0))
-        : (this.state.numOfFailure + this.state.cachedNumOfFailure);
+        ? (trails == 0)
+          ? 100
+          : (int) ((fails * 100.0) / (trails * 1.0))
+        : fails;
 
-    LOGGER.info(String.format(""Cache Ramp Result : [id = %s, action: %s, %s failure: %d, numOfTrail (%d, %d), numOfSuccess: (%d, %d), numOfFailure: (%d, %d), numOfIgnore: (%d, %d)]""
+    LOGGER.info(""[Ramp Cached Result] (id = {}, action: {}, {} failure: {}, numOfTrail ({}, {}), numOfSuccess: ({}, {}), numOfFailure: ({}, {}), numOfIgnore: ({}, {}))""
         , this.id
         , action.name()
         , this.metadata.isPercentageScaleForMaxFailure ? ""Percentage"" : "" ""
@@ -382,14 +389,26 @@ public class ExecutableRamp implements IRefreshable<ExecutableRamp> {
         , this.state.cachedNumOfFailure
         , this.state.numOfIgnored
         , this.state.cachedNumOfIgnored
-    ));
-    if (failure > this.metadata.maxFailureToRampDown) {
-      LOGGER.warn(String.format(""Failure over the threshold to Ramp Down [id = %s, failure = %d, threshold = %d]"", this.id, failure, this.metadata.maxFailureToRampDown));
-      if (this.state.rampStage > 0) {
-        this.state.rampStage--;
+    );
+
+    if (this.metadata.maxFailureToRampDown != 0) {
+      if (failure > this.metadata.maxFailureToRampDown) {
+        if (this.state.rampStage > 0) {
+          int currentStage = this.state.rampStage;
+          this.state.rampStage--;
+          int futureStage = this.state.rampStage;
+          LOGGER.warn(""[RAMP DOWN] (rampId = {}, failure = {}, threshold = {}, from stage {} to stage {}.)"",
+              this.getId(), failure, this.metadata.maxFailureToRampDown, currentStage, futureStage);
+        }
+      }
+    }
+
+    if (this.metadata.maxFailureToPause != 0) {
+      if (failure > this.metadata.maxFailureToPause) {
+        this.state.setPaused(true);
+        LOGGER.info(""[RAMP STOP] (rampId = {}, failure = {}, threshold = {}, timestamp = {})"",
+            this.getId(), failure, this.metadata.maxFailureToPause, System.currentTimeMillis());
       }
-    } else if (failure > this.metadata.maxFailureToPause) {
-      LOGGER.warn(String.format(""Failure over the threshold to Pause the Ramp [id = %s, failure = %d, threshold = %d]"", this.id, failure, this.metadata.maxFailureToRampDown));
     }
 
     this.getState().markChanged();
diff --git a/azkaban-common/src/main/java/azkaban/ramppolicy/SimpleAutoRampPolicy.java b/azkaban-common/src/main/java/azkaban/ramppolicy/SimpleAutoRampPolicy.java
index f59d7985..13d98991 100644
--- a/azkaban-common/src/main/java/azkaban/ramppolicy/SimpleAutoRampPolicy.java
+++ b/azkaban-common/src/main/java/azkaban/ramppolicy/SimpleAutoRampPolicy.java
@@ -20,6 +20,8 @@ import azkaban.executor.ExecutableRamp;
 import azkaban.utils.Props;
 import azkaban.utils.TimeUtils;
 import com.google.common.collect.ImmutableList;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 
 
 /**
@@ -31,11 +33,15 @@ import com.google.common.collect.ImmutableList;
  *  stage 5: 100%
  */
 public class SimpleAutoRampPolicy extends SimpleRampPolicy {
-  private static int ONE_DAY = 86400;
   private static final int MAX_RAMP_STAGE = 5;
   private static final ImmutableList<Integer> RAMP_STAGE_RESCALE_TABLE = ImmutableList.<Integer>builder()
       .add(5, 25, 50, 75)
       .build();
+  private static final ImmutableList<Integer> AUTO_RAMP_INTERVAL_TABLE = ImmutableList.<Integer>builder()
+      .add(1, 2, 3, 4)
+      .build();
+
+  private static final Logger LOGGER = LoggerFactory.getLogger(SimpleAutoRampPolicy.class);
 
 
   public SimpleAutoRampPolicy(Props sysProps, Props privateProps) {
@@ -60,15 +66,34 @@ public class SimpleAutoRampPolicy extends SimpleRampPolicy {
   }
 
   @Override
-  protected void preprocess(ExecutableRamp executableRamp) { // TODO VERIFY AUTO RAMP MECHANISM
-    if (TimeUtils.timeEscapedOver(executableRamp.getState().getLastUpdatedTime(), ONE_DAY)) {
-      int rampStage = executableRamp.getState().getRampStage();
-      if (rampStage <= getMaxRampStage()) {
-        executableRamp.getState().setRampStage(rampStage + 1);
-        executableRamp.getState().setLastUpdatedTime(System.currentTimeMillis());
-      } else {
-        executableRamp.getState().setEndTime(System.currentTimeMillis());
+  protected void preprocess(ExecutableRamp executableRamp) {
+    int escapedDays = TimeUtils.daysEscapedOver(executableRamp.getState().getStartTime());
+    int rampStage = executableRamp.getState().getRampStage();
+    int maxStage = getMaxRampStage();
+
+    if (rampStage == 0) {
+      // The ramp is still not stated yet. Auto Ramp should not be triggered.
+      return;
+    }
+
+    try {
+      if (escapedDays >= AUTO_RAMP_INTERVAL_TABLE.get(rampStage - 1)) {
+        if (rampStage < maxStage) {
+          // Ramp up
+          int newStage = rampStage + 1;
+          long timeStamp = System.currentTimeMillis();
+          executableRamp.getState().setRampStage(newStage);
+          executableRamp.getState().setLastUpdatedTime(timeStamp);
+          if (newStage == maxStage) {
+            executableRamp.getState().setEndTime(timeStamp);
+          }
+          LOGGER.info(""[AUTO RAMP UP] (rampId = {}, current Stage = {}, new Stage = {}, timeStamp = {}"",
+              executableRamp.getId(), rampStage, newStage, timeStamp);
+        }
       }
+    } catch (Exception e) {
+      LOGGER.error(""[AUTO RAMP ERROR] (rampId = {}, ramStage = {}, message = {}"",
+          executableRamp.getId(), rampStage, e.getMessage());
     }
   }
 }
diff --git a/azkaban-exec-server/src/main/java/azkaban/execapp/FlowRampManager.java b/azkaban-exec-server/src/main/java/azkaban/execapp/FlowRampManager.java
index 14f839f7..d80be8da 100644
--- a/azkaban-exec-server/src/main/java/azkaban/execapp/FlowRampManager.java
+++ b/azkaban-exec-server/src/main/java/azkaban/execapp/FlowRampManager.java
@@ -386,12 +386,20 @@ public class FlowRampManager implements EventListener, ThreadPoolExecutingListen
       for (ExecutableRamp executableRamp : executableRampMap.getActivatedAll()) {
         try {
           String rampId = executableRamp.getId();
+          LOGGER.info(""[Ramp Check] (rampId = {}, rampStage = {}, executionId = {}, flowName = {}, RampPercentageId = {})"",
+              rampId,
+              executableRamp.getState().getRampStage(),
+              executableFlow.getExecutionId(),
+              flowName,
+              executableFlow.getRampPercentageId()
+          );
 
           // get Base Props
           Props baseProps = new Props();
           baseProps.putAll(executableRampDependencyMap.getDefaultValues(executableRampItemsMap.getDependencies(rampId)));
 
           ExecutableRampStatus status = executableRampExceptionalFlowItemsMap.check(rampId, flowName);
+          LOGGER.info(""[Ramp Status] (Status = {}, flowName = {})"", status.name(), flowName);
           switch (status) {
             case BLACKLISTED: // blacklist
               executableFlowRampMetadata.setRampProps(
@@ -402,7 +410,7 @@ public class FlowRampManager implements EventListener, ThreadPoolExecutingListen
                       ExecutableRampStatus.BLACKLISTED.name()
                   )
               );
-              LOGGER.info(""Ramp Flow As BlackListed Item. [rampid = {}, flowName = {}]"", rampId, flowName);
+              LOGGER.info(""[Ramp BlackListed]. [rampId = {}, flowName = {}]"", rampId, flowName);
               break;
 
             case WHITELISTED: // whitelist
@@ -414,7 +422,7 @@ public class FlowRampManager implements EventListener, ThreadPoolExecutingListen
                       ExecutableRampStatus.WHITELISTED.name()
                   )
               );
-              LOGGER.info(""Ramp Flow As WhiteListed Item. [rampid = {}, flowName = {}]"", rampId, flowName);
+              LOGGER.info(""[Ramp WhiteListed]. [rampId = {}, flowName = {}]"", rampId, flowName);
               break;
 
             case SELECTED: // selected
@@ -426,7 +434,7 @@ public class FlowRampManager implements EventListener, ThreadPoolExecutingListen
                       ExecutableRampStatus.SELECTED.name()
                   )
               );
-              LOGGER.info(""Ramp Flow As Selected Item. [rampid = {}, flowName = {}]"", rampId, flowName);
+              LOGGER.info(""[Ramp Selected]. [rampId = {}, flowName = {}]"", rampId, flowName);
               break;
 
             case UNSELECTED: // selected
@@ -438,8 +446,7 @@ public class FlowRampManager implements EventListener, ThreadPoolExecutingListen
                       ExecutableRampStatus.UNSELECTED.name()
                   )
               );
-              LOGGER.info(""Ramp Flow As Unselected Item. [rampid = {}, flowName = {}]"",
-                  rampId, flowName);
+              LOGGER.info(""[Ramp Unselected]. [rampId = {}, flowName = {}]"", rampId, flowName);
               break;
 
             case EXCLUDED:
@@ -451,12 +458,18 @@ public class FlowRampManager implements EventListener, ThreadPoolExecutingListen
                       ExecutableRampStatus.EXCLUDED.name()
                   )
               );
-              LOGGER.info(""Ramp Flow As Excluded Item. [rampid = {}, flowName = {}]"",
-                  rampId, flowName);
+              LOGGER.info(""[Ramp Excluded]. [rampId = {}, flowName = {}]"", rampId, flowName);
               break;
 
             default:
               RampPolicy rampPolicy = rampPolicyManager.buildRampPolicyExecutor(executableRamp.getPolicy(), globalProps);
+              LOGGER.info (""[Ramp Policy Selecting]. [policy = {}, rampId = {}, flowName = {}, executionId = {}, RampPercentageId = {}]"",
+                  rampPolicy.getClass().getName(),
+                  rampId,
+                  flowName,
+                  executableFlow.getExecutionId(),
+                  executableFlow.getRampPercentageId()
+              );
               if (rampPolicy.check(executableFlow, executableRamp)) {
                 // Ramp Enabled
                 executableFlowRampMetadata.setRampProps(
@@ -467,8 +480,7 @@ public class FlowRampManager implements EventListener, ThreadPoolExecutingListen
                         ExecutableRampStatus.SELECTED.name()
                     )
                 );
-                LOGGER.info(""Undetermined Ramp Flow is selected for Ramping. [rampid = {}, flowName = {}]"",
-                    rampId, flowName);
+                LOGGER.info(""[Ramp Policy Selected]. [rampId = {}, flowName = {}]"", rampId, flowName);
               } else {
                 executableFlowRampMetadata.setRampProps(
                     rampId,
@@ -478,8 +490,7 @@ public class FlowRampManager implements EventListener, ThreadPoolExecutingListen
                         ExecutableRampStatus.UNSELECTED.name()
                     )
                 );
-                LOGGER.info(""Undetermined Ramp Flow is not selected for Ramping. [rampid = {}, flowName = {}]"",
-                    rampId, flowName);
+                LOGGER.info(""[Ramp Policy Unselected]. [rampId = {}, flowName = {}]"", rampId, flowName);
               }
               break;
           }
@@ -522,6 +533,10 @@ public class FlowRampManager implements EventListener, ThreadPoolExecutingListen
   private void moveFiles(File sourceDir, File destinationDir, String regExpression) {
     try {
       FileIOUtils.moveFiles(sourceDir, destinationDir, regExpression);
+      LOGGER.info(""Success to move files from {} to {} with REGEXP {}"",
+          sourceDir.getAbsolutePath(),
+          destinationDir.getAbsolutePath(),
+          regExpression);
     } catch (IOException e) {
       LOGGER.error(
           String.format(""Fail to move files from %s to %s with REGEXP %s"",
@@ -575,8 +590,12 @@ public class FlowRampManager implements EventListener, ThreadPoolExecutingListen
             if (!Action.SUCCEEDED.equals(action)) {
               String rampId = executableRamp.getId();
               String flowName =  flowRunner.getExecutableFlow().getFlowName();
-              LOGGER.warn(""Flow will be excluded from ramping. [rampId = {}, flow = {}, action = {}]"",
-                  rampId, rampId, action.name());
+              LOGGER.warn(""[Ramp Exclude Flow]. [executionId = {}, rampId = {}, flowName = {}, action = {}]"",
+                  flowRunner.getExecutableFlow().getExecutionId(),
+                  rampId,
+                  flowName,
+                  action.name()
+              );
               executableRampExceptionalFlowItemsMap.add(rampId, flowName, ExecutableRampStatus.EXCLUDED,
                   System.currentTimeMillis(), true);
             }",Add More Logs to diagnose Dali Pig Ramp by HadoopPigJob ( <issue_id> ) .,"""Enhanced Ramp Policy and Flow Management with Improved Logging and Error Handling""","""Added auto ramp functionality and improved logging for ramp-related operations""","This commit contains several changes to the Azkaban codebase. Here's a summary of the changes:

1. **TimeUtils.java**: Added a new method `daysEscapedOver` to calculate the number of days that have passed since a given reference time.

2. **TimeUtilsTest.java**: Added a new test case `testDayEscapedOver` to test the `daysEscapedOver` method.

3. **HadoopPigJob.java**: Modified the logging messages and error handling in the `getScriptArgs` method.

4. **ExecutableRamp.java**: Modified the `isActive` method to include additional logging.

5. **SimpleAutoRampPolicy.java**: Modified the `preprocess` method to use the new `daysEscapedOver` method from TimeUtils and added error handling.

6. **FlowRampManager.java**: Modified and added logging messages in various methods for better debugging and understanding of the flow.

The commit message could be: ""Added daysEscapedOver method in TimeUtils, updated logging in HadoopPigJob, ExecutableRamp, and FlowRampManager, and improved error handling in SimpleAutoRampPolicy.""","Added daysEscapedOver method, improved logging in HadoopPigJob, and ramp policy changes for better ramp handling and debugging.",Model 3
"diff --git a/github-android/res/layout/issue_view.xml b/github-android/res/layout/issue_view.xml
index e9c2d1e5..e7b08361 100644
--- a/github-android/res/layout/issue_view.xml
+++ b/github-android/res/layout/issue_view.xml
@@ -5,66 +5,60 @@
     android:background=""@color/item_background""
     android:orientation=""vertical"" >
 
+    <TextView
+        android:id=""@+id/tv_issue_number""
+        android:layout_width=""fill_parent""
+        android:layout_height=""wrap_content""
+        android:paddingLeft=""5dp""
+        android:paddingTop=""5dp""
+        android:singleLine=""true""
+        android:textAppearance=""?android:attr/textAppearanceLarge""
+        android:textColor=""@color/item_text_color"" />
+
     <LinearLayout
         android:layout_width=""fill_parent""
         android:layout_height=""wrap_content""
-        android:orientation=""vertical"" >
+        android:orientation=""horizontal""
+        android:paddingBottom=""5dp""
+        android:paddingLeft=""5dp""
+        android:paddingTop=""2dp"" >
 
-        <TextView
-            android:id=""@+id/tv_issue_number""
-            android:layout_width=""fill_parent""
-            android:layout_height=""wrap_content""
-            android:paddingLeft=""5dp""
-            android:paddingTop=""5dp""
-            android:singleLine=""true""
-            android:textAppearance=""?android:attr/textAppearanceLarge""
-            android:textColor=""@color/item_text_color"" />
+        <ImageView
+            android:id=""@+id/iv_gravatar""
+            android:layout_width=""32dp""
+            android:layout_height=""32dp""
+            android:layout_gravity=""center_vertical""
+            android:src=""@drawable/gravatar_icon"" />
 
         <LinearLayout
             android:layout_width=""fill_parent""
             android:layout_height=""wrap_content""
-            android:orientation=""horizontal""
-            android:paddingBottom=""5dp""
-            android:paddingLeft=""5dp""
-            android:paddingTop=""2dp"" >
-
-            <ImageView
-                android:id=""@+id/iv_gravatar""
-                android:layout_width=""32dp""
-                android:layout_height=""32dp""
-                android:layout_gravity=""center_vertical""
-                android:src=""@drawable/gravatar_icon"" />
+            android:orientation=""vertical""
+            android:paddingLeft=""5dp"" >
 
-            <LinearLayout
+            <TextView
+                android:id=""@+id/tv_issue_title""
                 android:layout_width=""fill_parent""
                 android:layout_height=""wrap_content""
-                android:orientation=""vertical""
-                android:paddingLeft=""5dp"" >
+                android:textColor=""@color/item_text_color""
+                android:textStyle=""bold"" />
 
-                <TextView
-                    android:id=""@+id/tv_issue_title""
-                    android:layout_width=""fill_parent""
-                    android:layout_height=""wrap_content""
-                    android:textColor=""@color/item_text_color""
-                    android:textStyle=""bold"" />
-
-                <TextView
-                    android:id=""@+id/tv_issue_creation""
-                    android:layout_width=""fill_parent""
-                    android:layout_height=""wrap_content""
-                    android:paddingTop=""1dp""
-                    android:singleLine=""true""
- ",Remove extra unneeded linear layout,"""Refactor issue view layout to display issue number separately and improve layout structure""","""Refactor issue view layout to include issue number and gravatar icon""

This commit message is concise and accurately describes the changes made in the commit. It mentions the specific changes (issue number and gravatar icon) and the fact that it's a refactor, which implies that the layout has been modified to include these new elements.","This commit refactors the issue_view.xml layout file. It moves the issue number TextView outside of the first LinearLayout and makes that LinearLayout horizontal. Inside this horizontal LinearLayout, it adds an ImageView for the gravatar icon and a vertical LinearLayout for the issue title and creation time TextViews. The issue title TextView is also moved directly into the vertical LinearLayout, and the issue creation TextView is removed. Additionally, some padding attributes are adjusted.","""Rearranged issue view layout: moved issue number outside nested layouts and restructured image and text views for better alignment.""",Model 3
"diff --git a/pmd-java/src/main/java/net/sourceforge/pmd/lang/java/typeresolution/ClassTypeResolver.java b/pmd-java/src/main/java/net/sourceforge/pmd/lang/java/typeresolution/ClassTypeResolver.java
index fc3c297fcc..6c0009ebac 100644
--- a/pmd-java/src/main/java/net/sourceforge/pmd/lang/java/typeresolution/ClassTypeResolver.java
+++ b/pmd-java/src/main/java/net/sourceforge/pmd/lang/java/typeresolution/ClassTypeResolver.java
@@ -51,6 +51,7 @@ import net.sourceforge.pmd.lang.java.ast.ASTImportDeclaration;
 import net.sourceforge.pmd.lang.java.ast.ASTInclusiveOrExpression;
 import net.sourceforge.pmd.lang.java.ast.ASTInstanceOfExpression;
 import net.sourceforge.pmd.lang.java.ast.ASTLiteral;
+import net.sourceforge.pmd.lang.java.ast.ASTLocalVariableDeclaration;
 import net.sourceforge.pmd.lang.java.ast.ASTMarkerAnnotation;
 import net.sourceforge.pmd.lang.java.ast.ASTMethodDeclaration;
 import net.sourceforge.pmd.lang.java.ast.ASTMultiplicativeExpression;
@@ -80,6 +81,7 @@ import net.sourceforge.pmd.lang.java.ast.ASTUnaryExpression;
 import net.sourceforge.pmd.lang.java.ast.ASTUnaryExpressionNotPlusMinus;
 import net.sourceforge.pmd.lang.java.ast.ASTVariableDeclarator;
 import net.sourceforge.pmd.lang.java.ast.ASTVariableDeclaratorId;
+import net.sourceforge.pmd.lang.java.ast.ASTVariableInitializer;
 import net.sourceforge.pmd.lang.java.ast.ASTWildcardBounds;
 import net.sourceforge.pmd.lang.java.ast.AbstractJavaTypeNode;
 import net.sourceforge.pmd.lang.java.ast.JavaNode;
@@ -624,6 +626,22 @@ public class ClassTypeResolver extends JavaParserVisitorAdapter {
         return data;
     }
 
+    @Override
+    public Object visit(ASTLocalVariableDeclaration node, Object data) {
+        super.visit(node, data);
+        // resolve ""var"" types: Upward projection of the type of the initializer expression
+        ASTType type = node.getFirstChildOfType(ASTType.class);
+        if (type.isVarType()) {
+            ASTVariableInitializer initializer = node.getFirstDescendantOfType(ASTVariableInitializer.class);
+            if (initializer.jjtGetChild(0) instanceof ASTExpression) {
+                // only Expression is allowed, ArrayInitializer is not allowed in combination with ""var"".
+                ASTExpression expression = (ASTExpression) initializer.jjtGetChild(0);
+                type.setTypeDefinition(expression.getTypeDefinition());
+            }
+        }
+        return data;
+    }
+
     @Override
     public Object visit(ASTReferenceType node, Object data) {
         super.visit(node, data);
diff --git a/pmd-java/src/test/java/net/sourceforge/pmd/lang/java/ParserTstUtil.java b/pmd-java/src/test/java/net/sourceforge/pmd/lang/java/ParserTstUtil.java
index e64f803c47..f6955f9288 100644
--- a/pmd-java/src/test/java/net/sourceforge/pmd/lang/java/ParserTstUtil.java
+++ b/pmd-java/src/test/java/net/sourceforge/pmd/lang/java/ParserTstUtil.java
@@ -244,4 +244,17 @@ public class ParserTstUtil {
         }
         return source;
     }
+
+    public static ASTCompilationUnit parseAndTypeResolveJava(String javaVersion, String sourceCode) {
+        LanguageVersionHandler languageVersionHandler = getLanguageVersionHandler(javaVersion);
+        ASTCompilationUnit rootNode = (ASTCompilationUnit) languageVersionHandler
+                .getParser(languageVersionHandler.getDefaultParserOptions())
+                    .parse(null, new StringReader(sourceCode));
+        languageVersionHandler.getQualifiedNameResolutionFacade(ParserTstUtil.class.getClassLoader()).start(rootNode);
+        languageVersionHandler.getSymbolFacade().start(rootNode);
+        languageVersionHandler.getDataFlowFacade().start(rootNode);
+        languageVersionHandler.getTypeResolutionFacade(ParserTstUtil.class.getClassLoader()).start(rootNode);
+        languageVersionHandler.getMultifileFacade().start(rootNode);
+        return rootNode;
+    }
 }
diff --git a/pmd-java/src/test/java/net/sourceforge/pmd/lang/java/ast/Java10Test.java b/pmd-java/src/test/java/net/sourceforge/pmd/lang/java/ast/Java10Test.java
index 04c7e983b8..88a76d52b5 100644
--- a/pmd-java/src/test/java/net/sourceforge/pmd/lang/java/ast/Java10Test.java
+++ b/pmd-java/src/test/java/net/sourceforge/pmd/lang/java/ast/Java10Test.java
@@ -8,10 +8,12 @@ import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNull;
+import static org.junit.Assert.assertSame;
 import static org.junit.Assert.assertTrue;
 
 import java.io.IOException;
 import java.nio.charset.StandardCharsets;
+import java.util.ArrayList;
 import java.util.List;
 
 import org.apache.commons.io.IOUtils;
@@ -33,7 +35,9 @@ public class Java10Test {
     @Test
     public void testLocalVarInferenceBeforeJava10() {
         // note, it can be parsed, but we'll have a ReferenceType of ""var""
-        ASTCompilationUnit compilationUnit = ParserTstUtil.parseJava9(loadSource(""LocalVariableTypeInference.java""));
+        ASTCompilationUnit compilationUnit = ParserTstUtil.parseAndTypeResolveJava(""9"",
+                loadSource(""LocalVariableTypeInference.java""));
+
         List<ASTLocalVariableDeclaration> localVars = compilationUnit.findDescendantsOfType(ASTLocalVariableDeclaration.class);
         assertEquals(2, localVars.size());
 
@@ -51,11 +55,19 @@ public class Java10Test {
         assertNull(classType.getType());
         assertNull(type.getType());
         assertFalse(type.isVarType());
+
+        // check the type of the variable initializer's expression
+        ASTExpression initExpression = localVars.get(0)
+                .getFirstChildOfType(ASTVariableDeclarator.class)
+                .getFirstChildOfType(ASTVariableInitializer.class)
+                .getFirstChildOfType(ASTExpression.class);
+        assertSame(""type should be ArrayList"", ArrayList.class, initExpression.getType());
     }
 
     @Test
     public void testLocalVarInferenceCanBeParsedJava10() {
-        ASTCompilationUnit compilationUnit = ParserTstUtil.parseJava10(loadSource(""LocalVariableTypeInference.java""));
+        ASTCompilationUnit compilationUnit = ParserTstUtil.parseAndTypeResolveJava(""10"",
+                loadSource(""LocalVariableTypeInference.java""));
         List<ASTLocalVariableDeclaration> localVars = compilationUnit.findDescendantsOfType(ASTLocalVariableDeclaration.class);
         assertEquals(2, localVars.size());
 
@@ -64,5 +76,6 @@ public class Java10Test {
         assertEquals(""var"", type.getImage());
         assertTrue(type.isVarType());
         assertEquals(0, type.jjtGetNumChildren());
+        assertSame(""type should be ArrayList"", ArrayList.class, type.getType());
     }
 }",Determine type for Local Variable using the initializer \' s expression,"""Support for local variable type inference in Java 10""

This commit message is short and to the point, it clearly states the main feature that was added in this commit.","""Added support for 'var' type inference in Java 10 and above, and updated tests to reflect this change.""","""Add support for resolving 'var' types in ASTLocalVariableDeclaration and a new method parseAndTypeResolveJava in ParserTstUtil""

Explanation:

The commit adds a new method `visit(ASTLocalVariableDeclaration node, Object data)` in `ClassTypeResolver` class to resolve ""var"" types in `ASTLocalVariableDeclaration`. The type of the variable is inferred from the initializer expression, if present.

Additionally, a new method `parseAndTypeResolveJava` is added in `ParserTstUtil` class. This method parses the given Java source code and performs type resolution on the generated AST.

The existing test cases in `Java10Test` are also updated to use the new `parseAndTypeResolveJava` method. The assertions are added to check that the inferred type of the variable is correct.",Enhance Java type resolution to support local variable type inference (`var`) with tests for Java 9 and 10 compatibility.,Model 3
"diff --git a/library/AndroidManifest.xml b/library/AndroidManifest.xml
index 5c0ac56..188f848 100644
--- a/library/AndroidManifest.xml
+++ b/library/AndroidManifest.xml
@@ -1,8 +1,8 @@
 <?xml version=""1.0"" encoding=""utf-8""?>
 <manifest xmlns:android=""http://schemas.android.com/apk/res/android""
     package=""com.nostra13.universalimageloader""
-    android:versionCode=""34""
-    android:versionName=""1.8.6"" >
+    android:versionCode=""35""
+    android:versionName=""1.8.7"" >
 
     <uses-sdk
         android:minSdkVersion=""5""
diff --git a/sample/AndroidManifest.xml b/sample/AndroidManifest.xml
index 304d350..50f9ffb 100644
--- a/sample/AndroidManifest.xml
+++ b/sample/AndroidManifest.xml
@@ -1,8 +1,8 @@
 <?xml version=""1.0"" encoding=""utf-8""?>
 <manifest xmlns:android=""http://schemas.android.com/apk/res/android""
     package=""com.nostra13.example.universalimageloader""
-    android:versionCode=""34""
-    android:versionName=""1.8.6"" >
+    android:versionCode=""35""
+    android:versionName=""1.8.7"" >
 
     <uses-sdk
         android:minSdkVersion=""5""",Prepare Manifests for next version,"""Bump version to 1.8.7""",Bump version to 1.8.7 (versionCode 35),"""Updated version code and version name to 35 and 1.8.7 respectively in AndroidManifest.xml files for library and sample.""",Update version code and name to 35 and 1.8.7 respectively in the AndroidManifest.xml files.,Model 4
"diff --git a/src/main/java/com/google/devtools/build/lib/util/FileType.java b/src/main/java/com/google/devtools/build/lib/util/FileType.java
index 6cfead9578..599851dbbb 100644
--- a/src/main/java/com/google/devtools/build/lib/util/FileType.java
+++ b/src/main/java/com/google/devtools/build/lib/util/FileType.java
@@ -20,6 +20,7 @@ import com.google.common.base.Predicates;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Iterables;
 import com.google.devtools.build.lib.skyframe.serialization.autocodec.AutoCodec;
+import com.google.devtools.build.lib.skyframe.serialization.autocodec.AutoCodec.VisibleForSerialization;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
@@ -27,9 +28,9 @@ import javax.annotation.concurrent.Immutable;
 
 /** A base class for FileType matchers. */
 @Immutable
-@AutoCodec
 public abstract class FileType implements Predicate<String> {
   // A special file type
+  @AutoCodec @VisibleForSerialization
   public static final FileType NO_EXTENSION =
       new FileType() {
         @Override
@@ -40,37 +41,48 @@ public abstract class FileType implements Predicate<String> {
       };
 
   public static FileType of(final String ext) {
-    return new FileType() {
-      @Override
-      public boolean apply(String path) {
-        return path.endsWith(ext);
-      }
-
-      @Override
-      public List<String> getExtensions() {
-        return ImmutableList.of(ext);
-      }
-    };
+    return new ListFileType(ImmutableList.of(ext));
   }
 
-  @AutoCodec.Instantiator
   public static FileType of(final List<String> extensions) {
-    return new FileType() {
-      @Override
-      public boolean apply(String path) {
-        for (String ext : extensions) {
-          if (path.endsWith(ext)) {
-            return true;
-          }
+    return new ListFileType(ImmutableList.copyOf(extensions));
+  }
+
+  @AutoCodec.VisibleForSerialization
+  @AutoCodec
+  static final class ListFileType extends FileType {
+    private final ImmutableList<String> extensions;
+
+    @AutoCodec.VisibleForSerialization
+    ListFileType(ImmutableList<String> extensions) {
+      this.extensions = Preconditions.checkNotNull(extensions);
+    }
+
+    @Override
+    public boolean apply(String path) {
+      for (String ext : extensions) {
+        if (path.endsWith(ext)) {
+          return true;
         }
-        return false;
       }
+      return false;
+    }
 
-      @Override
-      public List<String> getExtensions() {
-        return ImmutableList.copyOf(extensions);
-      }
-    };
+    @Override
+    public List<String> getExtensions() {
+      return ImmutableList.copyOf(extensions);
+    }
+
+    @Override
+    public int hashCode() {
+      return extensions.hashCode();
+    }
+
+    @Override
+    public boolean equals(Object obj) {
+      return (obj instanceof ListFileType
+          && this.extensions.equals(((ListFileType) obj).extensions));
+    }
   }
 
   public static FileType of(final String... extensions) {","Redo FileType @ AutoCodec : it is risky to assume that all subclasses are totally described by their extensions , since many are not .","""Refactor FileType to use a ListFileType subclass for better serialization and code organization""","The commit message should be:

""Add support for serializing FileType instances with multiple extensions""

This commit message accurately reflects the changes made in the diff, which include adding support for serializing FileType instances with multiple extensions, and introducing a new ListFileType class to handle this case.","""Refactor FileType class to use AutoCodec and extract ListFileType""

Explanation:
The provided code diff shows that the FileType class has been refactored to use the AutoCodec library for serialization. A new inner class, ListFileType, has been extracted from the FileType class to handle file types with multiple extensions. The ListFileType class now implements the apply() and getExtensions() methods, and also overrides the hashCode() and equals() methods. Additionally, the of() method in FileType has been updated to return an instance of ListFileType instead of an anonymous inner class.",Refactored FileType class to use a new ListFileType class and added proper serialization with @AutoCodec annotations.,Model 2
"diff --git a/server/src/test/java/org/elasticsearch/cluster/coordination/RareClusterStateIT.java b/server/src/test/java/org/elasticsearch/cluster/coordination/RareClusterStateIT.java
index ccde363fdc5..dc3cd4eb46f 100644
--- a/server/src/test/java/org/elasticsearch/cluster/coordination/RareClusterStateIT.java
+++ b/server/src/test/java/org/elasticsearch/cluster/coordination/RareClusterStateIT.java
@@ -146,7 +146,8 @@ public class RareClusterStateIT extends ESIntegTestCase {
     private <Req extends ActionRequest, Res extends ActionResponse> ActionFuture<Res> executeAndCancelCommittedPublication(
             ActionRequestBuilder<Req, Res> req) throws Exception {
         ActionFuture<Res> future = req.execute();
-        assertBusy(() -> assertTrue(((Coordinator)internalCluster().getMasterNodeInstance(Discovery.class)).cancelCommittedPublication()));
+        assertBusy(
+            () -> assertTrue(((Coordinator)internalCluster().getCurrentMasterNodeInstance(Discovery.class)).cancelCommittedPublication()));
         return future;
     }
 
@@ -276,7 +277,6 @@ public class RareClusterStateIT extends ESIntegTestCase {
         });
     }
 
-    @AwaitsFix(bugUrl=""https://github.com/elastic/elasticsearch/issues/36813"")
     public void testDelayedMappingPropagationOnReplica() throws Exception {
         // This is essentially the same thing as testDelayedMappingPropagationOnPrimary
         // but for replicas",Stabilize RareClusterState ( <issue_id> ) .,"""Fix testDelayedMappingPropagationOnReplica by updating getCurrentMasterNodeInstance and remove @AwaitsFix annotation""","According to the diff, the commit message should be:

""Fix delayed mapping propagation on replica nodes""

This commit message is concise and accurately describes the change made in the code. It also mentions the specific issue being fixed, which is a good practice for commit messages.","It seems like you're working with a Git diff and you've posted a snippet of Java code from Elasticsearch's test suite. The changes made in this diff are:

1. In the `executeAndCancelCommittedPublication` method, the way the current master node instance of the `Discovery` class is retrieved has been updated. Instead of using `getMasterNodeInstance`, `getCurrentMasterNodeInstance` is now used.

2. The `@AwaitsFix` annotation has been removed from the `testDelayedMappingPropagationOnReplica` method. This annotation is typically used to mark tests that are currently failing due to a known bug, providing a link to the bug report. Since it's been removed, it suggests that the bug it was referring to has been fixed.

As for the commit message, it should summarize these changes. Here's an example:

""Update master node retrieval in RareClusterStateIT and remove @AwaitsFix from testDelayedMappingPropagationOnReplica""","The commit message should be:

```
Fix access to the current master node instance in RareClusterStateIT and re-enable delayed mapping propagation test.
```",Model 3
"diff --git a/htroot/CrawlStartExpert_p.html b/htroot/CrawlStartExpert_p.html
index 5baece971..59a7dff61 100644
--- a/htroot/CrawlStartExpert_p.html
+++ b/htroot/CrawlStartExpert_p.html
@@ -310,14 +310,6 @@
             so they can omit starting a crawl with the same start point.
           </td>
         </tr>
-        <tr valign=""top"" class=""TableCellDark"">
-          <td><label for=""xsstopw"">Exclude <em>static</em> Stop-Words</label>:</td>
-          <td><input type=""checkbox"" name=""xsstopw"" id=""xsstopw"" #(xsstopwChecked)#::checked=""checked""#(/xsstopwChecked)# /></td>
-          <td>
-            This can be useful to circumvent that extremely common words are added to the database, i.e. ""the"", ""he"", ""she"", ""it""... To exclude all words given in the file <tt>yacy.stopwords</tt> from indexing,
-            check this box.
-          </td>
-        </tr>
         <tr valign=""top"" class=""TableCellLight"">
           <td><label for=""collection"">Add Crawl result to collection(s)</label>:</td>
           <td>
@@ -327,24 +319,6 @@
             A crawl result can be tagged with names which are candidates for a collection request. These tags can be selected with the <a href=""/gsa/search?q=www&site=#[collection]#"">GSA interface</a> using the 'site' operator. To use this option, the 'collection_sxt'-field must be switched on in the <a href=""/IndexFederated_p.html"">Solr Schema</a>
           </td>
         </tr>
-        <!--
-        <tr valign=""top"" class=""TableCellDark"">
-          <td>Exclude <em>dynamic</em> Stop-Words</td>
-          <td><input type=""checkbox"" name=""xdstopw"" #(xdstopwChecked)#::checked=""checked""#(/xdstopwChecked)# /></td>
-          <td colspan=""3"">
-            Excludes all words from indexing which are listed by statistic rules.
-            <em>THIS IS NOT YET FUNCTIONAL</em>
-          </td>
-        </tr>
-        <tr valign=""top"" class=""TableCellDark"">
-          <td>Exclude <em>parent-indexed</em> words</td>
-          <td><input type=""checkbox"" name=""xpstopw"" #(xpstopwChecked)#::checked=""checked""#(/xpstopwChecked)# /></td>
-          <td colspan=""3"">
-            Excludes all words from indexing which had been indexed in the parent web page.
-            <em>THIS IS NOT YET FUNCTIONAL</em>
-          </td>
-        </tr>
-        -->
         <tr valign=""top"" class=""TableCellSummary"">
           <td colspan=""5""><input type=""submit"" name=""crawlingstart"" value=""Start New Crawl"" class=""submitready""/></td>
         </tr>
diff --git a/htroot/CrawlStartSite_p.html b/htroot/CrawlStartSite_p.html
index 38a83864e..15978b66b 100644
--- a/htroot/CrawlStartSite_p.html
+++ b/htroot/CrawlStartSite_p.html
@@ -101,9 +101,6 @@
         <input type=""hidden"" name=""indexText"" id=""indexText"" value=""on"" />
         <input type=""hidden"" name=""indexMedia"" id=""indexMedia"" value=""on"" />
         <input type=""hidden"" name=""intention"" id=""intention"" value="""" />
-        <input type=""hidden"" name=""xsstopw"" id=""xsstopw"" value=""on"" />
-        <input type=""hidden"" name=""xdstopw"" id=""xdstopw"" value=""off"" />
-        <input type=""hidden"" name=""xpstopw"" id=""xpstopw"" value=""off"" />
         <input type=""hidden"" name=""collection"" id=""collection"" value="""" />
         </dd>
         <dt><label>Start</label></dt>
diff --git a/htroot/Crawler_p.java b/htroot/Crawler_p.java
index 615393757..ee147811f 100644
--- a/htroot/Crawler_p.java
+++ b/htroot/Crawler_p.java
@@ -265,15 +265,6 @@ public class Crawler_p {
                 CacheStrategy cachePolicy = CacheStrategy.parse(post.get(""cachePolicy"", ""iffresh""));
                 if (cachePolicy == null) cachePolicy = CacheStrategy.IFFRESH;
 
-                final boolean xsstopw = ""on"".equals(post.get(""xsstopw"", ""off""));
-                env.setConfig(""xsstopw"", xsstopw);
-
-                final boolean xdstopw = ""on"".equals(post.get(""xdstopw"", ""off""));
-                env.setConfig(""xdstopw"", xdstopw);
-
-                final boolean xpstopw = ""on"".equals(post.get(""xpstopw"", ""off""));
-                env.setConfig(""xpstopw"", xpstopw);
-
                 String crawlingMode = post.get(""crawlingMode"",""url"");
                 
                 if (""file"".equals(crawlingMode) && post.containsKey(""crawlingFile"")) {
@@ -365,9 +356,6 @@ public class Crawler_p {
                         indexMedia,
                         storeHTCache,
                         crawlOrder,
-                        xsstopw,
-                        xdstopw,
-                        xpstopw,
                         cachePolicy,
                         collection);
                 byte[] handle = ASCII.getBytes(profile.handle());
diff --git a/htroot/QuickCrawlLink_p.java b/htroot/QuickCrawlLink_p.java
index 894427fce..18fa543dc 100644
--- a/htroot/QuickCrawlLink_p.java
+++ b/htroot/QuickCrawlLink_p.java
@@ -102,9 +102,6 @@ public class QuickCrawlLink_p {
         final boolean indexMedia     = post.get(""indexMedia"", ""off"").equals(""on"");
         final boolean storeHTCache   = post.get(""storeHTCache"", """").equals(""on"");
         final boolean remoteIndexing = post.get(""crawlOrder"", """").equals(""on"");
-        final boolean xsstopw        = post.get(""xsstopw"", """").equals(""on"");
-        final boolean xdstopw        = post.get(""xdstopw"", """").equals(""on"");
-        final boolean xpstopw        = post.get(""xpstopw"", """").equals(""on"");
         final String collection      = post.get(""collection"", ""user"");
 
         prop.put(""mode_url"", (crawlingStart == null) ? ""unknown"" : crawlingStart);
@@ -151,9 +148,6 @@ public class QuickCrawlLink_p {
                         indexMedia,
                         storeHTCache,
                         remoteIndexing,
-                        xsstopw,
-                        xdstopw,
-                        xpstopw,
                         CacheStrategy.IFFRESH,
                         collection);
                 sb.crawler.putActive(pe.handle().getBytes(), pe);
diff --git a/source/net/yacy/crawler/CrawlSwitchboard.java b/source/net/yacy/crawler/CrawlSwitchboard.java
index a5a3fe7fe..c09072efb 100644
--- a/source/net/yacy/crawler/CrawlSwitchboard.java
+++ b/source/net/yacy/crawler/CrawlSwitchboard.java
@@ -245,9 +245,6 @@ public final class CrawlSwitchboard {
                 true /*getConfigBool(PROXY_INDEXING_LOCAL_MEDIA, true)*/,
                 true,
                 false /*getConfigBool(PROXY_INDEXING_REMOTE, false)*/,
-                true,
-                true,
-                true,
                 CacheStrategy.IFFRESH,
                 ""robot_"" + CRAWL_PROFILE_PROXY);
         this.profilesActiveCrawls.put(
@@ -274,9 +271,6 @@ public final class CrawlSwitchboard {
                 true,
                 false,
                 false,
-                true,
-                true,
-                false,
                 CacheStrategy.IFFRESH,
                 ""robot_"" + CRAWL_PROFILE_REMOTE);
         this.profilesActiveCrawls.put(
@@ -303,9 +297,6 @@ public final class CrawlSwitchboard {
                 false,
                 true,
                 false,
-                true,
-                true,
-                false,
                 CacheStrategy.IFEXIST,
                 ""robot_"" + CRAWL_PROFILE_SNIPPET_LOCAL_TEXT);
         this.profilesActiveCrawls.put(
@@ -332,9 +323,6 @@ public final class CrawlSwitchboard {
                 true,
                 true,
                 false,
-                true,
-                true,
-                false,
                 CacheStrategy.IFEXIST,
                 ""robot_"" + CRAWL_PROFILE_SNIPPET_GLOBAL_TEXT);
         this.profilesActiveCrawls.put(
@@ -362,9 +350,6 @@ public final class CrawlSwitchboard {
             ",removed options for stopwords which are not used,"""Remove unused stop-word exclusion options from crawl configuration""","The commit message should be: 

""Remove Exclude Stop-Words and Parent-Indexed words options from CrawlStartExpert and CrawlStartSite pages""

This commit message accurately reflects the changes made in the code, which involve removing the options for excluding stop-words and parent-indexed words from the CrawlStartExpert and CrawlStartSite pages.","This commit removes the option to exclude static, dynamic, and parent-indexed stop-words from the crawling process in the YaCy search engine. The related HTML code and Java variables have been removed from the CrawlStartExpert\_p.html, CrawlStartSite\_p.html, Crawler\_p.java, QuickCrawlLink\_p.java, and CrawlSwitchboard.java files. Additionally, the hidden input fields for these options have been removed from the CrawlStartSite\_p.html file.","### Commit Message
Remove stop-words handling options from crawl settings and UI.",Model 2
"diff --git a/src/main/java/org/graylog/plugins/netflow/flows/cflow/NetFlowV5Packet.java b/src/main/java/org/graylog/plugins/netflow/flows/cflow/NetFlowV5Packet.java
index 0880e34ec3..f27ef95ccf 100644
--- a/src/main/java/org/graylog/plugins/netflow/flows/cflow/NetFlowV5Packet.java
+++ b/src/main/java/org/graylog/plugins/netflow/flows/cflow/NetFlowV5Packet.java
@@ -7,6 +7,7 @@ import org.graylog.plugins.netflow.flows.FlowException;
 import org.graylog.plugins.netflow.flows.InvalidFlowVersionException;
 import org.graylog.plugins.netflow.utils.UUIDs;
 import org.joda.time.DateTime;
+import org.joda.time.DateTimeZone;
 
 import java.net.InetSocketAddress;
 import java.util.Collection;
@@ -122,7 +123,7 @@ public class NetFlowV5Packet implements NetFlowPacket {
         }
 
         final long uptime = getUnsignedInteger(buf, 4, 4);
-        final DateTime timestamp = new DateTime(getUnsignedInteger(buf, 8, 4) * 1000);
+        final DateTime timestamp = new DateTime(getUnsignedInteger(buf, 8, 4) * 1000, DateTimeZone.UTC);
         final UUID id = UUIDs.startOf(timestamp.getMillis());
         final long flowSequence = getUnsignedInteger(buf, 16, 4);
         final int engineType = (int) getUnsignedInteger(buf, 20, 1);
diff --git a/src/test/java/org/graylog/plugins/netflow/flows/cflow/NetFlowV5PacketTest.java b/src/test/java/org/graylog/plugins/netflow/flows/cflow/NetFlowV5PacketTest.java
index e4be860410..ec604505d4 100644
--- a/src/test/java/org/graylog/plugins/netflow/flows/cflow/NetFlowV5PacketTest.java
+++ b/src/test/java/org/graylog/plugins/netflow/flows/cflow/NetFlowV5PacketTest.java
@@ -12,6 +12,7 @@ import org.junit.Test;
 import java.net.InetSocketAddress;
 import java.net.URL;
 
+import static org.joda.time.DateTimeZone.UTC;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotEquals;
 import static org.junit.Assert.assertNotNull;
@@ -48,8 +49,8 @@ public class NetFlowV5PacketTest {
         assertEquals(0, message1.getField(""nf_dst_mask""));
         assertEquals(6, message1.getField(""nf_proto""));
         assertEquals(16, message1.getField(""nf_tcp_flags""));
-        assertEquals(new DateTime(""2015-06-21T13:40:51.914+02:00""), message1.getField(""nf_start""));
-        assertEquals(new DateTime(""2015-05-02T18:38:07.196Z""), message1.getField(""nf_stop""));
+        assertEquals(new DateTime(""2015-06-21T13:40:51.914+02:00"", UTC), message1.getField(""nf_start""));
+        assertEquals(new DateTime(""2015-05-02T18:38:07.196Z"", UTC), message1.getField(""nf_stop""));
         assertEquals(230L, message1.getField(""nf_bytes""));
         assertEquals(5L, message1.getField(""nf_pkts""));
 
@@ -67,8 +68,8 @@ public class NetFlowV5PacketTest {
         assertEquals(0, message2.getField(""nf_dst_mask""));
         assertEquals(6, message2.getField(""nf_proto""));
         assertEquals(24, message2.getField(""nf_tcp_flags""));
-        assertEquals(new DateTime(""2015-06-21T13:40:51.914+02:00""), message2.getField(""nf_start""));
-        assertEquals(new DateTime(""2015-05-02T18:38:07.196Z""), message2.getField(""nf_stop""));
+        assertEquals(new DateTime(""2015-06-21T13:40:51.914+02:00"", UTC), message2.getField(""nf_start""));
+        assertEquals(new DateTime(""2015-05-02T18:38:07.196Z"", UTC), message2.getField(""nf_stop""));
         assertEquals(304L, message2.getField(""nf_bytes""));
         assertEquals(4L, message2.getField(""nf_pkts""));
     }",Ensure UTC for new DateTime objects .,"""Specify DateTimeZone.UTC when creating DateTime objects in NetFlowV5Packet""","""Add support for UTC timezone in NetFlowV5Packet and tests""","""Update NetFlowV5Packet to use UTC time zone for timestamps and fix timestamp comparisons in NetFlowV5PacketTest""

This commit makes the following changes:

* In NetFlowV5Packet, it updates the creation of the `timestamp` variable to use the UTC time zone instead of the system default time zone. This ensures that the timestamp is always interpreted consistently, regardless of the time zone of the system running the code.
* In NetFlowV5PacketTest, it adds a static import for `org.joda.time.DateTimeZone.UTC` and updates the creation of the expected `DateTime` objects to use the UTC time zone. This ensures that the timestamps are compared correctly in the test case.

Overall, this commit improves the reliability and consistency of the NetFlow V5 packet processing code by ensuring that timestamps are always interpreted and compared in UTC.","""Set NetFlowV5Packet timestamps to UTC and update tests to ensure consistent timezone handling.""",Model 2
"diff --git a/core/src/main/java/org/apache/calcite/runtime/CalciteResource.java b/core/src/main/java/org/apache/calcite/runtime/CalciteResource.java
index a9129696c..5cb45dc13 100644
--- a/core/src/main/java/org/apache/calcite/runtime/CalciteResource.java
+++ b/core/src/main/java/org/apache/calcite/runtime/CalciteResource.java
@@ -670,31 +670,34 @@ ExInst<CalciteException> illegalArgumentForTableFunctionCall(String a0,
   ExInst<SqlValidatorException> auxiliaryWithoutMatchingGroupCall(String func1, String func2);
 
   @BaseMessage(""Pattern variable ''{0}'' has already been defined"")
-  ExInst<SqlValidatorException> PatternVarAlreadyDefined(String varName);
+  ExInst<SqlValidatorException> patternVarAlreadyDefined(String varName);
 
   @BaseMessage(""Cannot use PREV/NEXT in MEASURE ''{0}''"")
-  ExInst<SqlValidatorException> PatternPrevFunctionInMeasure(String call);
+  ExInst<SqlValidatorException> patternPrevFunctionInMeasure(String call);
 
   @BaseMessage(""Cannot nest PREV/NEXT under LAST/FIRST ''{0}''"")
-  ExInst<SqlValidatorException> PatternPrevFunctionOrder(String call);
+  ExInst<SqlValidatorException> patternPrevFunctionOrder(String call);
 
   @BaseMessage(""Cannot use aggregation in navigation ''{0}''"")
-  ExInst<SqlValidatorException> PatternAggregationInNavigation(String call);
+  ExInst<SqlValidatorException> patternAggregationInNavigation(String call);
 
   @BaseMessage(""Invalid number of parameters to COUNT method"")
-  ExInst<SqlValidatorException> PatternCountFunctionArg();
+  ExInst<SqlValidatorException> patternCountFunctionArg();
 
   @BaseMessage(""Cannot use RUNNING/FINAL in DEFINE ''{0}''"")
-  ExInst<SqlValidatorException> PatternRunningFunctionInDefine(String call);
+  ExInst<SqlValidatorException> patternRunningFunctionInDefine(String call);
 
   @BaseMessage(""Multiple pattern variables in ''{0}''"")
-  ExInst<SqlValidatorException> PatternFunctionVariableCheck(String call);
+  ExInst<SqlValidatorException> patternFunctionVariableCheck(String call);
 
   @BaseMessage(""Function ''{0}'' can only be used in MATCH_RECOGNIZE"")
-  ExInst<SqlValidatorException> FunctionMatchRecognizeOnly(String call);
+  ExInst<SqlValidatorException> functionMatchRecognizeOnly(String call);
 
   @BaseMessage(""Null parameters in ''{0}''"")
-  ExInst<SqlValidatorException> PatternFunctionNullCheck(String call);
+  ExInst<SqlValidatorException> patternFunctionNullCheck(String call);
+
+  @BaseMessage(""Unknown pattern ''{0}''"")
+  ExInst<SqlValidatorException> unknownPattern(String call);
 }
 
 // End CalciteResource.java
diff --git a/core/src/main/java/org/apache/calcite/sql/validate/MatchRecognizeScope.java b/core/src/main/java/org/apache/calcite/sql/validate/MatchRecognizeScope.java
index c0be246ac..1b6741cd6 100644
--- a/core/src/main/java/org/apache/calcite/sql/validate/MatchRecognizeScope.java
+++ b/core/src/main/java/org/apache/calcite/sql/validate/MatchRecognizeScope.java
@@ -21,12 +21,12 @@
 import org.apache.calcite.sql.SqlMatchRecognize;
 import org.apache.calcite.sql.SqlNode;
 
-import com.google.common.collect.Sets;
-
 import java.util.HashMap;
+import java.util.LinkedHashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
+import java.util.TreeSet;
 
 /**
  * Scope for expressions in a {@code MATCH_RECOGNIZE} clause.
@@ -38,14 +38,17 @@ public class MatchRecognizeScope extends ListScope {
 
   //~ Instance fields ---------------------------------------------
   private final SqlMatchRecognize matchRecognize;
-  private Set<String> patternVars;
+  private final Set<String> patternVars;
 
   /** Creates a MatchRecognizeScope. */
   public MatchRecognizeScope(SqlValidatorScope parent,
       SqlMatchRecognize matchRecognize) {
     super(parent);
     this.matchRecognize = matchRecognize;
-    patternVars = Sets.newHashSet(STAR);
+    patternVars = validator.getCatalogReader().nameMatcher().isCaseSensitive()
+        ? new LinkedHashSet<String>()
+        : new TreeSet<>(String.CASE_INSENSITIVE_ORDER);
+    patternVars.add(STAR);
   }
 
   @Override public SqlNode getNode() {
diff --git a/core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorImpl.java b/core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorImpl.java
index c458aabaf..28c4047d6 100644
--- a/core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorImpl.java
+++ b/core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorImpl.java
@@ -4473,6 +4473,17 @@ public void validateWindow(
 
     validateDefinitions(matchRecognize, scope);
 
+    // validate AFTER ... SKIP TO
+    final SqlNode skipTo = matchRecognize.getAfter();
+    if (skipTo instanceof SqlCall) {
+      final SqlCall skipToCall = (SqlCall) skipTo;
+      final SqlIdentifier id = skipToCall.operand(0);
+      if (!scope.getPatternVars().contains(id.getSimple())) {
+        throw newValidationError(id,
+            RESOURCE.unknownPattern(id.getSimple()));
+      }
+    }
+
     List<Map.Entry<String, RelDataType>> fields =
         validateMeasure(matchRecognize, scope);
     final RelDataType rowType = typeFactory.createStructType(fields);
@@ -4537,12 +4548,14 @@ private SqlNode navigationInMeasure(SqlNode node) {
 
   private void validateDefinitions(SqlMatchRecognize mr,
       MatchRecognizeScope scope) {
-    final Set<String> aliases = new HashSet<>();
+    final Set<String> aliases = catalogReader.nameMatcher().isCaseSensitive()
+        ? new LinkedHashSet<String>()
+        : new TreeSet<>(String.CASE_INSENSITIVE_ORDER);
     for (SqlNode item : mr.getPatternDefList().getList()) {
       final String alias = alias(item);
       if (!aliases.add(alias)) {
         throw newValidationError(item,
-            Static.RESOURCE.PatternVarAlreadyDefined(alias));
+            Static.RESOURCE.patternVarAlreadyDefined(alias));
       }
       scope.addPatternVar(alias);
     }
@@ -4655,7 +4668,7 @@ public void validateCall(
             == SqlFunctionCategory.MATCH_RECOGNIZE
         && !(operandScope instanceof MatchRecognizeScope)) {
       throw newValidationError(call,
-          Static.RESOURCE.FunctionMatchRecognizeOnly(call.toString()));
+          Static.RESOURCE.functionMatchRecognizeOnly(call.toString()));
     }
     // Delegate validation to the operator.
     operator.validateCall(call, this, scope, operandScope);
@@ -5417,28 +5430,28 @@ private class PatternValidator extends SqlBasicVisitor<Set<String>> {
         if (isPhysicalNavigation(kind)) {
           if (isMeasure) {
             throw newValidationError(call,
-                Static.RESOURCE.PatternPrevFunctionInMeasure(call.toString()));
+                Static.RESOURCE.patternPrevFunctionInMeasure(call.toString()));
           }
           if (firstLastCount != 0) {
             throw newValidationError(call,
-                Static.RESOURCE.PatternPrevFunctionOrder(call.toString()));
+                Static.RESOURCE.patternPrevFunctionOrder(call.toString()));
           }
           prevNextCount++;
         } else if (isLogicalNavigation(kind)) {
           if (firstLastCount != 0) {
             throw newValidationError(call,
-                Static.RESOURCE.PatternPrevFunctionOrder(call.toString()));
+                Static.RESOURCE.patternPrevFunctionOrder(call.toString()));
           }
           firstLastCount++;
         } else if (isAggregation(kind)) {
           // cannot apply aggregation in PREV/NEXT, FIRST/LAST
           if (firstLastCount != 0 || prevNextCount != 0) {
             throw newValidationError(call,
-                Static.RESOURCE.PatternAggregationInNavigation(call.toString()));
+                Static.RESOURCE.patternAggregationInNavigation(call.toString()));
           }
           if (kind == SqlKind.COUNT && call.getOperandList().size() > 1) {
             throw newValidationError(call,
-                Static.RESOURCE.PatternCountFunctionArg());
+                Static.RESOURCE.patternCountFunctionArg());
           }
           aggregateCount++;
         }
@@ -5446,7 +5459,7 @@ private class PatternValidator extends SqlBasicVisitor<Set<String>> {
 
       if (isRunningOrFinal(kind) && !isMeasure) {
         throw newValidationError(call,
-            Static.RESOURCE.PatternRunningFunctionInDefine(call.toString()));
+            Static.RESOURCE.patternRunningFunctionInDefine(call.toString()));
       }
 
       for (SqlNode node : operands) {
@@ -5461,17 +5474,17 @@ private class PatternValidator extends SqlBasicVisitor<Set<String>> {
         case COUNT:
           if (vars.size() > 1) {
             throw newValidationError(call,
-                Static.RESOURCE.PatternCountFunctionArg());
+                Static.RESOURCE.patternCountFunctionArg());
           }
           break;
         default:
           if (vars.isEmpty()) {
             throw newValidationError(call,
-              Static.RESOURCE.PatternFunctionNullCheck(call.toString()));
+              Static.RESOURCE.patternFunctionNullCheck(call.toString()));
           }
           if (vars.size() != 1) {
             throw newValidationError(call,
-                Static.RESOURCE.PatternFunctionVariableCheck(call.toString()));
+                Static.RESOURCE.patternFunctionVariableCheck(call.toString()));
           }
           break;
         }
diff --git a/core/src/main/resources/org/apache/calcite/runtime/CalciteResource.properties b/core/src/main/resources/org/apache/calcite/runtime/CalciteResource.properties
index 45a9b70d4..0006022d5 100644
--- a/core/src/main/resources/org/apache/calcite/runtime/CalciteResource.properties
+++ b/core/src/main/resources/org/apache/calcite/runtime/CalciteResource.properties
@@ -226,4 +226,5 @@ PatternRunningFunctionInDefine=Cannot use RUNNING/FINAL in DEFINE ''{0}''
 PatternFunctionVariableCheck=Multiple pattern variables in ''{0}''
 FunctionMatchRecognizeOnly=Function ''{0}'' can only be used in MATCH_RECOGNIZE
 PatternFunctionNullCheck=Null parameters in ''{0}''
+UnknownPattern=Unknown pattern ''{0}''
 # End CalciteResource.properties
diff --git a/core/src/test/java/org/apache/calcite/test/SqlValidatorMatchTest.java b/core/src/test/java/org/apache/calcite/test/SqlValidatorMatchTest.java
index 144c43c9c..c0fca1c81 100644
--- a/core/src/test/java/org/apache/calcite/test/SqlValidatorMatchTest.java
+++ b/core/src/test/java/org/apache/calcite/test/SqlValidatorMatchTest.java
@@ -159,6 +159,42 @@ public class SqlValidatorMatchTest extends SqlValidatorTestCase {
         .fails(""(?s).*Encountered \""measures\"" at .*"");
   }
 
+  @Test public void testMatchRecognizeSkipTo3() throws Exception {
+    final String sql = ""select *\n""
+        + ""from emp match_recognize (\n""
+        + ""  measures\n""
+        + ""    STRT.sal as start_sal,\n""
+        + ""    LAST(up.sal) as end_sal\n""
+        + ""    after match skip to ^no_exists^\n""
+        + ""    pattern (strt down+ up+)\n""
+        + ""    define\n""
+        + ""      down as down.sal < PREV(down.sal),\n""
+        + ""      up as up.sal > prev(up.sal)\n""
+        + ""  ) mr"";
+    sql(sql)
+        .fails(""Unknown pattern 'NO_EXISTS'"");
+  }
+
+  @Test public void testMatchRecognizeSkipToCaseInsensitive() throws Exception {
+    final String sql = ""select *\n""
+        + ""from emp match_recognize (\n""
+        + ""  measures\n""
+        + ""    STRT.sal as start_sal,\n""
+        + ""    LAST(up.sal) as end_sal\n""
+        + ""    after match skip to ^\""strt\""^\n""
+        + ""    pattern (strt down+ up+)\n""
+        + ""    define\n""
+        + ""      down as down.sal < PREV(down.sal),\n""
+        + ""      up as up.sal > prev(up.sal)\n""
+        + ""  ) mr"";
+    sql(sql)
+        .fails(""Unknown pattern 'strt'"");
+    sql(sql)
+        .tester(tester.withCaseSensitive(false))
+        .sansCarets()
+        .ok();
+  }
+
 }
 
 // End SqlValidatorMatchTest.java
diff --git a/core/src/test/java/org/apache/calcite/test/SqlValidatorTestCase.java b/core/src/test/java/org/apache/calcite/test/SqlValidatorTestCase.java
index 025de3aa7..cc66e3f3e 100644
--- a/core/src/test/java/org/apache/calcite/test/SqlValidatorTestCase.java
+++ b/core/src/test/java/org/apache/calcite/test/SqlValidatorTestCase.java
@@ -580,6 +580,10 @@ public void checkParameters(RelDataType parameterRowType) {
           SqlTests.ANY_RESULT_CHECKER);
       return this;
     }
+
+    public Sql sansCarets() {
+      return new Sql(tester, sql.replace(""^"", """"));
+    }
   }
 }
 
diff --git a/core/src/test/java/org/apache/calcite/util/UtilTest.java b/core/src/test/java/org/apache/calcite/util/UtilTest.java
index 2f48d64c7..34b61d662 100644
--- a/core/src/test/java/org/apache/calcite/util/UtilTest.java
+++ b/core/src/test/java/org/apache/calcite/util/UtilTest.java
@@ -51,6 +51,7 @@
 import java.io.UnsupportedEncodingException;
 import java.lang.management.MemoryType;
 import java.lang.reflect.Method;
+import java.lang.reflect.Modifier;
 import java.math.BigDecimal;
 import java.sql.Timestamp;
 import java.text.MessageFormat;
@@ -1498,6 +1499,16 @@ public List<String> list(String... xs) {
 
   @Test public void testResources() {
     Resources.validate(Static.RESOURCE);
+    checkResourceMethodNames(Static.RESOURCE);
+  }
+
+  private void checkResourceMethodNames(Object resource) {
+    for (Method method : resource.getClass().getMethods()) {
+      if (!Modifier.isStatic(method.getModifiers())
+          && !method.getName().matches(""^[a-z][A-Za-z0-9_]*$"")) {
+        fail(""resource method name must be camel case: "" + method.getName());
+      }
+    }
   }
 
   /** Tests that sorted sets behave the way we expect. */",Validate pattern name in AFTER . . .,"""Improve MATCH_RECOGNIZE validation and resource naming conventions""","""Add support for case-insensitive pattern matching in MATCH_RECOGNIZE and introduce new error messages for unknown patterns and invalid skip to clauses.""","""Update CalciteResource.java, MatchRecognizeScope.java, SqlValidatorImpl.java, and related test files to add support for validating pattern variables in MATCH_RECOGNIZE clause and fix naming conventions for resource method names.""

Explanation:

The commit includes several changes to the Calcite codebase related to the validation of pattern variables in the MATCH\_RECOGNIZE clause of SQL queries. Specifically, it adds a new method `unknownPattern()` to the `CalciteResource` class, which is used to throw an exception when an unknown pattern variable is encountered during validation.

Additionally, the commit updates the `MatchRecognizeScope` class to use a `LinkedHashSet` or `TreeSet` instead of a `HashSet` to store pattern variables, depending on whether the catalog reader is case sensitive or not. This ensures that the order of pattern variables is preserved during validation.

The `SqlValidatorImpl` class is also updated to validate the `AFTER ... SKIP TO` clause of the MATCH\_RECOGNIZE statement and throw an exception if an unknown pattern variable is encountered.

Finally, the commit includes changes to related test files to test the new functionality and ensure that it works as expected. It also fixes naming conventions for resource method names in the `CalciteResource` class to follow camel case.","""Add validation for unknown patterns in MATCH_RECOGNIZE and implement case sensitivity enhancements in pattern variable handling.""",Model 1
"diff --git a/presto-docs/src/main/sphinx/connector/hive.rst b/presto-docs/src/main/sphinx/connector/hive.rst
index 6c0f6da148..3670bf370e 100644
--- a/presto-docs/src/main/sphinx/connector/hive.rst
+++ b/presto-docs/src/main/sphinx/connector/hive.rst
@@ -114,14 +114,9 @@ Hive Configuration Properties
 ================================================== ============================================================ ============
 Property Name                                      Description                                                  Default
 ================================================== ============================================================ ============
-``hive.metastore.uri``                             The URI(s) of the Hive metastore to connect to using the
-                                                   Thrift protocol. If multiple URIs are provided, the first
-                                                   URI is used by default and the rest of the URIs are
-                                                   fallback metastores. This property is required.
-                                                   Example: ``thrift://192.0.2.3:9083`` or
-                                                   ``thrift://192.0.2.3:9083,thrift://192.0.2.4:9083``
-
-``hive.metastore.username``                        The username Presto will use to access the Hive metastore.
+``hive.metastore``                                 The type of Hive metastore to use. Presto currently supports ``thrift``
+                                                   the default Hive Thrift metastore (``thrift``), and the AWS
+                                                   Glue Catalog (``glue``) as metadata sources.
 
 ``hive.config.resources``                          An optional comma-separated list of HDFS
                                                    configuration files. These files must exist on the
@@ -152,16 +147,6 @@ Property Name                                      Description
 
 ``hive.max-partitions-per-scan``                   Maximum number of partitions for a single table scan.        100,000
 
-``hive.metastore.authentication.type``             Hive metastore authentication type.                          ``NONE``
-                                                   Possible values are ``NONE`` or ``KERBEROS``.
-
-``hive.metastore.service.principal``               The Kerberos principal of the Hive metastore service.
-
-``hive.metastore.client.principal``                The Kerberos principal that Presto will use when connecting
-                                                   to the Hive metastore service.
-
-``hive.metastore.client.keytab``                   Hive metastore client keytab location.
-
 ``hive.hdfs.authentication.type``                  HDFS authentication type.                                    ``NONE``
                                                    Possible values are ``NONE`` or ``KERBEROS``.
 
@@ -191,6 +176,65 @@ Property Name                                      Description
                                                    :ref:`s3selectpushdown`.
 ================================================== ============================================================ ============
 
+Hive Thrift Metastore Configuration Properties
+----------------------------------------------
+
+================================================== ============================================================
+Property Name                                      Description
+================================================== ============================================================
+``hive.metastore.uri``                             The URI(s) of the Hive metastore to connect to using the
+                                                   Thrift protocol. If multiple URIs are provided, the first
+                                                   URI is used by default and the rest of the URIs are
+                                                   fallback metastores. This property is required.
+                                                   Example: ``thrift://192.0.2.3:9083`` or
+                                                   ``thrift://192.0.2.3:9083,thrift://192.0.2.4:9083``
+
+``hive.metastore.username``                        The username Presto will use to access the Hive metastore.
+
+``hive.metastore.authentication.type``             Hive metastore authentication type.
+                                                   Possible values are ``NONE`` or ``KERBEROS``
+                                                   (defaults to ``NONE``).
+
+``hive.metastore.service.principal``               The Kerberos principal of the Hive metastore service.
+
+``hive.metastore.client.principal``                The Kerberos principal that Presto will use when connecting
+                                                   to the Hive metastore service.
+
+``hive.metastore.client.keytab``                   Hive metastore client keytab location.
+================================================== ============================================================
+
+AWS Glue Catalog Configuration Properties
+-----------------------------------------
+
+==================================================== ============================================================
+Property Name                                        Description
+==================================================== ============================================================
+``hive.metastore.glue.region``                       AWS region of the Glue Catalog. This is required when not
+                                                     running in EC2, or when the catalog is in a different region.
+                                                     Example: ``us-east-1``
+
+``hive.metastore.glue.pin-client-to-current-region`` Pin Glue requests to the same region as the EC2 instance
+                                                     where Presto is running (defaults to ``false``).
+
+``hive.metastore.glue.max-connections``              Max number of concurrent connections to Glue
+                                                     (defaults to ``5``).
+
+``hive.metastore.glue.default-warehouse-dir``        Hive Glue metastore default warehouse directory
+
+``hive.metastore.glue.aws-access-key``               AWS access key to use to connect to the Glue Catalog. If
+                               ",Add documentation for Glue Catalog support in Hive,"""Refactor Hive connector configuration properties to support multiple metastore types""","""Added support for AWS Glue Catalog as a Hive metastore option and updated documentation for Thrift metastore configuration properties.""","""Refactor Hive configuration properties into separate sections for Thrift metastore and AWS Glue Catalog""","""Reorganized Hive connector docs; added configuration properties for Hive Thrift and AWS Glue metastores.""",Model 1
"diff --git a/library/core/src/main/java/com/google/android/exoplayer2/mediacodec/MediaCodecRenderer.java b/library/core/src/main/java/com/google/android/exoplayer2/mediacodec/MediaCodecRenderer.java
index d965b662be..ef7d691c5b 100644
--- a/library/core/src/main/java/com/google/android/exoplayer2/mediacodec/MediaCodecRenderer.java
+++ b/library/core/src/main/java/com/google/android/exoplayer2/mediacodec/MediaCodecRenderer.java
@@ -1141,8 +1141,9 @@ public abstract class MediaCodecRenderer extends BaseRenderer {
    * @return The mode specifying when the adaptation workaround should be enabled.
    */
   private @AdaptationWorkaroundMode int codecAdaptationWorkaroundMode(String name) {
-    if (Util.SDK_INT <= 24 && ""OMX.Exynos.avc.dec.secure"".equals(name)
-        && (Util.MODEL.startsWith(""SM-T585"") || Util.MODEL.startsWith(""SM-A520""))) {
+    if (Util.SDK_INT <= 25 && ""OMX.Exynos.avc.dec.secure"".equals(name)
+        && (Util.MODEL.startsWith(""SM-T585"") || Util.MODEL.startsWith(""SM-A510"")
+        || Util.MODEL.startsWith(""SM-A520"") || Util.MODEL.startsWith(""SM-J700""))) {
       return ADAPTATION_WORKAROUND_MODE_ALWAYS;
     } else if (Util.SDK_INT < 24
         && (""OMX.Nvidia.h264.decode"".equals(name) || ""OMX.Nvidia.h264.decode.secure"".equals(name))",Broaden Samsung workaround to API level 25 + J7 .,"""Update codec adaptation workaround mode for Exynos and Nvidia devices""","""Update MediaCodecRenderer to support additional Samsung models for adaptation workaround.""","""Update codec adaptation workaround mode for specific devices and SDK versions""

Explanation:
The provided diff shows changes in the `codecAdaptationWorkaroundMode` method of the `MediaCodecRenderer` class. Specifically, it modifies the conditions for enabling the adaptation workaround based on the device model and SDK version. The changes include:

1. Extending the SDK version check from `<= 24` to `<= 25`.
2. Adding two more device models (`SM-A510` and `SM-J700`) to the list of devices that require the adaptation workaround.

Based on these changes, an appropriate commit message could be: ""Update codec adaptation workaround mode for specific devices and SDK versions"". This message briefly describes the purpose and scope of the changes in the given diff.","Expanded codec adaptation workaround for Exynos devices: added SM-A510 and SM-J700, raised SDK_INT limit to 25.",Model 1
"diff --git a/examples/transactions_distributed/initiator.bal b/examples/transactions_distributed/initiator.bal
index 8aba5efd01f..b8d7ce36a10 100644
--- a/examples/transactions_distributed/initiator.bal
+++ b/examples/transactions_distributed/initiator.bal
@@ -46,11 +46,11 @@ service<http:Service> InitiatorService bind {port: 8080} {
 }
 
 function printAbort(string transactionId) {
-    log:printInfo(""Transaction: "" + transactionId + "" aborted"");
+    log:printInfo(""Initiated transaction: "" + transactionId + "" aborted"");
 }
 
 function printCommit(string transactionId) {
-    log:printInfo(""Transaction: "" + transactionId + "" committed"");
+    log:printInfo(""Initiated transaction: "" + transactionId + "" committed"");
 }
 
 function callBusinessService() returns boolean {
diff --git a/examples/transactions_distributed/participant.bal b/examples/transactions_distributed/participant.bal
index fdcae6d5e61..fddaacff24b 100644
--- a/examples/transactions_distributed/participant.bal
+++ b/examples/transactions_distributed/participant.bal
@@ -19,7 +19,7 @@ service<http:Service> ParticipantService bind {port: 8889} {
 
         // At the beginning of the transaction statement, since a transaction context has been received, this service
         // will register with the initiator as a participant.
-        transaction {
+        transaction with oncommit = printParticipantCommit, onabort = printParticipantAbort {
             var updateReq = untaint req.getJsonPayload();
             match updateReq{
                 json updateReqJson => {
@@ -46,3 +46,11 @@ service<http:Service> ParticipantService bind {port: 8889} {
         }
     }
 }
+
+function printParticipantAbort(string transactionId) {
+    log:printInfo(""Participated transaction: "" + transactionId + "" aborted"");
+}
+
+function printParticipantCommit(string transactionId) {
+    log:printInfo(""Participated transaction: "" + transactionId + "" committed"");
+}
diff --git a/examples/transactions_distributed/transactions_distributed.out b/examples/transactions_distributed/transactions_distributed.out
index 505297235a2..c6371934413 100644
--- a/examples/transactions_distributed/transactions_distributed.out
+++ b/examples/transactions_distributed/transactions_distributed.out
@@ -16,26 +16,27 @@ $ curl -v localhost:8080
 
 Output from initiator:
 
-2018-04-23 23:42:53,992 INFO  [] - Initiating transaction...
-2018-04-23 23:42:54,009 INFO  [ballerina.transactions] - Created transaction: 29d99da9-9998-4b0b-b5e4-6ea031f4a245
-2018-04-23 23:42:54,011 INFO  [] - Started transaction: 29d99da9-9998-4b0b-b5e4-6ea031f4a245:1
-2018-04-23 23:42:54,591 INFO  [ballerina.transactions] - Registered remote participant: 962f02e7-908f-4f5d-b72a-4897119f824a:1 for transaction: 29d99da9-9998-4b0b-b5e4-6ea031f4a245
-2018-04-23 23:42:54,645 INFO  [] - Got response from bizservice
-2018-04-23 23:42:54,647 INFO  [ballerina.transactions] - Running 2-phase commit for transaction: 29d99da9-9998-4b0b-b5e4-6ea031f4a245:1
-2018-04-23 23:42:54,652 INFO  [ballerina.transactions] - Preparing remote participant: 962f02e7-908f-4f5d-b72a-4897119f824a:1
-2018-04-23 23:42:54,670 INFO  [ballerina.transactions] - Remote participant: 962f02e7-908f-4f5d-b72a-4897119f824a:1 prepared
-2018-04-23 23:42:54,671 INFO  [ballerina.transactions] - Notify(commit) remote participant: http://192.168.1.4:60142/balcoordinator/participant/2pc/1
-2018-04-23 23:42:54,678 INFO  [ballerina.transactions] - Remote participant: 962f02e7-908f-4f5d-b72a-4897119f824a:1 committed
-2018-04-23 23:42:54,679 INFO  [] - Transaction: 29d99da9-9998-4b0b-b5e4-6ea031f4a245:1 committed
-2018-04-23 23:42:54,682 INFO  [] - Sent response back to client
+2018-04-24 00:07:09,112 INFO  [] - Initiating transaction...
+2018-04-24 00:07:09,130 INFO  [ballerina.transactions] - Created transaction: 45936431-ae9e-43e0-bc54-4ab7769734da
+2018-04-24 00:07:09,131 INFO  [] - Started transaction: 45936431-ae9e-43e0-bc54-4ab7769734da:1
+2018-04-24 00:07:09,724 INFO  [ballerina.transactions] - Registered remote participant: facb8e2e-dc82-4fd0-bd0f-c7e80369e423:1 for transaction: 45936431-ae9e-43e0-bc54-4ab7769734da
+2018-04-24 00:07:09,779 INFO  [] - Got response from bizservice
+2018-04-24 00:07:09,781 INFO  [ballerina.transactions] - Running 2-phase commit for transaction: 45936431-ae9e-43e0-bc54-4ab7769734da:1
+2018-04-24 00:07:09,785 INFO  [ballerina.transactions] - Preparing remote participant: facb8e2e-dc82-4fd0-bd0f-c7e80369e423:1
+2018-04-24 00:07:09,801 INFO  [ballerina.transactions] - Remote participant: facb8e2e-dc82-4fd0-bd0f-c7e80369e423:1 prepared
+2018-04-24 00:07:09,804 INFO  [ballerina.transactions] - Notify(commit) remote participant: http://192.168.1.4:60366/balcoordinator/participant/2pc/1
+2018-04-24 00:07:09,814 INFO  [ballerina.transactions] - Remote participant: facb8e2e-dc82-4fd0-bd0f-c7e80369e423:1 committed
+2018-04-24 00:07:09,815 INFO  [] - Initiated transaction: 45936431-ae9e-43e0-bc54-4ab7769734da:1 committed
+2018-04-24 00:07:09,818 INFO  [] - Sent response back to client
 
 Output from participant:
 
-2018-04-23 23:42:54,316 INFO  [] - Received update stockquote request
-2018-04-23 23:42:54,336 INFO  [ballerina.transactions] - Registering for transaction: 29d99da9-9998-4b0b-b5e4-6ea031f4a245:1 with coordinator: http://192.168.1.4:60137/balcoordinator/initiator/1/register
-2018-04-23 23:42:54,607 INFO  [ballerina.transactions] - Registered with coordinator for transaction: 29d99da9-9998-4b0b-b5e4-6ea031f4a245
-2018-04-23 23:42:54,609 INFO  [] - Update stock quote request received. symbol:GOOG, price:244.95873638912178
-2018-04-23 23:42:54,643 INFO  [] - Sent response back to initiator
-2018-04-23 23:42:54,662 INFO  [ballerina.transactions] - Prepare received for transaction: 29d99da9-9998-4b0b-b5e4-6ea031f4a245:1
-2018-04-23 23:42:54,663 INFO  [ballerina.transactions] - Prepared transaction: 29d99da9-9998-4b0b-b5e4-6ea031f4a245
-2018-04-23 23:42:54,675 INFO  [ballerina.transactions] - Notify(commit) received for transaction: 29d99da9-9998-4b0b-b5e4-6ea031f4a245:1
+2018-04-24 00:07:09,433 INFO  [] - Received update stockquote request
+2018-04-24 00:07:09,458 INFO  [ballerina.transactions] - Registering for transaction: 45936431-ae9e-43e0-bc54-4ab7769734da:1 with coordinator: http://192.168.1.4:60365/balcoordinator/initiator/1/register
+2018-04-24 00:07:09,743 INFO  [ballerina.transactions] - Registered with coordinator for transaction: 45936431-ae9e-43e0-bc54-4ab7769734da
+2018-04-24 00:07:09,746 INFO  [] - Update stock quote request received. symbol:GOOG, price:206.76007974989048
+2018-04-24 00:07:09,777 INFO  [] - Sent response back to initiator
+2018-04-24 00:07:09,794 INFO  [ballerina.transactions] - Prepare received for transaction: 45936431-ae9e-43e0-bc54-4ab7769734da:1
+2018-04-24 00:07:09,795 INFO  [ballerina.transactions] - Prepared transaction: 45936431-ae9e-43e0-bc54-4ab7769734da
+2018-04-24 00:07:09,809 INFO  [ballerina.transactions] - Notify(commit) received for transaction: 45936431-ae9e-43e0-bc54-4ab7769734da:1
+2018-04-24 00:07:09,810 INFO  [] - Participated transaction: 45936431-ae9e-43e0-bc54-4ab7769734da:1 committed",Add transaction commit / abort functions for participant,"""Enhanced transaction logging for distributed transactions""","""Improved logging in transactions_distributed example to include initiator and participant context""","""Initiated transaction: 45936431-ae9e-43e0-bc54-4ab7769734da:1 committed"" instead of ""Participated transaction: 45936431-ae9e-43e0-bc54-4ab7769734da:1 committed"".

This is because the commit message is being printed by the initiator service, not the participant service. Therefore, it should indicate that the transaction initiated by this service has been committed, not that it participated in a transaction.

The same correction should be applied to the abort message.",Updated log messages for transaction initiation and participation to improve clarity and context in initiator and participant services.,Model 3
"diff --git a/README.md b/README.md
index 5e234e1468d..52fe84b4987 100644
--- a/README.md
+++ b/README.md
@@ -34,8 +34,6 @@ For Unix/Linux
 
 The command line will display the URL you can use to access the Composer in your browser.
 
-For complete instructions on creating your integrations and using the Composer, see the [Ballerina documentation](http://ballerinalang.org/docs/user-guide/0.8/quick-tour/#run-the-composer).
-
 ## How to build
 The build process of the composer works on Maven and Node Package Manager(npm).
 ",Removed broken url in read me,"""Remove outdated documentation link from README""","""Removed unnecessary Ballerina documentation link from README.md""","""Removed reference to Ballerina documentation link in README.md""","""Remove outdated link to Ballerina documentation from the README file.""",Model 1
"diff --git a/skywalking-sniffer/skywalking-toolkit-activation/skywalking-toolkit-opentracing-activation/src/main/java/com/a/eye/skywalking/toolkit/activation/opentracing/span/interceptor/SpanSetTagInterceptor.java b/skywalking-sniffer/skywalking-toolkit-activation/skywalking-toolkit-opentracing-activation/src/main/java/com/a/eye/skywalking/toolkit/activation/opentracing/span/interceptor/SpanSetTagInterceptor.java
index 6be7711856..2eaec73a53 100644
--- a/skywalking-sniffer/skywalking-toolkit-activation/skywalking-toolkit-opentracing-activation/src/main/java/com/a/eye/skywalking/toolkit/activation/opentracing/span/interceptor/SpanSetTagInterceptor.java
+++ b/skywalking-sniffer/skywalking-toolkit-activation/skywalking-toolkit-opentracing-activation/src/main/java/com/a/eye/skywalking/toolkit/activation/opentracing/span/interceptor/SpanSetTagInterceptor.java
@@ -54,13 +54,12 @@ public class SpanSetTagInterceptor implements InstanceMethodsAroundInterceptor {
     }
 
     /**
-     * Check current tag is peer tag.
+     * Check whether current tag is one of {@link Tags#PEER_HOSTNAME}, {@link Tags#PEER_HOST_IPV4} and {@link Tags#PEER_HOST_IPV6}.
+     * If yes, will use the {@link com.a.eye.skywalking.trace.tag.Tags#PEER_HOST} as the key, instead of original key,
+     * in {@link #adaptTag(String)}.
      *
-     * Skywalking put the tag value of {@link Tags#PEER_HOSTNAME}, {@link Tags#PEER_HOST_IPV4} and
-     * {@link Tags#PEER_HOST_IPV6} into {@link com.a.eye.skywalking.trace.tag.Tags#PEER_HOST} which
-     * facilitate analysis.
-     *
-     * @param key tag key
+     * @param key of current tag
+     * @return true if this tag is a host related.
      */
     private boolean isPeerTag(String key) {
         return Tags.PEER_HOST_IPV4.equals(key) || Tags.PEER_HOST_IPV6.equals(key) || Tags.PEER_HOSTNAME.equals(key);",modify Java doc to improve readable,"""Refactor SpanSetTagInterceptor to correctly handle peer host tags""",Refine `isPeerTag` method to check for host related tags and use `Tags#PEER_HOST` as the key when adapting tags.,"""Refactor SpanSetTagInterceptor to clarify the purpose of isPeerTag method and its usage in adaptTag method""

Explanation:
The code change in this diff is primarily focused on improving the clarity and readability of the `isPeerTag` method and its usage in the `adaptTag` method in the `SpanSetTagInterceptor` class.

1. The method comment for `isPeerTag` has been updated to better explain its purpose. It now clearly states that the method checks whether the current tag is one of `Tags#PEER_HOSTNAME`, `Tags#PEER_HOST_IPV4`, or `Tags#PEER_HOST_IPV6`. If yes, it will use the `com.a.eye.skywalking.trace.tag.Tags#PEER_HOST` as the key, instead of the original key, in the `adaptTag` method.

2. The method comment for `adaptTag` has been updated to include a reference to the `isPeerTag` method, making it clear that the `isPeerTag` method is used within the `adaptTag` method.

3. The return type comment for `isPeerTag` has been added to clearly state that the method returns true if the tag is a host related.

These changes improve the code readability and make it easier for other developers to understand the purpose and usage of the `isPeerTag` method.",Update JavaDoc in SpanSetTagInterceptor to clarify peer tag handling.,Model 3
"diff --git a/src/main/java/org/jabref/gui/fieldeditors/FieldEditors.java b/src/main/java/org/jabref/gui/fieldeditors/FieldEditors.java
index f1f588faca..d44cb882aa 100644
--- a/src/main/java/org/jabref/gui/fieldeditors/FieldEditors.java
+++ b/src/main/java/org/jabref/gui/fieldeditors/FieldEditors.java
@@ -90,14 +90,12 @@ public class FieldEditors {
             return new PersonsEditor(field, suggestionProvider, preferences, fieldCheckers, isSingleLine);
         } else if (StandardField.KEYWORDS.equals(field)) {
             return new KeywordsEditor(field, suggestionProvider, fieldCheckers, preferences);
-        } else if (fieldProperties.contains(FieldProperty.MULTILINE_TEXT)) {
-            return new MultilineEditor(field, suggestionProvider, fieldCheckers, preferences);
         } else if (field == InternalField.KEY_FIELD) {
             return new BibtexKeyEditor(field, preferences, suggestionProvider, fieldCheckers, databaseContext, undoManager, dialogService);
+        } else {
+            // default
+            return new SimpleEditor(field, suggestionProvider, fieldCheckers, preferences, isSingleLine);
         }
-
-        // default
-        return new SimpleEditor(field, suggestionProvider, fieldCheckers, preferences, isSingleLine);
     }
 
     @SuppressWarnings(""unchecked"")
diff --git a/src/main/java/org/jabref/gui/fieldeditors/MultilineEditor.java b/src/main/java/org/jabref/gui/fieldeditors/MultilineEditor.java
deleted file mode 100644
index ac1323c973..0000000000
--- a/src/main/java/org/jabref/gui/fieldeditors/MultilineEditor.java
+++ /dev/null
@@ -1,18 +0,0 @@
-package org.jabref.gui.fieldeditors;
-
-import org.jabref.gui.autocompleter.AutoCompleteSuggestionProvider;
-import org.jabref.logic.integrity.FieldCheckers;
-import org.jabref.model.entry.field.Field;
-import org.jabref.preferences.JabRefPreferences;
-
-public class MultilineEditor extends SimpleEditor implements FieldEditorFX {
-
-    public MultilineEditor(Field field, AutoCompleteSuggestionProvider<?> suggestionProvider, FieldCheckers fieldCheckers, JabRefPreferences preferences) {
-        super(field, suggestionProvider, fieldCheckers, preferences);
-    }
-
-    @Override
-    public double getWeight() {
-        return 4;
-    }
-}
diff --git a/src/main/java/org/jabref/model/entry/field/FieldFactory.java b/src/main/java/org/jabref/model/entry/field/FieldFactory.java
index 8c41d8f210..a5086283f6 100644
--- a/src/main/java/org/jabref/model/entry/field/FieldFactory.java
+++ b/src/main/java/org/jabref/model/entry/field/FieldFactory.java
@@ -139,7 +139,13 @@ public class FieldFactory {
         return defaultGeneralFields;
     }
 
+    // TODO: Move somewhere more appropriate and make user-configurable
     public static boolean isSingleLineField(final Field field) {
-        return !field.getProperties().contains(FieldProperty.MULTILINE_TEXT);
+        if (field.equals(StandardField.ABSTRACT) || field.equals(StandardField.COMMENT)) {
+            return false;
+        }
+
+        // Treat unknown fields as multi-line fields
+        return !(field instanceof UnknownField);
     }
 }
diff --git a/src/main/java/org/jabref/model/entry/field/FieldProperty.java b/src/main/java/org/jabref/model/entry/field/FieldProperty.java
index c774c6880e..df6603868b 100644
--- a/src/main/java/org/jabref/model/entry/field/FieldProperty.java
+++ b/src/main/java/org/jabref/model/entry/field/FieldProperty.java
@@ -13,7 +13,6 @@ public enum FieldProperty {
     JOURNAL_NAME,
     LANGUAGE,
     MONTH,
-    MULTILINE_TEXT,
     MULTIPLE_ENTRY_LINK,
     NUMERIC,
     PAGES,
diff --git a/src/main/java/org/jabref/model/entry/field/StandardField.java b/src/main/java/org/jabref/model/entry/field/StandardField.java
index 6acf86dfbc..2b3c7ebf53 100644
--- a/src/main/java/org/jabref/model/entry/field/StandardField.java
+++ b/src/main/java/org/jabref/model/entry/field/StandardField.java
@@ -11,7 +11,7 @@ import java.util.Set;
  */
 public enum StandardField implements Field {
 
-    ABSTRACT(""abstract"", FieldProperty.MULTILINE_TEXT),
+    ABSTRACT(""abstract""),
     ADDENDUM(""addendum""),
     ADDRESS(""address""),
     AFTERWORD(""afterword"", FieldProperty.PERSON_NAMES),
@@ -28,7 +28,7 @@ public enum StandardField implements Field {
     BOOKTITLEADDON(""booktitleaddon""),
     CHAPTER(""chapter""),
     COMMENTATOR(""commentator"", FieldProperty.PERSON_NAMES),
-    COMMENT(""comment"", FieldProperty.MULTILINE_TEXT),
+    COMMENT(""comment""),
     CROSSREF(""crossref"", FieldProperty.SINGLE_ENTRY_LINK),
     DATE(""date"", FieldProperty.DATE),
     DAY(""day""),",Treat unknown fields as multi - line fields ( <issue_id> ) .,"""Remove MultilineEditor and replace with SimpleEditor for non-multiline fields""","""Remove MultilineEditor and simplify field editor selection logic""

This commit message accurately summarizes the changes made in the commit, which include removing the MultilineEditor class and simplifying the logic for selecting field editors in the FieldEditors class.","""Remove MultilineEditor and FieldProperty.MULTILINE_TEXT, and update FieldFactory and StandardField accordingly""

Explanation:

* The file `MultilineEditor.java` has been deleted.
* In `FieldEditors.java`, the condition for creating a `MultilineEditor` has been removed, and the default behavior is now to create a `SimpleEditor`.
* In `FieldFactory.java`, the method `isSingleLineField()` has been updated to treat unknown fields as multi-line fields and return false for the fields `StandardField.ABSTRACT` and `StandardField.COMMENT`.
* In `FieldProperty.java`, the enum value `FieldProperty.MULTILINE_TEXT` has been removed.
* In `StandardField.java`, the `FieldProperty.MULTILINE_TEXT` property has been removed from the `ABSTRACT` and `COMMENT` fields.

This commit seems to be related to removing the special handling of multiline fields and treating them as simple fields instead. The `FieldFactory.isSingleLineField()` method now checks for specific fields and treats unknown fields as multi-line fields, instead of relying on the `FieldProperty.MULTILINE_TEXT` property. The `MultilineEditor` class has been removed, and the default behavior in `FieldEditors.java` is now to create a `SimpleEditor`.",Refactor FieldEditors to remove MultilineEditor class and handle multiline fields in isSingleLineField logic.,Model 4
"diff --git a/documentation/src/docs/asciidoc/user-guide/writing-tests.adoc b/documentation/src/docs/asciidoc/user-guide/writing-tests.adoc
index 133a7a62a4..0b134cc721 100644
--- a/documentation/src/docs/asciidoc/user-guide/writing-tests.adoc
+++ b/documentation/src/docs/asciidoc/user-guide/writing-tests.adoc
@@ -27,20 +27,21 @@ module.
 | `@TestTemplate`          | Denotes that a method is a <<writing-tests-test-templates, template for test cases>> designed to be invoked multiple times depending on the number of invocation contexts returned by the registered <<extensions-test-templates, providers>>. Such methods are _inherited_ unless they are _overridden_.
 | `@TestMethodOrder`       | Used to configure the <<writing-tests-test-execution-order, test method execution order>> for the annotated test class; similar to JUnit 4's `@FixMethodOrder`. Such annotations are _inherited_.
 | `@TestInstance`          | Used to configure the <<writing-tests-test-instance-lifecycle, test instance lifecycle>> for the annotated test class. Such annotations are _inherited_.
-| `@DisplayName`           | Declares a custom display name for the test class or test method. Such annotations are not _inherited_.
-| `@DisplayNameGeneration` | Declares a custom display name generator for the test class. Such annotations are _inherited_.
+| `@DisplayName`           | Declares a custom <<writing-tests-display-names,display name>> for the test class or test method. Such annotations are not _inherited_.
+| `@DisplayNameGeneration` | Declares a custom <<writing-tests-display-name-generator,display name generator>> for the test class. Such annotations are _inherited_.
 | `@BeforeEach`            | Denotes that the annotated method should be executed _before_ *each* `@Test`, `@RepeatedTest`, `@ParameterizedTest`, or `@TestFactory` method in the current class; analogous to JUnit 4's `@Before`. Such methods are _inherited_ unless they are _overridden_.
 | `@AfterEach`             | Denotes that the annotated method should be executed _after_ *each* `@Test`, `@RepeatedTest`, `@ParameterizedTest`, or `@TestFactory` method in the current class; analogous to JUnit 4's `@After`. Such methods are _inherited_ unless they are _overridden_.
 | `@BeforeAll`             | Denotes that the annotated method should be executed _before_ *all* `@Test`, `@RepeatedTest`, `@ParameterizedTest`, and `@TestFactory` methods in the current class; analogous to JUnit 4's `@BeforeClass`. Such methods are _inherited_ (unless they are _hidden_ or _overridden_) and must be `static` (unless the ""per-class"" <<writing-tests-test-instance-lifecycle, test instance lifecycle>> is used).
 | `@AfterAll`              | Denotes that the annotated method should be executed _after_ *all* `@Test`, `@RepeatedTest`, `@ParameterizedTest`, and `@TestFactory` methods in the current class; analogous to JUnit 4's `@AfterClass`. Such methods are _inherited_ (unless they are _hidden_ or _overridden_) and must be `static` (unless the ""per-class"" <<writing-tests-test-instance-lifecycle, test instance lifecycle>> is used).
-| `@Nested`                | Denotes that the annotated class is a nested, non-static test class. `@BeforeAll` and `@AfterAll` methods cannot be used directly in a `@Nested` test class unless the ""per-class"" <<writing-tests-test-instance-lifecycle, test instance lifecycle>> is used. Such annotations are not _inherited_.
-| `@Tag`                   | Used to declare _tags_ for filtering tests, either at the class or method level; analogous to test groups in TestNG or Categories in JUnit 4. Such annotations are _inherited_ at the class level but not at the method level.
-| `@Disabled`              | Used to _disable_ a test class or test method; analogous to JUnit 4's `@Ignore`. Such annotations are not _inherited_.
-| `@ExtendWith`            | Used to register custom <<extensions,extensions>>. Such annotations are _inherited_.
+| `@Nested`                | Denotes that the annotated class is a non-static <<writing-tests-nested,nested test class>>. `@BeforeAll` and `@AfterAll` methods cannot be used directly in a `@Nested` test class unless the ""per-class"" <<writing-tests-test-instance-lifecycle, test instance lifecycle>> is used. Such annotations are not _inherited_.
+| `@Tag`                   | Used to declare <<writing-tests-tagging-and-filtering,tags for filtering tests>>, either at the class or method level; analogous to test groups in TestNG or Categories in JUnit 4. Such annotations are _inherited_ at the class level but not at the method level.
+| `@Disabled`              | Used to <<writing-tests-disabling,disable>> a test class or test method; analogous to JUnit 4's `@Ignore`. Such annotations are not _inherited_.
+| `@ExtendWith`            | Used to <<extensions-registration-declarative,register extensions declaratively>>. Such annotations are _inherited_.
+| `@RegisterExtension`     | Used to <<extensions-registration-programmatic,register extensions programmatically>> via fields. Such fields are _inherited_ unless they are _shadowed_.
 |===
 
-Methods annotated with `@Test`, `@TestTemplate`, `@RepeatedTest`, `@BeforeAll`,
-`@AfterAll`, `@BeforeEach`, or `@AfterEach` annotations must not return a value.
+Any method annotated with `@Test`, `@TestTemplate`, `@RepeatedTest`, `@ParameterizedTest`,
+`@BeforeAll`, `@AfterAll`, `@BeforeEach`, or `@AfterEach` must not return a value.
 
 WARNING: Some annotations may currently be _experimental_. Consult the table in
 <<api-evolution-experimental-apis>> for details.
@@ -65,9 +66,10 @@ include::{testDir}/example/Fast.java[tags=user_guide]
 [[writing-tests-classes-and-methods]]
 === Test Classes and Methods
 
-A _test method_ is any instance method that is directly or meta-annotated with `@Test`,
-`@RepeatedTest`, `@ParameterizedTest`, `@TestFactory`, or `@TestTemplate`. A _test class_
-is any top level or static member class that contains at least one test method.
+A _test method_ is any instance method that is directly annotated or meta-annotated with
+`@Test`, `@RepeatedTest`, `@ParameterizedTest`, `@TestFactory`, or `@TestTemplate`. A
+_test class_ is any top-level or `static` member class that contains at least one _test
+method_.
 
 [source,java,indent=0]
 .A standard test class",Add cross - references to Annotations section of User Guide .,"""Update documentation for writing tests to include links to related sections""","""Update documentation for JUnit 5 annotations and test classes""","The commit message could be:

Update user guide: Improve documentation for JUnit 5 test annotations

Changes include:

* Adding links to relevant sections for `@DisplayName` and `@DisplayNameGeneration` annotations.
* Changing the description for `@Nested` annotation and adding a link to the section on nested test classes.
* Adding a link to the section on tagging and filtering tests for the `@Tag` annotation.
* Adding a link to the section on disabling tests for the `@Disabled` annotation.
* Adding a link to the section on registering extensions for the `@ExtendWith` annotation.
* Adding a new row for the `@RegisterExtension` annotation and linking to the section on registering extensions programmatically.
* Clarifying that methods annotated with `@ParameterizedTest` must not return a value, in addition to the other test methods.
* Adding a note that some annotations may be experimental and linking to the section on experimental APIs.
* Changing the description for test methods and test classes to include `@ParameterizedTest` and `@TestFactory` annotations.","Updated documentation for JUnit annotations, adding more inline links for clarity and expanding on annotations details.",Model 1
"diff --git a/compiler/src/it/multiple-scopes/invoker.properties b/compiler/src/it/multiple-scopes/invoker.properties
deleted file mode 100644
index fdd3d204..00000000
--- a/compiler/src/it/multiple-scopes/invoker.properties
+++ /dev/null
@@ -1 +0,0 @@
-invoker.buildResult=failure
diff --git a/compiler/src/it/multiple-scopes/pom.xml b/compiler/src/it/multiple-scopes/pom.xml
deleted file mode 100644
index a45735a2..00000000
--- a/compiler/src/it/multiple-scopes/pom.xml
+++ /dev/null
@@ -1,51 +0,0 @@
-<?xml version=""1.0"" encoding=""UTF-8""?>
-<!--
-  Copyright (C) 2013 Google, Inc.
-  Copyright (C) 2013 Square, Inc.
-
-  Licensed under the Apache License, Version 2.0 (the ""License"");
-  you may not use this file except in compliance with the License.
-  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an ""AS IS"" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
--->
-<project
-    xmlns=""http://maven.apache.org/POM/4.0.0""
-    xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
-    xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"">
-  <modelVersion>4.0.0</modelVersion>
-  <groupId>com.example.dagger.tests</groupId>
-  <artifactId>multiple-scopes</artifactId>
-  <version>HEAD-SNAPSHOT</version>
-  <dependencies>
-    <dependency>
-      <groupId>@dagger.groupId@</groupId>
-      <artifactId>dagger</artifactId>
-      <version>@dagger.version@</version>
-    </dependency>
-    <dependency>
-      <groupId>@dagger.groupId@</groupId>
-      <artifactId>dagger-compiler</artifactId>
-      <version>@dagger.version@</version>
-      <optional>true</optional>
-    </dependency>
-  </dependencies>
-  <build>
-    <plugins>
-      <plugin>
-        <artifactId>maven-compiler-plugin</artifactId>
-        <version>3.1</version>
-        <configuration>
-          <source>1.5</source>
-          <target>1.5</target>
-        </configuration>
-      </plugin>
-    </plugins>
-  </build>
-</project>
diff --git a/compiler/src/it/multiple-scopes/src/main/java/test/TestApp.java b/compiler/src/it/multiple-scopes/src/main/java/test/TestApp.java
deleted file mode 100644
index 06b36a6d..00000000
--- a/compiler/src/it/multiple-scopes/src/main/java/test/TestApp.java
+++ /dev/null
@@ -1,51 +0,0 @@
-/*
- * Copyright (C) 2013 Google, Inc.
- * Copyright (C) 2013 Square, Inc.
- *
- * Licensed under the Apache License, Version 2.0 (the ""License"");
- * you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package test;
-
-import dagger.Module;
-import dagger.Provides;
-import java.lang.annotation.Retention;
-import javax.inject.Inject;
-import javax.inject.Scope;
-import javax.inject.Singleton;
-
-import static java.lang.annotation.RetentionPolicy.RUNTIME;;
-
-class TestApp {
-
-  @Singleton
-  @CustomScope
-  static class InjectableClass {
-    @Inject
-    String string;
-  }
-
-  @Module(injects = InjectableClass.class)
-  static class TestModule {
-    @Singleton
-    @CustomScope
-    @Provides
-    String string() {
-      return ""string"";
-    }
-  }
-
-  @Scope
-  @Retention(value = RUNTIME)
-  public @interface CustomScope {
-  }
-}
diff --git a/compiler/src/it/multiple-scopes/verify.bsh b/compiler/src/it/multiple-scopes/verify.bsh
deleted file mode 100644
index 78491d57..00000000
--- a/compiler/src/it/multiple-scopes/verify.bsh
+++ /dev/null
@@ -1,8 +0,0 @@
-import dagger.testing.it.BuildLogValidator;
-import java.io.File;
-
-File buildLog = new File(basedir, ""build.log"");
-new BuildLogValidator().assertHasText(buildLog, new String[]{
-    ""Only one scoping annotation is allowed per element: test.TestApp.InjectableClass""});
-new BuildLogValidator().assertHasText(buildLog, new String[]{
-    ""Only one scoping annotation is allowed per element: test.TestApp.TestModule.string()""});
diff --git a/compiler/src/test/java/dagger/tests/integration/validation/ScopeAnnotationUseTest.java b/compiler/src/test/java/dagger/tests/integration/validation/ScopeAnnotationUseTest.java
index 2ac52ef0..88d4ff5f 100644
--- a/compiler/src/test/java/dagger/tests/integration/validation/ScopeAnnotationUseTest.java
+++ b/compiler/src/test/java/dagger/tests/integration/validation/ScopeAnnotationUseTest.java
@@ -24,7 +24,9 @@ import org.junit.runner.RunWith;
 import org.junit.runners.JUnit4;
 
 import static com.google.testing.compile.JavaSourceSubjectFactory.javaSource;
+import static com.google.testing.compile.JavaSourcesSubjectFactory.javaSources;
 import static dagger.tests.integration.ProcessorTestUtils.daggerProcessors;
+import static java.util.Arrays.asList;
 import static org.truth0.Truth.ASSERT;
 
 /**
@@ -103,6 +105,38 @@ public class ScopeAnnotationUseTest {
         .withErrorContaining(""intParam"").in(sourceFile).onLine(7).atColumn(49);
   }
 
+  @Test public void compileFailsWithMultipleScopeAnnotations() {
+    JavaFileObject annotation = JavaFileObjects.forSourceString(""MyScope"", Joiner.on(""\n"").join(
+        ""import java.lang.annotation.Retention;"",
+        ""import javax.inject.Scope;"",
+        ""import static java.lang.annotation.RetentionPolicy.RUNTIME;"",
+        ""@Scope @Retention(RUNTIME) public @interface MyScope { }""));
+
+    JavaFileObject module = JavaFileObjects.forSourceString(""MyModule"", Joiner.on(""\n"").join(
+        ""import dagger.Module;"",
+        ""import dagger.Provides;"",
+        ""import javax.inject.Singleton;"",
+        ""@Module(library = true, injects = Injectable.class)"",
+        ""class MyModule {"",
+        ""  @Provides @Singleton @MyScope String method() { return \""\""; }"",
+        ""}""));
+
+    JavaFileObject injectable = JavaFileObjects.forSourceString(""Test"", Joiner.on(""\n"").join(
+        ""import javax.inject.Inject;"",
+        ""import javax.inject.Singleton;"",
+        ""@Singleton @MyScope"",
+        ""class Injectable {"",
+        ""  @Inject String string;"",
+        ""}""));
+
+    String error = ""Only one scoping annotation is allowed per element: "";
+
+    ASSERT.about(javaSources()).that(asList(annotation, module, injectable))
+        .processedWith(daggerProcessors()).failsToCompile()
+        .withErrorContaining(error + ""MyModule.method()"").in(module).onLine(6).atColumn(40).and()
+        .withErrorContaining(error + ""Injectable"").in(injectable).onLine(4).atColumn(1);
+  }
+
   @Test public void compileFailsWithScopeOnConstructor() {
     JavaFileObject sourceFile = JavaFileObjects.forSourceString(""Test"", Joiner.on(""\n"").join(
         ""import dagger.Module;"",",Move more scope tests into compile - testing style tests .,Remove integration test for multiple scopes and update ScopeAnnotationUseTest.,"Remove tests for multiple scope annotations and unused test code.

Or, in a more concise format:

Remove unused test code and multiple scope annotation tests.","This commit removes the multiple-scopes integration test for Dagger compiler. The test checks if using multiple scope annotations on a single element results in a compilation failure. The test includes the following files:

* invoker.properties: contains the build result property, which is set to 'failure' in this case.
* pom.xml: the Maven project configuration file for the test.
* TestApp.java: the Java source code for the test, which includes a class with multiple scope annotations, a module, and a custom scope annotation.
* verify.bsh: a Beanshell script that checks the build log for error messages related to multiple scope annotations.

The commit also adds a new test method `compileFailsWithMultipleScopeAnnotations()` to the `ScopeAnnotationUseTest` class in the `compiler/src/test/java/dagger/tests/integration/validation` directory. This test checks if using multiple scope annotations on a single element results in a compilation failure. The test uses the Google Truth library for assertions and the Dagger processor test utilities for processing the Java source code with the Dagger compiler. The test includes the following Java source files:

* MyScope.java: a custom scope annotation.
* MyModule.java: a Dagger module with a method that has multiple scope annotations.
* Test.java: a class with multiple scope annotations.

The test checks that the compilation fails with error messages indicating that only one scoping annotation is allowed per element. The error messages are expected to appear in the build log for the corresponding source files and lines of code.","Remove multiple-scopes integration test and associated files, and add unit test for multiple scope annotations error checking.",Model 2
"diff --git a/logback-core/src/main/java/ch/qos/logback/core/util/TimeUtil.java b/logback-core/src/main/java/ch/qos/logback/core/util/TimeUtil.java
index 71e7703c4..030e0623f 100644
--- a/logback-core/src/main/java/ch/qos/logback/core/util/TimeUtil.java
+++ b/logback-core/src/main/java/ch/qos/logback/core/util/TimeUtil.java
@@ -5,7 +5,16 @@ import java.util.Date;
 
 public class TimeUtil {
 
-  static long computeStartOfNextDay(long now) {
+  
+  public static long computeStartOfNextSecond(long now) {
+    Calendar cal = Calendar.getInstance();
+    cal.setTime(new Date(now));
+    cal.set(Calendar.MILLISECOND, 0);
+    cal.add(Calendar.SECOND, 1);
+    return cal.getTime().getTime();
+  }
+  
+  public static long computeStartOfNextDay(long now) {
     Calendar cal = Calendar.getInstance();
     cal.setTime(new Date(now));
 
@@ -17,7 +26,7 @@ public class TimeUtil {
     return cal.getTime().getTime();
   }
   
-  static long computeStartOfNextWeek(long now) {
+  public static long computeStartOfNextWeek(long now) {
     Calendar cal = Calendar.getInstance();
     cal.setTime(new Date(now));
     
@@ -30,7 +39,7 @@ public class TimeUtil {
     return cal.getTime().getTime();
   }
 
-  static long computeStartOfNextMonth(long now) {
+  public static long computeStartOfNextMonth(long now) {
     Calendar cal = Calendar.getInstance();
     cal.setTime(new Date(now));
 
diff --git a/logback-core/src/test/java/ch/qos/logback/core/util/TimeUtilTest.java b/logback-core/src/test/java/ch/qos/logback/core/util/TimeUtilTest.java
index f4053f572..ed3293b2c 100644
--- a/logback-core/src/test/java/ch/qos/logback/core/util/TimeUtilTest.java
+++ b/logback-core/src/test/java/ch/qos/logback/core/util/TimeUtilTest.java
@@ -19,6 +19,15 @@ public class TimeUtilTest extends TestCase {
     super.tearDown();
   }
 
+  public void testSecond() {
+    // Mon Nov 20 18:05:17,522 CET 2006
+    long now = 1164042317522L;
+    // Mon Nov 20 18:06:00,000 CET 2006
+    long expected = 1164042318000L;
+    long computed = TimeUtil.computeStartOfNextSecond(now);
+    assertEquals(expected - now, 478); 
+    assertEquals(expected, computed);
+  }
   
   public void testDay() {
     // Mon Nov 20 18:05:17 CET 2006",added support for computing seconds,"""Added computeStartOfNextSecond method to TimeUtil and updated method visibility to public""","""Refactor TimeUtil to compute start of next second, day, and month correctly""","""Added new method computeStartOfNextSecond and updated method modifiers to public in TimeUtil.java, and added a new test case testSecond in TimeUtilTest.java.""",Added computeStartOfNextSecond method and its unit test to TimeUtil class for calculating the start of the next second.,Model 3
"diff --git a/azure-pipelines.yml b/azure-pipelines.yml
index 6403e38f7..affb9146f 100644
--- a/azure-pipelines.yml
+++ b/azure-pipelines.yml
@@ -155,7 +155,7 @@ steps:
       maven
     path: $(MAVEN_CACHE_FOLDER)
   displayName: Cache Maven local repo
-  condition: eq(variables.SKIP_CACHE, 'false')
+  condition: ne(variables.SKIP_CACHE, 'true')
 
 - bash: |
     set -e","skip azure cache only if explicitly defined ; not defined is expanded : eq ( \' \' , \' false \' )","""Update cache condition to skip only when SKIP_CACHE is true""","""Update Azure Pipelines to cache Maven local repo conditionally""","Updated Azure Pipelines YML condition for caching Maven local repo

 The condition in the Azure Pipelines YML file for caching the Maven local repository has been changed from `eq(variables.SKIP_CACHE, 'false')` to `ne(variables.SKIP_CACHE, 'true')`. This means that the caching step will now run if the `SKIP_CACHE` variable is not set to `true`, rather than only running if it is set to `false`.",Fix cache condition in azure-pipelines.yml to use 'ne' for SKIP_CACHE check.,Model 4
"diff --git a/src/main/java/com/alibaba/fastjson/serializer/SerializeWriter.java b/src/main/java/com/alibaba/fastjson/serializer/SerializeWriter.java
index 7747d281c..32278fcbb 100644
--- a/src/main/java/com/alibaba/fastjson/serializer/SerializeWriter.java
+++ b/src/main/java/com/alibaba/fastjson/serializer/SerializeWriter.java
@@ -641,7 +641,7 @@ public final class SerializeWriter extends Writer {
         if (text == null) {
             writeNull();
             if (seperator != 0) {
-            	write(seperator);
+                write(seperator);
             }
             return;
         }
@@ -755,6 +755,7 @@ public final class SerializeWriter extends Writer {
 
         int specialCount = 0;
         int lastSpecialIndex = -1;
+        int firstSpecialIndex = -1;
         char lastSpecial = '\0';
         if (checkSpecial) {
             for (int i = start; i < end; ++i) {
@@ -778,6 +779,10 @@ public final class SerializeWriter extends Writer {
                     specialCount++;
                     lastSpecialIndex = i;
                     lastSpecial = ch;
+
+                    if (firstSpecialIndex == -1) {
+                        firstSpecialIndex = i;
+                    }
                 }
             }
         }
@@ -793,21 +798,20 @@ public final class SerializeWriter extends Writer {
             buf[lastSpecialIndex] = '\\';
             buf[++lastSpecialIndex] = replaceChars[(int) lastSpecial];
         } else if (specialCount > 1) {
-            System.arraycopy(buf, lastSpecialIndex + 1, buf, lastSpecialIndex + 2, end - lastSpecialIndex - 1);
-            buf[lastSpecialIndex] = '\\';
-            buf[++lastSpecialIndex] = replaceChars[(int) lastSpecial];
-            end++;
-            for (int i = lastSpecialIndex - 2; i >= start; --i) {
-                char ch = buf[i];
+            int textIndex = firstSpecialIndex - start;
+            int bufIndex = firstSpecialIndex;
+            for (int i = textIndex; i < text.length(); ++i) {
+                char ch = text.charAt(i);
 
                 if (ch < CharTypes.specicalFlags_doubleQuotes.length
                     && CharTypes.specicalFlags_doubleQuotes[ch] //
                     || (ch == '\t' && isEnabled(SerializerFeature.WriteTabAsSpecial))
                     || (ch == '/' && isEnabled(SerializerFeature.WriteSlashAsSpecial))) {
-                    System.arraycopy(buf, i + 1, buf, i + 2, end - i - 1);
-                    buf[i] = '\\';
-                    buf[i + 1] = replaceChars[(int) ch];
+                    buf[bufIndex++] = '\\';
+                    buf[bufIndex++] = replaceChars[(int) ch];
                     end++;
+                } else {
+                    buf[bufIndex++] = ch;
                 }
             }
         }
@@ -1187,13 +1191,15 @@ public final class SerializeWriter extends Writer {
                     expandCapacity(newcount);
                 }
                 count = newcount;
-                
+
                 if (specialCount == 1) {
- ",improve performance,"""Optimize SerializeWriter to handle special characters in strings more efficiently""","According to the diff, the commit message should be:

""Optimize special character handling in SerializeWriter""

This commit message is concise and accurately describes the changes made in the code. It mentions the optimization of special character handling, which is the main focus of the changes.","Refactor SerializeWriter to improve handling of special characters in JSON strings

 The changes made in this commit aim to improve the way SerializeWriter handles special characters in JSON strings. Here's a summary of the changes:

 1. A new variable `firstSpecialIndex` is introduced to keep track of the index of the first special character in the string. This is useful for optimizing the handling of strings with only one special character.

 2. In the loop that iterates through the string to find special characters, a check is added to see if `firstSpecialIndex` is still -1 (meaning no special characters have been found yet). If a special character is found, `firstSpecialIndex` is set to the current index.

 3. If more than one special character is found in the string, a new approach is taken to write the escaped special characters to the buffer. Instead of using `System.arraycopy` to shift the remaining characters in the buffer, the code now uses a `bufIndex` variable to keep track of the current position in the buffer. This avoids the need to shift characters and should improve performance.

 Overall, these changes should make SerializeWriter more efficient at handling JSON strings with special characters.","```plaintext
Fix special character handling in SerializeWriter and improve efficiency.
```",Model 4
"diff --git a/controller-server/src/main/java/com/yahoo/vespa/hosted/controller/athenz/filter/UserAuthWithAthenzPrincipalFilter.java b/controller-server/src/main/java/com/yahoo/vespa/hosted/controller/athenz/filter/UserAuthWithAthenzPrincipalFilter.java
index 206c1adfbac..f16d3a42322 100644
--- a/controller-server/src/main/java/com/yahoo/vespa/hosted/controller/athenz/filter/UserAuthWithAthenzPrincipalFilter.java
+++ b/controller-server/src/main/java/com/yahoo/vespa/hosted/controller/athenz/filter/UserAuthWithAthenzPrincipalFilter.java
@@ -46,7 +46,7 @@ public class UserAuthWithAthenzPrincipalFilter extends AthenzPrincipalFilter {
     public void filter(DiscFilterRequest request, ResponseHandler responseHandler) {
         if (request.getMethod().equals(""OPTIONS"")) return; // Skip authentication on OPTIONS - required for Javascript CORS
 
-        switch (fromHttpRequest(request)) {
+        switch (getUserAuthenticationResult(request)) {
             case USER_COOKIE_MISSING:
             case USER_COOKIE_ALTERNATIVE_MISSING:
                 super.filter(request, responseHandler); // Cookie-based authentication failed, delegate to Athenz
@@ -60,7 +60,7 @@ public class UserAuthWithAthenzPrincipalFilter extends AthenzPrincipalFilter {
         }
     }
 
-    private UserAuthenticationResult fromHttpRequest(DiscFilterRequest request) {
+    private UserAuthenticationResult getUserAuthenticationResult(DiscFilterRequest request) {
         if (!request.containsAttribute(userAuthenticationPassThruAttribute)) {
             throw new IllegalStateException(""User authentication filter passthru attribute missing"");
         }",Rename method to better indicate its function,"""Renamed fromHttpRequest to getUserAuthenticationResult in UserAuthWithAthenzPrincipalFilter""","""Update UserAuthWithAthenzPrincipalFilter to use getUserAuthenticationResult instead of fromHttpRequest""","""Rename method fromHttpRequest to getUserAuthenticationResult in UserAuthWithAthenzPrincipalFilter""",Refactor method name from `fromHttpRequest` to `getUserAuthenticationResult` for clarity in `UserAuthWithAthenzPrincipalFilter`.,Model 1
"diff --git a/engine/src/core/com/jme3/app/state/AppState.java b/engine/src/core/com/jme3/app/state/AppState.java
index 77450b1a0..d94a35f6f 100644
--- a/engine/src/core/com/jme3/app/state/AppState.java
+++ b/engine/src/core/com/jme3/app/state/AppState.java
@@ -63,26 +63,6 @@ public interface AppState {
      */
     public boolean isInitialized();
 
-    /**
-     * Use setEnabled() instead.
-     * Activate or deactivate the functionality of the <code>AppState</code>.
-     * The effect of this call depends on implementation. An 
-     * <code>AppState</code> starts as being active by default.
-     * 
-     * @param active activate the AppState or not.
-     */
-    @Deprecated
-    public void setActive(boolean active);
-
-    /**
-     * Use isEnabled() instead.
-     * @return True if the <code>AppState</code> is active, false otherwise.
-     * 
-     * @see AppState#setActive(boolean)
-     */
-    @Deprecated
-    public boolean isActive();
-
     /**
      * Enable or disable the functionality of the <code>AppState</code>.
      * The effect of this call depends on implementation. An ",remove isActive from AppState interface .,"""Remove deprecated setActive and isActive methods from AppState interface""","Remove setActive and isActive methods from AppState interface. 

This commit message accurately reflects the changes made in the diff, which involves removing the deprecated setActive and isActive methods from the AppState interface.","""Removed deprecated methods setActive() and isActive() from AppState interface in com/jme3/app/state/AppState.java""","""Remove deprecated methods setActive() and isActive() from AppState interface.""",Model 4
"diff --git a/src/web/js/azkaban.schedule.panel.view.js b/src/web/js/azkaban.schedule.panel.view.js
index e445a5e9..af81c0c4 100644
--- a/src/web/js/azkaban.schedule.panel.view.js
+++ b/src/web/js/azkaban.schedule.panel.view.js
@@ -54,7 +54,7 @@ azkaban.SchedulePanelView= Backbone.View.extend({
   	 console.log(""Creating schedule for ""+projectName+"".""+scheduleData.flow);
 	var scheduleTime = $('#hour').val() + "","" + $('#minutes').val() + "","" + $('#am_pm').val() + "","" + $('#timezone').val();
 	var scheduleDate = $('#datepicker').val();
-	var is_recurring = $('#is_recurring').val();
+	var is_recurring = document.getElementById('is_recurring').checked ? 'on' : 'off'; 
 	var period = $('#period').val() + $('#period_units').val();
 	
 	scheduleData.ajax = ""scheduleFlow"";",fix the bug for non - recurring schedules to be scheduled correctly,"""Fix is_recurring value retrieval in SchedulePanelView""","""Update schedule panel view to use checkbox value for recurring schedules""","""Update azkaban.schedule.panel.view.js: Change how is_recurring value is obtained""

Explanation: The change is in the file azkaban.schedule.panel.view.js. The line that was modified is related to how the value of is_recurring is obtained. Instead of using $('#is_recurring').val(), the code now checks if the checkbox with id 'is_recurring' is checked or not using document.getElementById('is_recurring').checked ? 'on' : 'off'.",Fix recurring schedule value by checking the 'is_recurring' checkbox state in azkaban.schedule.panel.view.js.,Model 4
"diff --git a/lib/java/com/google/android/material/ripple/RippleDrawableCompat.java b/lib/java/com/google/android/material/ripple/RippleDrawableCompat.java
new file mode 100644
index 000000000..fa18a20c6
--- /dev/null
+++ b/lib/java/com/google/android/material/ripple/RippleDrawableCompat.java
@@ -0,0 +1,84 @@
+/*
+ * Copyright 2019 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package com.google.android.material.ripple;
+
+import android.graphics.Canvas;
+import androidx.annotation.RestrictTo;
+import androidx.annotation.RestrictTo.Scope;
+import com.google.android.material.shape.MaterialShapeDrawable;
+import com.google.android.material.shape.ShapeAppearanceModel;
+
+/**
+ * A compat {@link android.graphics.drawable.Drawable} to be used pre-Lollipop for drawing an
+ * overlay on top of a background for pressed, focused, and hovered states.
+ *
+ * <p>This Drawable is a {@link MaterialShapeDrawable} so that it can be shaped to match a
+ * MaterialShapeDrawable background.
+ *
+ * <p>Unlike the framework {@link android.graphics.drawable.RippleDrawable}, this will <b>not</b>
+ * apply different alphas for pressed, focused, and hovered states and it does not provide a ripple
+ * animation for the pressed state.
+ */
+@RestrictTo(Scope.LIBRARY_GROUP)
+public class RippleDrawableCompat extends MaterialShapeDrawable {
+
+  /**
+   * Whether this compat ripple should be drawn. True when enabled and (pressed, focused, or
+   * enabled).
+   */
+  private boolean shouldDrawRipple = false;
+
+  /**
+   * Creates a {@link RippleDrawableCompat} with the given shape.
+   *
+   * @param shapeAppearanceModel the {@link ShapeAppearanceModel} containing the path that will be
+   *     rendered in this drawable.
+   */
+  public RippleDrawableCompat(ShapeAppearanceModel shapeAppearanceModel) {
+    super(shapeAppearanceModel);
+  }
+
+  @Override
+  public void draw(Canvas canvas) {
+    if (shouldDrawRipple) {
+      super.draw(canvas);
+    }
+  }
+
+  @Override
+  protected boolean onStateChange(int[] stateSet) {
+    final boolean changed = super.onStateChange(stateSet);
+    boolean enabled = false;
+    boolean pressed = false;
+    boolean focused = false;
+    boolean hovered = false;
+
+    for (int state : stateSet) {
+      if (state == android.R.attr.state_enabled) {
+        enabled = true;
+      } else if (state == android.R.attr.state_focused) {
+        focused = true;
+      } else if (state == android.R.attr.state_pressed) {
+        pressed = true;
+      } else if (state == android.R.attr.state_hovered) {
+        hovered = true;
+      }
+    }
+    shouldDrawRipple = enabled && (pressed || focused || hovered);
+    return changed;
+  }
+}","Create compat ripples that are based on MaterialShapeDrawable and only draw when enabled and in the pressed , focused , or hovered states . . PiperOrigin - RevId : 253783048","""Add RippleDrawableCompat for pre-Lollipop compatibility""","""Add RippleDrawableCompat for pre-Lollipop compatibility""

This commit message accurately reflects the changes made in the commit, which is the addition of a new class `RippleDrawableCompat` that provides a compatible implementation of a ripple effect for pre-Lollipop devices.","""Added RippleDrawableCompat class""

This commit introduces a new class `RippleDrawableCompat` in the package `com.google.android.material.ripple`. This class extends `MaterialShapeDrawable` and is used as a compat drawable for versions before Lollipop. It draws an overlay on top of a background for pressed, focused, and hovered states. However, unlike the framework `RippleDrawable`, it does not apply different alphas for these states and does not provide a ripple animation for the pressed state. The class includes methods for drawing on a canvas, handling state changes, and a constructor that takes a `ShapeAppearanceModel`.","""Add RippleDrawableCompat to provide ripple effect support for pre-Lollipop devices using MaterialShapeDrawable.""",Model 3
"diff --git a/community/community-it/cypher-it/src/test/scala/org/neo4j/internal/collector/DataCollectorQueriesAcceptanceTest.scala b/community/community-it/cypher-it/src/test/scala/org/neo4j/internal/collector/DataCollectorQueriesAcceptanceTest.scala
new file mode 100644
index 00000000000..2dd4169f08e
--- /dev/null
+++ b/community/community-it/cypher-it/src/test/scala/org/neo4j/internal/collector/DataCollectorQueriesAcceptanceTest.scala
@@ -0,0 +1,80 @@
+/*
+ * Copyright (c) 2002-2018 ""Neo4j,""
+ * Neo4j Sweden AB [http://neo4j.com]
+ *
+ * This file is part of Neo4j.
+ *
+ * Neo4j is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+package org.neo4j.internal.collector
+
+import org.neo4j.cypher._
+
+class DataCollectorQueriesAcceptanceTest extends ExecutionEngineFunSuite {
+
+  import DataCollectorMatchers._
+
+  test(""should collect and retrieve queries"") {
+    // given
+    execute(""RETURN 'not collected!'"")
+    execute(""CALL db.stats.collect('QUERIES')"").single
+
+    execute(""MATCH (n) RETURN count(n)"")
+    execute(""MATCH (n)-->(m) RETURN n,m"")
+    execute(""WITH 'hi' AS x RETURN x+'-ho'"")
+
+    execute(""CALL db.stats.stop('QUERIES')"").single
+    execute(""RETURN 'not collected!'"")
+
+    // when
+    val res = execute(""CALL db.stats.retrieve('QUERIES')"").toList
+
+    // then
+    res should beListWithoutOrder(
+      beMapContaining(
+        ""section"" -> ""QUERIES"",
+        ""data"" -> beMapContaining(
+          ""query"" -> ""MATCH (n) RETURN count(n)""
+        )
+      ),
+      beMapContaining(
+        ""section"" -> ""QUERIES"",
+        ""data"" -> beMapContaining(
+          ""query"" -> ""MATCH (n)-->(m) RETURN n,m""
+        )
+      ),
+      beMapContaining(
+        ""section"" -> ""QUERIES"",
+        ""data"" -> beMapContaining(
+          ""query"" -> ""WITH 'hi' AS x RETURN x+'-ho'""
+        )
+      )
+    )
+  }
+
+  test(""should clear queries"") {
+    // given
+    execute(""CALL db.stats.collect('QUERIES')"").single
+    execute(""MATCH (n) RETURN count(n)"")
+    execute(""CALL db.stats.stop('QUERIES')"").single
+
+    // when
+    execute(""CALL db.stats.clear('QUERIES')"").single
+    execute(""CALL db.stats.collect('QUERIES')"").single
+    execute(""CALL db.stats.stop('QUERIES')"").single
+
+    // then
+    execute(""CALL db.stats.retrieve('QUERIES')"").toList should be(empty)
+  }
+}
diff --git a/community/data-collector/src/main/java/org/neo4j/internal/collector/CollectorStateMachine.java b/community/data-collector/src/main/java/org/neo4j/internal/collector/CollectorStateMachine.java
index d9c72b30888..ac4c9ed44df 100644
--- a/community/data-collector/src/main/java/org/neo4j/internal/collector/CollectorStateMachine.java
+++ b/community/data-collector/src/main/java/org/neo4j/internal/collector/CollectorStateMachine.java
@@ -22,7 +22,7 @@ package org.neo4j.internal.collector;
 /**
  * Base class for managing state transitions of data-collector daemons.
  */
-abstract class CollectorStateMachine
+abstract class CollectorStateMachine<DATA>
 {
     private enum State { IDLE, COLLECTING, HAS_DATA }
 
@@ -132,7 +132,23 @@ abstract class CollectorStateMachine
         }
     }
 
+    public synchronized DATA getData()
+    {
+        switch ( state )
+        {
+        case IDLE:
+            throw new IllegalStateException( ""Collector is idle and has no data."" );
+        case COLLECTING:
+            throw new IllegalStateException( ""Collector is still collecting."");
+        case HAS_DATA:
+            return doGetData();
+        default:
+            throw new IllegalStateException( ""Unknown state "" + state );
+        }
+    }
+
     abstract Result doCollect();
     abstract Result doStop();
     abstract Result doClear();
+    abstract DATA doGetData();
 }
diff --git a/community/data-collector/src/main/java/org/neo4j/internal/collector/DataCollector.java b/community/data-collector/src/main/java/org/neo4j/internal/collector/DataCollector.java
index 0c1c1ffaa5d..e1749b92cc4 100644
--- a/community/data-collector/src/main/java/org/neo4j/internal/collector/DataCollector.java
+++ b/community/data-collector/src/main/java/org/neo4j/internal/collector/DataCollector.java
@@ -20,6 +20,7 @@
 package org.neo4j.internal.collector;
 
 import org.neo4j.internal.kernel.api.Kernel;
+import org.neo4j.kernel.monitoring.Monitors;
 import org.neo4j.scheduler.JobScheduler;
 
 public class DataCollector implements AutoCloseable
@@ -28,11 +29,12 @@ public class DataCollector implements AutoCloseable
     final JobScheduler jobScheduler;
     final QueryCollector queryCollector;
 
-    DataCollector( Kernel kernel, JobScheduler jobScheduler )
+    DataCollector( Kernel kernel, JobScheduler jobScheduler, Monitors monitors )
     {
         this.kernel = kernel;
         this.jobScheduler = jobScheduler;
         this.queryCollector = new QueryCollector();
+        monitors.addMonitorListener( queryCollector );
     }
 
     @Override
diff --git a/community/data-collector/src/main/java/org/neo4j/internal/collector/DataCollectorModule.java b/community/data-collector/src/main/java/org/neo4j/internal/collector/DataCollectorModule.java
index e3b2c978857..02c6dea739c 100644
--- a/community/data-collector/src/main/java/org/neo4j/internal/collector/DataCollectorModule.java
+++ b/community/data-collector/src/main/java/org/neo4j/internal/collector/DataCollectorModule.java
@@ -22,6 +22,7 @@ package org.neo4j.internal.collector;
 import org.neo4j.internal.kernel.api.Kernel;
 import org.neo4j.internal.kernel.api.exceptions.KernelException;
 import org.neo4j.kernel.impl.proc.Procedures;
+import org.neo4j.kernel.monitoring.Monitors;
 import org.neo4j.scheduler.JobScheduler;
 import org.neo4j.util.Preconditions;
 
@@ -33,10 +34,11 @@ public class DataCollectorModule
 
     public static AutoCloseable setupDataCollector( Procedures procedures,
                                                     JobScheduler jobScheduler,
-                                                    Kernel kernel ) throws KernelException
+                                                    Kernel kernel,
+                                                    Monitors monitors ) throws KernelException
     {
         Preconditions.checkState( kernel != null, ""Kernel was null"" );
-        DataCollector dataCollector = new DataCollector( kernel, jobScheduler );
+        DataCollector dataCollector = new DataCollector( kernel, jobScheduler, monitors );
         procedures.registerComponent( DataCollector.class, ctx -> dataCollector, false );
         procedures.registerProcedure( DataCollectorProcedures.class );
         return dataCollector;
diff --git a/community/data-collector/src/main/java/org/neo4j/internal/collector/DataCollectorProcedures.java b/community/data-collector/src/main/java/org/neo4j/internal/collector/DataCollectorProcedures.java
index b3d1352ba28..b2baab3f7a5 100644
--- a/community/data-collector/src/main/java/org/neo4j/internal/collector/DataCollectorProcedures.java
+++ b/community/data-collector/src/main/java/org/neo4j/internal/collector/DataCollectorProcedures.java
@@ -20,7 +20,6 @@
 package org.neo4j.internal.collector;
 
 import java.time.ZonedDateTime;
-import java.util.Arrays;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.Map;
@@ -42,11 +41,9 @@ public class DataCollectorProcedures
     @Context
     public DataCollector dataCollector;
 
-    private static String[] SECTIONS = {GraphCountsSection.NAME, TokensSection.NAME, QueriesSection.NAME};
-
     @Admin
     @Description( ""Retrieve statistical data about the current database. Valid sections are '"" +
-                  GraphCountsSection.NAME + ""', '"" + TokensSection.NAME + ""', '"" + QueriesSection.NAME + ""'"" )
+                  Sections.GRAPH_COUNTS + ""', '"" + Sections.TOKENS + ""', '"" + Sections.QUERIES + ""'"" )
     @Procedure( name = ""db.stats.retrieve"", mode = Mode.READ )
     public Stream<RetrieveResult> retrieve( @Name( value = ""section"" ) String section )
             throws InvalidArgumentsException, IndexNotFoundKernelException, TransactionFailureException
@@ -54,17 +51,17 @@ public class DataCollectorProcedures
         String upperSection = section.toUpperCase();
         switch ( upperSection )
         {
-        case GraphCountsSection.NAME:
-            return GraphCountsSection.collect( dataCollector.kernel, Anonymizer.PLAIN_TEXT );
+        case Sections.GRAPH_COUNTS:
+            return GraphCountsSection.retrieve( dataCollector.kernel, Anonymizer.PLAIN_TEXT );
 
-        case TokensSection.NAME:
-            return TokensSection.collect( dataCollector.kernel );
+        case Sections.TOKENS:
+            return TokensSection.retrieve( dataCollector.kernel );
 
-        case QueriesSection.NAME:
-            throw new UnsupportedOperationException( ""not implemented"" );
+        case Sections.QUERIES:
+            return QueriesSection.retrieve( dataCollector.queryCollector.doGetData() );
 
         default:
-            throw unknownSectionException( section );
+            throw Sections.unknownSectionException( section );
         }
     }
 
@@ -80,7 +77,7 @@ public class DataCollectorProcedures
         TokensSection.putTokenCounts( metaData, dataCollector.kernel );
         Stream<RetrieveResult> meta = Stream.of( new RetrieveResult( ""META"", metaData ) );
 
-        return Stream.concat( meta, GraphCountsSection.collect( dataCollector.kernel, Anonymizer.IDS ) );
+        return Stream.concat( meta, GraphCountsSection.retrieve( dataCollector.kernel, Anonymizer.IDS ) );
     }
 
     @Admin
@@ -89,7 +86,7 @@ public class DataCollectorProcedures
     public Stream<StatusResult> status()
     {
         CollectorStateMachine.Status status = dataCollector.queryCollector.status();
-        return Stream.of( new StatusResult( QueriesSection.NAME, status.message, Collections.emptyMap() ) );
+        return Stream.of( new StatusResult( Sections.QUERIES, status.message, Collections.emptyMap() ) );
     }
 
     @Admin
@@ -123,19 +120,13 @@ public class DataCollectorProcedures
     {
         switch ( section )
         {
-        case TokensSection.NAME:
-        case GraphCountsSection.NAME:
+        case Sections.TOKENS:
+        case Sections.GRAPH_COUNTS:
             throw new InvalidArgumentsException( ""Section '%s' does not have to be explicitly collected, it can always be directly retrieved."" );
-        case QueriesSection.NAME:
+        case Sections.QUERIES:
             return dataCollector.queryCollector;
         default:
-            throw unknownSectionException( section );
+            throw Sections.unknownSectionException( section );
         }
     }
-
-    private InvalidArgumentsException unknownSectionException( @Name( ""section"" ) String section )
-    {
-        return new InvalidArgumentsException( String.format( ""Unknown section '%s', known sections are %s"",
-                                                             section, Arrays.toString( SECTIONS ) ) );
-    }
 }
diff --git a/community/data-collector/src/main/java/org/neo4j/internal/collector/GraphCountsSection.java b/community/data-collector/src/main/java/org/neo4j/internal/collector/GraphCountsSection.java
index fa11ed0b579..e84b7f1f73b 100644
--- a/community/data-collector/src/main/java/org/neo4j/internal/collector/GraphCountsSection.java
+++ b/community/data-collector/src/main/java/org/neo4j/internal/collector/GraphCountsSection.java
@@ -53,13 +53,11 @@ import org.neo4j.register.Registers;
  */
 final class GraphCountsSection
 {
-    static final String NAME = ""GRAPH COUNTS"";
-
     private GraphCountsSection()
     { // only static functionality
     }
 
-    static Stream<RetrieveResult> collect( Kernel kernel, Anonymizer anonymizer )
+    static Stream<RetrieveResult> retrieve( Kernel kernel, Anonymizer anonymizer )
             throws TransactionFailureException, IndexNotFoundKernelException
     {
         try ( Transaction tx = kernel.beginTransaction( Transaction.Type.explicit, LoginContext.AUTH_DISABLED ) )
@@ -73,7 +71,7 @@ final class GraphCountsSection
             data.put( ""indexes"", indexes( tokens, tx.schemaRead(), anonymizer ) );
             data.put( ""constraints"", constraints( tokens, tx.schemaRead(), anonymizer ) );
 
-            return Stream.of( new RetrieveResult( NAME, data ) );
+            return Stream.of( new RetrieveResult( Sections.GRAPH_COUNTS, data ) );
         }
     }
 
diff --git a/community/data-collector/src/main/java/org/neo4j/internal/collector/QueryCollector.java b/community/data-collector/src/main/java/org/neo4j/internal/collector/QueryCollector.java
index dc785840ae6..1c6d8bafc03 100644
--- a/community/data-collector/src/main/java/org/neo4j/internal/collector/QueryCollector.java
+++ b/community/data-collector/src/main/java/org/neo4j/internal/collector/QueryCollector.java
@@ -19,23 +19,77 @@
  */
 package org.neo4j.internal.collector;
 
-final class QueryCollector extends CollectorStateMachine
+import java.util.Iterator;
+import java.util.concurrent.ConcurrentLinkedQueue;
+
+import org.neo4j.kernel.api.query.ExecutingQuery;
+import org.neo4j.kernel.api.query.QuerySnapshot;
+import org.neo4j.kernel.impl.query.QueryExecutionMonitor;
+
+/**
+ * Simple Thread-safe query collector.
+ *
+ * Note that is has several potentially not-so-nice properties:
+ *
+ *  - It buffers all query data until collection is done. On high-workload systems
+ *    this could use substantial memory
+ *
+ *  - All threads that report queries on {@link QueryCollector#endSuccess(org.neo4j.kernel.api.query.ExecutingQuery)}
+ *    contend for writing to the queue, which might cause delays at query close time on highly concurrent systems
+ */
+class QueryCollector extends CollectorStateMachine<Iterator<QuerySnapshot>> implements QueryExecutionMonitor
 {
+    private volatile boolean on;
+    private final ConcurrentLinkedQueue<QuerySnapshot> queries;
+
+    QueryCollector()
+    {
+        on = false;
+        queries = new ConcurrentLinkedQueue<>();
+    }
+
+    // CollectorStateMachine
+
     @Override
     Result doCollect()
     {
+        on = true;
         return success( ""Collection started."" );
     }
 
     @Override
     Result doStop()
     {
+        on = false;
         return success( ""Collection stopped."" );
     }
 
     @Override
     Result doClear()
     {
+        queries.clear();
         return success( ""Data cleared."" );
     }
+
+    @Override
+    Iterator<QuerySnapshot> doGetData()
+    {
+        return queries.iterator();
+    }
+
+    // QueryExecutionMonitor
+
+    @Override
+    public void endFailure( ExecutingQuery query, Throwable failure )
+    {
+    }
+
+    @Override
+    public void endSuccess( ExecutingQuery query )
+    {
+        if ( on )
+        {
+            queries.add( query.snapshot() );
+        }
+    }
 }
diff --git a/community/data-collector/src/main/java/org/neo4j/internal/collector/QueriesSection.java b/community/data-collector/src/main/java/org/neo4j/internal/collector/Sections.java
similarity index 51%
rename from community/data-collector/src/main/java/org/neo4j/internal/collector/QueriesSection.java
rename to community/data-collector/src/main/java/org/neo4j/internal/collector/Sections.java
index b1961dbb407..d35b8965e77 100644
--- a/community/data-collector/src/main/java/org/neo4j/internal/collector/QueriesSection.java
+++ b/community/data-collector/src/main/java/org/neo4j/internal/collector/Sections.java
@@ -19,7 +19,27 @@
  */
 package org.neo4j.internal.collector;
 
-final class QueriesSection
+import java.util.Arrays;
+
+import org.neo4j.kernel.api.exceptions.InvalidArgumentsException;
+
+@SuppressWarnings( ""WeakerAccess"" )
+class Sections
 {
-    static final String NAME = ""QUERIES"";
+    private Sections()
+    { // only static methods
+    }
+
+    static final String GRAPH_COUNTS = ""GRAPH COUNTS"";
+    static final String TOKENS = ""TOKENS"";
+    static final String QUERIES = ""QUERIES"";
+
+    static final String[] SECTIONS = {GRAPH_COUNTS, TOKENS, QUERIES};
+    static final String NAMES = Arrays.toString( SECTIONS );
+
+    static InvalidArgumentsException unknownSectionException( String section )
+    {
+        return new InvalidArgumentsException( String.format( ""Unknown section '%s', known sections are %s"",
+                                                             section, NAMES ) );
+    }
 }
diff --git a/community/data-collector/src/main/java/org/neo4j/internal/collector/TokensSection.java b/community/data-collector/src/main/java/org/neo4j/internal/collector/TokensSection.java
index d8427e0e33d..7de31b9a9eb 100644
--- a/community/data-collector/src/main/java/org/neo4j/internal/collector/TokensSection.java
+++ b/community/data-collector/src/main/java/org/neo4j/internal/collector/TokensSection.java
@@ -31,15 +31,17 @@ import org.neo4j.internal.kernel.api.Transaction;
 import org.neo4j.internal.kernel.api.exceptions.TransactionFailureException;
 import org.neo4j.internal.kernel.api.security.LoginContext;
 
+/**
+ * Data collector section that simply return all tokens (propertyKeys, labels and relationship types) that
+ * are known to the database.
+ */
 final class TokensSection
 {
-    static final String NAME = ""TOKENS"";
-
     private TokensSection()
     { // only static methods
     }
 
-    static Stream<RetrieveResult> collect( Kernel kernel ) throws TransactionFailureException
+    static Stream<RetrieveResult> retrieve( Kernel kernel ) throws TransactionFailureException
     {
         try ( Transaction tx = kernel.beginTransaction( Transaction.Type.explicit, LoginContext.AUTH_DISABLED ) )
         {
@@ -58,7 +60,7 @@ final class TokensSection
             data.put( ""labels"", labels );
             data.put( ""relationshipTypes"", relationshipTypes );
             data.put( ""propertyKeys"", propertyKeys );
-            return Stream.of( new RetrieveResult( NAME, data ) );
+            return Stream.of( new RetrieveResult( Sections.TOKENS, data ) );
         }
     }
 
diff --git a/community/data-collector/src/main/scala/org/neo4j/internal/collector/QueriesSection.scala b/community/data-collector/src/main/scala/org/neo4j/internal/collector/QueriesSection.scala
new file mode 100644
index 00000000000..f1337b344d0
--- /dev/null
+++ b/community/data-collector/src/main/scala/org/neo4j/internal/collector/QueriesSection.scala
@@ -0,0 +1,98 @@
+/*
+ * Copyright (c) 2002-2018 ""Neo4j,""
+ * Neo4j Sweden AB [http://neo4j.com]
+ *
+ * This file is part of Neo4j.
+ *
+ * Neo4j is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.
+ */
+package org.neo4j.internal.collector
+
+import java.util
+import java.util.{Spliterator, Spliterators}
+import java.util.stream.{Stream, StreamSupport}
+
+import org.neo4j.kernel.api.query.QuerySnapshot
+import org.neo4j.values.virtual.MapValue
+
+import scala.collection.mutable
+import scala.collection.mutable.ArrayBuffer
+
+/**
+  * Data collector section which contains query invocation data. This includes the query itself,
+  * the logical plan, cardinality information, and listing of seen invocations.
+  */
+object QueriesSection {
+
+  sealed trait InvocationData
+  case class SingleInvocation(queryParameters: MapValue,
+                              elapsedTimeMicros: Long,
+                              compilationTimeMicros: Long) extends InvocationData
+
+  case class ProfileData(dbHits: util.ArrayList[Long], rows: util.ArrayList[Long], params: util.Map[String, AnyRef])
+
+  case class QueryKey(queryText: String)
+
+  class QueryData() {
+    val invocations = new ArrayBuffer[SingleInvocation]
+    val profiles = new ArrayBuffer[ProfileData]
+  }
+
+  def retrieve(querySnapshots: java.util.Iterator[QuerySnapshot]): Stream[RetrieveResult] = {
+    val queries = new mutable.HashMap[QueryKey, QueryData]()
+    while (querySnapshots.hasNext) {
+      val snapshot = querySnapshots.next()
+      val queryString = snapshot.queryText()
+      if (!queryString.contains(""CALL db.stats."")) {
+        val snapshotList = queries.getOrElseUpdate(QueryKey(queryString), new QueryData())
+        snapshotList.invocations += SingleInvocation(snapshot.queryParameters(),
+                                                     snapshot.elapsedTimeMicros(),
+                                                     snapshot.compilationTimeMicros())
+      }
+    }
+
+    asRetrieveStream(queries.toIterator.map({
+      case (queryKey, queryData) =>
+        val data = new util.HashMap[String, AnyRef]()
+        data.put(""query"", queryKey.queryText)
+        data.put(""invocations"", invocations(queryData.invocations))
+        new RetrieveResult(Sections.QUERIES, data)
+    }))
+  }
+
+  private def invocations(invocations: ArrayBuffer[QueriesSection.SingleInvocation]): util.ArrayList[util.Map[String, AnyRef]] = {
+    val result = new util.ArrayList[util.Map[String, AnyRef]]()
+    for (invocationData <- invocations) {
+      invocationData match {
+        case SingleInvocation(queryParameters, elapsedTimeMicros, compilationTimeMicros) =>
+          val data = new util.HashMap[String, AnyRef]()
+          val compileTime = compilationTimeMicros
+          val elapsed = elapsedTimeMicros
+          if (compileTime > 0) {
+            data.put(""elapsedCompileTimeInUs"", java.lang.Long.valueOf(compileTime))
+            data.put(""elapsedExecutionTimeInUs"", java.lang.Long.valueOf(elapsed - compileTime))
+          } else
+            data.put(""elapsedExecutionTimeInUs"", java.lang.Long.valueOf(elapsed))
+          result.add(data)
+      }
+    }
+
+    result
+  }
+
+  private def asRetrieveStream(iterator: Iterator[RetrieveResult]): Stream[RetrieveResult] = {
+    import scala.collection.JavaConverters._
+    StreamSupport.stream(Spliterators.spliterator(iterator.asJava, 0L, Spliterator.NONNULL), false)
+  }
+}
diff --git a/community/neo4j/src/main/java/org/neo4j/graphdb/facade/GraphDatabaseFacadeFactory.java b/community/neo4j/src/main/java/org/neo4j/graphdb/facade/GraphDatabaseFacadeFactory.java
index c81f5c29573..67e4f7fed43 100644
--- a/community/neo4j/src/main/java/org/neo4j/graphdb/facade/GraphDatabaseFacadeFactory.java
+++ b/community/neo4j/src/main/java/org/neo4j/graphdb/facade/GraphDatabaseFacadeFactory.java
@@ -177,7 +177,11 @@ public class GraphDatabaseFacadeFactory
         platform.life.add( databaseManager );
         platform.dependencies.satisfyDependency( databaseManager );
 
-        DataCollectorManager dataCollectorManager = new DataCollectorManager( platform.dataSourceManager, platform.jobScheduler, procedures );
+        DataCollectorManager dataCollectorManager =
+                new DataCollectorManager( platform.dataSourceManager,
+                                          platform.jobScheduler,
+                                          procedures,
+                                          platform.monitors );
         platform.life.add( dataCollectorManager );
 
         edition.createSecurityModule( platform, procedures );
diff --git a/community/neo4j/src/main/java/org/neo4j/internal/DataCollectorManager.java b/community/neo4j/src/main/java/org/neo4j/internal/DataCollectorManager.java
index 1b5bd939e88..a8b1eb5b574 100644
--- a/community/neo4j/src/main/java/org/neo4j/internal/DataCollectorManager.java
+++ b/community/neo4j/src/main/java/org/neo4j/internal/DataCollectorManager.java
@@ -28,6 +28,7 @@ import org.neo4j.kernel.NeoStoreDataSource;
 import org.neo4j.kernel.impl.proc.Procedures;
 import org.neo4j.kernel.impl.transaction.state.DataSourceManager;
 import org.neo4j.kernel.lifecycle.LifecycleAdapter;
+import org.neo4j.kernel.monitoring.Monitors;
 import org.neo4j.scheduler.JobScheduler;
 
 public class DataCollectorManager extends LifecycleAdapter
@@ -35,15 +36,18 @@ public class DataCollectorManager extends LifecycleAdapter
     private final DataSourceManager dataSourceManager;
     private final JobScheduler jobScheduler;
     private final Procedures procedures;
+    private final Monitors monitors;
     private final List<AutoCloseable> dataCollectors;
 
     public DataCollectorManager( DataSourceManager dataSourceManager,
                                  JobScheduler jobScheduler,
-                                 Procedures procedures )
+                                 Procedures procedures,
+                                 Monitors monitors )
     {
         this.dataSourceManager = dataSourceManager;
         this.jobScheduler = jobScheduler;
         this.procedures = procedures;
+        this.monitors = monitors;
         this.dataCollectors = new ArrayList<>();
     }
 
@@ -52,7 +56,10 @@ public class DataCollectorManager extends LifecycleAdapter
     {
         // When we have multiple dbs, this has to be suitably modified to get the right kernel and procedures
         NeoStoreDataSource dataSource = dataSourceManager.getDataSource();
-        dataCollectors.add( DataCollectorModule.setupDataCollector( procedures, jobScheduler, dataSource.getKernel() ) );
+        dataCollectors.add( DataCollectorModule.setupDataCollector( procedures,
+                                                         ",Retrieve section QUERIES,"""Added query collection and retrieval functionality to data collector""","Added data collector functionality to Neo4j, including query collection and retrieval, and added monitoring support.","The commit message should be something like: ""Add support for collecting and retrieving queries using the data collector framework"". This message indicates that the changes made in the commit add a new feature to the data collector framework that allows for the collection and retrieval of queries. The message also implies that this feature is implemented in the `DataCollectorQueriesAcceptanceTest` and `CollectorStateMachine` classes, as well as in the `CollectorStateMachine` interface. Additionally, the message suggests that the `doGetData` method has been added to the `CollectorStateMachine` interface and implemented in the `QueriesCollector` class. Overall, the commit message provides a high-level summary of the changes made in the commit and the purpose of those changes.","""Added query collection and retrieval feature to data collector with tests and refactored common sections code.""",Model 2
"diff --git a/wherehows-web/app/router.js b/wherehows-web/app/router.js
index 0c41564c59a..d3055f7cdf7 100644
--- a/wherehows-web/app/router.js
+++ b/wherehows-web/app/router.js
@@ -2,7 +2,7 @@ import Router from '@ember/routing/router';
 import { get, getWithDefault } from '@ember/object';
 import { inject as service } from '@ember/service';
 import { scheduleOnce } from '@ember/runloop';
-import config from './config/environment';
+import config from 'wherehows-web/config/environment';
 import { redirectToHttps } from 'wherehows-web/utils/build-url';
 
 const AppRouter = Router.extend({
@@ -13,9 +13,12 @@ const AppRouter = Router.extend({
   metrics: service(),
 
   willTransition() {
+    const { APP: { useSecureRedirect } } = config;
     this._super(...arguments);
 
-    redirectToHttps(window.location);
+    if (useSecureRedirect) {
+      redirectToHttps(window.location);
+    }
   },
 
   didTransition() {
diff --git a/wherehows-web/config/environment.js b/wherehows-web/config/environment.js
index ba060ae48a6..c63f18343b6 100644
--- a/wherehows-web/config/environment.js
+++ b/wherehows-web/config/environment.js
@@ -18,8 +18,7 @@ module.exports = function(environment) {
     },
 
     APP: {
-      // Here you can pass flags/options to your application instance
-      // when it is created
+      useSecureRedirect: true
     },
 
     eyeglass: {",adds cli application configs for secure - redirection,"""Added configurable secure redirect option and updated router to use it""","""Enable secure redirect in production environment""","""Update router.js to conditionally redirect to HTTPS based on config and add useSecureRedirect flag to environment.js""

Explanation:

* In router.js, the import statement for the config module has been updated to include the full package name ('wherehows-web/config/environment'). The willTransition() function has been modified to conditionally redirect to HTTPS based on the value of the useSecureRedirect flag in the config.
* In environment.js, the APP object has been updated to include a new flag called useSecureRedirect, which is set to true. This flag is used in router.js to determine whether to redirect to HTTPS or not.","""Add secure redirect configuration to environment settings and conditionally redirect to HTTPS in router""",Model 1
"diff --git a/wherehows-dao/src/main/java/wherehows/dao/table/DictDatasetDao.java b/wherehows-dao/src/main/java/wherehows/dao/table/DictDatasetDao.java
index be575a63828..c9e09e1404f 100644
--- a/wherehows-dao/src/main/java/wherehows/dao/table/DictDatasetDao.java
+++ b/wherehows-dao/src/main/java/wherehows/dao/table/DictDatasetDao.java
@@ -71,7 +71,7 @@ public class DictDatasetDao extends BaseDao {
     try {
       dataset = findBy(DictDataset.class, ""urn"", urn);
     } catch (Exception e) {
-      log.info(""Can't find dataset "" + urn, e.toString());
+      log.debug(""Can't find dataset "" + urn, e.toString());
     }
     // if not found, create new entity
     if (dataset == null) {
diff --git a/wherehows-kafka/src/main/java/wherehows/actors/KafkaWorker.java b/wherehows-kafka/src/main/java/wherehows/actors/KafkaWorker.java
index 29f3a21cf2f..4674a167bf7 100644
--- a/wherehows-kafka/src/main/java/wherehows/actors/KafkaWorker.java
+++ b/wherehows-kafka/src/main/java/wherehows/actors/KafkaWorker.java
@@ -64,7 +64,7 @@ public class KafkaWorker extends UntypedActor {
             }
 
             if (_receivedRecordCount % 1000 == 0) {
-              log.debug(_topic + "" received "" + _receivedRecordCount);
+              log.info(_topic + "" received "" + _receivedRecordCount);
             }
           }
 ",Adjust logging level for kafka consumer ( <issue_id> ),"""Update logging levels in DictDatasetDao and KafkaWorker""","""Log level adjustments for dataset lookup and Kafka worker metrics""","""Change log level from info to debug in DictDatasetDao and from debug to info in KafkaWorker""","Change log level from info to debug in DictDatasetDao, and from debug to info in KafkaWorker.",Model 3
"diff --git a/Mifare Classic Tool/app/src/main/assets/help/help.html b/Mifare Classic Tool/app/src/main/assets/help/help.html
index b94e2ae..836c342 100644
--- a/Mifare Classic Tool/app/src/main/assets/help/help.html	
+++ b/Mifare Classic Tool/app/src/main/assets/help/help.html	
@@ -1,4 +1,6 @@
-<?xml version=""1.0"" encoding=""utf-8""?>
+<!DOCTYPE html>
+<html lang=""en"">
+
 <!--
 /*
  * Copyright 2013 Gerhard Klostermeier
@@ -18,10 +20,6 @@
  */
 -->
 
-
-<!DOCTYPE html PUBLIC ""-//W3C//DTD XHTML 1.0 Transitional//EN""
-    ""http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"">
-<html xmlns=""http://www.w3.org/1999/xhtml"">
 <head>
   <title>Help and Info</title>
 </head>
@@ -30,7 +28,7 @@
   <div align=""center"">
     <img src=""mct_logo.png"" width=""250px"" alt=""logo"" />
   </div>
-  <hr />
+  <hr>
   <h1>Help and Info</h1>
   <h2>Table of Contents</h2>
   <ul>
@@ -83,7 +81,9 @@
     </li>
     <li><a href=""#external_nfc"">8. External NFC</a></li>
   </ul>
-  <hr />
+
+
+  <hr>
 
   <h2 id=""general_information"">1. General Information</h2>
     This tool provides several features to interact with (and only with)
@@ -177,7 +177,10 @@
   external storage (SD card) in a folder named <i>MifareClassicTool</i>. Dump files are
   in the format <i>.mct</i> and key files are in the format <i>.keys</i>. It is possible
   to import multiple files at once.
-  <br /><br />
+  <ul>
+    <li>Dump files: /sdcard/MifareClassicTool/dump-files/ (import as .mct)</li>
+    <li>Key files: /sdcard/MifareClassicTool/key-files/ (import as .keys)</li>
+  </ul>
   The regular version and the
   <a href=""https://play.google.com/store/apps/details?id=de.syss.MifareClassicToolDonate"">donate version</a>
   of MCT can not share the same storage. Therefore each version has its own dump an key files.
@@ -190,24 +193,26 @@
     2012/2013. It is free software under the
     <a href=""https://www.gnu.org/licenses/gpl-3.0.txt"">
       GNU General Public License v3.0 (GPLv3)</a>.
-    <br /><br />
+    <br><br>
     Icons used in this application:
     <ul>
 	  <li>Logo: <a href=""http://www.beneketraub.com/"">Beneke Traub</a>
-        <br />(<a href=""http://creativecommons.org/licenses/by-nc-sa/4.0/"">Creative
+        <br>(<a href=""http://creativecommons.org/licenses/by-nc-sa/4.0/"">Creative
         Commons 4.0</a>)
       </li>
       <li>Oxygen Icons: <a href=""http://www.oxygen-icons.org/"">www.oxygen-icons.org</a>
-        <br />(<a href=""http://www.gnu.org/licenses/lgpl.html"">GNU
+        <br>(<a href=""http://www.gnu.org/licenses/lgpl.html"">GNU
           Lesser General Public License</a>)
       </li>
       <li>RFID Tag: <a href=""http://www.nfc-tag.de/"">www.nfc-tag.de</a>
-        <br />(<a href=""http://creativecommons.org/licenses/by/3.0/"">Creative
+        <br>(<a href=""http://creativecommons.org/licenses/by/3.0/"">Creative
           Commons 3.0</a>)
       </li>
     </ul>
     MIFARE&reg; is a registered trademark of NXP Semiconductors.
-  <hr />
+
+
+  <hr>
 
 
   <h2 id=""getting_started"">2. Getting Started</h2>
@@ -218,30 +223,30 @@
     normal RFID-Readers and some special software
     (<a href=""https://github.com/nfc-tools/mfcuk"">mfcuk</a>,
     <a href=""https://github.com/nfc-tools/mfoc"">mfoc</a>).
-    <br /><br />
+    <br><br>
     The application comes with standard key files called
     <i>std.keys</i> and <i>extended-std.keys</i>, which contains the
     well known keys and some standard keys from a short Google search.
     You can try to read a tag with this key file using
     &quot;Read Tag&quot; from main menu.
-    <br /><br />
+    <br><br>
     Once you know some keys, you cam to put them into a simple text
     file (one key per line). You can do this on your PC and import
     the file using MCT's <a href=""#import_export_tool"">Import/Export
     Tool</a>, or you can create a new key file via &quot;Edit or Add
     Key File&quot; from main menu. If you are finished setting up your
     key file, you can read a tag using &quot;Read Tag&quot; from main menu.
-    <br /><br />
+    <br><br>
     <b>Advantages of the Key Files Concept:</b>
     <ul>
       <li>
         <b>You don't have to worry about which key is for which
-        sector.</b><br />
+        sector.</b><br>
         The application tries to authenticate with all keys from the key
         file against all sectors (like a dictionary-attack).
       </li>
       <li>
-        <b>You don't have to know all the keys.</b><br />
+        <b>You don't have to know all the keys.</b><br>
         If neither key A nor key B for a specific sector is found in the
         key file (dictionary), the application will skip reading said
         sector.
@@ -250,22 +255,24 @@
     This dictionary-attack based mapping process
     (keys &lt;-&gt; sectors) makes it easy for you to read as much as
     possible with the keys you know!
-  <hr />
+
+
+  <hr>
 
 
   <h2 id=""read_tag"">3. Read Tag</h2>
     Technically speaking, reading an RFID-Tag is done in two steps:
     <ul>
       <li>
-        <i>Choose a key file</i><br />
+        <i>Choose a key file</i><br>
         Press &quot;Read Tag&quot; in the main menu. Now select
         key files which (perhaps) contain the keys for the tag.
         You can also specify the range of sectors you want to read.
-        Start the mapping process with the lower right button.<br />
+        Start the mapping process with the lower right button.<br>
         But: For large key files this could take quite some time!
       </li>
       <li>
-        <i>Read tag</i><br />
+        <i>Read tag</i><br>
         After the keys are mapped to sectors based on a kind of
         dictionary-attack, the application will instantly start
         to read the tag. The result will be displayed in a
@@ -273,7 +280,9 @@
         <a href=""#edit_dump_file"">Edit Tag Dump File</a>.)
       </li>
     </ul>
-  <hr />
+
+
+  <hr>
 
 
   <h2 id=""write_tag"">4. Write Tag</h2>
@@ -295,32 +304,32 @@
     If you want to clone a tag, you first have to read and then dump
     the original tag. The second step is to restore the dumped data on another
     tag (for which you know the keys). You need the keys with write privileges
-    for all sectors you want to write.<br />
+    for all sectors you want to write.<br>
     After selecting the dump, the sectors and the key files, the App will check
     everything for you! If there are issues like 'block is read-only', 'key
     with write access not known', etc., you will get a report before writing.
-    <br /><br />
+    <br><br>
     <b>Options:</b>
     <ul>
       <li>
-        <i>Use static (custom) Access Conditions</i><br />
+        <i>Use static (custom) Access Conditions</i><br>
         By enabling this option, all Access Conditions from the dump
         will be replaced with the chosen ones.
-        <br />This is useful if the dump contains Access Conditions
+        <br>This is useful if the dump contains Access Conditions
         that will be permanent for a tag. In case the reader does not check
         them, you can easily use custom ones to make the tag reusable.
       </li>
       <li>
-        <i>Write to Manufacturer Block</i><br />
+        <i>Write to Manufacturer Block</i><br>
         The first block of the first sector of an <b>original</b>
         MIFARE Classic tag is read-only i.e. not writable. But there are
         <b>special</b> MIFARE Classic tags (aka <i>magic tags</i> 2nd gen/gen2) that support
         writing to the manufacturer block with a simple write command. This App is
         able to write to such tags and can therefore create fully correct clones.
-        <br />However, some special tags require a special command sequence to
+        <br>However, some special tags require a special command sequence to
         put them into the state where writing to the manufacturer block is
         possible. These tags will not work.
-        <br />Also, make sure the the BCC value (see
+        <br>Also, make sure the the BCC value (see
         <a href=""#bcc_tool"">BCC Calculator</a>), the SAK and the ATQA values are
         correct. If you just want to clone a UID, please use the
         <a href=""#clone_uid_tool"">Clone UID Tool</a>.
@@ -351,13 +360,15 @@
       </li>
     </ul>
     If a increment or decrement fails due to an interrupted and therefore
-    incomplete transaction, the Value Block could become unusable.<br /><br />
+    incomplete transaction, the Value Block could become unusable.<br><br>
 
     If you don't know what a MIFARE Classic Value Block is, you should read
     chapter 8.6.2.1 of the
     <a href=""https://www.nxp.com/docs/en/data-sheet/MF1S50YYX_V1.pdf"">
     MIFARE Classic (1k) Datasheet</a> (PDF).
-  <hr />
+
+
+  <hr>
 
 
   <h2 id=""edit_dump_file"">5. Edit Tag Dump File</h2>
@@ -365,12 +376,12 @@
     This editor can be accessed by two different ways:
     <ul>
       <li>
-        <i>Read a tag</i><br />
+        <i>Read a tag</i><br>
         After reading a tag the result is displayed in this
         editor (See chapter <a href=""#read_tag"">Read Tag</a>.)
       </li>
       <li>
-        <i>Open a saved tag</i><br />
+        <i>Open a saved tag</i><br>
         You can edit a saved dump via &quot;Edit Tag Dump&quot; from
         main menu.
       </li>
@@ -381,7 +392,7 @@
   <h3 id=""share_dump"">5.1 Share a Dump</h3>
     From the dump editor you can share a dump (via toolbar or menu item).
     You can choose between Apps that are willing to process the dump file.
-    Note that some Apps fail to process the dump.<br />
+    Note that some Apps fail to process the dump.<br>
     Apps which are known to work with MCT: Gmail, Bluetooth, etc.
 
   <h3 id=""display_ascii"">5.2 Display Data as ASCII</h3>
@@ -407,14 +418,14 @@
 
   <h3 id=""display_manuf_date"">5.5 Display the date of manufacture</h3>
     From the dump editor you can decode the date of manufacture (via the menu).
-    <br /><br />
+    <br><br>
     The last 2 bytes of the manufacturer block (sector 0, block 0) are
     representing the date of manufacture. They should be in binary
     coded decimal format (BCD, only digits, no letters). The first byte
     represents the week of manufacture and must be between 1 and 53.
     The second byte represents the year of manufacture and must be between 0
     and the current year (e.g. 12, meaning 2012).
-    <br /><br />
+    <br><br>
     This is not a standard. Some manufacturers don't stick to this.
     So it is possible that MCT can't display the date of manufacture
     or display a wrong one.
@@ -432,17 +443,19 @@
     You can save the keys of the currently viewed tag into a key file.
     This could be used to speed up the mapping process for the corresponding tag
     because the new key file will only contain valid keys.
-  <hr />
+
+
+  <hr>
 
 
   <h2 id=""edit_key_file"">6. Edit or Add Key File</h2>
     There are two ways to create a key file:
     <ul>
-      <li><i>This Application</i><br />
+      <li><i>This Application</i><br>
         You can create a new key file via
         &quot;Edit/Add Key File&quot; from main menu.
       </li>
-      <li><i>On your Computer</i><br />
+      <li><i>On your Computer</i><br>
         You can create a simple text file on your computer and
         import it using MCT's <a href=""#import_export_tool"">Import/Export Tool</a>.
       </li>
@@ -451,21 +464,23 @@
     key per line (hexadecimal, 6 bytes, 12 characters).
     Lines <b>starting</b> with # as well as empty lines are
     ignored.
-    <br /><br />
+    <br><br>
     You can edit key files any time you want with
     &quot;Edit/Add Key File&quot; from main menu.
-    <br /><br />
+    <br><br>
     Because key files are used like dictionaries in dictionary-attacks,
     it is sufficient to enter only different keys (even if the key
     is used for multiple sectors). You can remove duplicates
     in a key file (via menu) from the key editor. Also it is possible to
     share key files like dump files (see chapter
     <a href=""#share_dump"">Share a Dump</a>).
-    <br /><br />
+    <br><br>
     For other advantages see chapter
     <a href=""#getting_started"">Getting Started</a>, section
     &quot;Advantages of the key files concept&quot;.
-  <hr />
+
+
+  <hr>
 
 
   <h2 id=""tools"">7. Tools</h2>
@@ -474,11 +489,11 @@
   <h3 id=""tag_info_tool"">7.1 Display Tag Info</h3>
     In this view you can see some generic information
     (like UID, ATQA, SAK, Tag size, etc.) about the RFID-Tag.
-    <br /><br />
+    <br><br>
     If your device does not support MIFARE Classic, this is the
     only thing you can do with this App. :(
-    <br /><br />
-    <b>Tag type and manufacturer identification:</b><br />
+    <br><br>
+    <b>Tag type and manufacturer identification:</b><br>
     The identification mechanism is based on
     <a href=""http://nfc-tools.org/index.php?title=ISO14443A"">this website</a>.
     If you want to have a closer look at MIFARE tag identification read
@@ -487,7 +502,7 @@
     <a href=""http://ludovic.rousseau.free.fr/softwares/pcsc-tools/smartcard_list.txt"">
     helpful file</a> for ATS (ATR) based identification is provided
     by the PCSC project.
-    <br /><br />
+    <br><br>
     The tag type and manufacturer determined by MCT could be wrong for
     several reasons:
     <ul>
@@ -502,9 +517,9 @@
     chapter 8.6.2.1 of the
     <a href=""https://www.nxp.com/docs/en/data-sheet/MF1S50YYX_V1.pdf"">
     MIFARE Classic (1k) Datasheet</a> (PDF).
-    <br /><br />
+    <br><br>
     In most cases the &quot;Addr&quot; of a value block is 00 (hex)
-    because it is not used. However, according to NXP it<br />
+    because it is not used. However, according to NXP it<br>
     &quot;can be used to save the storage address of a
     block, when implementing a powerful backup management.&quot;.
 
@@ -526,7 +541,7 @@
     This tool can calculate the Bit Count Check (BCC) value. For MIFARE
     Classic tags with a 4-byte UID, the BCC must be the 5th byte of the very
     first block (manufacturers block).
-    <br /><br />
+    <br><br>
     More information about calculating the BCC and how it is used during
     the anti-collision phase can be found in
     <a href=""http://cache.nxp.com/documents/application_note/AN10927.pdf"">NXP's AN10927</a>.
@@ -545,7 +560,7 @@
     .bin/.mfd/.dump (Proxmark, libnfc, mfoc, others), .eml (Proxmark emulator) and
     .json (Proxmark, Chameleon Mini GUI). For converting a dump file from e.g.
     .bin to .json, it can be simply imported and then exported again.
-    <br /><br />
+    <br><br>
     A full backup of all dump and key files can be made using the backup function.
     The data will be saved as ZIP archive.
 
@@ -564,7 +579,7 @@
     or shared with other apps.
 
 
-  <hr />
+  <hr>
 
 
   <h2 id=""external_nfc"">8. External NFC</h2>
@@ -572,7 +587,7 @@
     <a href=""https://play.google.com/store/apps/details?id=eu.dedb.nfc.service"">External NFC</a>.
     This app allows you to connect an external USB-based RFID reader to
     your Android device. Not every RFID reader is supported by External
-    NFC and your Android device must be USB-OTG enabled.<br /><br />
+    NFC and your Android device must be USB-OTG enabled.<br><br>
 
     Readers which should work:
     <ul>
@@ -581,7 +596,7 @@
       <li>PN532 via USB-UART adapters</li>
     </ul>
 
-    According to user reports, the ACR 122U reader works the best.<br /><br />
+    According to user reports, the ACR 122U reader works the best.<br><br>
 
     For questions regarding the External NFC app please have a look at its
     <a href=""https://play.google.com/store/apps/details?id=eu.dedb.nfc.service"">Play Store</a>",Added old keys / dumps path to help & info + made it HTML5 conform .,"""Update help.html file with minor formatting changes and improvements""","""Update help.html to improve formatting and clarity""","Update HTML syntax to comply with HTML5 standards

The changes made in this commit are mainly related to updating the HTML syntax to comply with HTML5 standards. The DOCTYPE declaration has been updated from XHTML 1.0 Transitional to HTML5. The xmlns attribute has been removed from the html tag, and the lang attribute has been added to specify the language of the document. Additionally, some self-closing tags have been updated to include a closing tag, and some unnecessary line breaks have been removed.","Update help.html: change XML declaration to HTML5, adjust formatting and replace some deprecated tags.",Model 2
"diff --git a/core/client/src/main/java/alluxio/client/file/options/CompleteUfsFileOptions.java b/core/client/src/main/java/alluxio/client/file/options/CompleteUfsFileOptions.java
index a0f2df91a1..a090d40e3f 100644
--- a/core/client/src/main/java/alluxio/client/file/options/CompleteUfsFileOptions.java
+++ b/core/client/src/main/java/alluxio/client/file/options/CompleteUfsFileOptions.java
@@ -140,9 +140,8 @@ public final class CompleteUfsFileOptions {
     if (!mGroup.isEmpty()) {
       options.setGroup(mGroup);
     }
-    short mode = mMode.toShort();
-    if (mode != Constants.INVALID_MODE) {
-      options.setMode(mode);
+    if (mMode != null && mMode.toShort() != Constants.INVALID_MODE) {
+      options.setMode(mMode.toShort());
     }
     return options;
   }
diff --git a/core/client/src/main/java/alluxio/client/file/options/CreateDirectoryOptions.java b/core/client/src/main/java/alluxio/client/file/options/CreateDirectoryOptions.java
index 8dac92d1a9..23f88dc7a0 100644
--- a/core/client/src/main/java/alluxio/client/file/options/CreateDirectoryOptions.java
+++ b/core/client/src/main/java/alluxio/client/file/options/CreateDirectoryOptions.java
@@ -35,7 +35,7 @@ import javax.annotation.concurrent.NotThreadSafe;
 @JsonInclude(Include.NON_EMPTY)
 public final class CreateDirectoryOptions {
   private boolean mAllowExists;
-  private Mode mMode; // null if creating the dir using system default mode
+  private Mode mMode;
   private long mTtl;
   private TtlAction mTtlAction;
   private boolean mRecursive;
@@ -51,7 +51,7 @@ public final class CreateDirectoryOptions {
   private CreateDirectoryOptions() {
     mRecursive = false;
     mAllowExists = false;
-    mMode = null;
+    mMode = Mode.defaults().applyDirectoryUMask();
     mTtl = Constants.NO_TTL;
     mTtlAction = TtlAction.DELETE;
     mWriteType =
diff --git a/core/client/src/main/java/alluxio/client/file/options/CreateFileOptions.java b/core/client/src/main/java/alluxio/client/file/options/CreateFileOptions.java
index 26a028cc77..8713388230 100644
--- a/core/client/src/main/java/alluxio/client/file/options/CreateFileOptions.java
+++ b/core/client/src/main/java/alluxio/client/file/options/CreateFileOptions.java
@@ -45,7 +45,7 @@ public final class CreateFileOptions {
   private long mBlockSizeBytes;
   private long mTtl;
   private TtlAction mTtlAction;
-  private Mode mMode; // null if creating the file using system default mode
+  private Mode mMode;
   private int mWriteTier;
   private WriteType mWriteType;
 
@@ -70,7 +70,7 @@ public final class CreateFileOptions {
     mWriteType = Configuration.getEnum(PropertyKey.USER_FILE_WRITE_TYPE_DEFAULT, WriteType.class);
     mTtl = Constants.NO_TTL;
     mTtlAction = TtlAction.DELETE;
-    mMode = null;
+    mMode = Mode.defaults().applyFileUMask();
   }
 
   /**
diff --git a/core/client/src/main/java/alluxio/client/file/options/CreateUfsFileOptions.java b/core/client/src/main/java/alluxio/client/file/options/CreateUfsFileOptions.java
index 78f76626d4..cbda3d68fc 100644
--- a/core/client/src/main/java/alluxio/client/file/options/CreateUfsFileOptions.java
+++ b/core/client/src/main/java/alluxio/client/file/options/CreateUfsFileOptions.java
@@ -140,9 +140,8 @@ public final class CreateUfsFileOptions {
     if (!mGroup.isEmpty()) {
       options.setGroup(mGroup);
     }
-    short mode = mMode.toShort();
-    if (mode != Constants.INVALID_MODE) {
-      options.setMode(mode);
+    if (mMode != null && mMode.toShort() != Constants.INVALID_MODE) {
+      options.setMode(mMode.toShort());
     }
     return options;
   }
diff --git a/core/client/src/main/java/alluxio/client/file/options/OutStreamOptions.java b/core/client/src/main/java/alluxio/client/file/options/OutStreamOptions.java
index e773000d01..7baaadbfa9 100644
--- a/core/client/src/main/java/alluxio/client/file/options/OutStreamOptions.java
+++ b/core/client/src/main/java/alluxio/client/file/options/OutStreamOptions.java
@@ -69,13 +69,8 @@ public final class OutStreamOptions {
     }
     mWriteTier = Configuration.getInt(PropertyKey.USER_FILE_WRITE_TIER_DEFAULT);
     mWriteType = Configuration.getEnum(PropertyKey.USER_FILE_WRITE_TYPE_DEFAULT, WriteType.class);
-    try {
-      // Set user and group from user login module.
-      mOwner = SecurityUtils.getOwnerFromLoginModule();
-      mGroup = SecurityUtils.getGroupFromLoginModule();
-    } catch (IOException e) {
-      // Fall through to system property approach
-    }
+    mOwner = SecurityUtils.getOwnerFromLoginModule();
+    mGroup = SecurityUtils.getGroupFromLoginModule();
     mMode = Mode.defaults().applyFileUMask();
   }
 
diff --git a/core/client/src/test/java/alluxio/client/file/options/CompleteUfsFileOptionsTest.java b/core/client/src/test/java/alluxio/client/file/options/CompleteUfsFileOptionsTest.java
index 7b8ffd5520..009dd1709a 100644
--- a/core/client/src/test/java/alluxio/client/file/options/CompleteUfsFileOptionsTest.java
+++ b/core/client/src/test/java/alluxio/client/file/options/CompleteUfsFileOptionsTest.java
@@ -70,7 +70,7 @@ public final class CompleteUfsFileOptionsTest {
     CompleteUfsFileOptions options = CompleteUfsFileOptions.defaults();
     Assert.assertEquals(TEST_USER, options.getOwner());
     Assert.assertEquals(TEST_USER, options.getGroup());
-    Assert.assertEquals(Mode.defaults().applyDirectoryUMask(), options.getMode());
+    Assert.assertEquals(Mode.defaults().applyFileUMask(), options.getMode());
   }
 
   /**
diff --git a/core/client/src/test/java/alluxio/client/file/options/CreateDirectoryOptionsTest.java b/core/client/src/test/java/alluxio/client/file/options/CreateDirectoryOptionsTest.java
index 91a0b6f4c8..eea027fd3b 100644
--- a/core/client/src/test/java/alluxio/client/file/options/CreateDirectoryOptionsTest.java
+++ b/core/client/src/test/java/alluxio/client/file/options/CreateDirectoryOptionsTest.java
@@ -31,9 +31,6 @@ import java.util.Random;
 /**
  * Tests for the {@link CreateDirectoryOptions} class.
  */
-@RunWith(PowerMockRunner.class)
-// Need to mock Mode to use CommonTestUtils#testEquals.
-@PrepareForTest(Mode.class)
 public class CreateDirectoryOptionsTest {
   private final WriteType mDefaultWriteType =
       Configuration.getEnum(PropertyKey.USER_FILE_WRITE_TYPE_DEFAULT, WriteType.class);
diff --git a/core/client/src/test/java/alluxio/client/file/options/CreateFileOptionsTest.java b/core/client/src/test/java/alluxio/client/file/options/CreateFileOptionsTest.java
index c0c2113608..f6be7f54ea 100644
--- a/core/client/src/test/java/alluxio/client/file/options/CreateFileOptionsTest.java
+++ b/core/client/src/test/java/alluxio/client/file/options/CreateFileOptionsTest.java
@@ -33,9 +33,6 @@ import java.util.Random;
 /**
  * Tests for the {@link CreateFileOptions} class.
  */
-@RunWith(PowerMockRunner.class)
-// Need to mock Mode to use CommonTestUtils#testEquals.
-@PrepareForTest(Mode.class)
 public class CreateFileOptionsTest {
   private final long mDefaultBlockSizeBytes = Configuration.getBytes(
       PropertyKey.USER_BLOCK_SIZE_BYTES_DEFAULT);
diff --git a/core/client/src/test/java/alluxio/client/file/options/CreateUfsFileOptionsTest.java b/core/client/src/test/java/alluxio/client/file/options/CreateUfsFileOptionsTest.java
index 3242ab838f..4d9122e89c 100644
--- a/core/client/src/test/java/alluxio/client/file/options/CreateUfsFileOptionsTest.java
+++ b/core/client/src/test/java/alluxio/client/file/options/CreateUfsFileOptionsTest.java
@@ -70,7 +70,7 @@ public final class CreateUfsFileOptionsTest {
     CreateUfsFileOptions options = CreateUfsFileOptions.defaults();
     Assert.assertEquals(TEST_USER, options.getOwner());
     Assert.assertEquals(TEST_USER, options.getGroup());
-    Assert.assertEquals(Mode.defaults().applyDirectoryUMask(), options.getMode());
+    Assert.assertEquals(Mode.defaults().applyFileUMask(), options.getMode());
   }
 
   /**
diff --git a/core/client/src/test/java/alluxio/client/file/options/OutStreamOptionsTest.java b/core/client/src/test/java/alluxio/client/file/options/OutStreamOptionsTest.java
index 347fa44a21..b88e3a996f 100644
--- a/core/client/src/test/java/alluxio/client/file/options/OutStreamOptionsTest.java
+++ b/core/client/src/test/java/alluxio/client/file/options/OutStreamOptionsTest.java
@@ -60,9 +60,9 @@ public class OutStreamOptionsTest {
     Assert.assertEquals(alluxioType, options.getAlluxioStorageType());
     Assert.assertEquals(64 * Constants.MB, options.getBlockSizeBytes());
     Assert.assertTrue(options.getLocationPolicy() instanceof LocalFirstPolicy);
-    Assert.assertEquals("""", options.getOwner());
+    Assert.assertEquals(""test"", options.getOwner());
     Assert.assertEquals("""", options.getGroup());
-    Assert.assertEquals(Mode.defaults().applyDirectoryUMask(), options.getMode());
+    Assert.assertEquals(Mode.defaults().applyFileUMask(), options.getMode());
     Assert.assertEquals(Constants.NO_TTL, options.getTtl());
     Assert.assertEquals(TtlAction.DELETE, options.getTtlAction());
     Assert.assertEquals(ufsType, options.getUnderStorageType());
diff --git a/core/common/src/main/java/alluxio/security/authorization/Mode.java b/core/common/src/main/java/alluxio/security/authorization/Mode.java
index 9f447f94b2..b87c349407 100644
--- a/core/common/src/main/java/alluxio/security/authorization/Mode.java
+++ b/core/common/src/main/java/alluxio/security/authorization/Mode.java
@@ -59,7 +59,11 @@ public final class Mode {
     return new Mode(Bits.ALL, Bits.ALL, Bits.ALL);
   }
 
-  private Mode() {} // needed for JSON serialization and deserialization
+  private Mode() {
+    mOwnerBits = Bits.NONE;
+    mGroupBits = Bits.NONE;
+    mOtherBits = Bits.NONE;
+  } // needed for equality testing and JSON serialization and deserialization
 
   /**
    * Constructs an instance of {@link Mode} with the given {@link Bits}.
@@ -238,7 +242,7 @@ public final class Mode {
   private void applyUMask(Mode umask) {
     mOwnerBits = mOwnerBits.and(umask.mOwnerBits.not());
     mGroupBits = mGroupBits.and(umask.mGroupBits.not());
-    mOwnerBits = mOtherBits.and(umask.mOtherBits.not());
+    mOtherBits = mOtherBits.and(umask.mOtherBits.not());
   }
 
   /**
@@ -250,7 +254,7 @@ public final class Mode {
     int umask = Constants.DEFAULT_FILE_SYSTEM_UMASK;
     String confUmask = Configuration.get(PropertyKey.SECURITY_AUTHORIZATION_PERMISSION_UMASK);
     if (confUmask != null) {
-      if ((confUmask.length() > 4) || !tryParseInt(confUmask)) {
+      if ((confUmask.length() > 4) || !isValid(confUmask)) {
         throw new IllegalArgumentException(ExceptionMessage.INVALID_CONFIGURATION_VALUE
             .getMessage(confUmask, PropertyKey.SECURITY_AUTHORIZATION_PERMISSION_UMASK));
       }
@@ -264,7 +268,7 @@ public final class Mode {
     return new Mode((short) umask);
   }
 
-  private static boolean tryParseInt(String value) {
+  private static boolean isValid(String value) {
     try {
       Integer.parseInt(value);
       return true;
diff --git a/core/common/src/main/java/alluxio/util/SecurityUtils.java b/core/common/src/main/java/alluxio/util/SecurityUtils.java
index fe504c3765..395b5a7ac7 100644
--- a/core/common/src/main/java/alluxio/util/SecurityUtils.java
+++ b/core/common/src/main/java/alluxio/util/SecurityUtils.java
@@ -58,23 +58,43 @@ public final class SecurityUtils {
     return Configuration.getBoolean(PropertyKey.SECURITY_AUTHORIZATION_PERMISSION_ENABLED);
   }
 
-  public static String getOwnerFromLoginModule() throws IOException {
-    return LoginUser.get().getName();
+  public static String getOwnerFromLoginModule() {
+    try {
+      return LoginUser.get().getName();
+    } catch (IOException| UnsupportedOperationException e) {
+      return """";
+    }
   }
 
-  public static String getOwnerFromThriftClient() throws IOException {
-    User user = AuthenticatedClientUser.get();
-    if (user == null) {
-      throw new IOException(ExceptionMessage.AUTHORIZED_CLIENT_USER_IS_NULL.getMessage());
+  public static String getOwnerFromThriftClient() {
+    try {
+      User user = AuthenticatedClientUser.get();
+      if (user == null) {
+        return """";
+      }
+      return user.getName();
+    } catch (IOException e) {
+      return """";
     }
-    return user.getName();
   }
 
-  public static String getGroupFromLoginModule() throws IOException {
-    return CommonUtils.getPrimaryGroupName(getOwnerFromLoginModule());
+  public static String getGroupFromLoginModule() {
+    try {
+      return CommonUtils.getPrimaryGroupName(LoginUser.get().getName());
+    } catch (IOException | UnsupportedOperationException e) {
+      return """";
+    }
   }
 
-  public static String getGroupFromThriftClient() throws IOException {
-    return CommonUtils.getPrimaryGroupName(getOwnerFromThriftClient());
+  public static String getGroupFromThriftClient() {
+    try {
+      User user = AuthenticatedClientUser.get();
+      if (user == null) {
+        return """";
+      }
+      return CommonUtils.getPrimaryGroupName(user.getName());
+    } catch (IOException e) {
+      return """";
+    }
   }
 }
diff --git a/core/common/src/test/java/alluxio/underfs/options/CreateOptionsTest.java b/core/common/src/test/java/alluxio/underfs/options/CreateOptionsTest.java
index f46ebb0063..290c50ba07 100644
--- a/core/common/src/test/java/alluxio/underfs/options/CreateOptionsTest.java
+++ b/core/common/src/test/java/alluxio/underfs/options/CreateOptionsTest.java
@@ -43,7 +43,7 @@ public final class CreateOptionsTest {
     Assert.assertTrue(options.isEnsureAtomic());
     Assert.assertEquals("""", options.getOwner());
     Assert.assertEquals("""", options.getGroup());
-    Assert.assertEquals(Mode.defaults().applyDirectoryUMask(), options.getMode());
+    Assert.assertEquals(Mode.defaults().applyFileUMask(), options.getMode());
   }
 
   /**
@@ -64,7 +64,7 @@ public final class CreateOptionsTest {
     Assert.assertTrue(options.isEnsureAtomic());
     Assert.assertEquals("""", options.getOwner());
     Assert.assertEquals("""", options.getGroup());
-    Assert.assertEquals(Mode.defaults().applyDirectoryUMask(), options.getMode());
+    Assert.assertEquals(Mode.defaults().applyFileUMask(), options.getMode());
   }
 
   /**
diff --git a/core/common/src/test/java/alluxio/util/SecurityUtilsTest.java b/core/common/src/test/java/alluxio/util/SecurityUtilsTest.java
index e0e79a1765..c12a71dcbb 100644
--- a/core/common/src/test/java/alluxio/util/SecurityUtilsTest.java
+++ b/core/common/src/test/java/alluxio/util/SecurityUtilsTest.java
@@ -27,6 +27,7 @@ public class SecurityUtilsTest {
 
   @After
   public void after() {
+    LoginUserTestUtils.resetLoginUser();
     ConfigurationTestUtils.resetConfiguration();
   }
 
@@ -76,7 +77,6 @@ public class SecurityUtilsTest {
     Configuration.set(PropertyKey.SECURITY_LOGIN_USERNAME, ""test_login_user"");
     Configuration.set(PropertyKey.SECURITY_GROUP_MAPPING_CLASS,
         IdentityUserGroupsMapping.class.getName());
-    LoginUserTestUtils.resetLoginUser();
     Assert.assertEquals(""test_login_user"", SecurityUtils.getOwnerFromLoginModule());
   }
 
@@ -84,7 +84,7 @@ public class SecurityUtilsTest {
    * Tests the {@link SecurityUtils#getGroupFromLoginModule()} method.
    */
   @Test
-  public void getGroupFromLoginModule() throws Exception {
+  public void getGroupFromLoginModuleError() throws Exception {
     // When security is not enabled, user and group are not set
     Configuration.set(PropertyKey.SECURITY_AUTHENTICATION_TYPE, AuthType.NOSASL.getAuthName());
     Assert.assertEquals("""", SecurityUtils.getGroupFromLoginModule());
diff --git a/core/server/src/test/java/alluxio/master/file/meta/InodeTreeTest.java b/core/server/src/test/java/alluxio/master/file/meta/InodeTreeTest.java
index b5216b4f2c..74b79b1cdc 100644
--- a/core/server/src/test/java/alluxio/master/file/meta/InodeTreeTest.java
+++ b/core/server/src/test/java/alluxio/master/file/meta/InodeTreeTest.java
@@ -142,7 +142,7 @@ public final class InodeTreeTest {
     Assert.assertEquals(TEST_PATH, test.getName());
     Assert.assertTrue(test.isDirectory());
     Assert.assertEquals(""user1"", test.getOwner());
-    Assert.assertTrue(test.getGroup().isEmpty());
+    Assert.assertEquals(""group1"", test.getGroup());
     Assert.assertEquals((short) 0755, test.getMode());
 
     // create nested directory
@@ -153,7 +153,7 @@ public final class InodeTreeTest {
     Assert.assertEquals(2, nested.getParentId());
     Assert.assertTrue(test.isDirectory());
     Assert.assertEquals(""user1"", test.getOwner());
-    Assert.assertTrue(test.getGroup().isEmpty());
+    Assert.assertEquals(""group1"", test.getGroup());
     Assert.assertEquals((short) 0755, test.getMode());
   }
 
@@ -209,7 +209,7 @@ public final class InodeTreeTest {
     Assert.assertEquals(2, nestedFile.getParentId());
     Assert.assertTrue(nestedFile.isFile());
     Assert.assertEquals(""user1"", nestedFile.getOwner());
-    Assert.assertTrue(nestedFile.getGroup().isEmpty());
+    Assert.assertEquals(""group1"", nestedFile.getGroup());
     Assert.assertEquals((short) 0644, nestedFile.getMode());
   }
 ",Fixing up test failures .,"""Refactor file options to use default mode and owner/group from login module""","""Update file and directory mode defaults to apply file UMASK""","""Update Mode defaults and handling in client options and SecurityUtils""

This commit makes several changes to the Alluxio codebase:

1. It updates the default Mode for CreateDirectoryOptions, CreateFileOptions, CompleteUfsFileOptions, and OutStreamOptions to use the file umask instead of the directory umask.
2. It modifies the Mode class to initialize the owner, group, and other bits to Bits.NONE in the default constructor, which is used for equality testing and JSON serialization and deserialization.
3. It adds a new method isValid to the Mode class to check if a string is a valid mode representation.
4. It updates the SecurityUtils class to return an empty string instead of throwing an exception when the user or group cannot be determined from the login module or the Thrift client.
5. It updates several tests to reflect the changes in the default Mode and the handling of user and group names in SecurityUtils.

These changes affect the behavior of Alluxio when creating directories and files, and when determining the user and group names for authentication and authorization purposes. The commit message should reflect these changes and provide a brief explanation of why they were made.","Refactored mode handling and owner/group retrieval for create options, updated tests for better error handling and consistency.",Model 4
"diff --git a/resources/languages/resources.properties b/resources/languages/resources.properties
index dffa5525f..ac433864f 100644
--- a/resources/languages/resources.properties
+++ b/resources/languages/resources.properties
@@ -1070,6 +1070,7 @@ plugin.keybindings.OPEN_SMILIES=Show Smileys
 plugin.keybindings.globalchooser.ANSWER_CALL=Answer call
 plugin.keybindings.globalchooser.HANGUP_CALL=Hangup call
 plugin.keybindings.globalchooser.SHOW_CONTACTLIST=Show contact list
+plugin.keybindings.globalchooser.MUTE_CALLS=Mute calls
 plugin.keybindings.globalchooser.SHORTCUT_NAME=Name
 plugin.keybindings.globalchooser.SHORTCUT_PRIMARY=Primary shortcut
 plugin.keybindings.globalchooser.SHORTCUT_SECOND=Second shortcut",Adds resources string for the mute / unmute global shortcut feature .,"""Added 'Mute calls' keybinding option""",Added keybinding for muting calls in global chooser.,"""Added keybinding property for 'Mute calls' in resources.properties""",Added a new keybinding for muting calls under global chooser in the resources.properties file.,Model 1
"diff --git a/src/cpp/desktop/DesktopInfo.cpp b/src/cpp/desktop/DesktopInfo.cpp
index 339028cefa..b6e3e80ab5 100644
--- a/src/cpp/desktop/DesktopInfo.cpp
+++ b/src/cpp/desktop/DesktopInfo.cpp
@@ -34,9 +34,10 @@ namespace desktop {
 
 namespace {
 
-QString s_platform          = kUnknown;
-QString s_version           = kUnknown;
-QString s_sumatraPdfExePath = kUnknown;
+QString s_platform           = kUnknown;
+QString s_version            = kUnknown;
+QString s_sumatraPdfExePath  = kUnknown;
+QString s_fixedWidthFontList = kUnknown;
 
 #ifdef Q_OS_LINUX
 
@@ -129,7 +130,24 @@ DesktopInfo::DesktopInfo(QObject* parent)
 {
    initialize();
 
-   QObject::connect(this, &DesktopInfo::sumatraPdfExePathChanged, &DesktopInfo::setSumatraPdfExePath);
+   QObject::connect(
+            this,
+            &DesktopInfo::sumatraPdfExePathChanged,
+            &DesktopInfo::setSumatraPdfExePath);
+
+   QObject::connect(
+            this,
+            &DesktopInfo::fixedWidthFontListChanged,
+            &DesktopInfo::setFixedWidthFontList);
+
+   // TODO: consider deferring this work as it may
+   // be expensive (don't want it to slow down startup)
+   QFontDatabase db;
+   QStringList fonts;
+   for (QString family : db.families())
+      if (db.isFixedPitch(family))
+         fonts.append(family);
+   s_fixedWidthFontList = fonts.join(QStringLiteral(""\n""));
 }
 
 QString DesktopInfo::getPlatform()
@@ -155,8 +173,12 @@ QString DesktopInfo::getScrollingCompensationType()
 
 QString DesktopInfo::getFixedWidthFontList()
 {
-   // TODO: read from QFont database
-   return QStringLiteral(""None"");
+   return s_fixedWidthFontList;
+}
+
+void DesktopInfo::setFixedWidthFontList(QString list)
+{
+   s_fixedWidthFontList = list;
 }
 
 QString DesktopInfo::getFixedWidthFont()
diff --git a/src/cpp/desktop/DesktopInfo.hpp b/src/cpp/desktop/DesktopInfo.hpp
index bcda94f00f..4d6be15bc0 100644
--- a/src/cpp/desktop/DesktopInfo.hpp
+++ b/src/cpp/desktop/DesktopInfo.hpp
@@ -30,6 +30,7 @@ class DesktopInfo : public QObject
 
 Q_SIGNALS:
    void sumatraPdfExePathChanged(QString value);
+   void fixedWidthFontListChanged(QString value);
 
 public:
    explicit DesktopInfo(QObject* parent = nullptr);
@@ -44,7 +45,11 @@ public:
    Q_PROPERTY(QString scrollingCompensationType READ getScrollingCompensationType CONSTANT)
 
    Q_INVOKABLE QString getFixedWidthFontList();
-   Q_PROPERTY(QString fixedWidthFontList READ getFixedWidthFontList CONSTANT)
+   Q_INVOKABLE void setFixedWidthFontList(QString list);
+   Q_PROPERTY(QString fixedWidthFontList
+              READ getFixedWidthFontList
+              WRITE setFixedWidthFontList
+              NOTIFY fixedWidthFontListChanged)
 
    Q_INVOKABLE QString getFixedWidthFont();
    Q_PROPERTY(QString fixedWidthFont READ getFixedWidthFont CONSTANT)
@@ -60,7 +65,10 @@ public:
 
    Q_INVOKABLE QString getSumatraPdfExePath();
    Q_INVOKABLE void setSumatraPdfExePath(QString path);
-   Q_PROPERTY(QString sumatraPdfExePath READ getSumatraPdfExePath WRITE setSumatraPdfExePath NOTIFY sumatraPdfExePathChanged)
+   Q_PROPERTY(QString sumatraPdfExePath
+              READ getSumatraPdfExePath
+              WRITE setSumatraPdfExePath
+              NOTIFY sumatraPdfExePathChanged)
 };
 
 inline DesktopInfo& desktopInfo()",handle fonts,"""Added support for retrieving fixed-width font list from QFontDatabase""","""Added support for fixed-width fonts and improved DesktopInfo class""

Alternatively, you could also use:

* ""Added fixed-width font list and improved DesktopInfo class""
* ""Improved DesktopInfo class with fixed-width font support""
* ""Added fixed-width font functionality to DesktopInfo class""

These commit messages are concise and accurately describe the changes made in the commit.","""Add support for fixed-width font list in DesktopInfo""

Explanation: This commit introduces a new member variable `s_fixedWidthFontList` in the `DesktopInfo` class, along with the corresponding getter and setter methods. The constructor of the class now initializes the `s_fixedWidthFontList` by querying the `QFontDatabase` for fixed-width fonts. Furthermore, a new signal `fixedWidthFontListChanged` has been added, and the class now emits this signal whenever the fixed-width font list changes. Lastly, the class now exposes a new Q\_PROPERTY `fixedWidthFontList` that allows users to read and write the fixed-width font list.",Add support for fetching and setting fixed-width font lists in DesktopInfo.,Model 1
"diff --git a/jodd-core/src/main/java/jodd/typeconverter/impl/BooleanArrayConverter.java b/jodd-core/src/main/java/jodd/typeconverter/impl/BooleanArrayConverter.java
index 4f9cced5e..c9caaa2a3 100644
--- a/jodd-core/src/main/java/jodd/typeconverter/impl/BooleanArrayConverter.java
+++ b/jodd-core/src/main/java/jodd/typeconverter/impl/BooleanArrayConverter.java
@@ -5,9 +5,9 @@ package jodd.typeconverter.impl;
 import jodd.typeconverter.TypeConverter;
 import jodd.typeconverter.TypeConverterManagerBean;
 import jodd.util.StringUtil;
+import jodd.util.collection.BooleanArrayList;
 
 import java.util.Collection;
-import java.util.Iterator;
 import java.util.List;
 
 /**
@@ -83,20 +83,12 @@ public class BooleanArrayConverter implements TypeConverter<boolean[]> {
 		if (value instanceof Iterable) {
 			Iterable iterable = (Iterable) value;
 
-            int count = 0;
-			Iterator iterator = iterable.iterator();
-			while (iterator.hasNext()) {
-				iterator.next();
-				count++;
-			}
-
-			boolean[] target = new boolean[count];
-			int i = 0;
+			BooleanArrayList booleanArrayList = new BooleanArrayList();
 			for (Object element : iterable) {
-				target[i] = convertType(element);
-            	i++;
+				boolean convertedValue = convertType(element);
+				booleanArrayList.add(convertedValue);
             }
-			return target;
+			return booleanArrayList.toArray();
 		}
 
 		if (value instanceof CharSequence) {
diff --git a/jodd-core/src/main/java/jodd/typeconverter/impl/ByteArrayConverter.java b/jodd-core/src/main/java/jodd/typeconverter/impl/ByteArrayConverter.java
index 4592c3706..77b3825a8 100644
--- a/jodd-core/src/main/java/jodd/typeconverter/impl/ByteArrayConverter.java
+++ b/jodd-core/src/main/java/jodd/typeconverter/impl/ByteArrayConverter.java
@@ -7,6 +7,7 @@ import jodd.typeconverter.TypeConversionException;
 import jodd.typeconverter.TypeConverter;
 import jodd.typeconverter.TypeConverterManagerBean;
 import jodd.util.StringUtil;
+import jodd.util.collection.ByteArrayList;
 
 import java.io.File;
 import java.io.IOException;
@@ -111,19 +112,13 @@ public class ByteArrayConverter implements TypeConverter<byte[]> {
 		if (value instanceof Iterable) {
 			Iterable iterable = (Iterable) value;
 
-            int count = 0;
+			ByteArrayList byteArrayList = new ByteArrayList();
 			for (Object element : iterable) {
-				count++;
-			}
-
-			byte[] target = new byte[count];
-			int i = 0;
-			for (Object element : iterable) {
-				target[i] = convertType(element);
-            	i++;
+				byte convertedValue = convertType(element);
+				byteArrayList.add(convertedValue);
             }
 
-			return target;
+			return byteArrayList.toArray();
 		}
 
 		if (value instanceof CharSequence) {
diff --git a/jodd-core/src/main/java/jodd/typeconverter/impl/CharacterArrayConverter.java b/jodd-core/src/main/java/jodd/typeconverter/impl/CharacterArrayConverter.java
index 08e04a15c..9a0fedede 100644
--- a/jodd-core/src/main/java/jodd/typeconverter/impl/CharacterArrayConverter.java
+++ b/jodd-core/src/main/java/jodd/typeconverter/impl/CharacterArrayConverter.java
@@ -5,6 +5,7 @@ package jodd.typeconverter.impl;
 
 import jodd.typeconverter.TypeConverter;
 import jodd.typeconverter.TypeConverterManagerBean;
+import jodd.util.collection.CharArrayList;
 
 import java.util.Collection;
 import java.util.List;
@@ -84,19 +85,13 @@ public class CharacterArrayConverter implements TypeConverter<char[]> {
 		if (value instanceof Iterable) {
 			Iterable iterable = (Iterable) value;
 
-            int count = 0;
+			CharArrayList charArrayList = new CharArrayList();
 			for (Object element : iterable) {
-				count++;
-			}
-
-			char[] target = new char[count];
-			int i = 0;
-			for (Object element : iterable) {
-				target[i] = convertType(element);
-            	i++;
+				char convertedValue = convertType(element);
+				charArrayList.add(convertedValue);
             }
 
-			return target;
+			return charArrayList.toArray();
 		}
 
 		if (value instanceof CharSequence) {
diff --git a/jodd-core/src/main/java/jodd/typeconverter/impl/DoubleArrayConverter.java b/jodd-core/src/main/java/jodd/typeconverter/impl/DoubleArrayConverter.java
index c75837e32..dbff6fa96 100644
--- a/jodd-core/src/main/java/jodd/typeconverter/impl/DoubleArrayConverter.java
+++ b/jodd-core/src/main/java/jodd/typeconverter/impl/DoubleArrayConverter.java
@@ -5,6 +5,7 @@ package jodd.typeconverter.impl;
 import jodd.typeconverter.TypeConverter;
 import jodd.typeconverter.TypeConverterManagerBean;
 import jodd.util.StringUtil;
+import jodd.util.collection.DoubleArrayList;
 
 import java.util.Collection;
 import java.util.List;
@@ -84,19 +85,14 @@ public class DoubleArrayConverter implements TypeConverter<double[]> {
 		if (value instanceof Iterable) {
 			Iterable iterable = (Iterable) value;
 
-            int count = 0;
-			for (Object element : iterable) {
-				count++;
-			}
+			DoubleArrayList doubleArrayList = new DoubleArrayList();
 
-			double[] target = new double[count];
-			int i = 0;
 			for (Object element : iterable) {
-				target[i] = convertType(element);
-            	i++;
+				double convertedValue = convertType(element);
+				doubleArrayList.add(convertedValue);
             }
 
-			return target;
+			return doubleArrayList.toArray();
 		}
 
 		if (value instanceof CharSequence) {
diff --git a/jodd-core/src/main/java/jodd/typeconverter/impl/FloatArrayConverter.java b/jodd-core/src/main/java/jodd/typeconverter/impl/FloatArrayConverter.java
index 0a0f5a9f9..813981cec 100644
--- a/jodd-core/src/main/java/jodd/typeconverter/impl/FloatArrayConverter.java
+++ b/jodd-core/src/main/java/jodd/typeconverter/impl/FloatArrayConverter.java
@@ -5,6 +5,7 @@ package jodd.typeconverter.impl;
 import jodd.typeconverter.TypeConverter;
 import jodd.typeconverter.TypeConverterManagerBean;
 import jodd.util.StringUtil;
+import jodd.util.collection.FloatArrayList;
 
 import java.util.Collection;
 import java.util.List;
@@ -84,19 +85,14 @@ public class FloatArrayConverter implements TypeConverter<float[]> {
 		if (value instanceof Iterable) {
 			Iterable iterable = (Iterable) value;
 
-            int count = 0;
-			for (Object element : iterable) {
-				count++;
-			}
+			FloatArrayList floatArrayList = new FloatArrayList();
 
-			float[] target = new float[count];
-			int i = 0;
 			for (Object element : iterable) {
-				target[i] = convertType(element);
-            	i++;
+				float convertedValue = convertType(element);
+				floatArrayList.add(convertedValue);
             }
 
-			return target;
+			return floatArrayList.toArray();
 		}
 
 		if (value instanceof CharSequence) {
diff --git a/jodd-core/src/main/java/jodd/typeconverter/impl/IntegerArrayConverter.java b/jodd-core/src/main/java/jodd/typeconverter/impl/IntegerArrayConverter.java
index ef794b986..acb6e18ef 100644
--- a/jodd-core/src/main/java/jodd/typeconverter/impl/IntegerArrayConverter.java
+++ b/jodd-core/src/main/java/jodd/typeconverter/impl/IntegerArrayConverter.java
@@ -5,9 +5,9 @@ package jodd.typeconverter.impl;
 import jodd.typeconverter.TypeConverter;
 import jodd.typeconverter.TypeConverterManagerBean;
 import jodd.util.StringUtil;
+import jodd.util.collection.IntArrayList;
 
 import java.util.Collection;
-import java.util.Iterator;
 import java.util.List;
 
 /**
@@ -84,21 +84,14 @@ public class IntegerArrayConverter implements TypeConverter<int[]> {
 		if (value instanceof Iterable) {
 			Iterable iterable = (Iterable) value;
 
-			int count = 0;
-			Iterator iterator = iterable.iterator();
-			while (iterator.hasNext()) {
-				iterator.next();
-				count++;
-			}
+			IntArrayList intArrayList = new IntArrayList();
 
-			int[] target = new int[count];
-			int i = 0;
 			for (Object element : iterable) {
-				target[i] = convertType(element);
-				i++;
+				int convertedValue = convertType(element);
+				intArrayList.add(convertedValue);
 			}
 
-			return target;
+			return intArrayList.toArray();
 		}
 
 		if (value instanceof CharSequence) {
diff --git a/jodd-core/src/main/java/jodd/typeconverter/impl/LongArrayConverter.java b/jodd-core/src/main/java/jodd/typeconverter/impl/LongArrayConverter.java
index 541a0b765..79e0a4a7f 100644
--- a/jodd-core/src/main/java/jodd/typeconverter/impl/LongArrayConverter.java
+++ b/jodd-core/src/main/java/jodd/typeconverter/impl/LongArrayConverter.java
@@ -5,6 +5,7 @@ package jodd.typeconverter.impl;
 import jodd.typeconverter.TypeConverter;
 import jodd.typeconverter.TypeConverterManagerBean;
 import jodd.util.StringUtil;
+import jodd.util.collection.LongArrayList;
 
 import java.util.Collection;
 import java.util.List;
@@ -84,19 +85,14 @@ public class LongArrayConverter implements TypeConverter<long[]> {
 		if (value instanceof Iterable) {
 			Iterable iterable = (Iterable) value;
 
-            int count = 0;
-			for (Object element : iterable) {
-				count++;
-			}
+			LongArrayList longArrayList = new LongArrayList();
 
-			long[] target = new long[count];
-			int i = 0;
 			for (Object element : iterable) {
-				target[i] = convertType(element);
-            	i++;
+				long convertedValue = convertType(element);
+            	longArrayList.add(convertedValue);
             }
 
-			return target;
+			return longArrayList.toArray();
 		}
 
 		if (value instanceof CharSequence) {
diff --git a/jodd-core/src/main/java/jodd/typeconverter/impl/ShortArrayConverter.java b/jodd-core/src/main/java/jodd/typeconverter/impl/ShortArrayConverter.java
index 8dda8280c..147d2e07e 100644
--- a/jodd-core/src/main/java/jodd/typeconverter/impl/ShortArrayConverter.java
+++ b/jodd-core/src/main/java/jodd/typeconverter/impl/ShortArrayConverter.java
@@ -5,6 +5,7 @@ package jodd.typeconverter.impl;
 import jodd.typeconverter.TypeConverter;
 import jodd.typeconverter.TypeConverterManagerBean;
 import jodd.util.StringUtil;
+import jodd.util.collection.ShortArrayList;
 
 import java.util.Collection;
 import java.util.List;
@@ -84,19 +85,14 @@ public class ShortArrayConverter implements TypeConverter<short[]> {
 		if (value instanceof Iterable) {
 			Iterable iterable = (Iterable) value;
 
-            int count = 0;
-			for (Object element : iterable) {
-				count++;
-			}
+			ShortArrayList shortArrayList = new ShortArrayList();
 
-			short[] target = new short[count];
-			int i = 0;
 			for (Object element : iterable) {
-				target[i] = convertType(element);
-            	i++;
+				short convertedValue = convertType(element);
+            	shortArrayList.add(convertedValue);
             }
 
-			return target;
+			return shortArrayList.toArray();
 		}
 
 		if (value instanceof CharSequence) {",Removed double iteration of iterables on conversion,"""Optimize array converters to use ArrayList implementations for efficient conversion of iterables to arrays""","""Improved performance of array converters by using specialized collection classes for boolean, byte, char, double, float, int, long, and short arrays.""","""Refactor array converters to use Jodd collection utilities""

This commit refactors several array converter classes to use Jodd collection utilities instead of native Java arrays. This change simplifies the code and improves performance by avoiding unnecessary array copies.

The following classes were modified:

* BooleanArrayConverter
* ByteArrayConverter
* CharacterArrayConverter
* DoubleArrayConverter
* FloatArrayConverter
* IntegerArrayConverter
* LongArrayConverter
* ShortArrayConverter

In each of these classes, the code that converts an Iterable to an array was updated to use the corresponding Jodd collection utility class instead of creating a new array and copying the elements manually. For example, in BooleanArrayConverter, the code now uses a BooleanArrayList to store the converted boolean values, and then calls the toArray() method to convert the list to an array. This eliminates the need to iterate over the Iterable twice (once to count the elements and once to copy them to the array) and improves performance by avoiding unnecessary array allocation and copying.

This change should have no impact on the functionality or compatibility of the affected classes, but it may improve their performance and reduce memory usage in some cases.",Refactor array converters to use specialized ArrayLists for better efficiency and cleaner code by removing redundant counting logic.,Model 3
"diff --git a/enterprise/CHANGES.txt b/enterprise/CHANGES.txt
index e69de29bb2d..4dba816efec 100644
--- a/enterprise/CHANGES.txt
+++ b/enterprise/CHANGES.txt
@@ -0,0 +1,61 @@
+1.2.M04 (2010-11-18)
+--------------------
+
+o added a server packaging as part of neo4j
+o added more configuration options to neo4j-lucene-index
+o generating javadocs for all components automatically to components.neo4j.org/{component-name}
+o Added ImpermanentGraphDatabase to aid in testing
+
+1.2.M03 (2010-11-04)
+--------------------
+
+o Monitoring/management over JMX was moved to the new neo4j-management component.
+o Added ability to get the name and configuration of existing integrated indexes.
+
+1.2.M02 (2010-10-21)
+--------------------
+
+-New components
+o Lucene index, an implementation of the integrated index framework
+  using lucene as backend. Planned to replace current index service.
+
+-Important changes
+o Fixed shutdown issue regarding UDC leaving a thread running.
+o A new index framework integrated into the kernel API.
+o Getting relationships is faster due to less cache lookups.
+
+1.2.M01 (2010-10-08)
+--------------------
+
+-New components
+o Udc
+
+-Important changes
+o Index:
+   - Lucene version upgraded to 3.0.1
+o Shell:
+   - Apps discoverable with service locator
+   - Added read-only mode on server
+   - 'host' and 'config' options
+o Graph-algo:
+   - Find paths of certain length
+o Kernel:
+   - Lower memory footprint
+   - Higher throughput/concurrency for reads
+   - Common interface for loading kernel extensions (f.ex. shell)
+
+1.1 (2010-07-29)
+----------------
+
+-New components
+o Graph-algo
+o Online-backup
+
+1.0 (2010-02-16)
+----------------
+
+-Initial components
+o Kernel
+o Index
+o Remote-graphdb
+o Shell",updating CHANGES . txt .,"""Added CHANGES.txt file with release notes for Neo4j versions 1.0 to 1.2.M04""","""Update enterprise/CHANGES.txt to reflect new features and changes in Neo4j Enterprise 1.2.M04""","Added server packaging as part of neo4j, more configuration options to neo4j-lucene-index, javadocs generation for all components, and ImpermanentGraphDatabase for testing in version 1.2.M04.","""Added CHANGES.txt with version history and features for Neo4j enterprise releases 1.0 to 1.2.M04.""",Model 1
"diff --git a/misc/metrics-extensions/modules/ballerina-prometheus-extension/src/main/java/org/ballerinalang/observe/metrics/extension/prometheus/PrometheusMeterRegistryProvider.java b/misc/metrics-extensions/modules/ballerina-prometheus-extension/src/main/java/org/ballerinalang/observe/metrics/extension/prometheus/PrometheusMeterRegistryProvider.java
index 2506c038105..abf3a1e58ef 100644
--- a/misc/metrics-extensions/modules/ballerina-prometheus-extension/src/main/java/org/ballerinalang/observe/metrics/extension/prometheus/PrometheusMeterRegistryProvider.java
+++ b/misc/metrics-extensions/modules/ballerina-prometheus-extension/src/main/java/org/ballerinalang/observe/metrics/extension/prometheus/PrometheusMeterRegistryProvider.java
@@ -42,7 +42,6 @@ import static org.ballerinalang.util.observability.ObservabilityConstants.CONFIG
 public class PrometheusMeterRegistryProvider implements MeterRegistryProvider {
 
     private static final String METRICS_PORT = CONFIG_TABLE_METRICS + "".port"";
-    private static final String VERBOSE = CONFIG_TABLE_METRICS + "".verbose"";
     private static final int DEFAULT_PORT = 9797;
 
     private static final PrintStream console = System.out;
@@ -55,7 +54,6 @@ public class PrometheusMeterRegistryProvider implements MeterRegistryProvider {
     @Override
     public MeterRegistry get() {
         ConfigRegistry configRegistry = ConfigRegistry.getInstance();
-        final boolean verbose = Boolean.valueOf(configRegistry.getConfiguration(VERBOSE));
         PrometheusMeterRegistry registry = new PrometheusMeterRegistry(new BallerinaPrometheusConfig());
         String portConfigValue = configRegistry.getConfiguration(METRICS_PORT);
         int configuredPort = 0;
@@ -69,7 +67,7 @@ public class PrometheusMeterRegistryProvider implements MeterRegistryProvider {
         // Start in default port if there is no configured port.
         int port = configuredPort > 0 ? configuredPort : DEFAULT_PORT;
         try {
-            startServer(port, registry, verbose);
+            startServer(port, registry);
         } catch (BindException e) {
             if (configuredPort > 0) {
                 // User has configured a port and the program should exit.
@@ -86,7 +84,7 @@ public class PrometheusMeterRegistryProvider implements MeterRegistryProvider {
                     } catch (IOException e1) {
                         // Ignore IOException on close()
                     }
-                    startServer(port, registry, true);
+                    startServer(port, registry);
                 } catch (IOException e1) {
                     throw new IllegalStateException(""Failed to bind Prometheus HTTP endpoint to port ""
                             + port + "": "" + e.getMessage(), e);
@@ -98,13 +96,11 @@ public class PrometheusMeterRegistryProvider implements MeterRegistryProvider {
         return registry;
   ",Remove verbose option,"""Remove verbose configuration option from PrometheusMeterRegistryProvider""","The commit message should be:

""Remove unused 'verbose' configuration and related code from PrometheusMeterRegistryProvider""

This commit message accurately describes the changes made in the commit, which include removing the unused 'verbose' configuration and related code from the PrometheusMeterRegistryProvider class.","""Remove verbose configuration and related logic from PrometheusMeterRegistryProvider""

This commit removes the `VERBOSE` configuration constant and its usage in the `get()` method. It also removes the `verbose` parameter from the `startServer()` method and its usage inside the method. This means that the Prometheus server will no longer use a verbose mode based on a configuration value.","""Remove verbose configuration handling from PrometheusMeterRegistryProvider and refactor startServer method call.""",Model 3
"diff --git a/demos/main/src/main/assets/media.exolist.json b/demos/main/src/main/assets/media.exolist.json
index 8550377ddf..4375bdf3a7 100644
--- a/demos/main/src/main/assets/media.exolist.json
+++ b/demos/main/src/main/assets/media.exolist.json
@@ -600,6 +600,13 @@
         ""subtitle_uri"": ""https://storage.googleapis.com/exoplayer-test-media-1/ttml/netflix_ttml_sample.xml"",
         ""subtitle_mime_type"": ""application/ttml+xml"",
         ""subtitle_language"": ""en""
+      },
+      {
+        ""name"": ""SSA/ASS position & alignment"",
+        ""uri"": ""https://storage.googleapis.com/exoplayer-test-media-1/gen-3/screens/dash-vod-single-segment/video-avc-baseline-480.mp4"",
+        ""subtitle_uri"": ""https://storage.googleapis.com/exoplayer-test-media-1/ssa/test-subs-position.ass"",
+        ""subtitle_mime_type"": ""text/x-ssa"",
+        ""subtitle_language"": ""en""
       }
     ]
   }",Add SSA test file to the demo app .,"""Add SSA/ASS position & alignment test media to exolist.json""",Added new media item to exolist.json for SSA/ASS position & alignment testing.,"""Added new subtitle test case for SSA/ASS position & alignment in media.exolist.json""",Added SSA/ASS subtitle position & alignment test sample to media.exolist.json.,Model 3
"diff --git a/modules/swagger-codegen/src/main/resources/Java/libraries/retrofit2/build.gradle.mustache b/modules/swagger-codegen/src/main/resources/Java/libraries/retrofit2/build.gradle.mustache
index a5cfd0ebef2..9f34c16afc5 100644
--- a/modules/swagger-codegen/src/main/resources/Java/libraries/retrofit2/build.gradle.mustache
+++ b/modules/swagger-codegen/src/main/resources/Java/libraries/retrofit2/build.gradle.mustache
@@ -46,6 +46,10 @@ if(hasProperty('target') && target == 'android') {
 	            }
 	        }
 	    }
+
+      dependencies {
+          provided 'javax.annotation:jsr250-api:1.0'
+      }
 	}
 
 	afterEvaluate {
diff --git a/samples/client/petstore/java/retrofit2/build.gradle b/samples/client/petstore/java/retrofit2/build.gradle
index ae27a595eb5..ab71653f739 100644
--- a/samples/client/petstore/java/retrofit2/build.gradle
+++ b/samples/client/petstore/java/retrofit2/build.gradle
@@ -46,6 +46,10 @@ if(hasProperty('target') && target == 'android') {
 	            }
 	        }
 	    }
+
+      dependencies {
+          provided 'javax.annotation:jsr250-api:1.0'
+      }
 	}
 
 	afterEvaluate {",Provide dependency to javax . annotation . Generated for android with Retrofit 2 .,"""Add javax.annotation:jsr250-api dependency for retrofit2 library""",Add javax.annotation:jsr250-api dependency to Retrofit2 builds.,"""Add provided dependency for javax.annotation:jsr250-api:1.0 in build.gradle for Retrofit2 library""",Add 'javax.annotation:jsr250-api:1.0' dependency for Android targets in Retrofit2 build.gradle files.,Model 3
"diff --git a/modules/web/js/ballerina/components/transform-node-manager.js b/modules/web/js/ballerina/components/transform-node-manager.js
index 8c1b5725cd1..b4d80e0b2a5 100644
--- a/modules/web/js/ballerina/components/transform-node-manager.js
+++ b/modules/web/js/ballerina/components/transform-node-manager.js
@@ -148,13 +148,16 @@ class TransformNodeManager {
         // based on how the nested invocation is drawn. i.e. : adding two function nodes and then drawing
         // will be different from removing a param from a function and then drawing the connection
         // to the parent function invocation.
-        const assignmentStmtTarget = this.getParentAssignmentStmt(target.funcInv);
         const assignmentStmtSource = this.getParentAssignmentStmt(source.funcInv);
 
-        const funcNode = assignmentStmtTarget.getRightExpression();
-
         // remove the source assignment statement since it is now included in the target assignment statement.
         this._transformStmt.removeChild(assignmentStmtSource, true);
+
+        const currentChild = target.funcInv.getChildren()[target.index];
+        if(currentChild) {
+            target.funcInv.removeChild(currentChild, true);
+        }
+
         target.funcInv.addChild(source.funcInv, target.index);
     }
 ",Remove current child before adding new one in transform func - to - func connection,"""Fix nested function invocation in transform node manager""","""Refactor transform node manager to handle nested function invocations correctly""

Or, in a more concise format:

""Improve transform node manager for nested function invocations""

Or, in a format that follows the conventional commit message guidelines:

""feat: improve transform node manager for nested function invocations""

This commit message is concise, yet descriptive enough to convey the changes made in the commit.","""Update TransformNodeManager to remove current child before adding new child in handleNestedFunctionInvocation""

This commit appears to modify the behavior of the `handleNestedFunctionInvocation` method in the `TransformNodeManager` class. Previously, the method removed the source assignment statement and added the source function invocation to the target function invocation at a specified index.

The change introduces a new step before adding the source function invocation to the target. It checks if there is already a child at the specified index of the target function invocation, and if so, removes it before adding the source function invocation. This ensures that the target function invocation does not have multiple children at the same index.

Additionally, the commit removes two lines of code that assigned the `funcNode` variable, which is not used anywhere else in the provided code snippet. This suggests that the variable may no longer be necessary after the changes made in this commit.","""Fix nested invocation update by adjusting child removal and adding source function invocation at target index.""",Model 1
"diff --git a/assembly/package-res/samples/transformations/Rules Accumulator - Solve Golfer Rule.ktr b/assembly/package-res/samples/transformations/Rules Accumulator - Solve Golfer Rule.ktr
new file mode 100644
index 0000000000..b931c363a7
--- /dev/null
+++ b/assembly/package-res/samples/transformations/Rules Accumulator - Solve Golfer Rule.ktr	
@@ -0,0 +1,356 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<transformation>
+  <info>
+    <name>Rules Accumulator - Solve Golfer Rule</name>
+    <description/>
+    <extended_description/>
+    <trans_version/>
+    <trans_type>Normal</trans_type>
+    <trans_status>0</trans_status>
+    <directory>&#x2f;</directory>
+    <parameters>
+    </parameters>
+    <log>
+<trans-log-table><connection/>
+<schema/>
+<table/>
+<size_limit_lines/>
+<interval/>
+<timeout_days/>
+<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STATUS</id><enabled>Y</enabled><name>STATUS</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name><subject/></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name><subject/></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name><subject/></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name><subject/></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name><subject/></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name><subject/></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>STARTDATE</id><enabled>Y</enabled><name>STARTDATE</name></field><field><id>ENDDATE</id><enabled>Y</enabled><name>ENDDATE</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>DEPDATE</id><enabled>Y</enabled><name>DEPDATE</name></field><field><id>REPLAYDATE</id><enabled>Y</enabled><name>REPLAYDATE</name></field><field><id>LOG_FIELD</id><enabled>Y</enabled><name>LOG_FIELD</name></field><field><id>EXECUTING_SERVER</id><enabled>N</enabled><name>EXECUTING_SERVER</name></field><field><id>EXECUTING_USER</id><enabled>N</enabled><name>EXECUTING_USER</name></field><field><id>CLIENT</id><enabled>N</enabled><name>CLIENT</name></field></trans-log-table>
+<perf-log-table><connection/>
+<schema/>
+<table/>
+<interval/>
+<timeout_days/>
+<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>SEQ_NR</id><enabled>Y</enabled><name>SEQ_NR</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STEPNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>STEP_COPY</id><enabled>Y</enabled><name>STEP_COPY</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>INPUT_BUFFER_ROWS</id><enabled>Y</enabled><name>INPUT_BUFFER_ROWS</name></field><field><id>OUTPUT_BUFFER_ROWS</id><enabled>Y</enabled><name>OUTPUT_BUFFER_ROWS</name></field></perf-log-table>
+<channel-log-table><connection/>
+<schema/>
+<table/>
+<timeout_days/>
+<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>LOGGING_OBJECT_TYPE</id><enabled>Y</enabled><name>LOGGING_OBJECT_TYPE</name></field><field><id>OBJECT_NAME</id><enabled>Y</enabled><name>OBJECT_NAME</name></field><field><id>OBJECT_COPY</id><enabled>Y</enabled><name>OBJECT_COPY</name></field><field><id>REPOSITORY_DIRECTORY</id><enabled>Y</enabled><name>REPOSITORY_DIRECTORY</name></field><field><id>FILENAME</id><enabled>Y</enabled><name>FILENAME</name></field><field><id>OBJECT_ID</id><enabled>Y</enabled><name>OBJECT_ID</name></field><field><id>OBJECT_REVISION</id><enabled>Y</enabled><name>OBJECT_REVISION</name></field><field><id>PARENT_CHANNEL_ID</id><enabled>Y</enabled><name>PARENT_CHANNEL_ID</name></field><field><id>ROOT_CHANNEL_ID</id><enabled>Y</enabled><name>ROOT_CHANNEL_ID</name></field></channel-log-table>
+<step-log-table><connection/>
+<schema/>
+<table/>
+<timeout_days/>
+<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STEPNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>STEP_COPY</id><enabled>Y</enabled><name>STEP_COPY</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>LOG_FIELD</id><enabled>N</enabled><name>LOG_FIELD</name></field></step-log-table>
+<metrics-log-table><connection/>
+<schema/>
+<table/>
+<timeout_days/>
+<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>METRICS_DATE</id><enabled>Y</enabled><name>METRICS_DATE</name></field><field><id>METRICS_CODE</id><enabled>Y</enabled><name>METRICS_CODE</name></field><field><id>METRICS_DESCRIPTION</id><enabled>Y</enabled><name>METRICS_DESCRIPTION</name></field><field><id>METRICS_SUBJECT</id><enabled>Y</enabled><name>METRICS_SUBJECT</name></field><field><id>METRICS_TYPE</id><enabled>Y</enabled><name>METRICS_TYPE</name></field><field><id>METRICS_VALUE</id><enabled>Y</enabled><name>METRICS_VALUE</name></field></metrics-log-table>
+    </log>
+    <maxdate>
+      <connection/>
+      <table/>
+      <field/>
+      <offset>0.0</offset>
+      <maxdiff>0.0</maxdiff>
+    </maxdate>
+    <size_rowset>10000</size_rowset>
+    <sleep_time_empty>50</sleep_time_empty>
+    <sleep_time_full>50</sleep_time_full>
+    <unique_connections>N</unique_connections>
+    <feedback_shown>Y</feedback_shown>
+    <feedback_size>50000</feedback_size>
+    <using_thread_priorities>Y</using_thread_priorities>
+    <shared_objects_file/>
+    <capture_step_performance>N</capture_step_performance>
+    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
+    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
+    <dependencies>
+    </dependencies>
+    <partitionschemas>
+    </partitionschemas>
+    <slaveservers>
+    </slaveservers>
+    <clusterschemas>
+    </clusterschemas>
+  <created_user>-</created_user>
+  <created_date>2011&#x2f;08&#x2f;29 13&#x3a;57&#x3a;42.720</created_date>
+  <modified_user>-</modified_user>
+  <modified_date>2011&#x2f;08&#x2f;29 13&#x3a;57&#x3a;42.720</modified_date>
+  </info>
+  <notepads>
+    <notepad>
+      <note>Puzzle rules&#x3a;&#xa;&#xa;- A foursome of golfers is standing at a tee, in a line from left to right.&#xa;- Each golfer wears different colored pants&#x3b; one is wearing red pants.&#xa;- The golfer to Fred&#x2019;s immediate right is wearing blue pants.&#xa;- Joe is second in line.&#xa;- Bob is wearing plaid pants.&#xa;- Tom isn&#x2019;t in position one or four, and he isn&#x2019;t wearing the hideous orange pants.&#xa;- In what order will the four golfers tee off, and what color are each golfer&#x2019;s pants&#x3f;&#x201d;</note>
+      <xloc>28</xloc>
+      <yloc>365</yloc>
+      <width>630</width>
+      <heigth>186</heigth>
+      <fontname>Arial</fontname>
+      <fontsize>10</fontsize>
+      <fontbold>N</fontbold>
+      <fontitalic>N</fontitalic>
+      <fontcolorred>0</fontcolorred>
+      <fontcolorgreen>0</fontcolorgreen>
+      <fontcolorblue>0</fontcolorblue>
+      <backgroundcolorred>255</backgroundcolorred>
+      <backgroundcolorgreen>165</backgroundcolorgreen>
+      <backgroundcolorblue>0</backgroundcolorblue>
+      <bordercolorred>100</bordercolorred>
+      <bordercolorgreen>100</bordercolorgreen>
+      <bordercolorblue>100</bordercolorblue>
+      <drawshadow>Y</drawshadow>
+    </notepad>
+  </notepads>
+  <order>
+  <hop> <from>Generate Golfers</from><to>Insert Position</to><enabled>Y</enabled> </hop>
+  <hop> <from>Generate Position</from><to>Insert Position</to><enabled>Y</enabled> </hop>
+  <hop> <from>Insert Position</from><to>Insert Color</to><enabled>Y</enabled> </hop>
+  <hop> <from>Generate Color</from><to>Insert Color</to><enabled>Y</enabled> </hop>
+  <hop> <from>Insert Color</from><to>Rule Accumulator</to><enabled>Y</enabled> </hop>
+  <hop> <from>Rule Accumulator</from><to>Sort rows</to><enabled>Y</enabled> </hop>
+  </order>
+  <step>
+    <name>Generate Color</name>
+    <type>DataGrid</type>
+    <description/>
+    <distribute>Y</distribute>
+    <custom_distribution/>
+    <copies>1</copies>
+         <partitioning>
+           <method>none</method>
+           <schema_name/>
+           </partitioning>
+    <fields>
+      <field>
+        <name>color</name>
+        <type/>
+        <format/>
+        <currency/>
+        <decimal/>
+        <group/>
+        <length>-1</length>
+        <precision>-1</precision>
+        <set_empty_string>N</set_empty_string>
+      </field>
+    </fields>
+    <data>
+      <line> <item>red</item> </line>
+      <line> <item>blue</item> </line>
+      <line> <item>plaid</item> </line>
+      <line> <item>orange</item> </line>
+    </data>
+     <cluster_schema/>
+ <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
+      <xloc>453</xloc>
+      <yloc>24</yloc>
+      <draw>Y</draw>
+      </GUI>
+    </step>
+
+  <step>
+    <name>Generate Golfers</name>
+    <type>DataGrid</type>
+    <description/>
+    <distribute>Y</distribute>
+    <custom_distribution/>
+    <copies>1</copies>
+         <partitioning>
+           <method>none</method>
+           <schema_name/>
+           </partitioning>
+    <fields>
+      <field>
+        <name>name</name>
+        <type>String</type>
+        <format/>
+        <currency/>
+        <decimal/>
+        <group/>
+        <length>-1</length>
+        <precision>-1</precision>
+        <set_empty_string>N</set_empty_string>
+      </field>
+    </fields>
+    <data>
+      <line> <item>Fred</item> </line>
+      <line> <item>Joe</item> </line>
+      <line> <item>Bob</item> </line>
+      <line> <item>Tom</item> </line>
+    </data>
+     <cluster_schema/>
+ <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
+      <xloc>101</xloc>
+      <yloc>126</yloc>
+      <draw>Y</draw>
+      </GUI>
+    </step>
+
+  <step>
+    <name>Generate Position</name>
+    <type>DataGrid</type>
+    <description/>
+    <distribute>Y</distribute>
+    <custom_distribution/>
+    <copies>1</copies>
+         <partitioning>
+           <method>none</method>
+           <schema_name/>
+           </partitioning>
+    <fields>
+      <field>
+        <name>position</name>
+        <type>Integer</type>
+        <format/>
+        <currency/>
+        <decimal/>
+        <group/>
+        <length>-1</length>
+        <precision>-1</precision>
+        <set_empty_string>N</set_empty_string>
+      </field>
+    </fields>
+    <data>
+      <line> <item>1</item> </line>
+      <line> <item>2</item> </line>
+      <line> <item>3</item> </line>
+      <line> <item>4</item> </line>
+    </data>
+     <cluster_schema/>
+ <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
+      <xloc>271</xloc>
+      <yloc>24</yloc>
+      <draw>Y</draw>
+      </GUI>
+    </step>
+
+  <step>
+    <name>Insert Color</name>
+    <type>JoinRows</type>
+    <description/>
+    <distribute>N</distribute>
+    <custom_distribution/>
+    <copies>1</copies>
+         <partitioning>
+           <method>none</method>
+           <schema_name/>
+           </partitioning>
+      <directory>&#x25;&#x25;java.io.tmpdir&#x25;&#x25;</directory>
+      <prefix>out</prefix>
+      <cache_size>500</cache_size>
+      <main/>
+    <compare>
+<condition>
+ <negated>N</negated>
+ <leftvalue>name</leftvalue>
+ <function>IS NOT NULL</function>
+ <rightvalue/>
+ </condition>
+    </compare>
+     <cluster_schema/>
+ <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
+      <xloc>453</xloc>
+      <yloc>126</yloc>
+      <draw>Y</draw>
+      </GUI>
+    </step>
+
+  <step>
+    <name>Insert Position</name>
+    <type>JoinRows</type>
+    <description/>
+    <distribute>Y</distribute>
+    <custom_distribution/>
+    <copies>1</copies>
+         <partitioning>
+           <method>none</method>
+           <schema_name/>
+           </partitioning>
+      <directory>&#x25;&#x25;java.io.tmpdir&#x25;&#x25;</directory>
+      <prefix>out</prefix>
+      <cache_size>500</cache_size>
+      <main/>
+    <compare>
+<condition>
+ <negated>N</negated>
+ <leftvalue>name</leftvalue>
+ <function>IS NOT NULL</function>
+ <rightvalue/>
+ </condition>
+    </compare>
+     <cluster_schema/>
+ <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
+      <xloc>271</xloc>
+      <yloc>126</yloc>
+      <draw>Y</draw>
+      </GUI>
+    </step>
+
+  <step>
+    <name>Rule Accumulator</name>
+    <type>RuleAccumulator</type>
+    <description/>
+    <distribute>Y</distribute>
+    <custom_distribution/>
+    <copies>1</copies>
+         <partitioning>
+           <method>none</method>
+           <schema_name/>
+           </partitioning>
+    <fields>
+      <field>
+        <column-name>position</column-name>
+        <column-type>Integer</column-type>
+      </field>
+      <field>
+        <column-name>name</column-name>
+        <column-type>String</column-type>
+      </field>
+      <field>
+        <column-name>color</column-name>
+        <column-type>String</column-type>
+      </field>
+    </fields>
+    <rule-file/>
+    <rule-definition>package org.pentaho.di.trans.steps.rules&#xa; &#xa;import org.pentaho.di.trans.steps.rules.Rules.Row&#x3b;&#xa;&#xa;&#x23; Courtesy of http&#x3a;&#x2f;&#x2f;docs.huihoo.com&#x2f;drools&#x2f;4.0.7&#x2f;ch10.html&#xa;&#xa;rule &#x22;Golfers problem&#x22;&#xa;    dialect &#x22;mvel&#x22;&#xa;    when&#xa;&#xa;	&#x23; Define Fred&#xa;	&#x24;fred &#x3a; Row &#x28; externalSource &#x3d;&#x3d; true,&#xa;				column&#x5b;&#x22;name&#x22;&#x5d; &#x3d;&#x3d; &#x22;Fred&#x22;&#xa;	&#x29;&#xa;&#xa;	&#x23; Define Joe&#xa;	&#x24;joe &#x3a; Row &#x28; 	externalSource &#x3d;&#x3d; true, &#xa;			      	column&#x5b;&#x22;name&#x22;&#x5d; &#x3d;&#x3d; &#x22;Joe&#x22;,&#xa;			      	column&#x5b;&#x22;position&#x22;&#x5d; &#x3d;&#x3d; 2,&#xa;				column&#x5b;&#x22;position&#x22;&#x5d; &#x21;&#x3d; &#x24;fred.column&#x5b;&#x22;position&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;color&#x22;&#x5d; &#x21;&#x3d; &#x24;fred.column&#x5b;&#x22;color&#x22;&#x5d;&#xa;	&#x29;&#xa;       &#xa;	&#x23; Define Bob&#xa;	&#x24;bob &#x3a; Row &#x28; externalSource &#x3d;&#x3d; true,&#xa;				column&#x5b;&#x22;name&#x22;&#x5d; &#x3d;&#x3d; &#x22;Bob&#x22;,&#xa;				column&#x5b;&#x22;position&#x22;&#x5d; &#x21;&#x3d; &#x24;fred.column&#x5b;&#x22;position&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;position&#x22;&#x5d; &#x21;&#x3d; &#x24;joe.column&#x5b;&#x22;position&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;color&#x22;&#x5d; &#x3d;&#x3d; &#x22;plaid&#x22;,&#xa;				column&#x5b;&#x22;color&#x22;&#x5d; &#x21;&#x3d; &#x24;fred.column&#x5b;&#x22;color&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;color&#x22;&#x5d; &#x21;&#x3d; &#x24;joe.column&#x5b;&#x22;color&#x22;&#x5d;&#xa;	&#x29;&#xa;&#xa;	&#x23; Define Tom&#xa;	&#x24;tom &#x3a; Row &#x28; externalSource &#x3d;&#x3d; true,&#xa;				column&#x5b;&#x22;name&#x22;&#x5d; &#x3d;&#x3d; &#x22;Tom&#x22;,&#xa;				column&#x5b;&#x22;position&#x22;&#x5d; &#x21;&#x3d; 1,&#xa;				column&#x5b;&#x22;position&#x22;&#x5d; &#x21;&#x3d; 4,&#xa;				column&#x5b;&#x22;position&#x22;&#x5d; &#x21;&#x3d; &#x24;fred.column&#x5b;&#x22;position&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;position&#x22;&#x5d; &#x21;&#x3d; &#x24;joe.column&#x5b;&#x22;position&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;position&#x22;&#x5d; &#x21;&#x3d; &#x24;bob.column&#x5b;&#x22;position&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;color&#x22;&#x5d; &#x21;&#x3d; &#x22;orange&#x22;,&#xa;				column&#x5b;&#x22;color&#x22;&#x5d; &#x21;&#x3d; &#x24;fred.column&#x5b;&#x22;color&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;color&#x22;&#x5d; &#x21;&#x3d; &#x24;joe.column&#x5b;&#x22;color&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;color&#x22;&#x5d; &#x21;&#x3d; &#x24;bob.column&#x5b;&#x22;color&#x22;&#x5d;&#xa;	&#x29;&#xa;&#xa;	&#x23; Define Unknown&#xa;	&#x24;unknown &#x3a; Row &#x28; externalSource &#x3d;&#x3d; true,&#xa;					column&#x5b;&#x22;position&#x22;&#x5d; &#x3d;&#x3d; &#x28;&#x24;fred.column&#x5b;&#x22;position&#x22;&#x5d; &#x2b; 1&#x29;,&#xa;					column&#x5b;&#x22;color&#x22;&#x5d; &#x3d;&#x3d; &#x22;blue&#x22;,&#xa;					this in &#x28; &#x24;joe, &#x24;bob, &#x24;tom&#x29;&#xa;	&#x29;&#xa;&#xa;    then&#xa;&#xa;      Row fredRow &#x3d; new Row&#x28;&#x29;&#x3b;&#xa;      Row joeRow &#x3d; new Row&#x28;&#x29;&#x3b;&#xa;      Row bobRow &#x3d; new Row&#x28;&#x29;&#x3b;&#xa;      Row tomRow &#x3d; new Row&#x28;&#x29;&#x3b;&#xa;&#xa;	fredRow.addColumn&#x28;&#x22;name&#x22;, &#x22;Fred&#x22;&#x29;&#x3b;&#xa;	fredRow.addColumn&#x28;&#x22;position&#x22;, &#x24;fred.column&#x5b;&#x22;position&#x22;&#x5d;&#x29;&#x3b;&#xa;	fredRow.addColumn&#x28;&#x22;color&#x22;, &#x24;fred.column&#x5b;&#x22;color&#x22;&#x5d;&#x29;&#x3b;&#xa;&#xa;	joeRow.addColumn&#x28;&#x22;name&#x22;, &#x22;Joe&#x22;&#x29;&#x3b;&#xa;	joeRow.addColumn&#x28;&#x22;position&#x22;, &#x24;joe.column&#x5b;&#x22;position&#x22;&#x5d;&#x29;&#x3b;&#xa;	joeRow.addColumn&#x28;&#x22;color&#x22;, &#x24;joe.column&#x5b;&#x22;color&#x22;&#x5d;&#x29;&#x3b;&#xa;&#xa;	bobRow.addColumn&#x28;&#x22;name&#x22;, &#x22;Bob&#x22;&#x29;&#x3b;&#xa;	bobRow.addColumn&#x28;&#x22;position&#x22;, &#x24;bob.column&#x5b;&#x22;position&#x22;&#x5d;&#x29;&#x3b;&#xa;	bobRow.addColumn&#x28;&#x22;color&#x22;, &#x24;bob.column&#x5b;&#x22;color&#x22;&#x5d;&#x29;&#x3b;&#xa;&#xa;	tomRow.addColumn&#x28;&#x22;name&#x22;, &#x22;Tom&#x22;&#x29;&#x3b;&#xa;	tomRow.addColumn&#x28;&#x22;position&#x22;, &#x24;tom.column&#x5b;&#x22;position&#x22;&#x5d;&#x29;&#x3b;&#xa;	tomRow.addColumn&#x28;&#x22;color&#x22;, &#x24;tom.column&#x5b;&#x22;color&#x22;&#x5d;&#x29;&#x3b;&#xa;&#xa;      	insert&#x28;fredRow&#x29;&#x3b;&#xa;      	insert&#x28;joeRow&#x29;&#x3b;&#xa;      	insert&#x28;bobRow&#x29;&#x3b;&#xa;      	insert&#x28;tomRow&#x29;&#x3b; &#xa;&#xa;end</rule-definition>
+     <cluster_schema/>
+ <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
+      <xloc>656</xloc>
+      <yloc>126</yloc>
+      <draw>Y</draw>
+      </GUI>
+    </step>
+
+  <step>
+    <name>Sort rows</name>
+    <type>SortRows</type>
+    <description/>
+    <distribute>Y</distribute>
+    <custom_distribution/>
+    <copies>1</copies>
+         <partitioning>
+           <method>none</method>
+           <schema_name/>
+           </partitioning>
+      <directory>&#x25;&#x25;java.io.tmpdir&#x25;&#x25;</directory>
+      <prefix>out</prefix>
+      <sort_size>1000000</sort_size>
+      <free_memory/>
+      <compress>N</compress>
+      <compress_variable/>
+      <unique_rows>N</unique_rows>
+    <fields>
+      <field>
+        <name>position</name>
+        <ascending>Y</ascending>
+        <case_sensitive>N</case_sensitive>
+        <presorted>N</presorted>
+      </field>
+    </fields>
+     <cluster_schema/>
+ <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
+      <xloc>846</xloc>
+      <yloc>126</yloc>
+      <draw>Y</draw>
+      </GUI>
+    </step>
+
+  <step_error_handling>
+  </step_error_handling>
+   <slave-step-copy-partition-distribution>
+</slave-step-copy-partition-distribution>
+   <slave_transformation>N</slave_transformation>
+
+</transformation>
diff --git a/testfiles/blackbox/tests/trans/steps/rule/golf_rule.ktr b/testfiles/blackbox/tests/trans/steps/rule/golf_rule.ktr
new file mode 100644
index 0000000000..b931c363a7
--- /dev/null
+++ b/testfiles/blackbox/tests/trans/steps/rule/golf_rule.ktr
@@ -0,0 +1,356 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<transformation>
+  <info>
+    <name>Rules Accumulator - Solve Golfer Rule</name>
+    <description/>
+    <extended_description/>
+    <trans_version/>
+    <trans_type>Normal</trans_type>
+    <trans_status>0</trans_status>
+    <directory>&#x2f;</directory>
+    <parameters>
+    </parameters>
+    <log>
+<trans-log-table><connection/>
+<schema/>
+<table/>
+<size_limit_lines/>
+<interval/>
+<timeout_days/>
+<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STATUS</id><enabled>Y</enabled><name>STATUS</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name><subject/></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name><subject/></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name><subject/></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name><subject/></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name><subject/></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name><subject/></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>STARTDATE</id><enabled>Y</enabled><name>STARTDATE</name></field><field><id>ENDDATE</id><enabled>Y</enabled><name>ENDDATE</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>DEPDATE</id><enabled>Y</enabled><name>DEPDATE</name></field><field><id>REPLAYDATE</id><enabled>Y</enabled><name>REPLAYDATE</name></field><field><id>LOG_FIELD</id><enabled>Y</enabled><name>LOG_FIELD</name></field><field><id>EXECUTING_SERVER</id><enabled>N</enabled><name>EXECUTING_SERVER</name></field><field><id>EXECUTING_USER</id><enabled>N</enabled><name>EXECUTING_USER</name></field><field><id>CLIENT</id><enabled>N</enabled><name>CLIENT</name></field></trans-log-table>
+<perf-log-table><connection/>
+<schema/>
+<table/>
+<interval/>
+<timeout_days/>
+<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>SEQ_NR</id><enabled>Y</enabled><name>SEQ_NR</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STEPNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>STEP_COPY</id><enabled>Y</enabled><name>STEP_COPY</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>INPUT_BUFFER_ROWS</id><enabled>Y</enabled><name>INPUT_BUFFER_ROWS</name></field><field><id>OUTPUT_BUFFER_ROWS</id><enabled>Y</enabled><name>OUTPUT_BUFFER_ROWS</name></field></perf-log-table>
+<channel-log-table><connection/>
+<schema/>
+<table/>
+<timeout_days/>
+<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>LOGGING_OBJECT_TYPE</id><enabled>Y</enabled><name>LOGGING_OBJECT_TYPE</name></field><field><id>OBJECT_NAME</id><enabled>Y</enabled><name>OBJECT_NAME</name></field><field><id>OBJECT_COPY</id><enabled>Y</enabled><name>OBJECT_COPY</name></field><field><id>REPOSITORY_DIRECTORY</id><enabled>Y</enabled><name>REPOSITORY_DIRECTORY</name></field><field><id>FILENAME</id><enabled>Y</enabled><name>FILENAME</name></field><field><id>OBJECT_ID</id><enabled>Y</enabled><name>OBJECT_ID</name></field><field><id>OBJECT_REVISION</id><enabled>Y</enabled><name>OBJECT_REVISION</name></field><field><id>PARENT_CHANNEL_ID</id><enabled>Y</enabled><name>PARENT_CHANNEL_ID</name></field><field><id>ROOT_CHANNEL_ID</id><enabled>Y</enabled><name>ROOT_CHANNEL_ID</name></field></channel-log-table>
+<step-log-table><connection/>
+<schema/>
+<table/>
+<timeout_days/>
+<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>TRANSNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>STEPNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>STEP_COPY</id><enabled>Y</enabled><name>STEP_COPY</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>LOG_FIELD</id><enabled>N</enabled><name>LOG_FIELD</name></field></step-log-table>
+<metrics-log-table><connection/>
+<schema/>
+<table/>
+<timeout_days/>
+<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>METRICS_DATE</id><enabled>Y</enabled><name>METRICS_DATE</name></field><field><id>METRICS_CODE</id><enabled>Y</enabled><name>METRICS_CODE</name></field><field><id>METRICS_DESCRIPTION</id><enabled>Y</enabled><name>METRICS_DESCRIPTION</name></field><field><id>METRICS_SUBJECT</id><enabled>Y</enabled><name>METRICS_SUBJECT</name></field><field><id>METRICS_TYPE</id><enabled>Y</enabled><name>METRICS_TYPE</name></field><field><id>METRICS_VALUE</id><enabled>Y</enabled><name>METRICS_VALUE</name></field></metrics-log-table>
+    </log>
+    <maxdate>
+      <connection/>
+      <table/>
+      <field/>
+      <offset>0.0</offset>
+      <maxdiff>0.0</maxdiff>
+    </maxdate>
+    <size_rowset>10000</size_rowset>
+    <sleep_time_empty>50</sleep_time_empty>
+    <sleep_time_full>50</sleep_time_full>
+    <unique_connections>N</unique_connections>
+    <feedback_shown>Y</feedback_shown>
+    <feedback_size>50000</feedback_size>
+    <using_thread_priorities>Y</using_thread_priorities>
+    <shared_objects_file/>
+    <capture_step_performance>N</capture_step_performance>
+    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
+    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
+    <dependencies>
+    </dependencies>
+    <partitionschemas>
+    </partitionschemas>
+    <slaveservers>
+    </slaveservers>
+    <clusterschemas>
+    </clusterschemas>
+  <created_user>-</created_user>
+  <created_date>2011&#x2f;08&#x2f;29 13&#x3a;57&#x3a;42.720</created_date>
+  <modified_user>-</modified_user>
+  <modified_date>2011&#x2f;08&#x2f;29 13&#x3a;57&#x3a;42.720</modified_date>
+  </info>
+  <notepads>
+    <notepad>
+      <note>Puzzle rules&#x3a;&#xa;&#xa;- A foursome of golfers is standing at a tee, in a line from left to right.&#xa;- Each golfer wears different colored pants&#x3b; one is wearing red pants.&#xa;- The golfer to Fred&#x2019;s immediate right is wearing blue pants.&#xa;- Joe is second in line.&#xa;- Bob is wearing plaid pants.&#xa;- Tom isn&#x2019;t in position one or four, and he isn&#x2019;t wearing the hideous orange pants.&#xa;- In what order will the four golfers tee off, and what color are each golfer&#x2019;s pants&#x3f;&#x201d;</note>
+      <xloc>28</xloc>
+      <yloc>365</yloc>
+      <width>630</width>
+      <heigth>186</heigth>
+      <fontname>Arial</fontname>
+      <fontsize>10</fontsize>
+      <fontbold>N</fontbold>
+      <fontitalic>N</fontitalic>
+      <fontcolorred>0</fontcolorred>
+      <fontcolorgreen>0</fontcolorgreen>
+      <fontcolorblue>0</fontcolorblue>
+      <backgroundcolorred>255</backgroundcolorred>
+      <backgroundcolorgreen>165</backgroundcolorgreen>
+      <backgroundcolorblue>0</backgroundcolorblue>
+      <bordercolorred>100</bordercolorred>
+      <bordercolorgreen>100</bordercolorgreen>
+      <bordercolorblue>100</bordercolorblue>
+      <drawshadow>Y</drawshadow>
+    </notepad>
+  </notepads>
+  <order>
+  <hop> <from>Generate Golfers</from><to>Insert Position</to><enabled>Y</enabled> </hop>
+  <hop> <from>Generate Position</from><to>Insert Position</to><enabled>Y</enabled> </hop>
+  <hop> <from>Insert Position</from><to>Insert Color</to><enabled>Y</enabled> </hop>
+  <hop> <from>Generate Color</from><to>Insert Color</to><enabled>Y</enabled> </hop>
+  <hop> <from>Insert Color</from><to>Rule Accumulator</to><enabled>Y</enabled> </hop>
+  <hop> <from>Rule Accumulator</from><to>Sort rows</to><enabled>Y</enabled> </hop>
+  </order>
+  <step>
+    <name>Generate Color</name>
+    <type>DataGrid</type>
+    <description/>
+    <distribute>Y</distribute>
+    <custom_distribution/>
+    <copies>1</copies>
+         <partitioning>
+           <method>none</method>
+           <schema_name/>
+           </partitioning>
+    <fields>
+      <field>
+        <name>color</name>
+        <type/>
+        <format/>
+        <currency/>
+        <decimal/>
+        <group/>
+        <length>-1</length>
+        <precision>-1</precision>
+        <set_empty_string>N</set_empty_string>
+      </field>
+    </fields>
+    <data>
+      <line> <item>red</item> </line>
+      <line> <item>blue</item> </line>
+      <line> <item>plaid</item> </line>
+      <line> <item>orange</item> </line>
+    </data>
+     <cluster_schema/>
+ <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
+      <xloc>453</xloc>
+      <yloc>24</yloc>
+      <draw>Y</draw>
+      </GUI>
+    </step>
+
+  <step>
+    <name>Generate Golfers</name>
+    <type>DataGrid</type>
+    <description/>
+    <distribute>Y</distribute>
+    <custom_distribution/>
+    <copies>1</copies>
+         <partitioning>
+           <method>none</method>
+           <schema_name/>
+           </partitioning>
+    <fields>
+      <field>
+        <name>name</name>
+        <type>String</type>
+        <format/>
+        <currency/>
+        <decimal/>
+        <group/>
+        <length>-1</length>
+        <precision>-1</precision>
+        <set_empty_string>N</set_empty_string>
+      </field>
+    </fields>
+    <data>
+      <line> <item>Fred</item> </line>
+      <line> <item>Joe</item> </line>
+      <line> <item>Bob</item> </line>
+      <line> <item>Tom</item> </line>
+    </data>
+     <cluster_schema/>
+ <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
+      <xloc>101</xloc>
+      <yloc>126</yloc>
+      <draw>Y</draw>
+      </GUI>
+    </step>
+
+  <step>
+    <name>Generate Position</name>
+    <type>DataGrid</type>
+    <description/>
+    <distribute>Y</distribute>
+    <custom_distribution/>
+    <copies>1</copies>
+         <partitioning>
+           <method>none</method>
+           <schema_name/>
+           </partitioning>
+    <fields>
+      <field>
+        <name>position</name>
+        <type>Integer</type>
+        <format/>
+        <currency/>
+        <decimal/>
+        <group/>
+        <length>-1</length>
+        <precision>-1</precision>
+        <set_empty_string>N</set_empty_string>
+      </field>
+    </fields>
+    <data>
+      <line> <item>1</item> </line>
+      <line> <item>2</item> </line>
+      <line> <item>3</item> </line>
+      <line> <item>4</item> </line>
+    </data>
+     <cluster_schema/>
+ <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
+      <xloc>271</xloc>
+      <yloc>24</yloc>
+      <draw>Y</draw>
+      </GUI>
+    </step>
+
+  <step>
+    <name>Insert Color</name>
+    <type>JoinRows</type>
+    <description/>
+    <distribute>N</distribute>
+    <custom_distribution/>
+    <copies>1</copies>
+         <partitioning>
+           <method>none</method>
+           <schema_name/>
+           </partitioning>
+      <directory>&#x25;&#x25;java.io.tmpdir&#x25;&#x25;</directory>
+      <prefix>out</prefix>
+      <cache_size>500</cache_size>
+      <main/>
+    <compare>
+<condition>
+ <negated>N</negated>
+ <leftvalue>name</leftvalue>
+ <function>IS NOT NULL</function>
+ <rightvalue/>
+ </condition>
+    </compare>
+     <cluster_schema/>
+ <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
+      <xloc>453</xloc>
+      <yloc>126</yloc>
+      <draw>Y</draw>
+      </GUI>
+    </step>
+
+  <step>
+    <name>Insert Position</name>
+    <type>JoinRows</type>
+    <description/>
+    <distribute>Y</distribute>
+    <custom_distribution/>
+    <copies>1</copies>
+         <partitioning>
+           <method>none</method>
+           <schema_name/>
+           </partitioning>
+      <directory>&#x25;&#x25;java.io.tmpdir&#x25;&#x25;</directory>
+      <prefix>out</prefix>
+      <cache_size>500</cache_size>
+      <main/>
+    <compare>
+<condition>
+ <negated>N</negated>
+ <leftvalue>name</leftvalue>
+ <function>IS NOT NULL</function>
+ <rightvalue/>
+ </condition>
+    </compare>
+     <cluster_schema/>
+ <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
+      <xloc>271</xloc>
+      <yloc>126</yloc>
+      <draw>Y</draw>
+      </GUI>
+    </step>
+
+  <step>
+    <name>Rule Accumulator</name>
+    <type>RuleAccumulator</type>
+    <description/>
+    <distribute>Y</distribute>
+    <custom_distribution/>
+    <copies>1</copies>
+         <partitioning>
+           <method>none</method>
+           <schema_name/>
+           </partitioning>
+    <fields>
+      <field>
+        <column-name>position</column-name>
+        <column-type>Integer</column-type>
+      </field>
+      <field>
+        <column-name>name</column-name>
+        <column-type>String</column-type>
+      </field>
+      <field>
+        <column-name>color</column-name>
+        <column-type>String</column-type>
+      </field>
+    </fields>
+    <rule-file/>
+    <rule-definition>package org.pentaho.di.trans.steps.rules&#xa; &#xa;import org.pentaho.di.trans.steps.rules.Rules.Row&#x3b;&#xa;&#xa;&#x23; Courtesy of http&#x3a;&#x2f;&#x2f;docs.huihoo.com&#x2f;drools&#x2f;4.0.7&#x2f;ch10.html&#xa;&#xa;rule &#x22;Golfers problem&#x22;&#xa;    dialect &#x22;mvel&#x22;&#xa;    when&#xa;&#xa;	&#x23; Define Fred&#xa;	&#x24;fred &#x3a; Row &#x28; externalSource &#x3d;&#x3d; true,&#xa;				column&#x5b;&#x22;name&#x22;&#x5d; &#x3d;&#x3d; &#x22;Fred&#x22;&#xa;	&#x29;&#xa;&#xa;	&#x23; Define Joe&#xa;	&#x24;joe &#x3a; Row &#x28; 	externalSource &#x3d;&#x3d; true, &#xa;			      	column&#x5b;&#x22;name&#x22;&#x5d; &#x3d;&#x3d; &#x22;Joe&#x22;,&#xa;			      	column&#x5b;&#x22;position&#x22;&#x5d; &#x3d;&#x3d; 2,&#xa;				column&#x5b;&#x22;position&#x22;&#x5d; &#x21;&#x3d; &#x24;fred.column&#x5b;&#x22;position&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;color&#x22;&#x5d; &#x21;&#x3d; &#x24;fred.column&#x5b;&#x22;color&#x22;&#x5d;&#xa;	&#x29;&#xa;       &#xa;	&#x23; Define Bob&#xa;	&#x24;bob &#x3a; Row &#x28; externalSource &#x3d;&#x3d; true,&#xa;				column&#x5b;&#x22;name&#x22;&#x5d; &#x3d;&#x3d; &#x22;Bob&#x22;,&#xa;				column&#x5b;&#x22;position&#x22;&#x5d; &#x21;&#x3d; &#x24;fred.column&#x5b;&#x22;position&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;position&#x22;&#x5d; &#x21;&#x3d; &#x24;joe.column&#x5b;&#x22;position&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;color&#x22;&#x5d; &#x3d;&#x3d; &#x22;plaid&#x22;,&#xa;				column&#x5b;&#x22;color&#x22;&#x5d; &#x21;&#x3d; &#x24;fred.column&#x5b;&#x22;color&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;color&#x22;&#x5d; &#x21;&#x3d; &#x24;joe.column&#x5b;&#x22;color&#x22;&#x5d;&#xa;	&#x29;&#xa;&#xa;	&#x23; Define Tom&#xa;	&#x24;tom &#x3a; Row &#x28; externalSource &#x3d;&#x3d; true,&#xa;				column&#x5b;&#x22;name&#x22;&#x5d; &#x3d;&#x3d; &#x22;Tom&#x22;,&#xa;				column&#x5b;&#x22;position&#x22;&#x5d; &#x21;&#x3d; 1,&#xa;				column&#x5b;&#x22;position&#x22;&#x5d; &#x21;&#x3d; 4,&#xa;				column&#x5b;&#x22;position&#x22;&#x5d; &#x21;&#x3d; &#x24;fred.column&#x5b;&#x22;position&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;position&#x22;&#x5d; &#x21;&#x3d; &#x24;joe.column&#x5b;&#x22;position&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;position&#x22;&#x5d; &#x21;&#x3d; &#x24;bob.column&#x5b;&#x22;position&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;color&#x22;&#x5d; &#x21;&#x3d; &#x22;orange&#x22;,&#xa;				column&#x5b;&#x22;color&#x22;&#x5d; &#x21;&#x3d; &#x24;fred.column&#x5b;&#x22;color&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;color&#x22;&#x5d; &#x21;&#x3d; &#x24;joe.column&#x5b;&#x22;color&#x22;&#x5d;,&#xa;				column&#x5b;&#x22;color&#x22;&#x5d; &#x21;&#x3d; &#x24;bob.column&#x5b;&#x22;color&#x22;&#x5d;&#xa;	&#x29;&#xa;&#xa;	&#x23; Define Unknown&#xa;	&#x24;unknown &#x3a; Row &#x28; externalSource &#x3d;&#x3d; true,&#xa;					column&#x5b;&#x22;position&#x22;&#x5d; &#x3d;&#x3d; &#x28;&#x24;fred.column&#x5b;&#x22;position&#x22;&#x5d; &#x2b; 1&#x29;,&#xa;					column&#x5b;&#x22;color&#x22;&#x5d; &#x3d;&#x3d; &#x22;blue&#x22;,&#xa;					this in &#x28; &#x24;joe, &#x24;bob, &#x24;tom&#x29;&#xa;	&#x29;&#xa;&#xa;    then&#xa;&#xa;      Row fredRow &#x3d; new Row&#x28;&#x29;&#x3b;&#xa;      Row joeRow &#x3d; new Row&#x28;&#x29;&#x3b;&#xa;      Row bobRow &#x3d; new Row&#x28;&#x29;&#x3b;&#xa;      Row tomRow &#x3d; new Row&#x28;&#x29;&#x3b;&#xa;&#xa;	fredRow.addColumn&#x28;&#x22;name&#x22;, &#x22;Fred&#x22;&#x29;&#x3b;&#xa;	fredRow.addColumn&#x28;&#x22;position&#x22;, &#x24;fred.column&#x5b;&#x22;position&#x22;&#x5d;&#x29;&#x3b;&#xa;	fredRow.addColumn&#x28;&#x22;color&#x22;, &#x24;fred.column&#x5b;&#x22;color&#x22;&#x5d;&#x29;&#x3b;&#xa;&#xa;	joeRow.addColumn&#x28;&#x22;name&#x22;, &#x22;Joe&#x22;&#x29;&#x3b;&#xa;	joeRow.addColumn&#x28;&#x22;position&#x22;, &#x24;joe.column&#x5b;&#x22;position&#x22;&#x5d;&#x29;&#x3b;&#xa;	joeRow.addColumn&#x28;&#x22;color&#x22;, &#x24;joe.column&#x5b;&#x22;color&#x22;&#x5d;&#x29;&#x3b;&#xa;&#xa;	bobRow.addColumn&#x28;&#x22;name&#x22;, &#x22;Bob&#x22;&#x29;&#x3b;&#xa;	bobRow.addColumn&#x28;&#x22;position&#x22;, &#x24;bob.column&#x5b;&#x22;position&#x22;&#x5d;&#x29;&#x3b;&#xa;	bobRow.addColumn&#x28;&#x22;color&#x22;, &#x24;bob.column&#x5b;&#x22;color&#x22;&#x5d;&#x29;&#x3b;&#xa;&#xa;	tomRow.addColumn&#x28;&#x22;name&#x22;, &#x22;Tom&#x22;&#x29;&#x3b;&#xa;	tomRow.addColumn&#x28;&#x22;position&#x22;, &#x24;tom.column&#x5b;&#x22;position&#x22;&#x5d;&#x29;&#x3b;&#xa;	tomRow.addColumn&#x28;&#x22;color&#x22;, &#x24;tom.column&#x5b;&#x22;color&#x22;&#x5d;&#x29;&#x3b;&#xa;&#xa;      	insert&#x28;fredRow&#x29;&#x3b;&#xa;      	insert&#x28;joeRow&#x29;&#x3b;&#xa;      	insert&#x28;bobRow&#x29;&#x3b;&#xa;      	insert&#x28;tomRow&#x29;&#x3b; &#xa;&#xa;end</rule-definition>
+     <cluster_schema/>
+ <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
+      <xloc>656</xloc>
+      <yloc>126</yloc>
+      <draw>Y</draw>
+      </GUI>
+    </step>
+
+  <step>
+    <name>Sort rows</name>
+    <type>SortRows</type>
+    <description/>
+    <distribute>Y</distribute>
+    <custom_distribution/>
+    <copies>1</copies>
+         <partitioning>
+           <method>none</method>
+           <schema_name/>
+           </partitioning>
+      <directory>&#x25;&#x25;java.io.tmpdir&#x25;&#x25;</directory>
+      <prefix>out</prefix>
+      <sort_size>1000000</sort_size>
+      <free_memory/>
+      <compress>N</compress>
+      <compress_variable/>
+      <unique_rows>N</unique_rows>
+    <fields>
+      <field>
+        <name>position</name>
+        <ascending>Y</ascending>
+        <case_sensitive>N</case_sensitive>
+        <presorted>N</presorted>
+      </field>
+    </fields>
+     <cluster_schema/>
+ <remotesteps>   <input>   </input>   <output>   </output> </remotesteps>    <GUI>
+      <xloc>846</xloc>
+      <yloc>126</yloc>
+      <draw>Y</draw>
+      </GUI>
+    </step>
+
+  <step_error_handling>
+  </step_error_handling>
+   <slave-step-copy-partition-distribution>
+</slave-step-copy-partition-distribution>
+   <slave_transformation>N</slave_transformation>
+
+</transformation>",Added sample transformation for the Rules Accumulator step .,"""Added transformation file for solving the Golfer Rule puzzle using Rules Accumulator""",Added Rules Accumulator - Solve Golfer Rule transformation and test case.,"This commit adds a new transformation to the Kettle (Pentaho Data Integration) project. The transformation is called ""Rules Accumulator - Solve Golfer Rule"" and it is designed to solve a puzzle involving a group of golfers and their pants colors.

 The transformation consists of several steps, including:

 * Generate Golfers: a DataGrid step that generates a dataset containing the names of the golfers.
 * Generate Position: a DataGrid step that generates a dataset containing the possible positions of the golfers.
 * Generate Color: a DataGrid step that generates a dataset containing the possible colors of the pants worn by the golfers.
 * Insert Position: a JoinRows step that combines the datasets generated by Generate Golfers and Generate Position to create a dataset containing the names of the golfers and their positions.
 * Insert Color: a JoinRows step that combines the datasets generated by Generate Golfers and Generate Color to create a dataset containing the names of the golfers and the colors of their pants.
 * Rule Accumulator: a RuleAccumulator step that uses a set of rules to determine the correct order of the golfers and the colors of their pants.
 * Sort rows: a SortRows step that sorts the output of the Rule Accumulator step by the position of the golfers.

 The transformation also includes a notepad containing a description of the puzzle and the rules used to solve it.

 The commit also adds the transformation to the testfiles/blackbox/tests/trans/steps/rule directory of the project.",Add transformation and test files for solving the Golfer Rule using Rules Accumulator in Pentaho.,Model 1
"diff --git a/src/main/java/tachyon/command/TFsShell.java b/src/main/java/tachyon/command/TFsShell.java
index 3134870e80..2658acf15f 100644
--- a/src/main/java/tachyon/command/TFsShell.java
+++ b/src/main/java/tachyon/command/TFsShell.java
@@ -47,7 +47,7 @@ public class TFsShell {
     return 0;
   }
 
-  public int mkdir(String argv[]) throws InvalidPathException {
+  public int mkdir(String argv[]) throws InvalidPathException, FileAlreadyExistException {
     if (argv.length != 2) {
       System.out.println(""Usage: tfs mkdir <path>"");
       return -1;
diff --git a/src/main/java/tachyon/hadoop/TFileInputStreamHdfs.java b/src/main/java/tachyon/hadoop/TFileInputStreamHdfs.java
index b558e008a1..d8cf188d80 100644
--- a/src/main/java/tachyon/hadoop/TFileInputStreamHdfs.java
+++ b/src/main/java/tachyon/hadoop/TFileInputStreamHdfs.java
@@ -123,10 +123,6 @@ implements Seekable, PositionedReadable {
 
   @Override
   public int read() throws IOException {
-    if (mHdfsInputStream != null) {
-      return readFromHdfsBuffer();
-    }
-
     if (mTachyonFileInputStream != null) {
       int ret = 0;
       try {
@@ -139,6 +135,10 @@ implements Seekable, PositionedReadable {
       }
     }
 
+    if (mHdfsInputStream != null) {
+      return readFromHdfsBuffer();
+    }
+
     FileSystem fs = mHdfsPath.getFileSystem(mHadoopConf);
     mHdfsInputStream = fs.open(mHdfsPath, mHadoopBufferSize);
     mHdfsInputStream.seek(mCurrentPosition);",expose filealreadyexistexception in mkdir .,"""Fix TFsShell mkdir command to throw FileAlreadyExistException and refactor TFileInputStreamHdfs read method""","""Added FileAlreadyExistException to mkdir command and fixed potential null pointer exception in TFileInputStreamHdfs""","""Add FileAlreadyExistException to TFsShell mkdir method and refactor TFileInputStreamHdfs read method""

Explanation:
The first part of the diff shows that the method signature of `mkdir` in `TFsShell.java` has been changed to include a new exception `FileAlreadyExistException`. This means that the method can now throw this exception if a file with the same name already exists.

The second part of the diff shows that the `read` method in `TFileInputStreamHdfs.java` has been refactored. The code block that checks if `mHdfsInputStream` is not null and returns the result of `readFromHdfsBuffer()` has been moved from the beginning of the method to the end. This means that the method will now first try to read from the Tachyon file input stream, and if that is null, it will try to read from the HDFS input stream. The change also includes the addition of a new line of code that gets the file system of the HDFS path using the Hadoop configuration.","""Throw FileAlreadyExistException in mkdir and rearrange read method in TFileInputStreamHdfs for HDFS stream handling.""",Model 1
"diff --git a/src/soot/jimple/FieldRef.java b/src/soot/jimple/FieldRef.java
index 4de1fe0c90..dc58d86e6c 100644
--- a/src/soot/jimple/FieldRef.java
+++ b/src/soot/jimple/FieldRef.java
@@ -37,5 +37,6 @@ import java.util.*;
 public interface FieldRef extends ConcreteRef
 {
     public SootFieldRef getFieldRef();
+    public void setFieldRef(SootFieldRef sfr);
     public SootField getField();
 }
diff --git a/src/soot/jimple/InvokeExpr.java b/src/soot/jimple/InvokeExpr.java
index 96cbbc618b..7395edecdc 100644
--- a/src/soot/jimple/InvokeExpr.java
+++ b/src/soot/jimple/InvokeExpr.java
@@ -35,6 +35,7 @@ import java.util.*;
 
 public interface InvokeExpr extends Expr
 {
+    public void setMethodRef(SootMethodRef smr);
     public SootMethodRef getMethodRef();
     public SootMethod getMethod();
     public List getArgs();
diff --git a/src/soot/jimple/StaticFieldRef.java b/src/soot/jimple/StaticFieldRef.java
index 46ec9b65cb..50caff4f37 100644
--- a/src/soot/jimple/StaticFieldRef.java
+++ b/src/soot/jimple/StaticFieldRef.java
@@ -39,7 +39,9 @@ import java.io.*;
 
 public class StaticFieldRef implements FieldRef, ConvertToBaf
 {
-    protected SootFieldRef fieldRef;
+
+
+	protected SootFieldRef fieldRef;
 
     protected StaticFieldRef(SootFieldRef fieldRef)
     {
@@ -65,6 +67,10 @@ public class StaticFieldRef implements FieldRef, ConvertToBaf
     {
         return fieldRef;
     }
+
+	public void setFieldRef(SootFieldRef fieldRef) {
+		this.fieldRef = fieldRef;
+	}
     public SootField getField()
     {
         return fieldRef.resolve();
diff --git a/src/soot/jimple/internal/AbstractInstanceFieldRef.java b/src/soot/jimple/internal/AbstractInstanceFieldRef.java
index 0618ae8a71..b2ca96a657 100644
--- a/src/soot/jimple/internal/AbstractInstanceFieldRef.java
+++ b/src/soot/jimple/internal/AbstractInstanceFieldRef.java
@@ -41,7 +41,7 @@ public abstract class AbstractInstanceFieldRef implements InstanceFieldRef, Conv
     protected SootFieldRef fieldRef;
     ValueBox baseBox;
 
-    protected AbstractInstanceFieldRef(ValueBox baseBox, SootFieldRef fieldRef)
+	protected AbstractInstanceFieldRef(ValueBox baseBox, SootFieldRef fieldRef)
     {
         if( fieldRef.isStatic() ) throw new RuntimeException(""wrong static-ness"");
         this.baseBox = baseBox;
@@ -82,6 +82,9 @@ public abstract class AbstractInstanceFieldRef implements InstanceFieldRef, Conv
     {
         return fieldRef;
     }
+	public void setFieldRef(SootFieldRef fieldRef) {
+		this.fieldRef = fieldRef;
+	}
 
     public SootField getField()
     {
diff --git a/src/soot/jimple/internal/AbstractInvokeExpr.java b/src/soot/jimple/internal/AbstractInvokeExpr.java
index 1ff4092cb8..9e72a7e674 100644
--- a/src/soot/jimple/internal/AbstractInvokeExpr.java
+++ b/src/soot/jimple/internal/AbstractInvokeExpr.java
@@ -41,6 +41,10 @@ abstract public class AbstractInvokeExpr implements InvokeExpr
     protected SootMethodRef methodRef;
     protected ValueBox[] argBoxes;
 
+	public void setMethodRef(SootMethodRef methodRef) {
+		this.methodRef = methodRef;
+	}
+	
     public SootMethodRef getMethodRef()
     {
         return methodRef;",Added setMethodRef and setFieldRef methods to InvokeExpr and FieldRef .,"""Added setter methods for FieldRef and InvokeExpr interfaces""",Added setter methods for FieldRef and InvokeExpr interfaces and their implementing classes.,"""Added setter methods for FieldRef and InvokeExpr interfaces and their respective implementations""","Added setFieldRef and setMethodRef methods to FieldRef, InvokeExpr, and their implementing classes for setting references.",Model 1
"diff --git a/src/tools/android/java/com/google/devtools/build/android/aapt2/ResourceCompiler.java b/src/tools/android/java/com/google/devtools/build/android/aapt2/ResourceCompiler.java
index 92ca14b34e..8f7fedf03e 100644
--- a/src/tools/android/java/com/google/devtools/build/android/aapt2/ResourceCompiler.java
+++ b/src/tools/android/java/com/google/devtools/build/android/aapt2/ResourceCompiler.java
@@ -172,10 +172,29 @@ public class ResourceCompiler {
     }
 
     static String interpolateAapt2Filename(Qualifiers qualifiers, String filename) {
-      return qualifiers.asFolderType().equals(ResourceFolderType.VALUES)
-          ? (filename.indexOf('.') != -1 ? filename.substring(0, filename.indexOf('.')) : filename)
-              + "".arsc""
-          : filename;
+      // res/<not values>/foo.bar -> foo.bar
+      if (!qualifiers.asFolderType().equals(ResourceFolderType.VALUES)) {
+        return filename;
+      }
+
+      int periodIndex = filename.indexOf('.');
+
+      // res/values/foo -> foo.arsc
+      if (periodIndex == -1) {
+        return filename + "".arsc"";
+      }
+
+      // res/values/foo.bar.baz -> throw error.
+      if (filename.lastIndexOf('.') != periodIndex) {
+        throw new CompileError(
+            new IllegalArgumentException(
+                ""aapt2 does not support compiling resource xmls with multiple periods in the ""
+                    + ""filename: ""
+                    + filename));
+      }
+
+      // res/values/foo.xml -> foo.arsc
+      return filename.substring(0, periodIndex) + "".arsc"";
     }
 
     private void compile(","Throw contextual error when compiling value xmls with > 1 period in filename with aapt2 , instead of just failing with \"" < file > . arsc . flat does not exist after aapt2 ran \"" : .","""Improve aapt2 filename interpolation for ResourceCompiler""

or 

""Enhance ResourceCompiler to handle multiple periods in aapt2 filenames""

or 

""Fix and improve aapt2 filename interpolation in ResourceCompiler""

These commit messages are short and descriptive, indicating the main change made in the commit.","""Improve ResourceCompiler's handling of AAPT2 filenames""","""Update ResourceCompiler to throw error for values resource XMLs with multiple periods in filename""

Explanation:
The commit updates the `interpolateAapt2Filename` method in the `ResourceCompiler` class to throw an `IllegalArgumentException` when the filename of a values resource XML contains multiple periods. The error message explains that aapt2 does not support compiling resource XMLs with multiple periods in the filename. The change affects only values resource XMLs and does not affect other resource types. The commit message should reflect this change and provide a brief explanation of the issue and the solution.","""Ensure aapt2 compiles resource XMLs correctly; throw error for multiple periods in values filenames.""",Model 2
"diff --git a/core/src/processing/core/PMatrix3D.java b/core/src/processing/core/PMatrix3D.java
index 2840d4ec1..4732ed6eb 100644
--- a/core/src/processing/core/PMatrix3D.java
+++ b/core/src/processing/core/PMatrix3D.java
@@ -229,7 +229,19 @@ public final class PMatrix3D implements PMatrix /*, PConstants*/ {
 
 
   public void rotate(float angle, float v0, float v1, float v2) {
-    // TODO should make sure this vector is normalized
+    float norm2 = v0 * v0 + v1 * v1 + v2 * v2;
+    if (norm2 < PConstants.EPSILON) {
+      // The vector is zero, cannot apply rotation.
+      return;
+    }    
+    
+    if (Math.abs(norm2 - 1) > PConstants.EPSILON) {
+      // The rotation vector is not normalized.
+      float norm = PApplet.sqrt(norm2);
+      v0 /= norm;
+      v1 /= norm;
+      v2 /= norm;
+    } 
 
     float c = cos(angle);
     float s = sin(angle);
diff --git a/java/libraries/opengl/src/processing/opengl/PGL.java b/java/libraries/opengl/src/processing/opengl/PGL.java
index 59d01b93b..76be3eb24 100644
--- a/java/libraries/opengl/src/processing/opengl/PGL.java
+++ b/java/libraries/opengl/src/processing/opengl/PGL.java
@@ -1135,14 +1135,14 @@ public class PGL {
 
   
   public class Context {
-    protected GLContext context;
+    protected GLContext glContext;
 
     Context() {
-      context = null;    
+      glContext = null;    
     }
     
     Context(GLContext context) {
-      this.context = context;
+      glContext = context;
     }
 
     boolean current() {
@@ -1150,20 +1150,20 @@ public class PGL {
     }    
     
     boolean equal(GLContext context) {
-      if (this.context == null || context == null) {
+      if (glContext == null || context == null) {
         // A null context means a still non-created resource,
         // so it is considered equal to the argument.
         return true; 
       } else {        
-        return this.context.hashCode() == context.hashCode();
+        return glContext.hashCode() == context.hashCode();
       }
     }
     
     int code() {
-      if (context == null) {
+      if (glContext == null) {
         return -1;
       } else {
-        return context.hashCode();
+        return glContext.hashCode();
       }
     }
   }
diff --git a/java/libraries/opengl/src/processing/opengl/PGraphicsOpenGL.java b/java/libraries/opengl/src/processing/opengl/PGraphicsOpenGL.java
index 7e764b095..4eae32c9a 100644
--- a/java/libraries/opengl/src/processing/opengl/PGraphicsOpenGL.java
+++ b/java/libraries/opengl/src/processing/opengl/PGraphicsOpenGL.java
@@ -1429,8 +1429,8 @@ public class PGraphicsOpenGL extends PGraphics {
       } else {
         setFramebuffer(offscreenFramebuffer);
       }
-      pgl.glDrawBuffer(PGL.GL_COLOR_ATTACHMENT0);
       pgl.updateOffscreen(pg.pgl);
+      pgl.glDrawBuffer(PGL.GL_COLOR_ATTACHMENT0);      
     }
 
     // We are ready to go!
@@ -3159,14 +3159,12 @@ public class PGraphicsOpenGL extends PGraphics {
       flush();
     }
 
-    modelview.rotate(angle, v0, v1, v2);
-    invRotate(modelviewInv, angle, v0, v1, v2);
-    calcProjmodelview(); // Possibly cheaper than doing projmodelview.rotate()
-  }
-
-
-  static private void invRotate(PMatrix3D matrix, float angle, float v0, float v1, float v2) {
     float norm2 = v0 * v0 + v1 * v1 + v2 * v2;
+    if (norm2 < EPSILON) {
+      // The vector is zero, cannot apply rotation.
+      return;
+    }    
+    
     if (Math.abs(norm2 - 1) > EPSILON) {
       // The rotation vector is not normalized.
       float norm = PApplet.sqrt(norm2);
@@ -3175,6 +3173,13 @@ public class PGraphicsOpenGL extends PGraphics {
       v2 /= norm;
     }    
     
+    modelview.rotate(angle, v0, v1, v2);
+    invRotate(modelviewInv, angle, v0, v1, v2);
+    calcProjmodelview(); // Possibly cheaper than doing projmodelview.rotate()
+  }
+
+
+  static private void invRotate(PMatrix3D matrix, float angle, float v0, float v1, float v2) {
     float c = PApplet.cos(-angle);
     float s = PApplet.sin(-angle);
     float t = 1.0f - c;
@@ -5010,10 +5015,10 @@ public class PGraphicsOpenGL extends PGraphics {
     // Getting the context and capabilities from the main renderer.
     pg = (PGraphicsOpenGL)parent.g;
     pgl.initOffscreenSurface(pg.pgl);
-
     pgl.updateOffscreen(pg.pgl);
+    
     loadTextureImpl(BILINEAR);
-
+    
     // In case of reinitialization (for example, when the smooth level
     // is changed), we make sure that all the OpenGL resources associated
     // to the surface are released by calling delete().","rotate ( ) check for zero vectors , fixed naming error in PGL . Context class","""Fixed PMatrix3D rotation to normalize vector and added null checks for GLContext. Also, renamed 'context' to 'glContext' in PGL.Context for clarity.""","""Fixed vector normalization and rotation in PMatrix3D and PGraphicsOpenGL to prevent division by zero and ensure correct rotation calculations.""","It appears you're working with some code changes in Java, specifically in the Processing core and OpenGL libraries. Here's a summary of the changes you've made:

1. In `PMatrix3D.java`, you've added a check to ensure the rotation vector is not zero and normalized before applying the rotation. If the vector is zero, the rotation function returns without doing anything. If the vector is not normalized, it is normalized before the rotation is applied.

2. In `PGL.java`, you've renamed `context` to `glContext` in the `Context` class and updated all references to this variable accordingly.

3. In `PGraphicsOpenGL.java`, you've added a check to ensure the rotation vector is not zero before applying the rotation in the `rotate()` function. If the vector is zero, the function returns without doing anything. You've also moved the rotation code into this function from a separate `invRotate()` function.

These changes seem to be aimed at improving the robustness of the code by adding checks for edge cases and normalizing vectors before using them in rotations. The renaming in `PGL.java` might be for clarity or consistency with other code.

As for the commit message, it could be something like: ""Added checks for zero and non-normalized rotation vectors in `PMatrix3D` and `PGraphicsOpenGL`. Renamed `context` to `glContext` in `PGL` for clarity.""","""Normalize rotation vectors in PMatrix3D and correct draw buffer settings and context handling in PGraphicsOpenGL for OpenGL.""",Model 4
"diff --git a/litho-core/src/main/java/com/facebook/litho/LithoView.java b/litho-core/src/main/java/com/facebook/litho/LithoView.java
index b081e6c034..5e734bd599 100644
--- a/litho-core/src/main/java/com/facebook/litho/LithoView.java
+++ b/litho-core/src/main/java/com/facebook/litho/LithoView.java
@@ -23,6 +23,7 @@ import static com.facebook.litho.ThreadUtils.assertMainThread;
 import android.content.Context;
 import android.graphics.Canvas;
 import android.graphics.Rect;
+import android.os.Build;
 import android.util.AttributeSet;
 import android.view.View;
 import android.view.ViewGroup;
@@ -47,6 +48,7 @@ public class LithoView extends Host {
   public static final String ZERO_HEIGHT_LOG = ""LithoView:0-height"";
   public static final String SET_ALREADY_ATTACHED_COMPONENT_TREE =
       ""LithoView:SetAlreadyAttachedComponentTree"";
+  private static final int TOO_BIG_TEXTURE_SIZE = 4096;
   private boolean mIsMountStateDirty;
   private final boolean mUseExtensions;
   private final @Nullable MountDelegateTarget mMountDelegateTarget;
@@ -449,6 +451,25 @@ public class LithoView extends Host {
             ""Trying to layout a LithoView holding onto a released ComponentTree"");
       }
 
+      if (bottom - top >= TOO_BIG_TEXTURE_SIZE || right - left >= TOO_BIG_TEXTURE_SIZE) {
+        if (isDeviceThatCantHandleTooBigTextures()) {
+          ComponentsReporter.emitMessage(
+              ComponentsReporter.LogLevel.ERROR,
+              ""TextureTooBig"",
+              ""LithoView has measured greater than ""
+                  + TOO_BIG_TEXTURE_SIZE
+                  + "" in one dimension. Size: ""
+                  + (right - left)
+                  + ""x""
+                  + (bottom - top)
+                  + "", component: ""
+                  + (mComponentTree.getRoot() != null
+                      ? mComponentTree.getRoot().getSimpleName()
+                      : null),
+              100);
+        }
+      }
+
       if (mDoMeasureInLayout || mComponentTree.getMainThreadLayoutState() == null) {
         final int widthWithoutPadding =
             Math.max(0, right - left - getPaddingRight() - getPaddingLeft());
@@ -1327,6 +1348,20 @@ public class LithoView extends Host {
     forceRelayout();
   }
 
+  private static boolean isDeviceThatCantHandleTooBigTextures() {
+    switch (Build.MODEL) {
+      case ""SM-J610F"":
+   ",Add soft error for large LithoViews .,"""Add warning for devices that can't handle large textures in LithoView""","""Added check for too big textures and device-specific handling""","""Added check for too big textures and logging for devices that can't handle them""

The code change adds a new constant `TOO_BIG_TEXTURE_SIZE` and checks if the measured dimensions of the LithoView are greater than this value. If they are, and the device is one that can't handle such large textures, an error message is logged. The `isDeviceThatCantHandleTooBigTextures` method is also added, which currently only checks if the device model is ""SM-J610F"".",Add check for devices handling large textures in LithoView layout phase.,Model 2
"diff --git a/.gitignore b/.gitignore
index 4f1483bcee..94e42a33fa 100644
--- a/.gitignore
+++ b/.gitignore
@@ -17,6 +17,7 @@ src/com/facebook/buck/intellij/ideabuck/third-party/*.iml
 /.buckd
 /.buckjavaargs.local
 /.bucklogging.local.properties
+.buckversion
 .fakebuckversion
 /.nobuckcheck
 ","Revert \"" [ buck ] Buck to have . buckversion \"" .","""Add .buckversion to .gitignore""",Added .buckversion to .gitignore.,"""Added .buckversion to .gitignore""",Add .buckversion to .gitignore to ignore Buck version configuration files.,Model 1
"diff --git a/searchlib/src/vespa/searchlib/datastore/buffer_type.h b/searchlib/src/vespa/searchlib/datastore/buffer_type.h
index d937a60209b..b89aaa1bf84 100644
--- a/searchlib/src/vespa/searchlib/datastore/buffer_type.h
+++ b/searchlib/src/vespa/searchlib/datastore/buffer_type.h
@@ -2,7 +2,7 @@
 
 #pragma once
 
-#include <assert.h>
+#include <cassert>
 #include <cstdint>
 #include <sys/types.h>
 
diff --git a/searchlib/src/vespa/searchlib/datastore/bufferstate.h b/searchlib/src/vespa/searchlib/datastore/bufferstate.h
index cd765b22a40..173d74b9e63 100644
--- a/searchlib/src/vespa/searchlib/datastore/bufferstate.h
+++ b/searchlib/src/vespa/searchlib/datastore/bufferstate.h
@@ -2,14 +2,11 @@
 
 #pragma once
 
-#include <vector>
-#include <deque>
-#include <vespa/vespalib/util/alloc.h>
-#include <vespa/vespalib/util/array.h>
-
 #include ""buffer_type.h""
 #include ""entryref.h""
 #include <vespa/vespalib/util/generationhandler.h>
+#include <vespa/vespalib/util/alloc.h>
+#include <vespa/vespalib/util/array.h>
 
 namespace search {
 namespace datastore {
@@ -40,24 +37,24 @@ public:
     };
 
 private:
-    size_t _usedElems;
-    size_t _allocElems;
-    uint64_t _deadElems;
-    State _state;
-    bool  _disableElemHoldList;
-    uint64_t _holdElems;
+    size_t        _usedElems;
+    size_t        _allocElems;
+    uint64_t      _deadElems;
+    State         _state;
+    bool          _disableElemHoldList;
+    uint64_t      _holdElems;
     // Number of bytes that are heap allocated by elements that are stored in this buffer.
     // For simple types this is 0.
-    size_t _extraUsedBytes;
+    size_t        _extraUsedBytes;
     // Number of bytes that are heap allocated by elements that are stored in this buffer and is now on hold.
     // For simple types this is 0.
-    size_t _extraHoldBytes;
-    FreeList _freeList;
+    size_t        _extraHoldBytes;
+    FreeList      _freeList;
     FreeListList *_freeListList;	// non-NULL if free lists are enabled
 
     // NULL pointers if not on circular list of buffer states with free elems
-    BufferState *_nextHasFree;
-    BufferState *_prevHasFree;
+    BufferState    *_nextHasFree;
+    BufferState    *_prevHasFree;
 
     BufferTypeBase *_typeHandler;
     uint32_t        _typeId;
@@ -83,9 +80,8 @@ public:
      * @param sizeNeeded	Number of elements needed to be free
      * @param buffer		start of buffer.
      */
-    void
-    onActive(uint32_t bufferId, uint32_t typeId, BufferTypeBase *typeHandler,
-             size_t sizeNeeded, void *&buffer);
+    void onActive(uint32_t bufferId, uint32_t typeId, BufferTypeBase *typeHandler,
+                  size_t sizeNeeded, void *&buffer);
 
     /**
      * Transition from ACTIVE to HOLD state.
diff --git a/searchlib/src/vespa/searchlib/datastore/datastore.hpp b/searchlib/src/vespa/searchlib/datastore/datastore.hpp
index 56db025c28c..f4d80795c87 100644
--- a/searchlib/src/vespa/searchlib/datastore/datastore.hpp
+++ b/searchlib/src/vespa/searchlib/datastore/datastore.hpp
@@ -30,7 +30,7 @@ void
 DataStoreT<RefT>::freeElem(EntryRef ref, uint64_t len)
 {
     RefType intRef(ref);
-    BufferState &state = _states[intRef.bufferId()];
+    BufferState &state = getBufferState(intRef.bufferId());
     if (state.isActive()) {
         if (state.freeListList() != NULL && len == state.getClusterSize()) {
             if (state.freeList().empty()) {
@@ -54,7 +54,7 @@ DataStoreT<RefT>::holdElem(EntryRef ref, uint64_t len, size_t extraBytes)
 {
     RefType intRef(ref);
     uint64_t alignedLen = RefType::align(len);
-    BufferState &state = _states[intRef.bufferId()];
+    BufferState &state = getBufferState(intRef.bufferId());
     assert(state.isActive());
     if (state.hasDisabledElemHoldList()) {
         state.incDeadElems(alignedLen);
@@ -79,7 +79,7 @@ DataStoreT<RefT>::trimElemHoldList(generation_t usedGen)
         if (static_cast<sgeneration_t>(it->_generation - usedGen) >= 0)
             break;
         RefType intRef(it->_ref);
-        BufferState &state = _states[intRef.bufferId()];
+        BufferState &state = getBufferState(intRef.bufferId());
         freeElem(it->_ref, it->_len);
         state.decHoldElems(it->_len);
         ++freed;
@@ -100,7 +100,7 @@ DataStoreT<RefT>::clearElemHoldList(void)
     ElemHold2List::iterator ite(elemHold2List.end());
     for (; it != ite; ++it) {
         RefType intRef(it->_ref);
-        BufferState &state = _states[intRef.bufferId()];
+        BufferState &state = getBufferState(intRef.bufferId());
         freeElem(it->_ref, it->_len);
         state.decHoldElems(it->_len);
     }
diff --git a/searchlib/src/vespa/searchlib/datastore/datastorebase.cpp b/searchlib/src/vespa/searchlib/datastore/datastorebase.cpp
index 5a99db4c305..e73dcb2d43a 100644
--- a/searchlib/src/vespa/searchlib/datastore/datastorebase.cpp
+++ b/searchlib/src/vespa/searchlib/datastore/datastorebase.cpp
@@ -75,9 +75,9 @@ public:
 };
 
 
-DataStoreBase::DataStoreBase(uint32_t numBuffers,
-                             size_t maxClusters)
+DataStoreBase::DataStoreBase(uint32_t numBuffers, size_t maxClusters)
     : _buffers(numBuffers),
+      _typeIds(numBuffers),
       _activeBufferIds(),
       _states(numBuffers),
       _typeHandlers(),
@@ -160,18 +160,6 @@ DataStoreBase::addType(BufferTypeBase *typeHandler)
     return typeId;
 }
 
-uint32_t
-DataStoreBase::getNumActiveBuffers() const
-{
-    uint32_t result = 0;
-    for (const auto &state : _states) {
-        if (state.isActive()) {
-            ++result;
-        }
-    }
-    return result;
-}
-
 void
 DataStoreBase::transferElemHoldList(generation_t generation)
 {
@@ -373,8 +361,7 @@ DataStoreBase::getAddressSpaceUsage() const
 }
 
 void
-DataStoreBase::onActive(uint32_t bufferId, uint32_t typeId,
-                        size_t sizeNeeded)
+DataStoreBase::onActive(uint32_t bufferId, uint32_t typeId, size_t sizeNeeded)
 {
     assert(typeId < _typeHandlers.size());
     assert(bufferId < _numBuffers);
diff --git a/searchlib/src/vespa/searchlib/datastore/datastorebase.h b/searchlib/src/vespa/searchlib/datastore/datastorebase.h
index ed28cf0fa8c..c6aa098cb9f 100644
--- a/searchlib/src/vespa/searchlib/datastore/datastorebase.h
+++ b/searchlib/src/vespa/searchlib/datastore/datastorebase.h
@@ -7,6 +7,7 @@
 #include <vespa/searchlib/util/memoryusage.h>
 #include <vespa/searchlib/common/address_space.h>
 #include <vector>
+#include <deque>
 
 namespace search {
 namespace datastore {
@@ -36,6 +37,9 @@ protected:
     typedef vespalib::GenerationHandler::sgeneration_t sgeneration_t;
 
     std::vector<void *>   _buffers; // For fast mapping with known types
+private:
+    std::vector<uint32_t> _typeIds; // Cached,compact access to frequently used typeId
+protected:
     std::vector<uint32_t> _activeBufferIds; // typeId -> active buffer
 
     // Hold list at freeze, when knowing how long elements must be held
@@ -121,8 +125,9 @@ public:
         }
     };
 
-protected:
+private:
     std::vector<BufferState> _states;
+protected:
     std::vector<BufferTypeBase *> _typeHandlers; // TypeId -> handler
 
     std::vector<BufferState::FreeListList> _freeListLists;
@@ -132,8 +137,8 @@ protected:
     ElemHold1List _elemHold1List;
     ElemHold2List _elemHold2List;
 
-    uint32_t _numBuffers;
-    size_t _maxClusters;
+    const uint32_t _numBuffers;
+    const size_t   _maxClusters;
 
     vespalib::GenerationHolder _genHolder;
 
@@ -220,15 +225,9 @@ public:
      * Get active buffer id for the given type id.
      */
     uint32_t getActiveBufferId(uint32_t typeId) const { return _activeBufferIds[typeId]; }
-
     const BufferState &getBufferState(uint32_t bufferId) const { return _states[bufferId]; }
-
     BufferState &getBufferState(uint32_t bufferId) { return _states[bufferId]; }
-
     uint32_t getNumBuffers() const { return _numBuffers; }
-
-    uint32_t getNumActiveBuffers() const;
-
     bool hasElemHold1() const { return !_elemHold1List.empty(); }
 
     /**",Align code and GC some unused code .,"""Refactor DataStoreBase and BufferState classes for improved code organization and readability""","The commit message should be:

""Replace assert.h with cassert, and add includes for deque and generationhandler""

However, this commit message seems to be too specific and doesn't capture the full scope of the changes. A more general commit message could be:

""Refactor BufferState and DataStoreBase to improve code organization and readability""

Or, if you want to focus on the changes that were made:

""Improve BufferState and DataStoreBase to use more modern C++ features and improve performance""

Or, if you want to focus on the bug fixes:

""Fix issues with BufferState and DataStoreBase, including incorrect usage of assert and missing includes""

But the most suitable commit message would be:

""Refactor BufferState and DataStoreBase to improve code organization and readability""

This commit message is clear, concise, and accurately reflects the changes made in the commit.","It seems like you're sharing changes between two versions of a C++ codebase. The changes include:

1. Including `<cassert>` instead of `<assert.h>` in `buffer_type.h`.
2. Reordering and reformatting some includes in `bufferstate.h`.
3. Changing the style of member variable declarations in `BufferState` class in `bufferstate.h`.
4. Removing the `DataStoreBase::getNumActiveBuffers()` function and some other changes in `datastorebase.cpp` and `datastorebase.h`.

However, your message got cut off at the end, so I'm not sure what exactly you need help with. If you have any questions about these changes or need help with something else, please provide more details.",Refactor includes and improve code consistency and readability in the DataStore implementation.,Model 2
"diff --git a/core/ktx/src/androidTest/java/androidx/content/ContentValuesTest.kt b/core/ktx/src/androidTest/java/androidx/content/ContentValuesTest.kt
new file mode 100644
index 00000000000..ee5eea36385
--- /dev/null
+++ b/core/ktx/src/androidTest/java/androidx/content/ContentValuesTest.kt
@@ -0,0 +1,58 @@
+/*
+ * Copyright (C) 2018 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *       http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package androidx.content
+
+import androidx.assertThrows
+import org.junit.Assert.assertArrayEquals
+import org.junit.Assert.assertEquals
+import org.junit.Assert.assertNull
+import org.junit.Test
+import java.util.concurrent.atomic.AtomicInteger
+
+class ContentValuesTest {
+    @Test fun valuesOfValid() {
+        val values = contentValuesOf(
+                ""null"" to null,
+                ""string"" to ""string"",
+                ""byte"" to 1.toByte(),
+                ""short"" to 1.toShort(),
+                ""int"" to 1,
+                ""long"" to 1L,
+                ""float"" to 1f,
+                ""double"" to 1.0,
+                ""boolean"" to true,
+                ""byteArray"" to byteArrayOf()
+        )
+        assertEquals(10, values.size())
+        assertNull(values.get(""null""))
+        assertEquals(""string"", values.get(""string""))
+        assertEquals(1.toByte(), values.get(""byte""))
+        assertEquals(1.toShort(), values.get(""short""))
+        assertEquals(1, values.get(""int""))
+        assertEquals(1L, values.get(""long""))
+        assertEquals(1f, values.get(""float""))
+        assertEquals(1.0, values.get(""double""))
+        assertEquals(true, values.get(""boolean""))
+        assertArrayEquals(byteArrayOf(), values.get(""byteArray"") as ByteArray)
+    }
+
+    @Test fun valuesOfInvalid() {
+        assertThrows<IllegalArgumentException> {
+            contentValuesOf(""nope"" to AtomicInteger(1))
+        }.hasMessageThat().isEqualTo(""Illegal value type java.util.concurrent.atomic.AtomicInteger for key \""nope\"""")
+    }
+}
diff --git a/core/ktx/src/main/java/androidx/content/ContentValues.kt b/core/ktx/src/main/java/androidx/content/ContentValues.kt
new file mode 100644
index 00000000000..41b6f203c64
--- /dev/null
+++ b/core/ktx/src/main/java/androidx/content/ContentValues.kt
@@ -0,0 +1,41 @@
+/*
+ * Copyright (C) 2018 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *       http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package androidx.content
+
+import android.content.ContentValues
+
+/** Returns a new [ContentValues] with the given key/value pairs as elements. */
+fun contentValuesOf(vararg pairs: Pair<String, Any?>) = ContentValues(pairs.size).apply {
+    for ((key, value) in pairs) {
+        when (value) {
+            null -> putNull(key)
+            is String -> put(key, value)
+            is Int -> put(key, value)
+            is Long -> put(key, value)
+            is Boolean -> put(key, value)
+            is Float -> put(key, value)
+            is Double -> put(key, value)
+            is ByteArray -> put(key, value)
+            is Byte -> put(key, value)
+            is Short -> put(key, value)
+            else -> {
+                val valueType = value.javaClass.canonicalName
+                throw IllegalArgumentException(""Illegal value type $valueType for key \""$key\"""")
+            }
+        }
+    }
+}",Add ContentValues factory method from pairs .,"""Added ContentValues extension function and test""","""Add ContentValues and ContentValuesTest classes for testing and creating ContentValues instances""","""Add ContentValuesTest.kt and ContentValues.kt to core/ktx""

This commit adds two new files to the `core/ktx` directory: `ContentValuesTest.kt` and `ContentValues.kt`.

`ContentValuesTest.kt` contains two tests for the `contentValuesOf` function:

* `valuesOfValid` tests that the function correctly creates a `ContentValues` object with the expected key-value pairs.
* `valuesOfInvalid` tests that the function throws an `IllegalArgumentException` when given an invalid value type.

`ContentValues.kt` contains the implementation of the `contentValuesOf` function, which returns a new `ContentValues` object with the given key-value pairs as elements. The function takes a vararg of `Pair<String, Any?>` and uses a `when` statement to determine how to add each pair to the `ContentValues` object. If the value is not a supported type, an `IllegalArgumentException` is thrown.","""Add ContentValues extension function and tests to handle various key/value pairs with improved type safety.""",Model 3
"diff --git a/core/src/main/java/com/orientechnologies/orient/core/sql/executor/GetValueFromIndexEntryStep.java b/core/src/main/java/com/orientechnologies/orient/core/sql/executor/GetValueFromIndexEntryStep.java
index edde63476a..e087e8d3ad 100644
--- a/core/src/main/java/com/orientechnologies/orient/core/sql/executor/GetValueFromIndexEntryStep.java
+++ b/core/src/main/java/com/orientechnologies/orient/core/sql/executor/GetValueFromIndexEntryStep.java
@@ -5,8 +5,10 @@ import com.orientechnologies.orient.core.command.OCommandContext;
 import com.orientechnologies.orient.core.db.record.OIdentifiable;
 import com.orientechnologies.orient.core.id.ORID;
 
+import java.util.Arrays;
 import java.util.Map;
 import java.util.Optional;
+import java.util.stream.Collectors;
 
 /**
  * Created by luigidellaquila on 16/03/17.
@@ -161,6 +163,13 @@ public class GetValueFromIndexEntryStep extends AbstractExecutionStep {
     if (profilingEnabled) {
       result += "" ("" + getCostFormatted() + "")"";
     }
+    if (filterClusterIds != null) {
+      result += ""\n"";
+      result += spaces;
+      result += ""  filter clusters ["";
+      result += Arrays.asList(filterClusterIds).stream().map(x -> """" + x).collect(Collectors.joining("",""));
+      result += ""]"";
+    }
     return result;
   }
 ",Add information to execution plan toString ( ) ( filter clusters on index search ),"""Added filter cluster IDs to GetValueFromIndexEntryStep debug output""","""Added filtering of cluster IDs to GetValueFromIndexEntryStep output""","""Added cluster filter information to GetValueFromIndexEntryStep's toString method""

This commit appears to add a new section to the toString method of the GetValueFromIndexEntryStep class, which displays the filterClusterIds array as a comma-separated list enclosed in square brackets. This change would be useful for debugging or logging purposes, as it provides more information about the state of the object.",Add logging of filterClusterIds to step description in GetValueFromIndexEntryStep.,Model 1
"diff --git a/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/AvroReader.java b/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/AvroReader.java
index cf51cc7344..92c3492e21 100644
--- a/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/AvroReader.java
+++ b/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/AvroReader.java
@@ -28,6 +28,7 @@ import org.apache.avro.file.DataFileReader;
 import org.apache.avro.file.SeekableInput;
 import org.apache.avro.io.DatumReader;
 
+import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.nio.channels.ReadableByteChannel;
@@ -70,16 +71,20 @@ public class AvroReader<T> extends Reader<WindowedValue<T>> {
   public ReaderIterator<WindowedValue<T>> iterator(DatumReader<T> datumReader) throws IOException {
     IOChannelFactory factory = IOChannelUtils.getFactory(filename);
     Collection<String> inputs = factory.match(filename);
+    if (inputs.isEmpty()) {
+      throw new FileNotFoundException(""No match for file pattern '"" + filename + ""'"");
+    }
 
     if (inputs.size() == 1) {
       String input = inputs.iterator().next();
       ReadableByteChannel reader = factory.open(input);
       return new AvroFileIterator(datumReader, input, reader, startPosition, endPosition);
-
     } else {
       if (startPosition != null || endPosition != null) {
-        throw new UnsupportedOperationException(
-            ""Unable to apply range limits to multiple-input stream: "" + filename);
+        throw new IllegalArgumentException(
+            ""Offset range specified: ["" + startPosition + "", "" + endPosition + ""), so ""
+            + ""an exact filename was expected, but more than 1 file matched \"""" + filename
+            + ""\"" (total "" + inputs.size() + ""): apparently a filepattern was given."");
       }
       return new AvroFileMultiIterator(datumReader, factory, inputs.iterator());
     }
diff --git a/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/FileBasedReader.java b/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/FileBasedReader.java
index d9e8bd2ab0..f55165c4e5 100644
--- a/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/FileBasedReader.java
+++ b/sdk/src/main/java/com/google/cloud/dataflow/sdk/runners/worker/FileBasedReader.java
@@ -35,6 +35,7 @@ import org.slf4j.LoggerFactory;
 
 import java.io.BufferedInputStream;
 import java.io.ByteArrayOutputStream;
+import java.io.FileNotFoundException;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.PushbackInputStream;
@@ -98,13 +99,15 @@ public abstract class FileBasedReader<T> extends Reader<T> {
     IOChannelFactory factory = IOChannelUtils.getFactory(filename);
     Collection<String> inputs = factory.match(filename);
     if (inputs.isEmpty()) {
-      throw new IOException(""No match for file pattern '"" + filename + ""'"");
+      throw new FileNotFoundException(""No match for file pattern '"" + filename + ""'"");
     }
 
     if (startPosition != null || endPosition != null) {
       if (inputs.size() != 1) {
-        throw new UnsupportedOperationException(
-            ""Unable to apply range limits to multiple-input stream: "" + filename);
+        throw new IllegalArgumentException(
+            ""Offset range specified: ["" + startPosition + "", "" + endPosition + ""), so ""
+            + ""an exact filename was expected, but more than 1 file matched \"""" + filename
+            + ""\"" (total "" + inputs.size() + ""): apparently a filepattern was given."");
       }
 
       return newReaderIteratorForRangeInFile(factory, inputs.iterator().next(),
diff --git a/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/AvroReaderTest.java b/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/AvroReaderTest.java
index d5ea3b8266..957da90ab5 100644
--- a/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/AvroReaderTest.java
+++ b/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/AvroReaderTest.java
@@ -31,11 +31,13 @@ import org.apache.avro.io.DatumWriter;
 import org.junit.Assert;
 import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.ExpectedException;
 import org.junit.rules.TemporaryFolder;
 import org.junit.runner.RunWith;
 import org.junit.runners.JUnit4;
 
 import java.io.File;
+import java.io.FileNotFoundException;
 import java.io.OutputStream;
 import java.nio.channels.Channels;
 import java.util.ArrayList;
@@ -52,6 +54,8 @@ import javax.annotation.Nullable;
 public class AvroReaderTest {
   @Rule
   public TemporaryFolder tmpFolder = new TemporaryFolder();
+  @Rule
+  public ExpectedException expectedException = ExpectedException.none();
 
   private <T> void runTestRead(
       List<List<T>> elemsList, AvroCoder<T> coder, boolean requireExactMatch) throws Exception {
@@ -179,6 +183,25 @@ public class AvroReaderTest {
         false/* don't require exact match */);
   }
 
+  @Test
+  public void testErrorOnFileNotFound() throws Exception {
+    expectedException.expect(FileNotFoundException.class);
+    readElems(""file-not-found"", 0L, 100L, AvroCoder.of(String.class), new ArrayList<Integer>());
+  }
+
+  @Test
+  public void testErrorOnMultipleFiles() throws Exception {
+    File file1 = tmpFolder.newFile(""foo1.avro"");
+    File file2 = tmpFolder.newFile(""foo2.avro"");
+    Channels.newOutputStream(IOChannelUtils.create(file1.getPath(), MimeTypes.BINARY)).close();
+    Channels.newOutputStream(IOChannelUtils.create(file2.getPath(), MimeTypes.BINARY)).close();
+
+    expectedException.expect(IllegalArgumentException.class);
+    expectedException.expectMessage(""more than 1 file matched"");
+    readElems(new File(tmpFolder.getRoot(), ""*"").getPath(), 0L, 100L,
+        AvroCoder.of(String.class), new ArrayList<Integer>());
+  }
+
   // TODO: sharded filenames
   // TODO: reading from GCS
 }
diff --git a/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/TextReaderTest.java b/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/TextReaderTest.java
index ea7a3e5c37..857f0b66bd 100644
--- a/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/TextReaderTest.java
+++ b/sdk/src/test/java/com/google/cloud/dataflow/sdk/runners/worker/TextReaderTest.java
@@ -38,6 +38,8 @@ import com.google.cloud.dataflow.sdk.coders.TextualIntegerCoder;
 import com.google.cloud.dataflow.sdk.io.TextIO;
 import com.google.cloud.dataflow.sdk.io.TextIO.CompressionType;
 import com.google.cloud.dataflow.sdk.util.CoderUtils;
+import com.google.cloud.dataflow.sdk.util.IOChannelUtils;
+import com.google.cloud.dataflow.sdk.util.MimeTypes;
 import com.google.cloud.dataflow.sdk.util.common.worker.ExecutorTestUtils;
 import com.google.cloud.dataflow.sdk.util.common.worker.Reader;
 
@@ -45,15 +47,18 @@ import org.apache.commons.compress.compressors.bzip2.BZip2CompressorOutputStream
 import org.hamcrest.Matchers;
 import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.ExpectedException;
 import org.junit.rules.TemporaryFolder;
 import org.junit.runner.RunWith;
 import org.junit.runners.JUnit4;
 
 import java.io.File;
+import java.io.FileNotFoundException;
 import java.io.FileOutputStream;
 import java.io.IOException;
 import java.io.OutputStream;
 import java.io.PrintStream;
+import java.nio.channels.Channels;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.LinkedList;
@@ -79,6 +84,8 @@ public class TextReaderTest {
 
   @Rule
   public TemporaryFolder tmpFolder = new TemporaryFolder();
+  @Rule
+  public ExpectedException expectedException = ExpectedException.none();
 
   private File initTestFile() throws IOException {
     File tmpFile = tmpFolder.newFile();
@@ -651,6 +658,29 @@ public class TextReaderTest {
     }
   }
 
+  @Test
+  public void testErrorOnFileNotFound() throws Exception {
+    expectedException.expect(FileNotFoundException.class);
+    TextReader<String> textReader = new TextReader<>(
+        ""file-not-found"", true, 0L, 100L,
+        StringUtf8Coder.of(), TextIO.CompressionType.UNCOMPRESSED);
+    textReader.iterator();
+  }
+
+  @Test
+  public void testErrorOnMultipleFiles() throws Exception {
+    File file1 = tmpFolder.newFile(""foo1.avro"");
+    File file2 = tmpFolder.newFile(""foo2.avro"");
+    Channels.newOutputStream(IOChannelUtils.create(file1.getPath(), MimeTypes.BINARY)).close();
+    Channels.newOutputStream(IOChannelUtils.create(file2.getPath(), MimeTypes.BINARY)).close();
+    TextReader<String> textReader = new TextReader<>(
+        new File(tmpFolder.getRoot(), ""*"").getPath(), true, 0L, 100L,
+        StringUtf8Coder.of(), TextIO.CompressionType.UNCOMPRESSED);
+    expectedException.expect(IllegalArgumentException.class);
+    expectedException.expectMessage(""more than 1 file matched"");
+    textReader.iterator();
+  }
+
   // TODO: sharded filenames
   // TODO: reading from GCS
 }",Improves error messages in AvroReader and FileBasedReader when filepattern matches .,"""Improve error handling for file-based readers: throw FileNotFoundException when file not found and IllegalArgumentException when multiple files match a pattern.""","""Improved error handling for file not found and multiple file matches in Avro and Text readers""

Or, if you want to follow the conventional commit message format:

""fix: improved error handling for file not found and multiple file matches in Avro and Text readers""

This commit message accurately reflects the changes made in the code, which include:

* Adding `FileNotFoundException` to handle cases where a file is not found
* Improving error messages for cases where multiple files match a pattern
* Adding test cases to cover these scenarios

The commit message is concise and clear, making it easy for others to understand the purpose of the commit.","""Update AvroReader and FileBasedReader to throw FileNotFoundException and add tests for file not found and multiple files""

Explanation:

* In AvroReader.java and FileBasedReader.java, the code has been updated to throw FileNotFoundException instead of IOException when no match for the file pattern is found.
* In AvroReaderTest.java and TextReaderTest.java, new tests have been added to check for the FileNotFoundException when the file is not found and for IllegalArgumentException when multiple files match the file pattern but an exact filename was expected.
* Additionally, in FileBasedReader.java, the code has been updated to throw IllegalArgumentException when an offset range is specified but more than one file matches the file pattern. This is checked for in the new test added to TextReaderTest.java.",Add detailed exception handling for file not found and multiple file matches in AvroReader and FileBasedReader.,Model 2
"diff --git a/cli/ballerina-launcher/src/main/java/org/ballerinalang/launcher/Main.java b/cli/ballerina-launcher/src/main/java/org/ballerinalang/launcher/Main.java
index 7007f5522e9..27f92067323 100644
--- a/cli/ballerina-launcher/src/main/java/org/ballerinalang/launcher/Main.java
+++ b/cli/ballerina-launcher/src/main/java/org/ballerinalang/launcher/Main.java
@@ -323,15 +323,27 @@ public class Main {
          * @return  the index of the colon to split at
          */
         private int getSourceFunctionSplitIndex(Path sourceRootPath, String programArg) {
-            int indexOfColon = programArg.indexOf(COLON);
-            while (indexOfColon != -1) {
-                String potentialPath = programArg.substring(0, indexOfColon);
+            String[] programArgConstituents = programArg.split(COLON);
+            int index = programArgConstituents.length - 1;
+
+            String potentialFunction = programArgConstituents[index];
+            String potentialPath = programArg.replace(COLON.concat(potentialFunction), """");
+            if (Files.exists(sourceRootPath.resolve(potentialPath))) {
+                return potentialPath.length();
+            }
+            index--;
+
+            while (index != -1) {
+                potentialFunction = programArgConstituents[index].concat(COLON).concat(potentialFunction);
+                potentialPath = programArg.replace(COLON.concat(potentialFunction), """");
+
                 if (Files.exists(sourceRootPath.resolve(potentialPath))) {
-                    return indexOfColon;
+                    return potentialPath.length();
                 }
-                indexOfColon = programArg.indexOf(COLON, indexOfColon + 1);
+
+                index--;
             }
-            return indexOfColon;
+            return index;
         }
     }
 
diff --git a/tests/ballerina-tools-integration-test/src/test/java/org/ballerinalang/test/run/BalRunFunctionNegativeTestCase.java b/tests/ballerina-tools-integration-test/src/test/java/org/ballerinalang/test/run/BalRunFunctionNegativeTestCase.java
index dddf1fae665..9678c8a6d12 100644
--- a/tests/ballerina-tools-integration-test/src/test/java/org/ballerinalang/test/run/BalRunFunctionNegativeTestCase.java
+++ b/tests/ballerina-tools-integration-test/src/test/java/org/ballerinalang/test/run/BalRunFunctionNegativeTestCase.java
@@ -40,9 +40,9 @@ public class BalRunFunctionNegativeTestCase extends BaseTest {
     private String sourceRootPath = ""src/test/resources/run/file/"";
 
     @Test
-    public void testEmptyEntryFunctionName() throws BallerinaTestException {
+    public void testInvalidSourceArg() throws BallerinaTestException {
         String sourceArg = (new File(sourceRootPath + ""test_entry_function.bal"")).getAbsolutePath() + "":"";
-        LogLeecher errLogLeecher = new LogLeecher(""ballerina: expected function name after final ':'"",
+        LogLeecher errLogLeecher = new LogLeecher(""error: no ballerina source files found in module "" + sourceArg,
                 LeecherType.ERROR);
         balClient.runMain(sourceArg, new LogLeecher[]{errLogLeecher});
         errLogLeecher.waitForText(2000);
diff --git a/tests/ballerina-tools-integration-test/src/test/java/org/ballerinalang/test/run/BalxRunFunctionNegativeTestCase.java b/tests/ballerina-tools-integration-test/src/test/java/org/ballerinalang/test/run/BalxRunFunctionNegativeTestCase.java
index ae477da102b..7b2b5b84aa7 100644
--- a/tests/ballerina-tools-integration-test/src/test/java/org/ballerinalang/test/run/BalxRunFunctionNegativeTestCase.java
+++ b/tests/ballerina-tools-integration-test/src/test/java/org/ballerinalang/test/run/BalxRunFunctionNegativeTestCase.java
@@ -65,10 +65,10 @@ public class BalxRunFunctionNegativeTestCase extends BaseTest {
     }
 
     @Test
-    public void testEmptyEntryFunctionName() throws BallerinaTestException {
+    public void testInvalidSourceArg() throws BallerinaTestException {
         String sourceArg = balxPath + "":"";
-        LogLeecher errLogLeecher = new LogLeecher(""ballerina: expected function name after final ':'"",
-                LeecherType.ERROR);
+        LogLeecher errLogLeecher = new LogLeecher(""error: no ballerina source files found in module "" + balxPath +
+                                                          "":"", LeecherType.ERROR);
         balClient.runMain(sourceArg, new LogLeecher[]{errLogLeecher});
         errLogLeecher.waitForText(2000);
     }
diff --git a/tests/ballerina-tools-integration-test/src/test/java/org/ballerinalang/test/run/PkgRunFunctionNegativeTestCase.java b/tests/ballerina-tools-integration-test/src/test/java/org/ballerinalang/test/run/PkgRunFunctionNegativeTestCase.java
index bc0f716f050..3db4fbed311 100644
--- a/tests/ballerina-tools-integration-test/src/test/java/org/ballerinalang/test/run/PkgRunFunctionNegativeTestCase.java
+++ b/tests/ballerina-tools-integration-test/src/test/java/org/ballerinalang/test/run/PkgRunFunctionNegativeTestCase.java
@@ -40,10 +40,10 @@ public class PkgRunFunctionNegativeTestCase extends BaseTest {
     private String sourceRoot = (new File(""src/test/resources/run/package/"")).getAbsolutePath();
 
     @Test
-    public void testEmptyEntryFunctionName() throws BallerinaTestException {
+    public void testInvalidSourceArg() throws BallerinaTestException {
         String sourceArg = ""entry:"";
-        LogLeecher errLogLeecher = new LogLeecher(""ballerina: expected function name after final ':'"",
-                LeecherType.ERROR);
+        LogLeecher errLogLeecher = new LogLeecher(""error: no ballerina source files found in module "" +
+                   ",Improve split index identification,"""Fix source function split index logic and update test cases for invalid source args""","""Improve handling of invalid source arguments in Ballerina launcher and tests""","""Update Main.java and negative test cases for Ballerina launcher""

Explanation:
The changes in Main.java modify the logic for finding the split index in the program argument that contains the source path and function name. The changes in the negative test cases update the expected error messages for invalid source arguments.",Fix getSourceFunctionSplitIndex method and update test cases for handling invalid source arguments.,Model 1
"diff --git a/jdk/src/java.desktop/share/classes/javax/swing/text/html/HTMLDocument.java b/jdk/src/java.desktop/share/classes/javax/swing/text/html/HTMLDocument.java
index 1166f569728..a981e87f304 100644
--- a/jdk/src/java.desktop/share/classes/javax/swing/text/html/HTMLDocument.java
+++ b/jdk/src/java.desktop/share/classes/javax/swing/text/html/HTMLDocument.java
@@ -1400,8 +1400,13 @@ public void insertAfterEnd(Element elem, String htmlText) throws
             Element parent = elem.getParentElement();
 
             if (parent != null) {
+                // If we are going to insert the string into the body
+                // section, it is necessary to set the corrsponding flag.
+                if (HTML.Tag.BODY.name.equals(parent.getName())) {
+                    insertInBody = true;
+                }
                 int offset = elem.getEndOffset();
-                if (offset > getLength()) {
+                if (offset > (getLength() + 1)) {
                     offset--;
                 }
                 else if (elem.isLeaf() && getText(offset - 1, 1).
@@ -1409,6 +1414,10 @@ else if (elem.isLeaf() && getText(offset - 1, 1).
                     offset--;
                 }
                 insertHTML(parent, offset, htmlText, false);
+                // Cleanup the flag, if any.
+                if (insertInBody) {
+                    insertInBody = false;
+                }
             }
         }
     }
@@ -1846,6 +1855,11 @@ String getBaseTarget() {
 
     private static char[] NEWLINE;
 
+    /**
+     * Indicates that direct insertion to body section takes place.
+     */
+    private boolean insertInBody = false;
+
     /**
      * I18N property key.
      *
@@ -2610,7 +2624,9 @@ public void handleText(char[] data, int pos) {
                     // Assume content should be added.
                     foundInsertTag(false);
                     foundInsertTag = true;
-                    inParagraph = impliedP = true;
+                    // If content is added directly to the body, it should
+                    // be wrapped by p-implied.
+                    inParagraph = impliedP = !insertInBody;
                 }
                 if (data.length >= 1) {
                     addContent(data, 0, data.length);
diff --git a/jdk/test/javax/swing/text/html/HTMLDocument/8058120/bug8058120.java b/jdk/test/javax/swing/text/html/HTMLDocument/8058120/bug8058120.java
new file mode 100644
index 00000000000..2378fd2e334
--- /dev/null
+++ b/jdk/test/javax/swing/text/html/HTMLDocument/8058120/bug8058120.java
@@ -0,0 +1,109 @@
+/*
+ * Copyright (c) 2014, Oracle and/or its affiliates. All rights reserved.
+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
+ *
+ * This code is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License version 2 only, as
+ * published by the Free Software Foundation.
+ *
+ * This code is distributed in the hope that it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ * version 2 for more details (a copy is included in the LICENSE file that
+ * accompanied this code).
+ *
+ * You should have received a copy of the GNU General Public License version
+ * 2 along with this work; if not, write to the Free Software Foundation,
+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
+ * or visit www.oracle.com if you need additional information or have any
+ * questions.
+ */
+
+/* @test
+ * @bug 8058120
+ * @summary Rendering / caret errors with HTMLDocument
+ * @author Dmitry Markov
+ * @run main bug8058120
+ */
+
+import sun.awt.SunToolkit;
+
+import javax.swing.*;
+import javax.swing.text.Element;
+import javax.swing.text.html.HTML;
+import javax.swing.text.html.HTMLDocument;
+import javax.swing.text.html.HTMLEditorKit;
+import java.awt.*;
+
+public class bug8058120 {
+    private static SunToolkit toolkit = (SunToolkit) Toolkit.getDefaultToolkit();
+    private static HTMLDocument document = null;
+    private static final String text = ""<p id = 'ab'>ab</p>"";
+    private static final String textToInsert = ""c"";
+
+    public static void main(String[] args) {
+        SwingUtilities.invokeLater(new Runnable() {
+            @Override
+            public void run() {
+                createAndShowGUI();
+            }
+        });
+
+        toolkit.realSync();
+
+        SwingUtilities.invokeLater(new Runnable() {
+            @Override
+            public void run() {
+                try {
+                    document.insertAfterEnd(document.getElement(""ab""), textToInsert);
+                } catch (Exception ex) {
+                    throw new RuntimeException(ex);
+                }
+            }
+        });
+
+        toolkit.realSync();
+
+        SwingUtilities.invokeLater(new Runnable() {
+            @Override
+            public void run() {
+                Element parent = document.getElement(""ab"").getParentElement();
+                int count = parent.getElementCount();
+                if (count != 2) {
+                    throw new RuntimeException(""Test Failed! Unexpected Element count = ""+count);
+                }
+         ",Rendering / caret errors with HTMLDocument .,"""Fix for Bug 8058120: Rendering / caret errors with HTMLDocument""","""Fix rendering and caret errors with HTMLDocument by introducing a flag to track direct insertion into the body section.""","""Fixed rendering/caret errors with HTMLDocument in Swing (#8058120)""

This commit appears to address an issue with the `HTMLDocument` class in the Swing library, specifically related to inserting text into the body of an HTML document. The changes include adding a new flag `insertInBody` to track whether an insertion is happening directly in the body section, and updating the `handleText()` method to properly handle this case.

Additionally, a new test file has been added to verify the correct behavior of the `insertAfterEnd()` method when inserting content directly into the body of an HTML document. This test checks that the number of elements in the parent of the target element is correct after the insertion.

Based on these changes, a suitable commit message might be ""Fixed rendering/caret errors with HTMLDocument in Swing (#8058120)"". This message indicates that the commit is addressing a specific issue (#8058120) and provides a brief summary of the changes.",Fix rendering and caret errors by setting flag for direct body insertion and appropriately handling implied paragraph wrapping in HTMLDocument.,Model 2
"diff --git a/src/main/java/com/fasterxml/jackson/databind/deser/impl/BeanPropertyMap.java b/src/main/java/com/fasterxml/jackson/databind/deser/impl/BeanPropertyMap.java
index 9a8107208..6f1871557 100644
--- a/src/main/java/com/fasterxml/jackson/databind/deser/impl/BeanPropertyMap.java
+++ b/src/main/java/com/fasterxml/jackson/databind/deser/impl/BeanPropertyMap.java
@@ -533,7 +533,7 @@ public abstract class BeanPropertyMap
             // and allocate enough to contain primary/secondary, expand for spillovers as need be
             int alloc = size + (size>>1);
             String[] keys = new String[alloc];
-            SettableBeanProperty[] fieldHash = new SettableBeanProperty[alloc];
+            SettableBeanProperty[] propHash = new SettableBeanProperty[alloc];
             int spills = 0;
 
             for (SettableBeanProperty prop : props) {
@@ -555,15 +555,21 @@ public abstract class BeanPropertyMap
                         ++spills;
                         if (slot >= keys.length) {
                             keys = Arrays.copyOf(keys, keys.length + 4);
-                            fieldHash = Arrays.copyOf(fieldHash, fieldHash.length + 4);
+                            propHash = Arrays.copyOf(propHash, propHash.length + 4);
                         }
                     }
                 }
+//System.err.println("" add '""+key+"" at #""+slot+"" (hashed at ""+(key.hashCode() & _hashMask)+"")"");             
                 keys[slot] = key;
-                fieldHash[slot] = prop;
+                propHash[slot] = prop;
             }
+/*
+for (int i = 0; i < keys.length; ++i) {
+    System.err.printf(""#%02d: %s\n"", i, (keys[i] == null) ? ""-"" : keys[i]);
+}
+*/
             _keys = keys;
-            _propsHash = fieldHash;
+            _propsHash = propHash;
             _spillCount = spills;
         }
 
@@ -620,14 +626,15 @@ public abstract class BeanPropertyMap
             // If not, append
 
             int slot = key.hashCode() & _hashMask;
+            int hashSize = _hashMask+1;
 
             // primary slot not free?
             if (_keys[slot] != null) {
                 // secondary?
-                slot = _size + (slot >> 1);
+                slot = hashSize + (slot >> 1);
                 if (_keys[slot] != null) {
                     // ok, spill over.
-                    slot = _size + (_size >> 1) + _spillCount;
+            ",Fix the remaining problems with new BeanPropertyMap impl,"""Refactor BeanPropertyMap to use consistent variable naming""","""Renamed fieldHash to propHash in BeanPropertyMap to better reflect its purpose.""","""Fixed array index calculation for spillovers in BeanPropertyMap""

Explanation:
The change in the code is related to how the index for the spillover properties is calculated. In the original code, the index was calculated as `_size + (_size >> 1) + _spillCount`, but this could lead to incorrect index values if `_size` and `_spillCount` are not properly synchronized.

The updated code calculates the index as `hashSize + (slot >> 1)`, where `hashSize` is `_hashMask + 1`. This ensures that the index is always within the bounds of the `_propsHash` array, and avoids potential `ArrayIndexOutOfBoundsException`.

The comment at the end of the code seems to be a debugging print statement that was left in by mistake, and should be removed in the final commit.",Refactor variable names in `assign` method and fix hash slot calculations in `BeanPropertyMap.java`.,Model 4
"diff --git a/src/main/java/com/owncloud/android/db/ProviderMeta.java b/src/main/java/com/owncloud/android/db/ProviderMeta.java
index ce29ce0619..e7e6d11c64 100644
--- a/src/main/java/com/owncloud/android/db/ProviderMeta.java
+++ b/src/main/java/com/owncloud/android/db/ProviderMeta.java
@@ -35,7 +35,7 @@ import java.util.List;
  */
 public class ProviderMeta {
     public static final String DB_NAME = ""filelist"";
-    public static final int DB_VERSION = 60;
+    public static final int DB_VERSION = 61;
 
     private ProviderMeta() {
         // No instance
diff --git a/src/main/java/com/owncloud/android/providers/FileContentProvider.java b/src/main/java/com/owncloud/android/providers/FileContentProvider.java
index 2a54561626..c11c73c555 100644
--- a/src/main/java/com/owncloud/android/providers/FileContentProvider.java
+++ b/src/main/java/com/owncloud/android/providers/FileContentProvider.java
@@ -2288,6 +2288,23 @@ public class FileContentProvider extends ContentProvider {
             if (!upgraded) {
                 Log_OC.i(SQL, String.format(Locale.ENGLISH, UPGRADE_VERSION_MSG, oldVersion, newVersion));
             }
+
+            if (oldVersion < 61 && newVersion >= 61) {
+                Log_OC.i(SQL, ""Entering in the #61 reset eTag to force capability refresh"");
+                db.beginTransaction();
+                try {
+                    db.execSQL(""UPDATE capabilities SET etag = '' WHERE 1=1"");
+
+                    upgraded = true;
+                    db.setTransactionSuccessful();
+                } finally {
+                    db.endTransaction();
+            ","Reset eTag so that capability get parsed again , so status is set .","""Bump database version to 61 and reset eTag to force capability refresh""","""Update database version to 61 and reset etag for capabilities on upgrade""","""Bump database version to 61 and reset eTag to force capability refresh""

Explanation:
The first change is in the file `ProviderMeta.java`, where the database version is increased from 60 to 61. The second change is in the file `FileContentProvider.java`, where a new block of code is added to reset the eTag for all capabilities when upgrading from a database version lower than 61 to 61 or higher. The purpose of this change is to force a refresh of the capabilities. Therefore, a suitable commit message would be ""Bump database version to 61 and reset eTag to force capability refresh"".",Increase database version to 61 and reset eTag in capabilities to force capability refresh.,Model 1
"diff --git a/sdks/python/container/base_image_requirements.txt b/sdks/python/container/base_image_requirements.txt
index 49375dc31e..f3d9b86221 100644
--- a/sdks/python/container/base_image_requirements.txt
+++ b/sdks/python/container/base_image_requirements.txt
@@ -73,3 +73,4 @@ pymongo==3.9.0
 # Packages needed for testing.
 tenacity>=5.0.2
 pyhamcrest<2.0,>=1.9
+nose==1.3.7
diff --git a/sdks/python/container/license_scripts/dep_urls_py.yaml b/sdks/python/container/license_scripts/dep_urls_py.yaml
index 473674e7a9..4a2b6f3557 100644
--- a/sdks/python/container/license_scripts/dep_urls_py.yaml
+++ b/sdks/python/container/license_scripts/dep_urls_py.yaml
@@ -79,6 +79,8 @@ pip_dependencies:
     license: ""https://raw.githubusercontent.com/testing-cabal/mock/master/LICENSE.txt""
   monotonic:
     license: ""https://raw.githubusercontent.com/atdt/monotonic/master/LICENSE""
+  nose:
+      license: ""https://raw.githubusercontent.com/nose-devs/nose/master/lgpl.txt""
   numpy:
     license: ""https://raw.githubusercontent.com/numpy/numpy/master/LICENSE.txt""
   oauth2client:",Adds nose back under packages needed for testing .,"""Added nose 1.3.7 as a testing dependency""",Added nose to base image requirements and updated license information in dep_urls_py.yaml.,"The diff you provided suggests that the following changes have been made:

1. In the file `base_image_requirements.txt`, the package `nose==1.3.7` has been added to the list of dependencies.

2. In the file `dep_urls_py.yaml`, a new entry for `nose` has been added under `pip_dependencies`, with a link to its license.

Based on these changes, a suitable commit message could be:

""Added nose package and its license to base image requirements and dependency URLs respectively.""",Add 'nose' package to base_image_requirements.txt and its license URL to dep_urls_py.yaml for testing purposes.,Model 2
"diff --git a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezSessionState.java b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezSessionState.java
index e1a8041818..e5df2ec2d7 100644
--- a/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezSessionState.java
+++ b/ql/src/java/org/apache/hadoop/hive/ql/exec/tez/TezSessionState.java
@@ -315,7 +315,12 @@ private void openInternal(
       FutureTask<TezClient> sessionFuture = new FutureTask<>(new Callable<TezClient>() {
         @Override
         public TezClient call() throws Exception {
-          return startSessionAndContainers(session, conf, commonLocalResources, tezConfig, true);
+          try {
+            return startSessionAndContainers(session, conf, commonLocalResources, tezConfig, true);
+          } catch (Throwable t) {
+            LOG.error(""Failed to start Tez session"", t);
+            throw (t instanceof Exception) ? (Exception)t : new Exception(t);
+          }
         }
       });
       new Thread(sessionFuture, ""Tez session start thread"").start();
@@ -341,9 +346,7 @@ private TezClient startSessionAndContainers(TezClient session, HiveConf conf,
           session.preWarm(prewarmVertex);
         } catch (IOException ie) {
           if (!isOnThread && ie.getMessage().contains(""Interrupted while waiting"")) {
-            if (LOG.isDebugEnabled()) {
-              LOG.debug(""Hive Prewarm threw an exception "", ie);
-            }
+            LOG.warn(""Hive Prewarm threw an exception "", ie);
           } else {
             throw ie;
           }
@@ -483,11 +486,14 @@ public TezClient getSession() {
       try {
         session = sessionFuture.get();
       } catch (InterruptedException e) {
+        console.printInfo(""Interrupted while waiting for the session"");
         Thread.currentThread().interrupt();
         return null;
       } catch (ExecutionException e) {
+        console.printInfo(""Failed to get session"");
  ","add better logging for Tez session creation thread failures ( Sergey Shelukhin , reviewed by Siddharth Seth )","""Improve Tez session start error handling and logging""","""Improved error handling and logging in TezSessionState""","""Add error handling and logging to TezSessionState""

Explanation:

* The first change adds error handling and logging to the `call()` method of the `FutureTask` used to start a Tez session. If an exception is thrown while starting the session, it is logged and re-thrown as an `Exception`.
* The second change updates the log level for a specific exception thrown while pre-warming a Tez session from `DEBUG` to `WARN`.
* The third change adds console logging to the `getSession()` method to indicate when an interruption or execution exception occurs while waiting for the session to start.

These changes improve the robustness and diagnostic capabilities of the TezSessionState class.",Improve exception handling and logging in TezSessionState to provide clearer error messages and session startup feedback.,Model 1
